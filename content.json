{"meta":{"title":"黑风雅过吟","subtitle":"不积跬步无以至千里","description":null,"author":"Zhao Zhengkang","url":"http://yoursite.com/child"},"pages":[{"title":"about","date":"2019-05-23T07:59:58.000Z","updated":"2019-05-23T07:59:58.731Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/child/about/index.html","excerpt":"","text":""}],"posts":[{"title":"数据库-centos安装配置MySql8.0","slug":"数据库-centos安装配置MySql8.0","date":"2019-07-31T00:36:00.173Z","updated":"2019-07-31T01:43:48.415Z","comments":true,"path":"2019/07/31/数据库-centos安装配置MySql8.0/","link":"","permalink":"http://yoursite.com/child/2019/07/31/数据库-centos安装配置MySql8.0/","excerpt":"","text":"MySQL8.0和MySQL5.7具有众多不同之处，此处不述。这里，只简单讲讲在安装过程中遇到的问题之一和解决办法： MySQL8.0安装完成之后的默认密码是多少？如何修改初始密码？ 1 安装MySQL8.0 yum仓库下载MySQL： 1shell&gt; yum localinstall https://repo.mysql.com//mysql80-community-release-el7-1.noarch.rpm yum安装MySQL： 1shell&gt; yum install mysql-community-server 2 启动MySQL服务 启动MySQL服务的命令： 123shell&gt; service mysqld startStarting mysqld:[ OK ] 检查MySQL服务器的运行状态： 123456789101112131415shell&gt; sudo service mysqld status● mysqld.service - MySQL Server Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled) Active: active (running) since Sun 2018-06-03 18:31:51 CST; 6min ago Docs: man:mysqld(8) http://dev.mysql.com/doc/refman/en/using-systemd.html Process: 5281 ExecStartPre=/usr/bin/mysqld_pre_systemd (code=exited, status=0/SUCCESS) Main PID: 5299 (mysqld) Status: \"SERVER_OPERATING\" CGroup: /system.slice/mysqld.service └─5299 /usr/sbin/mysqldJun 03 18:31:50 &#123;your-server-name&#125; systemd[1]: Starting MySQL Server...Jun 03 18:31:51 &#123;your-server-name&#125; systemd[1]: Started MySQL Server. 以上信息表示MySQL服务启动成功。 3 MySQL默认密码和修改密码在启动MySQL服务的时候，主要会发生以下4件事 MySQL Server初始化并启动起来； MySQL的data文件夹中生成SSL证书和key文件； 密码验证组件被安装并且生效； 创建一个超级管用户‘root‘@’localhost‘。超级用户设置的密码被保存在错误日志文件中，可以通过以下命令查看： 123shell&gt; sudo grep 'temporary password' /var/log/mysqld.log2018-06-03T10:15:57.448920Z 5 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: 0xxXxxXx?xXX 通过默认密码登录MySQL服务器，并马上修改密码(强烈建议)！！！。 有些时候使用上面的筛选命令检索不到文件或内容，可以手动查看/var/log/mysqld.log文件获取初始密码。 用默认密码(0xxXxxXx?xXX)登录： 1shell&gt; mysql -uroot -p 修改密码： 1mysql&gt; ALTER USER 'root'@'localhost' IDENTIFIED BY 'your-password'; 4 设置允许远程连接在终端登录mysql之后查看是否允许远程访问： 1mysql -u root -p 12345mysql&gt; use mysqlReading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changed 12345678910mysql&gt; select host,user,plugin from user;+-----------+------------------+-----------------------+| host | user | plugin |+-----------+------------------+-----------------------+| localhost | mysql.infoschema | caching_sha2_password || localhost | mysql.session | caching_sha2_password || localhost | mysql.sys | caching_sha2_password || localhost | root | caching_sha2_password |+-----------+------------------+-----------------------+4 rows in set (0.00 sec) 可以看到最后一行root 用户的host为localhost，要远程访问，需要将它改成% 1234567891011121314mysql&gt; update user set host=&apos;%&apos; where user =&apos;root&apos;;Query OK, 1 row affected (0.07 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; select host,user,plugin from user;+-----------+------------------+-----------------------+| host | user | plugin |+-----------+------------------+-----------------------+| % | root | caching_sha2_password || localhost | mysql.infoschema | caching_sha2_password || localhost | mysql.session | caching_sha2_password || localhost | mysql.sys | caching_sha2_password |+-----------+------------------+-----------------------+4 rows in set (0.00 sec) 最后刷新权限 12mysql&gt; FLUSH PRIVILEGES;Query OK, 0 rows affected (0.10 sec)","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/child/tags/数据库/"}],"keywords":[]},{"title":"nio-入门篇-应用案例讲解","slug":"nio-入门篇-应用案例讲解","date":"2019-05-26T02:21:34.000Z","updated":"2019-06-09T12:14:33.240Z","comments":true,"path":"2019/05/26/nio-入门篇-应用案例讲解/","link":"","permalink":"http://yoursite.com/child/2019/05/26/nio-入门篇-应用案例讲解/","excerpt":"","text":"1. Buffer在channel中传输的是buffer中的数据，而不是buffer对象。 使用Buffer读写数据一般遵循以下四个步骤（buffer为读写主体）： 写入数据到Buffer 调用flip()方法 从Buffer中读取数据 调用clear()方法或者compact()方法 说明： 当向buffer写入数据时，buffer会记录下写了多少数据。一旦要读取数据，需要通过flip()方法将Buffer从写模式切换到读模式。在读模式下，可以读取之前写入到buffer的所有数据。 一旦读完了所有的数据，就需要清空缓冲区，让它可以再次被写入。有两种方式能清空缓冲区：调用clear()或compact()方法。clear()方法会清空整个缓冲区。compact()方法只会清除已经读过的数据。任何未读的数据都被移到缓冲区的起始处，新写入的数据将放到缓冲区未读数据的后面。1.1 Buffer抽象类Buffer抽象类中定义的常用方法： Buffer flip() flip方法将Buffer从写模式切换到读模式。调用flip()方法会将position设回0，并将limit设置成之前position的值。 Buffer rewind() 将position设回0，所以你可以重读Buffer中的所有数据。limit保持不变，仍然表示能从Buffer中读取多少个元素（byte、char等） int remaining() 返回position到limit之间的元素个数（未读出元素个数） boolean hasRemaining() 返回是否还有未读出的数据 boolean isReadOnly() 是否此buffer只能读出 Buffer mark() 可以标记Buffer中的一个特定position，之后可以通过调用Buffer.reset()方法恢复到这个position。 Buffer reset() 恢复到mark()标记的状态 Buffer clear() 重置position、limit、capacity和mark，从读模式转换成写模式 此外Buffer还声明了几个抽象方法如下，这些方法都是在Buffer的子类中定义的12345boolean hasArray();boolean isReadOnly();Object array();int arrayOffset();boolean isDirect(); 1.2 Buffer的类型Java NIO 有以下Buffer类型： ByteBuffer MappedByteBuffer CharBuffer DoubleBuffer FloatBuffer IntBuffer LongBuffer ShortBuffer 这些类都是Buffer的子类，其实也是抽象类，它们在Buffer抽象类的基础上扩展了与数据类型相关的功能，下面以ByteBuffer为例介绍 扩展的常用方法： ByteBuffer compact() 将所有未读的数据拷贝到Buffer起始处。然后将position设到最后一个未读元素正后面。limit属性依然像clear()方法一样，设置成capacity。 byte get() 获取position所指的byte，并且position加1 byte get(int index) 获取指定位置的byte ByteBuffer put(byte b) 将指定的byte写入buffer ByteBuffer put(int index,byte b) 将指定的byte写入buffer的指定位置 …许多的不同类型的get/put操作 2. ChannelJava NIO的通道类似流，但又有些不同： 既可以从通道中读取数据，又可以写数据到通道。但流的读写通常是单向的。 通道可以异步地读写。 通道中的数据总是要先读到一个Buffer，或者总是要从一个Buffer中写入。 常见的channel： FileChannel 从文件中读写数据。 DatagramChannel 能通过UDP读写网络中的数据。 SocketChannel 能通过TCP读写网络中的数据。 ServerSocketChannel可以监听新进来的TCP连接，像Web服务器那样。对每一个新进来的连接都会创建一个SocketChannel。 本文暂不分析具体的Channel类型，将在下一篇博文中具体阐述。123456789 /** * Reads a sequence of bytes from this channel into the given buffer. */public int read(ByteBuffer dst) throws IOException;/** * Writes a sequence of bytes to this channel from the given buffer. */public int write(ByteBuffer src) throws IOException; 注意对Channel的read和write的理解容易让人懵圈： channel.read(buffer) 意思是Read from this channel to buffer channel.write(buffer) 意思是Write to this channel from buffer 3. Selector 创建：调用Selector类的静态方法open()创建selector对象 1Selector selector = Selector.open(); 注册通道：调用Channel的实例方法将通道注册到selector上12channel.configureBlocking(false);SelectionKey key = channel.register(selector,Selectionkey.OP_READ); 与Selector一起使用时，Channel必须处于非阻塞模式下。这意味着不能将FileChannel与Selector一起使用，因为FileChannel不能切换到非阻塞模式。而套接字通道都可以。 register()方法的第二个参数是一个“interest集合”，意思是在Selector监听该Channel时对什么事件感兴趣。可以监听四种不同类型的事件： connect accept read write 当以上四种事件就绪的时候，会触发对应的通道事件，通道事件会被selector发现。所以，某个channel成功连接到另一个服务器称为“连接就绪”。一个server socket channel准备好接收新进入的连接称为“接收就绪”。一个有数据可读的通道可以说是“读就绪”。通道等待写数据可以说是“写就绪”。 这四种事件用SelectionKey的四个常量来表示： SelectionKey.OP_CONNECT SelectionKey.OP_ACCEPT SelectionKey.OP_READ SelectionKey.OP_WRITE 如果对不止一种事件感兴趣，那么可以用“位或”操作符将常量连接起来，如下：1int interestSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE; 3.1 SelectionKey当向Selector注册Channel时，register()方法会返回一个SelectionKey对象。这个对象包含了一些有用的属性： interest集合 ready集合 Channel Selector 附件对象（可选） interest集合可以通过SelectionKey读写interest集合，像这样：123456int interestSet = selectionKey.interestOps();boolean isInterestedInAccept = (interestSet &amp; SelectionKey.OP_ACCEPT) == SelectionKey.OP_ACCEPT；boolean isInterestedInConnect = interestSet &amp; SelectionKey.OP_CONNECT;boolean isInterestedInRead = interestSet &amp; SelectionKey.OP_READ;boolean isInterestedInWrite = interestSet &amp; SelectionKey.OP_WRITE; 可以看到，用“位与”操作interest 集合和给定的SelectionKey常量，可以确定某个确定的事件是否在interest 集合中。 ready集合ready 集合是通道已经准备就绪的操作的集合，是四个常量通过‘或’运算生成的。在一次选择(Selection)之后，你会首先访问这个ready set。Selection将在下一小节进行解释。可以这样访问ready集合：1int readySet = selectionKey.readyOps(); 可以用像检测interest集合那样的方法，来检测channel中什么事件或操作已经就绪。但是，也可以使用以下四个方法，它们都会返回一个布尔类型： 1234selectionKey.isAcceptable();selectionKey.isConnectable();selectionKey.isReadable();selectionKey.isWritable(); Channel &amp; Selector从SelectionKey访问Channel和Selector很简单。如下：12Channel channel = selectionKey.channel();Selector selector = selectionKey.selector(); 在程序中需要对返回的channel做类型转换 附件对象可以将一个对象或者更多信息附着到SelectionKey上，这样就能方便的识别某个给定的通道。例如，可以附加 与通道一起使用的Buffer，或是包含聚集数据的某个对象。使用方法如下：12selectionKey.attach(theObject);Object attachedObj = selectionKey.attachment(); 还可以在用register()方法向Selector注册Channel的时候附加对象。如：1SelectionKey key = channel.register(selector, SelectionKey.OP_READ, theObject); 3.2 Selector选择通道select() 一旦向Selector注册了一或多个通道，就可以调用几个重载的select()方法。这些方法返回你所感兴趣的事件（如连接、接受、读或写）已经准备就绪的那些通道。换句话说，如果你对“读就绪”的通道感兴趣，select()方法会返回读事件已经就绪的那些通道。 三种select： int select() 阻塞方法，阻塞到至少有一个通道在注册的事件上就绪。 int select(long timeout) 超时返回的阻塞方法 int selectNow() 非阻塞方法，不管是否有通道就绪，立即返回。如果自上次select之后没有通道就绪，直接返回0 方法返回的int值表示有多少通道已经就绪。亦即，自上次调用select()方法后有多少通道变成就绪状态。例如第一次调用select()方法，有一个通道变成就绪状态，返回了1，若再次调用select()方法，如果另一个通道就绪了，它会再次返回1，即使对第一个就绪的channel没有做任何操作，现在有两个就绪的通道。 selectedKeys() 一旦调用了select()方法，并且返回值表明有一个或更多个通道就绪了，然后可以通过调用selector的selectedKeys()方法，访问“已选择键集（selected key set）”中的就绪通道。如下所示：1Set selectedKeys = selector.selectedKeys(); 可以遍历这个已选择的键集合来访问就绪通道，像这样： 1234567891011121314151617Iterator&lt;SelectionKey&gt; iter = selector.selectedKeys().iterator();while(iter.hasNext())&#123; SelectionKey key = iter.next(); if(key.isAcceptable())&#123; handleAccept(key); &#125; if(key.isReadable())&#123; handleRead(key); &#125; if(key.isWritable() &amp;&amp; key.isValid())&#123; handleWrite(key); &#125; if(key.isConnectable())&#123; System.out.println(\"isConnectable = true\"); &#125; iter.remove();&#125; 注意每次迭代末尾需要调用remove()。Selector不会自己从已选择键集中移除SelectionKey实例，必须在处理完通道时自己移除。下次该通道变成就绪时，Selector会再次将其放入已选择键集中。 wakeUp() 某个线程调用select()方法后阻塞了，即使没有通道已经就绪，也有办法让其从select()方法返回。只要让其它线程在第一个线程调用select()方法的那个对象上调用Selector.wakeup()方法即可。阻塞在select()方法上的线程会立马返回。 如果有其它线程调用了wakeup()方法，但当前没有线程阻塞在select()方法上，下个调用select()方法的线程会立即“醒来（wake up）”。 close() 用完Selector后调用其close()方法会关闭该Selector，该方法使注册到该Selector上的所有SelectionKey实例无效，通道本身并不会关闭。 4. 一个完整的案例客户端程序：12345678910111213141516171819202122232425262728293031323334353637383940public class SocketChannelClient &#123; public static void main(String[] args)&#123; client(); &#125; public static void client()&#123; ByteBuffer buffer = ByteBuffer.allocate(1024); SocketChannel socketChannel = null; try&#123; socketChannel = SocketChannel.open(); socketChannel.configureBlocking(false); socketChannel.connect(new InetSocketAddress(\"127.0.0.1\",8080)); if(socketChannel.finishConnect()) &#123; int i = 0; while (true) &#123; TimeUnit.SECONDS.sleep(1); String info = \"I'm \" + i++ + \"-th information from client\"; buffer.clear(); buffer.put(info.getBytes()); buffer.flip(); while (buffer.hasRemaining()) &#123; System.out.println(buffer); socketChannel.write(buffer); &#125; &#125; &#125; &#125;catch (IOException | InterruptedException e)&#123; e.printStackTrace(); &#125;finally &#123; try&#123; if(socketChannel!=null)&#123; socketChannel.close(); &#125; &#125;catch(IOException e)&#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 服务器端程序： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293public class NIOSocketServer &#123; private static final int BUF_SIZE=1024; private static final int PORT = 8080; private static final int TIMEOUT = 3000; public static void main(String[] args) &#123; selector(); &#125; public static void selector() &#123; Selector selector = null; ServerSocketChannel ssc = null; try&#123; selector = Selector.open(); ssc= ServerSocketChannel.open(); ssc.socket().bind(new InetSocketAddress(PORT)); ssc.configureBlocking(false); ssc.register(selector, SelectionKey.OP_ACCEPT); while(true)&#123; if(selector.select(TIMEOUT) == 0)&#123; System.out.println(\"==\"); continue; &#125; Iterator&lt;SelectionKey&gt; iter = selector.selectedKeys().iterator(); while(iter.hasNext())&#123; SelectionKey key = iter.next(); if(key.isAcceptable())&#123; handleAccept(key); &#125; if(key.isReadable())&#123; handleRead(key); &#125; if(key.isWritable() &amp;&amp; key.isValid())&#123; handleWrite(key); &#125; if(key.isConnectable())&#123; System.out.println(\"isConnectable = true\"); &#125; iter.remove(); &#125; &#125; &#125;catch(IOException e)&#123; e.printStackTrace(); &#125;finally&#123; try&#123; if(selector!=null)&#123; selector.close(); &#125; if(ssc!=null)&#123; ssc.close();//关闭ServerSocketChannel &#125; &#125;catch(IOException e)&#123; e.printStackTrace(); &#125; &#125; &#125; public static void handleAccept(SelectionKey key) throws IOException &#123; ServerSocketChannel ssChannel = (ServerSocketChannel)key.channel(); SocketChannel sc = ssChannel.accept(); sc.configureBlocking(false); sc.register(key.selector(), SelectionKey.OP_READ, ByteBuffer.allocateDirect(BUF_SIZE)); &#125; public static void handleRead(SelectionKey key) throws IOException&#123; SocketChannel sc = (SocketChannel)key.channel(); ByteBuffer buf = (ByteBuffer)key.attachment(); long bytesRead = sc.read(buf); while(bytesRead&gt;0)&#123; buf.flip(); while(buf.hasRemaining())&#123; System.out.print((char)buf.get()); &#125; System.out.println(); buf.clear(); bytesRead = sc.read(buf); &#125; if(bytesRead == -1)&#123; sc.close(); &#125; &#125; public static void handleWrite(SelectionKey key) throws IOException&#123; ByteBuffer buf = (ByteBuffer)key.attachment(); buf.flip(); SocketChannel sc = (SocketChannel) key.channel(); while(buf.hasRemaining())&#123; sc.write(buf); &#125; buf.compact(); &#125;&#125;","categories":[],"tags":[{"name":"nio","slug":"nio","permalink":"http://yoursite.com/child/tags/nio/"}],"keywords":[]},{"title":"nio-I/O模型","slug":"nio-IO模型","date":"2019-05-19T16:00:00.000Z","updated":"2019-07-14T13:34:22.634Z","comments":true,"path":"2019/05/20/nio-IO模型/","link":"","permalink":"http://yoursite.com/child/2019/05/20/nio-IO模型/","excerpt":"","text":"上一篇我们讲到了关于TCP/IP协议的一些内容，这些是网络编程的必备知识。在了解NIO之前我们必须要了解一下对应的系统层IO模型，比如java的NIO对应是那种IO模型，阻塞和同步的差异在哪里，又是否相同。了解了这些更方便我们的后续的NIO探解。 1. 同步/异步、阻塞/非阻塞同步、异步，阻塞、非阻塞，这四种状态常有人分不清，主要是这四种状态的定义本身也不是很明确，所以各种解答的方式都有。常见的分类有以下: 同步阻塞IO 同步非阻塞IO 异步非阻塞IO 阻塞是指执行I/O操作的线程，在I/O操作过程中能不能处理其他任务。同步指I/O操作过程中的消息通知机制。 同步：是否同步体现在消息通信机制上。 1.1 如何分类针对某种IO模型，我们如何分类，可以基于POSIX对同步/异步的定义来判别：同步的I/O操作会导致请求进程阻塞，直到I/O操作完成；而异步的I/O操做则不会引起请求进程阻塞。 如果说以上的定义依然无法判别，我们可以从输入操作的两个阶段来看： 一般来说，一个输入操作通常包括两个不同阶段： （1）等待数据准备好； （2）从内核向进程复制数据。 是否同步的判断依据是：针对整个过程，也就是2个阶段，是否有阻塞。 是否阻塞的判断依据是：按程序（线程）等待消息通知时的状态角度来说的，也就是主要是针对第一阶段来说。 1.2 举例说明我们举例来说：比如说做饭这件事，一般要分为连个步骤。 1、买菜，准备食材 2、炒菜，做出饭菜 方案一：自己动手。 1、去超市买菜，准备食材（阻塞，当前时段只能做一件事，且需要持续的等待） 2、回家切菜，炒菜，做饭菜（阻塞，还是自己来处理） 方案一同步阻塞。首先阶段一是阻塞的，所以认定为阻塞；两个阶段都是阻塞的，认定为同步的。 方案二：网购食材，自己做饭 1、网上下单，配送食材。（非阻塞的，这期间你可以干其他事） 2、拿到菜，切菜、炒菜，做饭菜（阻塞） 方案二为同步非阻塞。阶段一为非阻塞，认定为非阻塞。阶段二为阻塞，两阶段中有一个为阻塞，认定为同步。 方案三：网购食材，请人做饭 1、网上下单，配送食材。（非阻塞的，这期间你可以干其他事） 2、请小时工，帮忙做这一餐，做好通知我。（非阻塞，期间可以干其他事） 方案三为异步非阻塞。阶段一为非阻塞，认定为非阻塞。阶段二非阻塞，则两阶段中都没有阻塞，认定为异步。 那么是否有异步阻塞IO模型，没有，要记得异步状态是包含二个阶段的，如果有阻塞的过程，为何还叫异步？ 2. Unix 5种I/O模型在《UNIX网络编程：卷一》的第六章书中列出了五种IO模型： 阻塞式I/O 非阻塞式I/O I/O复用（select，poll，epoll…） 信号驱动式I/O（SIGIO） 异步I/O（POSIX的aio_系列函数） 2.1 阻塞式I/O同步阻塞 IO 模型是最常用的一个模型，也是最简单的模型。在linux中，默认情况下所有的socket都是blocking。它符合人们最常见的思考逻辑。 在这个IO模型中，用户空间的应用程序执行一个系统调用（recvform），这会导致应用程序阻塞，什么也不干，直到数据准备好，等待kernel准备好从网络上接收到的数据报 + 等待收到的报文被从kernel复制到buf中，recvfrom方法才会返回，最后进程再处理数据。 这就是阻塞式IO模型 2.2 非阻塞式I/O非阻塞IO时对一个非阻塞描述符循环调用recvfrom，持续的轮询（polling）,以查看某个操作是否就绪。与阻塞IO不一样，”非阻塞将大的整片时间的阻塞分成N多的小的阻塞, 所以进程不断地有机会 ‘被’ CPU光顾”。 非阻塞的recvform系统调用调用之后，进程并没有被阻塞，内核马上返回给进程，如果数据还没准备好，此时会返回一个error。进程在返回之后，可以干点别的事情，然后再发起recvform系统调用。如此循环的进行recvform系统调用，检查内核数据，直到数据准备好，再拷贝数据到进程。拷贝数据整个过程，进程仍然是属于阻塞的状态。 这就是非阻塞式IO模型 2.3 I/O复用IO multiplexing就是我们说的select，poll，epoll 。为何叫多路复用，是因为它I/O多路复用可以同时监听多个fd，如此就减少了为每个需要监听的fd开启线程的开销。 select调用是内核级别的，可以等待多个socket，能实现同时对多个IO端口进行监听，当其中任何一个socket的数据准好了，就能返回进行可读，然后进程再进行recvform系统调用，将数据由内核拷贝到用户进程，这个过程是阻塞的。 I/O复用模型会用到select、poll、epoll函数，这几个函数也会使进程阻塞，但是和阻塞I/O所不同的的，这几个函数可以同时阻塞多个I/O操作`。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时（不是等到socket数据全部到达再处理, 而是有了一部分数据就会调用用户进程来处理），才真正调用I/O操作函数。 IO复用有人把其成为同步非阻塞的，也有称为同步阻塞。其实这个是否阻塞还需要看第一个阶段，第一个阶段有的阻塞，有的不阻塞。主要也是阻塞在select阶段，属于用户主动等待阶段，我们且规范为阻塞状态，所以，把IO多路复用归为同步阻塞模式。 这是IO复用的模型: select、poll、epoll的不同 2.4 信号驱动式I/O信号驱动式I/O：首先我们允许Socket进行信号驱动IO,并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据。 也就是说第一个阶段，完全是非阻塞的，等数据到达会给一个信号通知，第二个阶段recvfrom还是阻塞过程，和之上无差异。 信号驱动式I/O 过程如下: 2.5 异步I/O异步IO不是顺序执行,用户进程进行aio_read系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程，然后用户态进程可以去做别的事情。等到socket数据准备好了，内核直接复制数据给进程，然后从内核向进程发送通知。IO两个阶段，进程都是非阻塞的。 2.6 总结针对这5中IO模型，我采用一张图来总结一下。 3. java IOUnix中的五种I/O模型，除信号驱动I/O外，Java对其它四种I/O模型都有所支持。其中Java最早提供的blocking I/O即是同步阻塞I/O，而NIO即是同步非阻塞I/O，同时通过NIO实现的Reactor模式即是I/O复用模型的实现，通过AIO实现的Proactor模式即是异步I/O模型的实现。 所以说严格意义上来说，通过Reactor模式实现的NIO，和unix中的I/O多路复用是相同的概念，但这是一种编程模型，而不是原生支持。这也是我们下面所要进行的netty讲解的主要思想。","categories":[],"tags":[{"name":"nio","slug":"nio","permalink":"http://yoursite.com/child/tags/nio/"}],"keywords":[]},{"title":"源码分析-会用HashMap","slug":"源码分析-会用HashMap","date":"2018-07-21T12:41:36.000Z","updated":"2019-05-23T02:57:29.493Z","comments":true,"path":"2018/07/21/源码分析-会用HashMap/","link":"","permalink":"http://yoursite.com/child/2018/07/21/源码分析-会用HashMap/","excerpt":"","text":"一个问题引发的思考如果确定只装载100个元素，new HashMap(?)多少是最佳的，why？要弄解答这个问题，第一要知道HashMap的数据结构，第二再弄明白存取数据的逻辑。 1.首先，我是一个数组HashMap本质上是一个数组，数组的每个元素是一个单链表或者红黑树，由0个或多个节点组成。java源码中的定义如下： 1transient Node&lt;K,V&gt;[] table; 1.1节点类Node&lt;K,V&gt;Node类是HashMap的一个静态内部类，可以将其看成是一个独立的类，只是声明在HashMap类内部而已。下面是源码： 123456789101112131415161718192021222324252627282930313233343536373839static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123;//Entry是Map接口中的一个内部接口 final int hash;//此节点的哈希值，同一个链表上的哈希值不一定相同 final K key;//键，不能修改 V value;//值 Node&lt;K,V&gt; next;//指向下一个节点 Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + &quot;=&quot; + value; &#125; public final int hashCode() &#123;//此Node类的hashCode方法 return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123;//重新设置节点Value，返回旧Value V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123;//判断节点相等的方法， if (o == this)//同一个对象，返回true return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true;//键和值都相等则返回true &#125; return false; &#125;&#125; 1.2为啥有链表还有树为了提高查询效率，当链表的长度达到阈值的时候会自动将链表树形化，源码中的三个阈值常量如下： 123static final int TREEIFY_THRESHOLD = 8;static final int UNTREEIFY_THRESHOLD = 6;static final int MIN_TREEIFY_CAPACITY = 64; TREEIFY_THRESHOLD 树形化阈值：当链表长度超过这个值的时候，将链表进行树形化改造 UNTREEIFY_THRESHOLD 链表化阈值：当节点数低于这个阈值，将红黑树改造成链表。这个值必须必树形化阈值小，避免频繁的转换。 MIN_TREEIFY_CAPACITY 最小树形化容量：当数组table的长度低于这个值，即使元素链表的长度超过树形化阈值，也不会进行树形化改造，而是对table进行扩容。这个值不能小于4*TREEIFY_THRESHOLD 2.怎么进行数据的存取呢2.1hash方法拿到一个&lt;Key,Value&gt;，要存在table的哪个位置呢，这就需要用hash方法来决定了。。。从代码说起： 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; key.hashCode()函数调用的是key键值类型自带的哈希函数（与HashMap的hashCode()函数不是同一个），它返回一个32位int类型的散列值。 考虑到hash值得取值范围太大，不可能创建一个如此大的hash table，因此定位到table的位置只使用hash值的后几位（具体位数与table长度有关）。 如果只取后几位，碰撞会比较严重，因此就有了扰动函数，将hash值右移16位（高16位移到低16位），再与自身亦或，得到的结果混合了原hash值得高位和低位，以此来加大低位的随机性。 2.2定位最终得到的hash值，将由低位进行定位，定位操作如下：12n = tab.lengthtab[(n - 1) &amp; hash] 数组长度必为2的整数次幂，因此(n-1)相当于低位掩码，与h进行与操作，保留h低位，掩盖高位。 这里不做取余，是因为取余可能为负数（hashCode为负数的时候） 不对取余进行模运算，是因为最大的整数Math.abs()会返回负值 由此可知，对于HashMap的同一个链表的各个节点key值得hash值不一定相同（只是低位相同） 2.3扩容(resize)默认容量是1616是2的整数次幂的原因，在小数据量的情况下16比15或20更能减少key之间的碰撞，而加快查询的效率。 容量是15会怎样？当数组长度为15的时候，hashcode的值会与14（1110）进行“与”，那么最后一位永远是0，而0001，0011，0101，1001，1011，0111，1101这几个位置永远都不能存放元素了，空间浪费相当大，更糟的是这种情况中，数组可以使用的位置比数组长度小了很多，这意味着进一步增加了碰撞的几率（hash不均匀），降低了查询的效率！所以，在存储大容量数据的时候，最好预先指定hashmap的size为2的整数次幂次方。就算不指定的话，也会以大于且最接近指定值大小的2次幂来初始化的，代码如下(HashMap的构造方法中)：123int capacity = 1; while (capacity &lt; initialCapacity) capacity &lt;&lt;= 1; //乘以2 什么时候扩容&amp;怎么扩容当hashmap中的元素越来越多的时候，碰撞的几率也就越来越高（因为数组的长度是固定的），所以为了提高查询的效率，就要对hashmap的数组进行扩容，数组扩容这个操作也会出现在ArrayList中，所以这是一个通用的操作，很多人对它的性能表示过怀疑，不过想想我们的“均摊”原理，就释然了，而在hashmap数组扩容之后，最消耗性能的点就出现了：原数组中的数据必须重新计算其在新数组中的位置，并放进去，这就是resize。那么hashmap什么时候进行扩容呢？当hashmap中的元素个数超过数组大小length x loadFactor时，就会进行数组扩容，==loadFactor的默认值为0.75==，也就是说，默认情况下，数组大小为16，那么当hashmap中元素个数超过16x0.75=12的时候，就把数组的大小扩展为2*16=32，即扩大一倍，然后重新计算每个元素在数组中的位置，而这是一个非常消耗性能的操作，所以++如果我们已经预知hashmap中元素的个数，那么预设元素的个数能够有效的提高hashmap的性能++。 回到开篇的问题当有100个元素new HashMap(100), 但是理论上来讲new HashMap(128)更合适，不过上面已经说过，即使是100，hashmap也自动会将其设置为128。 但是new HashMap(128)还不是更合适的，因为0.75x100 &lt; 100, 也就是说为了让0.75 x size &gt; 100, 我们必须这样new HashMap(256)才最合适，既考虑了&amp;的问题，也避免了resize的问题。 3.可以使用自定义的类作为key的类型吗可以，但是必须改写key类型的hashcode与equals方法首先计算key的hashcode，找到数组中对应位置的某一元素，然后通过key的equals方法在对应位置的链表中找到需要的元素。所以，hashcode与equals方法对于找到对应元素是两个关键方法。Hashmap的key可以是任何类型的对象，例如User这种对象，为了保证两个具有相同属性的user的hashcode相同，我们就需要改写hashcode方法，比方把hashcode值的计算与User对象的id关联起来，那么只要user对象拥有相同id，那么他们的hashcode也能保持一致了，这样就可以找到在hashmap数组中的位置了。如果这个位置上有多个元素，还需要用key的equals方法在对应位置的链表中找到需要的元素，所以只改写了hashcode方法是不够的，equals方法也是需要改写滴~当然啦，按正常思维逻辑，equals方法一般都会根据实际的业务内容来定义，例如根据user对象的id来判断两个user是否相等。 参考链接深入理解HashMapHashMap详解","categories":[],"tags":[{"name":"源码分析","slug":"源码分析","permalink":"http://yoursite.com/child/tags/源码分析/"}],"keywords":[]},{"title":"并发编程-并发容器CopyOnWriteArrayList","slug":"并发编程-CopyOnWrite容器","date":"2018-05-26T04:32:12.000Z","updated":"2019-05-28T14:59:58.865Z","comments":true,"path":"2018/05/26/并发编程-CopyOnWrite容器/","link":"","permalink":"http://yoursite.com/child/2018/05/26/并发编程-CopyOnWrite容器/","excerpt":"","text":"Copy-On-Write简称COW，是一种用于程序设计中的优化策略。其基本思路是，从一开始大家都在共享同一个内容，当某个人想要修改这个内容的时候，才会真正把内容Copy出去形成一个新的内容然后再改，这是一种延时懒惰策略。从JDK1.5开始Java并发包里提供了两个使用CopyOnWrite机制实现的并发容器,它们是CopyOnWriteArrayList和CopyOnWriteArraySet。CopyOnWrite容器非常有用，可以在非常多的并发场景中使用到。 1. 什么是CopyOnWrite容器CopyOnWrite容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。 2. CopyOnWriteArrayList的实现原理在使用CopyOnWriteArrayList之前，我们先阅读其源码了解下它是如何实现的。以下代码是向CopyOnWriteArrayList中add方法的实现（向CopyOnWriteArrayList里添加元素），可以发现在添加的时候是需要加锁的，否则多线程写的时候会Copy出N个副本出来。 1234567891011121314public boolean add(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); newElements[len] = e; setArray(newElements); return true; &#125; finally &#123; lock.unlock(); &#125;&#125; 读的时候不需要加锁，如果读的时候有多个线程正在向CopyOnWriteArrayList添加数据，读还是会读到旧的数据，因为写的时候不会锁住旧的CopyOnWriteArrayList。 123public E get(int index) &#123; return get(getArray(), index);&#125; JDK中并没有提供CopyOnWriteMap，我们可以参考CopyOnWriteArrayList来实现一个，基本代码如下： 123456789101112131415161718192021222324252627282930313233import java.util.Collection;import java.util.Map;import java.util.Set; public class CopyOnWriteMap&lt;K, V&gt; implements Map&lt;K, V&gt;, Cloneable &#123; private volatile Map&lt;K, V&gt; internalMap; public CopyOnWriteMap() &#123; internalMap = new HashMap&lt;K, V&gt;(); &#125; public V put(K key, V value) &#123; synchronized (this) &#123; Map&lt;K, V&gt; newMap = new HashMap&lt;K, V&gt;(internalMap); V val = newMap.put(key, value); internalMap = newMap; return val; &#125; &#125; public V get(Object key) &#123; return internalMap.get(key); &#125; public void putAll(Map&lt;? extends K, ? extends V&gt; newData) &#123; synchronized (this) &#123; Map&lt;K, V&gt; newMap = new HashMap&lt;K, V&gt;(internalMap); newMap.putAll(newData); internalMap = newMap; &#125; &#125;&#125; 实现很简单，只要了解了CopyOnWrite机制，我们可以实现各种CopyOnWrite容器，并且在不同的应用场景中使用。 3. CopyOnWrite的应用场景CopyOnWrite并发容器用于读多写少的并发场景。比如白名单，黑名单，商品类目的访问和更新场景，假如我们有一个搜索网站，用户在这个网站的搜索框中，输入关键字搜索内容，但是某些关键字不允许被搜索。这些不能被搜索的关键字会被放在一个黑名单当中，黑名单每天晚上更新一次。当用户搜索时，会检查当前关键字在不在黑名单当中，如果在，则提示不能搜索。实现代码如下： 123456789101112131415161718192021222324252627282930313233import java.util.Map; import com.ifeve.book.forkjoin.CopyOnWriteMap; /** * 黑名单服务 * * @author fangtengfei * */public class BlackListServiceImpl &#123; private static CopyOnWriteMap&lt;String, Boolean&gt; blackListMap = new CopyOnWriteMap&lt;String, Boolean&gt;( 1000); public static boolean isBlackList(String id) &#123; return blackListMap.get(id) == null ? false : true; &#125; public static void addBlackList(String id) &#123; blackListMap.put(id, Boolean.TRUE); &#125; /** * 批量添加黑名单 * * @param ids */ public static void addBlackList(Map&lt;String,Boolean&gt; ids) &#123; blackListMap.putAll(ids); &#125; &#125; 代码很简单，但是使用CopyOnWriteMap需要注意两件事情： 减少扩容开销。根据实际需要，初始化CopyOnWriteMap的大小，避免写时CopyOnWriteMap扩容的开销。 使用批量添加。因为每次添加，容器每次都会进行复制，所以减少添加次数，可以减少容器的复制次数。如使用上面代码里的addBlackList方法。 4. CopyOnWrite的缺点CopyOnWrite容器有很多优点，但是同时也存在两个问题，即内存占用问题和数据一致性问题。所以在开发的时候需要注意一下。 内存占用问题。因为CopyOnWrite的写时复制机制，所以在进行写操作的时候，内存里会同时驻扎两个对象的内存，旧的对象和新写入的对象（注意:在复制的时候只是复制容器里的引用，只是在写的时候会创建新对象添加到新容器里，而旧容器的对象还在使用，所以有两份对象内存）。如果这些对象占用的内存比较大，比如说200M左右，那么再写入100M数据进去，内存就会占用300M，那么这个时候很有可能造成频繁的Yong GC和Full GC。之前我们系统中使用了一个服务由于每晚使用CopyOnWrite机制更新大对象，造成了每晚15秒的Full GC，应用响应时间也随之变长。 针对内存占用问题，可以通过压缩容器中的元素的方法来减少大对象的内存消耗，比如，如果元素全是10进制的数字，可以考虑把它压缩成36进制或64进制。或者不使用CopyOnWrite容器，而使用其他的并发容器，如ConcurrentHashMap。 数据一致性问题。CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。所以如果你希望写入的的数据，马上能读到，请不要使用CopyOnWrite容器。 5. 相关文章CopyOnWriteArrayList和同步容器的性能验证 CopyOnWriteArrayList使用简介","categories":[],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"http://yoursite.com/child/tags/并发编程/"}],"keywords":[]},{"title":"并发编程-ConcurrentHashMap源码分析","slug":"并发编程-ConcurrentHashMap源码分析","date":"2018-05-25T04:35:45.000Z","updated":"2019-06-12T09:32:31.636Z","comments":true,"path":"2018/05/25/并发编程-ConcurrentHashMap源码分析/","link":"","permalink":"http://yoursite.com/child/2018/05/25/并发编程-ConcurrentHashMap源码分析/","excerpt":"","text":"1.重要的属性首先来看几个重要的属性，与HashMap相同的就不再介绍了，这里重点解释一下sizeCtl这个属性。可以说它是ConcurrentHashMap中出镜率很高的一个属性，因为它是一个控制标识符，在不同的地方有不同用途，而且它的取值不同，也代表不同的含义。 负数代表正在进行初始化或扩容操作 -1代表正在初始化 -N 表示有N-1个线程正在进行扩容操作 正数或0代表hash表还没有被初始化，这个数值表示初始化或下一次进行扩容的大小，这一点类似于扩容阈值的概念。还后面可以看到，它的值始终是当前ConcurrentHashMap容量的0.75倍，这与loadfactor是对应的。1234567891011121314151617181920212223242526//盛装Node元素的数组,它的大小是2的整数次幂transient volatile Node&lt;K,V&gt;[] table;/** hash表初始化或扩容时的一个控制位标识量。 负数代表正在进行初始化或扩容操作 -1代表正在初始化 -N 表示有N-1个线程正在进行扩容操作 正数或0代表hash表还没有被初始化，这个数值表示初始化或下一次进行扩容的大小 */private transient volatile int sizeCtl;// 以下两个是用来控制扩容的时候 单线程进入的变量 /** * The number of bits used for generation stamp in sizeCtl. * Must be at least 6 for 32bit arrays. */private static int RESIZE_STAMP_BITS = 16;/** * The bit shift for recording size stamp in sizeCtl. */private static final int RESIZE_STAMP_SHIFT = 32- RESIZE_STAMP_BITS;static final int MOVED = -1;// hash值是-1，表示这是一个forwardNode节点static final int TREEBIN = -2;// hash值是-2 表示这时一个TreeBin节点 2.重要的类2.1 NodeNode是最核心的内部类，它包装了key-value键值对，所有插入ConcurrentHashMap的数据都包装在这里面。它与HashMap中的定义很相似，但是但是有一些差别它对value和next属性设置了volatile同步锁(与JDK7的Segment相同)，它不允许调用setValue方法直接改变Node的value域，它增加了find方法辅助map.get()方法。 2.2 TreeNode树节点类，另外一个核心的数据结构。当链表长度过长的时候，会转换为TreeNode。但是与HashMap不相同的是，它并不是直接转换为红黑树，而是把这些结点包装成TreeNode放在TreeBin对象中，由TreeBin完成对红黑树的包装。而且TreeNode在ConcurrentHashMap集成自Node类，而并非HashMap中的集成自LinkedHashMap.Entry&lt;K,V&gt;类，也就是说TreeNode带有next指针，这样做的目的是方便基于TreeBin的访问。 2.3 TreeBin这个类并不负责包装用户的key、value信息，而是包装的很多TreeNode节点。它代替了TreeNode的根节点，也就是说在实际的ConcurrentHashMap“数组”中，存放的是TreeBin对象，而不是TreeNode对象，这是与HashMap的区别。另外这个类还带有了读写锁。 这里仅贴出它的构造方法。可以看到在构造TreeBin节点时，仅仅指定了它的hash值为TREEBIN常量，这也就是个标识为。同时也看到我们熟悉的红黑树构造方法 2.4 ForwardingNode一个用于连接两个table的节点类。它包含一个nextTable指针，用于指向下一张表。而且这个节点的key value next指针全部为null，它的hash值为-1. 这里面定义的find的方法是从nextTable里进行查询节点，而不是以自身为头节点进行查找。 123456789101112131415161718192021222324252627282930313233343536/** * A node inserted at head of bins during transfer operations. */static final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; final Node&lt;K,V&gt;[] nextTable; ForwardingNode(Node&lt;K,V&gt;[] tab) &#123; super(MOVED,null,null,null); this.nextTable = tab; &#125; Node&lt;K,V&gt; find(inth, Object k) &#123; // loop to avoid arbitrarily deep recursion on forwarding nodes outer:for(Node&lt;K,V&gt;[] tab = nextTable;;) &#123; Node&lt;K,V&gt; e; intn; if(k == null|| tab == null|| (n = tab.length) == 0|| (e = tabAt(tab, (n - 1) &amp; h)) == null) returnnull; for(;;) &#123; inteh; K ek; if((eh = e.hash) == h &amp;&amp; ((ek = e.key) == k || (ek != null&amp;&amp; k.equals(ek)))) returne; if(eh &lt; 0) &#123; if(einstanceofForwardingNode) &#123; tab = ((ForwardingNode&lt;K,V&gt;)e).nextTable; continueouter; &#125; else returne.find(h, k); &#125; if((e = e.next) == null) returnnull; &#125; &#125; &#125;&#125; 3.Unsafe与CAS在ConcurrentHashMap中，随处可以看到U, 大量使用了U.compareAndSwapXXX的方法，这个方法是利用一个CAS算法实现无锁化的修改值的操作，他可以大大降低锁代理的性能消耗。这个算法的基本思想就是不断地去比较当前内存中的变量值与你指定的一个变量值是否相等，如果相等，则接受你指定的修改的值，否则拒绝你的操作。因为当前线程中的值已经不是最新的值，你的修改很可能会覆盖掉其他线程修改的结果。这一点与乐观锁，SVN的思想是比较类似的。 3.1 unsafe静态块unsafe代码块控制了一些属性的修改工作，比如最常用的SIZECTL 。在这一版本的concurrentHashMap中，大量应用来的CAS方法进行变量、属性的修改工作。利用CAS进行无锁操作，可以大大提高性能。 1234567891011121314151617181920212223242526272829private static final sun.misc.Unsafe U; private static final long SIZECTL; private static final long TRANSFERINDEX; private static final long BASECOUNT; private static final long CELLSBUSY; private static final long CELLVALUE; private static final long ABASE; private static final int ASHIFT; static&#123; try&#123; U = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; k = ConcurrentHashMap.class; SIZECTL = U.objectFieldOffset(k.getDeclaredField(\"sizeCtl\")); TRANSFERINDEX = U.objectFieldOffset(k.getDeclaredField(\"transferIndex\")); BASECOUNT = U.objectFieldOffset(k.getDeclaredField(\"baseCount\")); CELLSBUSY = U.objectFieldOffset(k.getDeclaredField(\"cellsBusy\")); Class&lt;?&gt; ck = CounterCell.class; CELLVALUE = U.objectFieldOffset(ck.getDeclaredField(\"value\")); Class&lt;?&gt; ak = Node[].class; ABASE = U.arrayBaseOffset(ak); intscale = U.arrayIndexScale(ak); if((scale &amp; (scale - 1)) != 0) thrownewError(\"data type scale not a power of two\"); ASHIFT = 31- Integer.numberOfLeadingZeros(scale); &#125;catch(Exception e) &#123; thrownewError(e); &#125; &#125; 3.2 三个核心方法ConcurrentHashMap定义了三个原子操作，用于对指定位置的节点进行操作。正是这些原子操作保证了ConcurrentHashMap的线程安全。 12345678910111213141516static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) &#123;//获得在i位置上的Node节点 return(Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE);&#125; static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) &#123; //因此当前线程中的值并不是最新的值，这种修改可能会覆盖掉其他线程的修改结果有点类似于SVN returnU.compareAndSwapObject(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v);&#125;static final &lt;K,V&gt; voidsetTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; v) &#123; //利用volatile方法设置节点位置的值 U.putObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, v);&#125; 4 初始化方法initTable对于ConcurrentHashMap来说，调用它的构造方法仅仅是设置了一些参数而已。而整个table的初始化是在向ConcurrentHashMap中插入元素的时候发生的。如调用put、computeIfAbsent、compute、merge等方法的时候，调用时机是检查table==null。 初始化方法主要应用了关键属性sizeCtl 如果这个值〈0，表示其他线程正在进行初始化，就放弃这个操作。在这也可以看出ConcurrentHashMap的初始化只能由一个线程完成。如果获得了初始化权限，就用CAS方法将sizeCtl置为-1，防止其他线程进入。初始化数组后，将sizeCtl的值改为0.75*n。 12345678910111213141516171819202122232425private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while((tab = table) == null|| tab.length == 0) &#123; //sizeCtl表示有其他线程正在进行初始化操作，把线程挂起。对于table的初始化工作，只能有一个线程在进行。 if((sc = sizeCtl) &lt; 0) Thread.yield(); else if(U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; //利用CAS方法把sizectl的值置为-1 表示本线程正在进行初始化 try&#123; if((tab = table) == null|| tab.length == 0) &#123; intn = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])newNode&lt;?,?&gt;[n]; table = tab = nt; sc = n - (n &gt;&gt;&gt; 2);//相当于0.75*n 设置一个扩容的阈值 &#125; &#125;finally&#123; sizeCtl = sc; &#125; break; &#125; &#125; returntab;&#125; 5 扩容方法 transfer当ConcurrentHashMap容量不足的时候，需要对table进行扩容。这个方法的基本思想跟HashMap是很像的，但是由于它是支持并发扩容的，所以要复杂的多。原因是它支持多线程进行扩容操作，而并没有加锁。我想这样做的目的不仅仅是为了满足concurrent的要求，而是希望利用并发处理去减少扩容带来的时间影响。因为在扩容的时候，总是会涉及到从一个“数组”到另一个“数组”拷贝的操作，如果这个操作能够并发进行，那真真是极好的了。 整个扩容操作分为两个部分 第一部分是构建一个nextTable,它的容量是原来的两倍，这个操作是单线程完成的。这个单线程的保证是通过RESIZE_STAMP_SHIFT这个常量经过一次运算来保证的，这个地方在后面会有提到； 第二个部分就是将原来table中的元素复制到nextTable中，这里允许多线程进行操作。 先来看一下单线程是如何完成的：它的大体思想就是遍历、复制的过程。首先根据运算得到需要遍历的次数i，然后利用tabAt方法获得i位置的元素： 如果这个位置为空，就在原table中的i位置放入forwardNode节点，这个也是触发并发扩容的关键点； 如果这个位置是Node节点（fh&gt;=0），如果它是一个链表的头节点，就构造一个反序链表，把他们分别放在nextTable的i和i+n的位置上 如果这个位置是TreeBin节点（fh&lt;0），也做一个反序处理，并且判断是否需要untreefi，把处理的结果分别放在nextTable的i和i+n的位置上 遍历过所有的节点以后就完成了复制工作，这时让nextTable作为新的table，并且更新sizeCtl为新容量的0.75倍 ，完成扩容。再看一下多线程是如何完成的： 在代码的69行有一个判断，如果遍历到的节点是forward节点，就向后继续遍历，再加上给节点上锁的机制，就完成了多线程的控制。多线程遍历节点，处理了一个节点，就把对应点的值set为forward，另一个线程看到forward，就向后遍历。这样交叉就完成了复制工作。而且还很好的解决了线程安全的问题。 这个方法的设计实在是让我膜拜。 6 Put方法前面的所有的介绍其实都为这个方法做铺垫。ConcurrentHashMap最常用的就是put和get两个方法。现在来介绍put方法，这个put方法依然沿用HashMap的put方法的思想，根据hash值计算这个新插入的点在table中的位置i，如果i位置是空的，直接放进去，否则进行判断，如果i位置是树节点，按照树的方式插入新的节点，否则把i插入到链表的末尾。ConcurrentHashMap中依然沿用这个思想，有一个最重要的不同点就是ConcurrentHashMap不允许key或value为null值。另外由于涉及到多线程，put方法就要复杂一点。在多线程中可能有以下两个情况 如果一个或多个线程正在对ConcurrentHashMap进行扩容操作，当前线程也要进入扩容的操作中。这个扩容的操作之所以能被检测到，是因为transfer方法中在空结点上插入forward节点，如果检测到需要插入的位置被forward节点占有，就帮助进行扩容； 如果检测到要插入的节点是非空且不是forward节点，就对这个节点加锁，这样就保证了线程安全。尽管这个有一些影响效率，但是还是会比hashTable的synchronized要好得多。 整体流程就是首先定义不允许key或value为null的情况放入 对于每一个放入的值，首先利用spread方法对key的hashcode进行一次hash计算，由此来确定这个值在table中的位置。 如果这个位置是空的，那么直接放入，而且不需要加锁操作。 如果这个位置存在结点，说明发生了hash碰撞，首先判断这个节点的类型。如果是链表节点（fh&gt;0）,则得到的结点就是hash值相同的节点组成的链表的头节点。需要依次向后遍历确定这个新加入的值所在位置。如果遇到hash值与key值都与新加入节点是一致的情况，则只需要更新value值即可。否则依次向后遍历，直到链表尾插入这个结点。如果加入这个节点以后链表长度大于8，就把这个链表转换成红黑树。如果这个节点的类型已经是树节点的话，直接调用树节点的插入方法进行插入新的值。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879publicV put(K key, V value) &#123; return putVal(key, value, false);&#125;/** Implementation for put and putIfAbsent */final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if(key == null|| value == null) throw new NullPointerException(); //计算hash值 int hash = spread(key.hashCode()); int binCount = 0; //死循环 何时插入成功 何时跳出 for(Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; //如果table为空的话，初始化table if(tab == null|| (n = tab.length) == 0) tab = initTable(); //根据hash值计算出在table里面的位置 else if((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; //如果这个位置没有值 ，直接放进去，不需要加锁 if(casTabAt(tab, i, null,new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; //当遇到表连接点时，需要进行整合表的操作 else if((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else&#123; V oldVal = null; //结点上锁 这里的结点可以理解为hash值相同组成的链表的头结点 synchronized(f) &#123; if(tabAt(tab, i) == f) &#123; //fh〉0 说明这个节点是一个链表的节点 不是树的节点 if(fh &gt;= 0) &#123; binCount = 1; //在这里遍历链表所有的结点 for(Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; //如果hash值和key值相同 则修改对应结点的value值 if(e.hash == hash &amp;&amp;((ek = e.key) == key ||(ek != null&amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if(!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; //如果遍历到了最后一个结点，那么就证明新的节点需要插入 就把它插入在链表尾部 if((e = e.next) == null) &#123; pred.next = newNode&lt;K,V&gt;(hash, key,value,null); break; &#125; &#125; &#125; //如果这个节点是树节点，就按照树的方式插入值 else if(f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key,value)) != null) &#123; oldVal = p.val; if(!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if(binCount != 0) &#123; //如果链表长度已经达到临界值8 就需要把链表转换为树结构 if(binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if(oldVal != null) return oldVal; break; &#125; &#125; &#125; //将当前ConcurrentHashMap的元素数量+1 addCount(1L, binCount); return null;&#125; 我们可以发现JDK8中的实现也是锁分离的思想，只是锁住的是一个Node，而不是JDK7中的Segment，而锁住Node之前的操作是无锁的并且也是线程安全的，建立在之前提到的3个原子操作上。 6.1 helpTransfer方法这是一个协助扩容的方法。这个方法被调用的时候，当前ConcurrentHashMap一定已经有了nextTable对象，首先拿到这个nextTable对象，调用transfer方法。回看上面的transfer方法可以看到，当本线程进入扩容方法的时候会直接进入复制阶段。 6.2 treeifyBin方法这个方法用于将过长的链表转换为TreeBin对象。但是他并不是直接转换，而是进行一次容量判断，如果容量没有达到转换的要求，直接进行扩容操作并返回；如果满足条件才链表的结构抓换为TreeBin ，这与HashMap不同的是，它并没有把TreeNode直接放入红黑树，而是利用了TreeBin这个小容器来封装所有的TreeNode. 7 get方法get方法比较简单，给定一个key来确定value的时候，必须满足两个条件 key相同 hash值相同，对于节点可能在链表或树上的情况，需要分别去查找。 1234567891011121314151617181920212223242526public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; //计算hash值 int h = spread(key.hashCode()); //根据hash值确定节点位置 if((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; //如果搜索到的节点key与传入的key相同且不为null,直接返回这个节点 if((eh = e.hash) == h) &#123; if((ek = e.key) == key || (ek != null&amp;&amp; key.equals(ek))) returne.val; &#125; //如果eh&lt;0 说明这个节点在树上 直接寻找 else if(eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; //否则遍历链表 找到对应的值并返回 while((e = e.next) != null) &#123; if(e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null&amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125; 8 Size相关的方法对于ConcurrentHashMap来说，这个table里到底装了多少东西其实是个不确定的数量，因为不可能在调用size()方法的时候像GC的“stop the world”一样让其他线程都停下来让你去统计，因此只能说这个数量是个估计值。对于这个估计值，ConcurrentHashMap也是大费周章才计算出来的。 8.1 辅助定义为了统计元素个数，ConcurrentHashMap定义了一些变量和一个内部类 1234567891011121314151617181920212223242526/** * A padded cell for distributing counts. Adapted from LongAdder * and Striped64. See their internal docs for explanation. */@sun.misc.Contendedstaticfinalclass CounterCell &#123; volatilelongvalue; CounterCell(longx) &#123; value = x; &#125;&#125;/******************************************/ /** * 实际上保存的是hashmap中的元素个数 利用CAS锁进行更新 但它并不用返回当前hashmap的元素个数 */privatetransientvolatile long baseCount;/** * Spinlock (locked via CAS) used when resizing and/or creating CounterCells. */privatetransientvolatile int cellsBusy;/** * Table of counter cells. When non-null, size is a power of 2. */privatetransientvolatile CounterCell[] counterCells; 8.2 mappingCount与Size方法mappingCount与size方法的类似 从Java工程师给出的注释来看，应该使用mappingCount代替size方法 两个方法都没有直接返回basecount 而是统计一次这个值，而这个值其实也是一个大概的数值，因此可能在统计的时候有其他线程正在执行插入或删除操作。 1234567891011121314151617181920212223242526272829303132publicintsize() &#123; longn = sumCount(); return((n &lt; 0L) ? 0: (n &gt; (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int)n); &#125; /** * Returns the number of mappings. This method should be used * instead of &#123;@link #size&#125; because a ConcurrentHashMap may * contain more mappings than can be represented as an int. The * value returned is an estimate; the actual count may differ if * there are concurrent insertions or removals. * * @return the number of mappings * @since 1.8 */ publiclongmappingCount() &#123; longn = sumCount(); return(n &lt; 0L) ? 0L : n; // ignore transient negative values &#125; finallongsumCount() &#123; CounterCell[] as = counterCells; CounterCell a; longsum = baseCount; if(as != null) &#123; for(inti = 0; i &lt; as.length; ++i) &#123; if((a = as[i]) != null) sum += a.value;//所有counter的值求和 &#125; &#125; returnsum; &#125; 8.3 addCount方法在put方法结尾处调用了addCount方法，把当前ConcurrentHashMap的元素个数+1这个方法一共做了两件事,更新baseCount的值，检测是否进行扩容。 123456789101112131415161718192021222324252627282930313233343536373839404142privatefinalvoid addCount(longx,intcheck) &#123; CounterCell[] as; longb, s; //利用CAS方法更新baseCount的值 if((as = counterCells) != null|| !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) &#123; CounterCell a; longv;intm; booleanuncontended = true; if(as == null|| (m = as.length - 1) &lt; 0|| (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null|| !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) &#123; fullAddCount(x, uncontended); return; &#125; if(check &lt;= 1) return; s = sumCount(); &#125; //如果check值大于等于0 则需要检验是否需要进行扩容操作 if(check &gt;= 0) &#123; Node&lt;K,V&gt;[] tab, nt; intn, sc; while(s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null&amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123; intrs = resizeStamp(n); // if(sc &lt; 0) &#123; if((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1|| sc == rs + MAX_RESIZERS || (nt = nextTable) == null|| transferIndex &lt;= 0) break; //如果已经有其他线程在执行扩容操作 if(U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; //当前线程是唯一的或是第一个发起扩容的线程 此时nextTable=null elseif(U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab,null); s = sumCount(); &#125; &#125;&#125; 总结JDK6,7中的ConcurrentHashmap主要使用Segment来实现减小锁粒度，把HashMap分割成若干个Segment，在put的时候需要锁住Segment，get时候不加锁，使用volatile来保证可见性，当要统计全局时（比如size），首先会尝试多次计算modcount来确定，这几次尝试中，是否有其他线程进行了修改操作，如果没有，则直接返回size。如果有，则需要依次锁住所有的Segment来计算。 jdk7中ConcurrentHashmap中，当长度过长碰撞会很频繁，链表的增改删查操作都会消耗很长的时间，影响性能,所以jdk8 中完全重写了concurrentHashmap,代码量从原来的1000多行变成了 6000多 行，实现上也和原来的分段式存储有很大的区别。 主要设计上的变化有以下几点: 不采用segment而采用node，锁住node来实现减小锁粒度。 设计了MOVED状态 当resize的中过程中 线程2还在put数据，线程2会帮助resize。 使用3个CAS操作来确保node的一些操作的原子性，这种方式代替了锁。 sizeCtl的不同值来代表不同含义，起到了控制的作用。 至于为什么JDK8中使用synchronized而不是ReentrantLock，我猜是因为JDK8中对synchronized有了足够的优化吧。 参考文档JDK1.8 实现解读扩容源码分析","categories":[],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"http://yoursite.com/child/tags/并发编程/"}],"keywords":[]},{"title":"并发编程-并发工具类","slug":"并发编程-并发工具类","date":"2018-05-17T12:36:12.000Z","updated":"2019-05-28T14:59:12.732Z","comments":true,"path":"2018/05/17/并发编程-并发工具类/","link":"","permalink":"http://yoursite.com/child/2018/05/17/并发编程-并发工具类/","excerpt":"","text":"在JDK的并发包中提供了几个非常有用的并发工具类。CountDownLatch、CyclicBarrier和Semaphore提供了并发流程控制手段，Exchanger提供了两个线程之间交换数据的手段，本文将配合应用场景介绍该如何使用这几个工具类。 1. CountDownLatchCountDownLatch是JDK 5+里面闭锁的一个实现，他允许一个或多个线程等待其他线程完成各自的工作后再执行。 闭锁（Latch）：一种同步方法，可以延迟线程的进度直到线程到达某个终点状态。 与CountDownLatch第一次交互是主线程等待其它的线程，主线程必须在启动其它线程后立即调用await方法，这样主线程的操作就会在这个方法上阻塞，直到其他线程完成各自的任务。 其他的N个线程必须引用闭锁对象，因为他们需要通知CountDownLatch对象，他们已经完成了各自的任务，这种机制就是通过调用countDown()方法来完成的。每调用一次这个方法，在构造函数中初始化的count值就减1，所以当N个线程都调用了这个方法count的值等于0，然后主线程就能通过await方法，恢复自己的任务。 与Join的区别：调用join方法需要等待thread执行完毕才能继续向下执行,而CountDownLatch只需要检查计数器的值为零就可以继续向下执行，相比之下，CountDownLatch更加灵活一些，可以实现一些更加复杂的业务场景。 1.1 使用场景 开启多个线程分块下载一个大文件，每个线程只下载固定的一截，最后由另外一个线程来拼接所有的分段。 应用程序的主线程希望在负责启动框架服务的线程已经启动所有的框架服务之后再执行。 确保一个计算不会执行，直到所需要的资源被初始化。 1.2 主要方法12345678910//初始化计数的次数，不能重置public CountDownLatch(int count); //调用此方法则计数减1public void countDown(); //得到当前的计数Public Long getCount(); //调用此方法会一直阻塞当前线程，直到计时器的值为0，除非线程被中断。public void await() throws InterruptedException //调用此方法会一直阻塞当前线程，直到计时器的值为0，除非线程被中断或者计数器超时，返回false代表计数器超时。Public boolean await(long timeout, TimeUnit unit) 1.3 使用案例 latch.countDown(); 建议放到finally语句里。 对这个计数器的操作都是原子操作，同时只能有一个线程去操作这个计数器。 12345678910111213141516171819202122232425262728293031public class CountDownLatchTest &#123; private final CountDownLatch latch = new CountDownLatch(3); private final ReentrantLock lock = new ReentrantLock(); private int count; public int getCount()&#123; return this.count; &#125; public class RunnableTask implements Runnable&#123; @Override public void run() &#123; try &#123; lock.lock(); count += 100; &#125;finally &#123; latch.countDown(); lock.unlock(); &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException&#123; CountDownLatchTest demo = new CountDownLatchTest(); int i = 3; while(i-- &gt; 0)&#123; new Thread(demo.new RunnableTask()).start(); &#125; demo.latch.await(); System.out.println(demo.getCount()); &#125;&#125; 三个线程分别对count加100，等三个线程执行完后，主线程输出count的值。输出300 2. CyclicBarrier字面意思是可以循环使用的屏障。他要做的事情是让一组线程到达一个同步点时被阻塞，直到最后一个线程到达同步点，才会打开屏障，所有线程继续运行。 默认的构造方法 CyclicBarrier(int parties) ，参数代表屏障拦截的线程数量，每个线程调用await方法告诉CyclicBarrier已经到达屏障，然后被阻塞。 1.1 使用场景可用于多线程计算数据，最后合并计算结果 1.2 主要方法123456789101112131415//初始化public CyclicBarrier(int parties)//barrierAction表示被拦住的线程需要执行的任务public CyclicBarrier(int parties, Runnable barrierAction)//被拦住的线程调用次函数进入阻塞状态public int await()//被拦住的线程调用次函数进入阻塞状态，超时唤醒public int await(long timeout, TimeUnit unit)public void reset() //返回需要被拦住的线程数量public int getParties() //查询此屏障是否处于断开状态public boolean isBroken()//返回已被拦住的线程数量public int getNumberWaiting() 1.3 使用案例初始化线程数为2，加上主线程调用await()3次，所以得出结论主线程调用不计入await次数之内。123456789101112131415161718192021222324252627public class CyclicBarrierTest &#123; private static CyclicBarrier cb = new CyclicBarrier(2); private static ReentrantLock lock = new ReentrantLock(); private static int count; public static class RunnableTask implements Runnable&#123; @Override public void run() &#123; try &#123; lock.lock(); count += 100; cb.await(); &#125;catch (Throwable e)&#123; &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; public static void main(String[] args) throws Exception&#123; for(int i = 0; i &lt; 2; i++) &#123; new Thread(new RunnableTask()).start(); &#125; cb.await(); System.out.println(count); &#125;&#125; 输出200 1.4 与CountDownLatch的区别 CountDownLatch的计数器只能使用一次，而CyclicBarrier的计数器可以使用reset()方法重置，可以使用多次，所以CyclicBarrier能够处理更为复杂的场景； CyclicBarrier还提供了一些其他有用的方法，比如getNumberWaiting()方法可以获得CyclicBarrier阻塞的线程数量，isBroken()方法用来了解阻塞的线程是否被中断； CountDownLatch允许一个或多个线程等待一组事件的产生，而CyclicBarrier用于等待其他线程运行到栅栏位置。 3. SemaphoreSemaphore是用来控制同事访问特定资源的线程数量，它通过协调各个线程以保证合理的使用公共资源。 3.1 使用场景可用于做流量控制，特别是公用资源有限的场景，比如数据库连接。 4. ExchangerExchanger类可用于两个线程之间交换信息。可简单地将Exchanger对象理解为一个包含两个格子的容器，通过exchanger方法可以向两个格子中填充信息。当两个格子中的均被填充时，该对象会自动将两个格子的信息交换，然后返回给线程，从而实现两个线程的信息交换。 Exchanger类仅可用作两个线程的信息交换，当超过两个线程调用同一个exchanger对象时，得到的结果是不确定的，exchanger对象仅关心其包含的两个“格子”是否已被填充数据，当两个格子都填充数据完成时，该对象就认为线程之间已经配对成功，然后开始执行数据交换操作。12345678910111213141516171819202122232425public class ExchangerTest &#123; private static Exchanger&lt;String&gt; exgr = new Exchanger&lt;&gt;(); private static ExecutorService threadpool = Executors.newFixedThreadPool(3); public static void main(String[] args)&#123; threadpool.execute(() -&gt; &#123; String a = &quot;银行流水A&quot;; try &#123; exgr.exchange(a); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); threadpool.execute(() -&gt; &#123; String b = &quot;银行流水B&quot;; try &#123; String a = exgr.exchange(b); System.out.println(a); &#125; catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125;); threadpool.shutdown(); &#125;&#125;","categories":[],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"http://yoursite.com/child/tags/并发编程/"}],"keywords":[]},{"title":"并发编程-线程池源码详解","slug":"并发编程-线程池源码详解","date":"2018-05-15T03:28:21.000Z","updated":"2019-06-09T01:21:43.793Z","comments":true,"path":"2018/05/15/并发编程-线程池源码详解/","link":"","permalink":"http://yoursite.com/child/2018/05/15/并发编程-线程池源码详解/","excerpt":"","text":"阿里巴巴Java手册有一条：【强制】线程资源必须通过线程池提供，禁止在应用程序中显示创建线程。说明：使用线程池的好处是减少在创建和销毁线程上所花的时间以及系统资源的开销，解决资源不足的问题。如果不使用线程池，有可能造成系统创建大量同类线程导致消耗完内存或者过度切换的问题。 简单来说使用线程池有以下几个目的： 避免频繁的创建。线程是稀缺资源。 解耦。线程的创建与执行分开，方便维护。 线程资源复用。 1. 线程池原理本文从线程池的创建开始说起，跟着源码分析一下线程池的工作原理，本文源码基于JDK1.8 1.1 ExecutorsExecutors有一个私有的默认构造函数，不能实例化，是一个工具类，主要用于提供各种类型线程池创建的静态方法。提供的静态创建方法有： newSingleThreadExecutor 创建一个执行器，该执行器使用一个工作线程操作一个无界队列。(但是请注意，如果这个线程在关闭之前的执行过程中由于失败而终止，那么如果需要执行后续任务，将会有一个新的线程代替它。与 newFixedThreadPool(1)不同，返回的executor不能被其他线程重新配置。 newFixedThreadPool 创建一个线程池，该线程池重用固定数量的线，如果任何线程在关闭之前的执行过程中由于失败而终止，那么如果需要执行后续任务，则会替换一个新线程。池中的线程将一直存在，直到显式关闭为止操作一个共享的无界队列。 newWorkStealingPool 创建一个线程池，该线程池维护足够的线程以支持给定的并行度级别，并且可以使用多个队列来减少争用。并行度级别对应于积极参与或可用参与任务处理的线程的最大数量。线程的实际数量可以动态地增长和收缩。工作窃取池不能保证所提交任务的执行顺序。 newCachedThreadPool 创建一个线程池，该线程池根据需要创建新线程，但在可用时将重用以前构造的线程。这些池通常会提高执行许多短期异步任务的程序的性能。如果可用，对execute的调用将重用以前构造的线程。如果没有可用的现有线程，将创建一个新线程并将其添加到池中。未使用60秒的线程将被终止并从缓存中删除。因此，长时间空闲的池不会消耗任何资源。注意，可以使用ThreadPoolExecutor构造函数创建具有相似属性但不同细节(例如超时参数)的池。 newSingleThreadScheduledExecutor 创建一个单线程执行器，该执行器可以安排命令在给定的延迟之后运行，或者定期执行。(但是请注意，如果这个线程在关闭之前的执行过程中由于失败而终止，那么如果需要执行后续任务，将会有一个新的线程代替它。)，与 newFixedThreadPool(1)不同，返回的executor不能被其他线程重新配置。 newScheduledThreadPool 创建一个线程池，该线程池可以在给定延迟之后调度命令运行，或者定期执行命令。 Executors 返回的线程池对象的弊端如下： FixedThreadPool 和 SingleThreadPool: 允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。 CachedThreadPool 和 ScheduledThreadPool: 允许的创建线程数量为 Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。 1.2 ThreadPoolExecutor首先看一下newFixedThreadPool创建方法的源码：12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 事实上，大多数类型的线程池创建都是调用new ThreadPoolExecutor(…)创建一个ThreadPoolExecutor对象，只不过初始化参数不同而已。newWorkStealingPool创建时构造的是ForkJoinPool对象，本文不述。 下面是ThreadPoolExecutor的其中一个构造方法：123456789public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; ...&#125; 初始化参数的如下： corePoolSize 表示线程池的核心数,线程池保持alive状态的线程数，即使线程是空闲的。 maximumPoolSize 表示线程池支持的最大的线程个数。 keepAliveTime 表示池中线程空闲后的生存时间 unit 表示上一个时间参数的单位 workQueue 用于存放任务的阻塞队列 threadFactory 表示创建线程的工厂，一般使用默认的线程创建工厂Excutors.DefaultThreadFactor() handler 当队列和最大线程池都满了之后的饱和策略，一般使用默认的handler—AbortPolicy（内部类） 1234567891011121314151617代码摘自：java.util.concurrent.ThreadPoolExecutorprivate static final RejectedExecutionHandler defaultHandler = new AbortPolicy();public static class AbortPolicy implements RejectedExecutionHandler &#123; public AbortPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; throw new RejectedExecutionException(\"Task \" + r.toString() + \" rejected from \" + e.toString()); &#125;&#125;final void reject(Runnable command) &#123; handler.rejectedExecution(command, this);&#125; 用户也可以自己实现RejectedExecutionHandler接口定义一个handler，当提交的任务因为各种原因被线程池拒绝，就会调用rejectedExecution方法。 1.2.1 提交任务excute()使用线程池时，通常我们用1threadPool.execute(new Job()); 这样的方式提交一个任务到线程池中，所以线程池ThreadPoolExecutor的核心逻辑就是execute()函数了，这个方法是在Excutor接口中声明。 在分析核心逻辑之前，先了解一下线程池重定义的状态，这些状态都和线程的执行密切相关 1234567891011121314代码摘自：java.util.concurrent.ThreadPoolExecutorprivate static final int COUNT_BITS = Integer.SIZE - 3;private static final int CAPCITY = (1 &lt;&lt; COUNT_BITS) - 1;private static final int RUNNING = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;private static final int STOP = 1 &lt;&lt; COUNT_BITS;private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS;private static int runStateOf(int c)&#123;return c &amp; ~CAPCITY;&#125;private static int workerCountOf(int c)&#123;return c &amp; CAPCITY;&#125;private static int ctlOf(int rs, int wc)&#123;return rs | wc;&#125; 分析上面的代码得到下表： 常量名 二进制 CAPCITY 0001 1111 1111 1111 1111 1111 1111 1111 RUNNING 1110 0000 0000 0000 0000 0000 0000 0000 SHUTDOWN 0000 0000 0000 0000 0000 0000 0000 0000 STOP 0010 0000 0000 0000 0000 0000 0000 0000 TIDYING 0100 0000 0000 0000 0000 0000 0000 0000 TERMINATED 0110 0000 0000 0000 0000 0000 0000 0000 由上表可以看出，原子对象ctl的前三位表示状态，后29位记录池中worker的个数，CAPCITY就像是一个掩码，通过掩码可以快速的从ctl中获得当前线程池的运行状态和池中的worker个数。 JDK1.8的并发包中不再通过设置阻塞队列的长度来限制任务的提交。阻塞队列的长度初始化之后就不能改变，因此如果担心阻塞队列太大导致内存占用太多，可以从两方面入手：1、初始化的时候选择合适的阻塞队列大小；2、调高corePoolSize或maxmumPoolSize加快任务的处理速度。参数的动态调整见下文。 线程池状态简述： RUNNING 是运行状态，指可以接受任务，执行队列里的任务。 SHUTDOWN 是指调用了shutdown()函数，不再接受新任务，但是会把队列里的任务执行完毕。 STOP 是指调用了shutdownNow()函数，不再接受新任务，同时终端正在执行的任务并丢弃队列中的待执行任务。 TIDYING 指所用任务都执行完毕。 TERMINATED 终止状态，在调用shutdown()/shutdownNow()中都会尝试更新这个状态。 下面分析核心代码excute()方法123456789101112131415161718192021222324252627代码摘自：java.util.concurrent.ThreadPoolExecutorpublic void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); //1、获取当前线程池的状态 int c = ctl.get(); //2、当线程数量小于corePoolSize，创建新线程运行 if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; //线程池线程数大于核心线程数 或者 新增worker失败 会执行下面的代码 //3、如果线程池处于运行状态，并且写入阻塞队列成功 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); //4、再次检查线程状态，若线程池状态改变（非运行状态），需要从阻塞队列移除该任务，并执行拒绝策略 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); //5、如果线程池状态没有发生变化，判断当前池是否为空，为空就创建一个没有指定具体任务的新线程 else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; //6、如果第一次检查不通过（线程池不处于运行状态或者任务写入队列失败），尝试新建线程，如果失败则执行拒绝策略 else if (!addWorker(command, false)) reject(command);&#125; 疑问：addWorker(null, false) 添加了一个没有具体任务的worker，作用是什么？ 如果线程池中的线程数为0，但任务队列中有需要执行的任务，这时候新建一个没有任务的线程是为了去执行任务队列中的任务。 下图表示了当有任务提交到线程池后线程池的处理流程： 1.2.2 创建工人（线程）addWorker(Runnable firstTask, boolean core) 参数： firstTask： worker线程的初始任务，可以为空core： true：将corePoolSize作为上限，false：将maximumPoolSize作为上限 addWorker函数是execute函数的核心逻辑，线程池持有一个HashSet对象存放池中的workers，每个worker对应一个线程，addWorker的作用就是创建worker执行任务。 addWorker方法有4种调用方式： addWorker(command, true) addWorker(command, false) addWorker(null, false) addWorker(null, true) 在execute方法中就使用了前3种，结合这个方法进行以下分析 线程数小于corePoolSize时，放一个需要处理的task进Workers Set。如果Workers Set长度超过corePoolSize，就返回false 当队列被放满时，就尝试将这个新来的task直接放入Workers Set，而此时Workers Set的长度限制是maximumPoolSize。如果线程池也满了的话就返回false 放入一个空的task进workers Set，长度限制是maximumPoolSize。这样一个task为空的worker在线程执行的时候会去任务队列里拿任务，这样就相当于创建了一个新的线程，只是没有马上分配任务 这个方法就是放一个null的task进Workers Set，而且是在小于corePoolSize时，如果此时Set中的数量已经达到corePoolSize那就返回false，什么也不干。实际使用中是在prestartAllCoreThreads()方法，这个方法用来为线程池预先启动corePoolSize个worker等待从workQueue中获取任务执行 下面将源代码分成两部分进行分析，第一段代码为检验模块，主要判断线程池当前是否为可以添加worker线程的状态，可以则继续下一步，不可以则返回 false，具体分为三种情况： 线程池状态&gt;shutdown，可能为stop、tidying、terminated，不能添加worker线程 线程池状态==shutdown，firstTask不为空，不能添加worker线程，因为shutdown状态的线程池不接收新任务 线程池状态==shutdown，firstTask==null，workQueue为空，不能添加worker线程，因为firstTask为空是为了添加一个没有任务的线程再从workQueue获取task，而workQueue为空，说明添加无任务线程已经没有意义 当以上的情况都没有发生，在创建worker之前还需要验证一下线程池中的线程数量有没有达到极限，达到极限直接返回false；没达到极限，先CAS修改线程池状态(+1操作)，若修改成功，直接退出检验模块循环，执行下面的运行模块。CAS设置状态失败则重新获取运行状态进行二重检验，若线程池状态发生改变，从头开始大循环检验，否则继续小循环执行cas。 123456789101112131415161718192021222324252627282930313233343536代码摘自：java.util.concurrent.ThreadPoolExecutorprivate final ReentrantLock mainLock = new ReentrantLock();private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); //状态为 RUNNING 继续往下执行 //状态为不为RUNNING时，如果状态为SHUTDOWN并且firstTask为null并且阻塞队列空时，可继续向下运行 //否则返回false，添加worker失败 if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); //线程数大于CAPACITY //线程数大于corePoolSize或maximumPoolSize（取决于core） //否则添加worker失败 if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; //线程数验证通过，使用CAS对c加1，执行成功则终止大循环继续向下运行 if (compareAndIncrementWorkerCount(c)) break retry; //CAS设置失败则重新获取运行状态，若线程池状态发生改变，从头开始大循环，否则继续小循环 c = ctl.get(); if (runStateOf(c) != rs) continue retry; &#125; &#125; ... &#125; 第二部分为运行模块，直接进入主题，将提交的任务包装成worker对象，加入worker set 并启动该worker的线程，worker插入set需要加锁。 123456789101112131415161718192021222324252627282930313233343536373839404142private boolean addWorker(Runnable firstTask, boolean core) &#123; ... boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 二重验证，获取池状态 int rs = runStateOf(ctl.get()); //状态为RUNNING 则通过继续执行 //状态为SHUTDOWN并且提交的任务为null 则通过继续执行 //否则直接执行finally解锁 if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // 如果worker中的线程t已经处于运行状态 throw new IllegalThreadStateException();//抛异常 workers.add(w);//将w加入HashSet int s = workers.size(); //更新largestPoolSize，largestPoolSize只能在lock下修改 if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125; addWorker执行流程总结： 判断是否可以addworker 线程池当前线程数量是否超过上限（corePoolSize 或 maximumPoolSize），超过了return false，没超过则对workerCount+1，继续下一步 在线程池的ReentrantLock保证下，向Workers Set中添加新创建的worker实例，添加完成后解锁，并启动worker线程，只有在新建的线程成功启动的情况下才能返回 true。如果添加worker入Set失败或启动失败，调用addWorkerFailed()逻辑 1.2.3 worker创建失败的善后处理addWorkerFailed() 当任务执行失败，程序需要进行善后处理，即恢复任务执行过程中对内存的改动，移除Worker set中的worker对象，修改池状态，最后尝试终止线程池。1234567891011121314代码摘自：java.util.concurrent.ThreadPoolExecutorprivate void addWorkerFailed(Worker w) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; if (w != null) workers.remove(w); //CAS对ctl减1 decrementWorkerCount(); tryTerminate(); &#125; finally &#123; mainLock.unlock(); &#125;&#125; 1.2.4 空闲线程怎么从阻塞队列中取任务2. 配置线程池流程介绍完了先来总结以下上文提到了几个核心参数在流程中的具体作用，然后介绍应该如何配置。 2.1 参数详解 corePoolSize：核心线程数 核心线程会一直存活，即使没有任务需要执行 当线程数小于核心线程数时，即使有线程空闲，线程池也会有限创建新的线程 设置allowCoreThreadTimeout=true（默认是false）时，核心线程会超时关闭 maximumPoolSize：最大线程数 当线程数 &gt;= corePoolSize，且队列已满。线程池会创建新线程来处理 当线程数 = maxmumPoolSize，且队列任务已满是，线程会拒绝处理任务 keepAliveTime：线程空闲时间 当线程空闲时间达到keepAliveTime时，线程会退出，知道线程数量 = corePoolSize 如果allowCoreThreadTimeout = true，则会知道线程数量 = 0 rejectedExecutionHandler：任务拒绝处理器两种情况会拒绝处理任务： 当线程数已经达到maxmumPoolSize，且队列已满，会拒绝新任务 当线程池被调用shutdown()后，会等待线程池里的任务执行完毕，再shutdown。如果在调用shutdown()和线程池真正shutdown之间提交任务，会拒绝新任务 线程池会调用rejectedExecutionHandler来处理这个任务。如果没有设置默认是AbortPolicy，会抛出异常，ThreadPoolExecutor类有几个内部实现类来处理这类情况： AbortPolicy 丢弃任务，抛运行时异常CallerRunsPolicy 执行任务，调用Runnable的run强制执行。DiscardPolicy 忽视，什么都不会发生DiscardOldestPolicy 如果是应为第一种情况被拒绝，则从阻塞队列中踢出最先进入队列（最后一个执行）的任务，然后再次提交当前任务。 实现RejectedExecutionHandler接口，可自定义处理器处理reject。 2.2 参数配置默认值：12345corePoolSize=1maxPoolSize=Integer.MAX_VALUEkeepAliveTime=60sallowCoreThreadTimeout=falserejectedExecutionHandler=AbortPolicy() 如何设置，需要根据几个值来决定： tasks ：系统每秒任务数，假设为500~1000 taskcost：单任务耗时，假设为0.1s responsetime：系统允许容忍的最大响应时间，假设为1s 做几个计算：corePoolSize = 系统每秒任务数/单线程每秒任务数 = 系统每秒任务数/（1/单任务耗时）corePoolSize = tasks/(1/taskcost) =taskstaskcout = (500~1000)0.1 = 50~100 。 corePoolSize设置应该大于50，根据8020原则，如果80%的系统每秒任务数小于800，那么corePoolSize设置为80即可 maxPoolSize = （最大任务数-队列容量）/每个线程每秒处理能力 = 最大线程数计算可得 maxPoolSize = (1000-80)/10 = 92队列容量在初始化池的时候指定，一旦指定不能修改 rejectedExecutionHandler：根据具体情况来决定，任务不重要可丢弃，任务重要则要利用一些缓冲机制来处理 keepAliveTime和allowCoreThreadTimeout采用默认通常能满足以上都是理想值，实际情况下要根据机器性能来决定。如果在未达到最大线程数的情况机器cpu load已经满了，则需要通过升级硬件和优化代码，降低taskcost来处理。 2.3 参数动态调整用户可以通过corePoolSize和maxmumPoolSize的getter/setter进行访问和设置，具体怎么设置需要根据当前池中一些状态变量进行判断，如： getLargestPoolSize() 获取到目前为止达到过的最大线程数 getPoolSize() 获取当前线程数 getQueue().size() 获取当前阻塞队列任务数 3. 关闭线程池关闭线程池无非就是两个方法 shutdown()/shutdownNow()。 但他们有着重要的区别： shutdown() 执行后停止接受新任务，会把队列的任务执行完毕。 shutdownNow() 也是停止接受新任务，但会中断所有的任务，将线程池状态变为 stop。 两个方法都会中断线程，用户可自行判断是否需要响应中断。shutdownNow() 要更简单粗暴，可以根据实际场景选择不同的方法。 通常是按照以下方式关闭线程池的：12345678910long start = System.currentTimeMillis();for (int i = 0; i &lt;= 5; i++) &#123; pool.execute(new Job());&#125;pool.shutdown();while (!pool.awaitTermination(1, TimeUnit.SECONDS)) &#123; LOGGER.info(\"线程还在执行。。。\");&#125;long end = System.currentTimeMillis();LOGGER.info(\"一共处理了【&#123;&#125;】\", (end - start)); pool.awaitTermination(1, TimeUnit.SECONDS) 会每隔一秒钟检查一次是否执行完毕（状态为 TERMINATED），当从 while 循环退出时就表明线程池已经完全终止了。","categories":[],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"http://yoursite.com/child/tags/并发编程/"}],"keywords":[]},{"title":"并发编程-ThreadLocal原理","slug":"并发编程-ThreadLocal原理","date":"2018-05-03T12:58:11.000Z","updated":"2019-05-17T04:53:22.000Z","comments":true,"path":"2018/05/03/并发编程-ThreadLocal原理/","link":"","permalink":"http://yoursite.com/child/2018/05/03/并发编程-ThreadLocal原理/","excerpt":"","text":"ThreadLocal是一个本地线程副本变量工具类，ThreadLocal的实例代表了一个线程局部的变量，主要用于将私有线程和该线程存放的副本对象做一个映射，各个线程之间的变量互不干扰，在高并发场景下，可以实现无状态的调用，特别适用于各个线程依赖不通的变量值完成操作的场景。 1. 我是什么 是让线程拥有独占的变量 它通过set、get方法进行设值和取值操作 它可以覆盖initialValue方法设置初始值，在没进行set之前调用get会调用初始化方法，一个线程只会调用一次 每个线程都会有一个指向threadLocal的弱引用，只要线程一直存活或者该threadLocal实例能被访问到，就不会被GC清理掉。当jvm内存溢出时，会清理掉值为Null的弱引用。 2. 使用方法1234567891011121314public static void main(String[] args)&#123; ThreadLocal&lt;String&gt; stringThreadLocal = new ThreadLocal&lt;String&gt;()&#123; @Override protected String initialValue()&#123; return &quot;default string&quot;; &#125; &#125;; for(int i = 0; i&lt; 10; i++)&#123; new Thread(() -&gt; &#123; stringThreadLocal.set(Thread.currentThread().getName()); System.out.println(stringThreadLocal.get()); &#125;).start(); &#125;&#125; 3. 我在一个map里每个线程都有一个ThreadLocalMap对象，map中存放了(ThreadLocal,t)键值对 3.1 get源码12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; 获取当前线程内部的ThreadLocalMap map存在则获取当前ThreadLocal对应的值 不存在则调用setInitialValue进行初始化 3.2 setInitialValue()源码12345678910private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125; 调用重载的initialValue方法获取初始值 获取当前线程的ThreadLocalMap map存在则将初始值put进去 map不存在则使用初始值为当前线程创建ThreadLocalMap 3.3 set(T value)源码12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125; 获取当前线程内部的ThreadLocalMap map存在则把当前ThreadLocal和value添加到map中 map不存在则创建一个ThreadLocalMap，保存到当前线程内部 小结每个线程都有一个ThreadLocalMap类型的私有变量，当为线程添加ThreadLocal对象时，就是保存到了这个map中，所以线程之间不会相互干扰。 4. 我还有一个大坑ThreadLocal使用不当，会引发内存泄露的问题ThreadLocal对象存在thread对象中，只要线程没有死亡，该对象就不会被回收 remove()源码12345public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this); &#125; 获取当前线程内部的ThreadLocalMap，存在则从map中删除这个ThreadLocal对象。 5. 无处不在的map分析完4个公开方法的源码，发现每个方法都离不开ThreadLocalMap类，下面分析一下这个无处不在的map。 ThreadLocalMap是一个自定义的Hashmap，专门用来保存线程的ThreadLocal变量 它的操作仅限于ThreadLocal类中，不对外暴露 这个类被用在Thread类的私有变量threadLocals和inheritableThreadLocals上 为了能够保存大量且存活时间较长的threadLocal实例，hash table entries采用了WeakReferences作为key的类型 一旦hash table运行空间不足，key为null的entry就会被清理掉 源码1234567891011121314151617181920212223242526272829static class ThreadLocalMap &#123; static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; private static final int INITIAL_CAPACITY = 16; private Entry[] table; private int size = 0; private int threshold; // Default to 0 private void setThreshold(int len) &#123; threshold = len * 2 / 3; &#125; ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; table = new Entry[INITIAL_CAPACITY]; int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); size = 1; setThreshold(INITIAL_CAPACITY); &#125;&#125;","categories":[],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"http://yoursite.com/child/tags/并发编程/"}],"keywords":[]},{"title":"并发编程-阻塞队列BQ","slug":"并发编程-阻塞队列BQ","date":"2018-04-27T07:37:41.000Z","updated":"2019-06-12T09:27:09.764Z","comments":true,"path":"2018/04/27/并发编程-阻塞队列BQ/","link":"","permalink":"http://yoursite.com/child/2018/04/27/并发编程-阻塞队列BQ/","excerpt":"","text":"阻塞队列常用于生产者-消费者场景。 BQ有4套出队入队操作： offer(e) &amp; poll() 这套操作不会阻塞线程，队列满/空的时候返回特殊值 false/null add(e) &amp; remove() 该操作对offer(e) &amp; pool()返回的特殊值抛出异常 put(e) &amp; take() 阻塞方法，遇到队列满/空的时候会阻塞，直到收到通知可以继续执行 offer(e,time,unit) &amp; poll(time,unit) 超时阻塞方法，超时返回 false/null Jdk7中给出了7种BQ： ArrayBlockingQueue LinkedBlockingQueue priorityBlockingQueue DelayQueue SynchronousQueue LinkenTransferQueue LinkedBlockingDeque 本文将以LinkedBlockingQueue为例进行源码解读 1. Condition任意的一个java对象，都拥有一组监视器方法（定义在Object类中），主要包括wait()、wait(long timeout)、notify()、notifyAll()方法，这些方法与sychronized关键字配合使用，可以实现等待/通知模式。Condition接口也通过平了类似Object的监视器方法，与Lock配合可以实现等待/通知模式。但是这两种方式在使用方式以及功能特性上还是有差别的： 每个Object监视器只有一个等待队列，而Condition接口可以支持多个等待队列 当前线程释放锁进入等待状态，Object监视器在等待过程中是不相应中断的，而Condition接口是可以的 Object监视器不支持线程等待到将来的某个特定时间，Condition接口支持 1.1 Condition的原理将在另一篇中解析AQS.ConditionObject类的源码 1.2 LBQ中的ConditionLBQ的入队和出队使用了两把重入锁，相应的也有两个条件队列notFull和notEmpty： 当队列满的时候执行入队操作，入队线程会进入notFull等待，当有元素出队则通知入队线程–队列notFull，可以继续执行； 当队列为空执行出队操作，出队线程会进入notEmpty等待，当有元素入队后则通知出队线程–队列notEmpty，可以继续执行。1234567891011/** Lock held by take, poll, etc */private final ReentrantLock takeLock = new ReentrantLock();/** Wait queue for waiting takes */private final Condition notEmpty = takeLock.newCondition();/** Lock held by put, offer, etc */private final ReentrantLock putLock = new ReentrantLock();/** Wait queue for waiting puts */private final Condition notFull = putLock.newCondition(); 具体如何使用的，见下文LBQ源码分析 2. offer(e) &amp; poll()这套方法是在接口 Queue 中定义12345678910111213141516171819202122232425262728以下代码摘自： java.util.concurrent.LinkedBlockingQueuepublic boolean offer(E e) &#123; if (e == null) throw new NullPointerException(); final AtomicInteger count = this.count; //满了直接返回失败 if (count.get() == capacity) return false; int c = -1; Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; putLock.lock(); try &#123; if (count.get() &lt; capacity) &#123; enqueue(node); c = count.getAndIncrement(); //c是更新之前的计数 if (c + 1 &lt; capacity) //更新之后还未满，唤醒一个入队线程 notFull.signal(); &#125; &#125; finally &#123; putLock.unlock(); &#125; if (c == 0) //更新之前是空的，更新完就不空了，唤醒一个阻塞的出队线程 signalNotEmpty(); return c &gt;= 0;&#125; offer(e)方法总结： 开始先检查参数是否为null，null则抛出NPE异常； 然后判断队列是否已经满了，满了直接返回false； 以上检查都通过，构造新节点，获取入队锁putLock 二重检查，判断队列是否未满，如果未满执行入队，计数器加1，如果计数器更新之后还小于capacity，则唤醒一个入队线程(如果有入队线程阻塞) 最后判断一下该线程入队前是否为空队列，如果之前是空的，入队完成就可以唤醒一个阻塞的出队线程。 最后入队成功返回true12345678910111213141516171819202122public E poll() &#123; final AtomicInteger count = this.count; if (count.get() == 0) return null; E x = null; int c = -1; final ReentrantLock takeLock = this.takeLock; takeLock.lock(); try &#123; if (count.get() &gt; 0) &#123; x = dequeue(); c = count.getAndDecrement(); if (c &gt; 1) notEmpty.signal(); &#125; &#125; finally &#123; takeLock.unlock(); &#125; if (c == capacity) signalNotFull(); return x;&#125; poll()方法总结： 首先检查队列是否空，若空直接返回null，不空继续执行； 获取出队锁takelock 二重检查，检查队列是否不空，不空执行出队，计数器减1，计数器更新之后还大于0(出队后队列还不空)，唤醒一个出队线程（如果有阻塞的出队线程） 释放锁，然后判断此次出队前队列是否满的，若出队前满则此次出队结束就有余位了，唤醒一个阻塞入队线程执行 3. add(e) &amp; remove()这套方法也是在 Queue 中定义，add方法继承自Collection接口，内部调用了offer(e) &amp; pool()，对队空或队满返回的特殊值做异常处理，队满执行入队操作抛 IllegalStateException 异常；队空做出队操作抛 NoSuchElementException 异常 。源码如下：123456789101112131415以下代码摘自： java.util.AbstractQueuepublic boolean add(E e) &#123; if (offer(e)) return true; else throw new IllegalStateException(\"Queue full\");&#125;public E remove() &#123; E x = poll(); if (x != null) return x; else throw new NoSuchElementException();&#125; 4. put(e) &amp; take()这是阻塞接口，定义在 BlockingQueue 接口中12345678910111213141516171819202122232425262728以下代码摘自： java.util.concurrent.LinkedBlockingQueuepublic void put(E e) throws InterruptedException &#123; if (e == null) throw new NullPointerException(); // 除非设置，否则保持计数器的值为-1表示失败 int c = -1; Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try &#123; //这里使用while进行判断，是因为await的线程被唤醒时从await返回，需要再进行一次判断 //如果使用if的话就直接往下运行了，运行结果会不稳定。 while (count.get() == capacity) &#123; notFull.await(); &#125; enqueue(node); //返回旧的计数然后计数+1 c = count.getAndIncrement(); //入队之后如果还有位置，给notFull队列发信号，唤醒put线程 if (c + 1 &lt; capacity) notFull.signal(); &#125; finally &#123; putLock.unlock(); &#125; //这个c是入队之前的计数，入队之前为空，入队后有元素了，所以要唤醒一个出队线程 if (c == 0) signalNotEmpty();&#125; put(e)方法总结： 检查参数为空抛NPE异常 使用参数构造新节点，获取入队锁putLock 当队满时，调用 notFull.await() 阻塞当前线程，注意此处使用while语句进行判断，原因后文分析。 队不满执行入队，计数器 +1 判断计数器更新后队是否未满，未满则唤醒阻塞的入队线程（如果存在的话） 解锁 判断此次入队前是否为空队列，如果是，此次入队完成后就不是了，所以要唤醒一个阻塞的出队线程。 无返回值 123456789101112131415161718192021public E take() throws InterruptedException &#123; E x; int c = -1; final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly();//1 try &#123; while (count.get() == 0) &#123;//2 notEmpty.await(); &#125; x = dequeue();//3 c = count.getAndDecrement(); if (c &gt; 1)//4 notEmpty.signal(); &#125; finally &#123; takeLock.unlock();//5 &#125; if (c == capacity)//6 signalNotFull(); return x;//7&#125; take()方法总结： 获取出队锁takeLock 判断队列是否为空，为空就调用notEmpty.await()阻塞线程 不空就执行出队操作，计数器 -1 如果出队后队列仍然不空，唤醒一个阻塞的出队线程（如果存在的话） 解锁 若此次出队之前队列满，执行完本次出队就不满了，可以唤醒一个入队线程 返回出队的元素 5. offer(e,time,unit) &amp; poll(time, unit)超时阻塞方法，定义在 BlockingQueue 接口中，该组方法在put/take的基础上加上了超时返回的功能，出队超时返回null，入队超时返回false。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455以下代码摘自： java.util.concurrent.LinkedBlockingQueuepublic boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException &#123; if (e == null) throw new NullPointerException(); long nanos = unit.toNanos(timeout);//1 int c = -1; final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try &#123; while (count.get() == capacity) &#123; if (nanos &lt;= 0)//超时了 return false; //没超时阻塞，nanos之后自动唤醒 nanos = notFull.awaitNanos(nanos); //唤醒后返回到这里，继续while循环判断队列是否满，还是满就妥妥的超时了 &#125; enqueue(new Node&lt;E&gt;(e)); c = count.getAndIncrement(); if (c + 1 &lt; capacity) notFull.signal(); &#125; finally &#123; putLock.unlock(); &#125; if (c == 0) signalNotEmpty(); return true;&#125;public E poll(long timeout, TimeUnit unit) throws InterruptedException &#123; E x = null; int c = -1; long nanos = unit.toNanos(timeout); final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly(); try &#123; while (count.get() == 0) &#123; if (nanos &lt;= 0)//超时了 return null; //没超时阻塞，nanos之后自动唤醒 nanos = notEmpty.awaitNanos(nanos); //唤醒后返回到这，继续为了循环判断队列是否为空，还是为空妥妥的超时 &#125; x = dequeue(); c = count.getAndDecrement(); if (c &gt; 1) notEmpty.signal(); &#125; finally &#123; takeLock.unlock(); &#125; if (c == capacity) signalNotFull(); return x;&#125; 6. await之前的判断为什么用while用put作为例子解释一下123456789101112putLock.lockInterruptibly();try &#123; while (count.get() == capacity) &#123; notFull.await();//1 &#125; enqueue(node); c = count.getAndIncrement(); //2 if (c + 1 &lt; capacity) notFull.signal();//3&#125; finally &#123; putLock.unlock();//4&#125; 假设A线程入队操作结束后(执行到2位置)，队列还剩一个空位，那么程序会唤醒阻塞队列中的put线程（3位置）B线程 B线程从await返回前需要竞争put锁（await会释放锁），但这时候有个C线程也来竞争put锁并且成功，C执行入队之后队列已经满了 C释放锁之后B获得锁，从await返回（位置1），如果这里使用 if 判断，1位置之后继续向下执行入队操作，显然会出错，因为最后一个空位让C线程用掉了 但是使用 while 判断，await返回之后，还在循环体内，继续循环判断队列是否满，发现满了，再次await。 所以使用while判断其实是在这里进行了一次 double check， 不管是使用await还是wait，都需要while进行判断，不然在多线程环境中就会出错。 7. 其他方法 peek() 返回头结点，队列空返回null element() 调用peak()，peak()返回null则抛异常 NoSuchElementException remove(o) 移除指定的元素，参数接受null，若没找到该元素返回false contains(o) 判断是否包含指定元素，参数为空或不包含返回false remainingCapacity() 返回剩余容量 size() 返回现有元素数量 clear() 原子性的清除所有元素 drainTo(c) 将队列中的元素放到集合c中，返回转换的元素个数","categories":[],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"http://yoursite.com/child/tags/并发编程/"}],"keywords":[]},{"title":"并发编程-共享式AQS源码详解","slug":"并发编程-共享式AQS源码详解","date":"2018-04-25T12:36:12.000Z","updated":"2019-05-21T06:49:12.000Z","comments":true,"path":"2018/04/25/并发编程-共享式AQS源码详解/","link":"","permalink":"http://yoursite.com/child/2018/04/25/并发编程-共享式AQS源码详解/","excerpt":"","text":"上篇文章详细的阐述了AQS在独占模式下的底层原理，本篇主要讲述共享式同步器的原理。 1. acquireShared(int)此方式是共享模式下线程获取贡献资源的入口，他会获取指定量的资源，获取成功直接返回，失败则进入等待队列，知道获取到资源为止，整个过程忽略终端。下面看源码： 12345public final void acquireShared(int arg) &#123; // if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125; 123protected int tryAcquireShared(int arg) &#123; throw new UnsupportedOperationException();&#125; 这里 tryAcquireShared 依然需要自定义同步器去实现，但是AQS已经将返回值的语义定义好了，重载该函数的时候执行逻辑要符合下列语义：-返回负值表示获取失败 返回0表示获取成功，但是没有剩余资源 返回正数表示获取成功，还有剩余资源 tryAcquireShared获取失败则执行 doAcquireShared 方法，看下面源码：12345678910111213141516171819202122232425262728293031323334private void doAcquireShared(int arg) &#123; //将线程以共享方式加入同步队列尾部 final Node node = addWaiter(Node.SHARED); //获取失败吗，默认true（失败） boolean failed = true; try &#123; //记录等待过程是否被中断过 boolean interrupted = false; for (;;) &#123; //拿到前驱节点 final Node p = node.predecessor(); if (p == head) &#123;//如果前驱是头结点 //尝试获取 int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; //自己获取资源的同时，如果还有剩余资源,唤醒后继节点 setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted)//补上中断标志 selfInterrupt(); failed = false; return; &#125; &#125; //前驱不是头结点，获取失败后寻找安全点 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 整个过程与acquireQueued()很相似，区别在于唤醒等待线程的条件不同。setHeadAndPropagate方法在setHead()的基础上多了一步，就是自己苏醒的同时，如果条件符合（比如还有剩余资源），还会去唤醒后继结点，看代码： 1234567891011private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; //与独占式不同原head并没有释放资源 setHead(node); if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); &#125;&#125; 2. releaseShared()上一小节已经把acquireShared()说完了，这一小节就来讲讲它的反操作releaseShared()吧。此方法是共享模式下线程释放共享资源的顶层入口。它会释放指定量的资源，如果成功释放且允许唤醒等待线程，它会唤醒等待队列里的其他线程来获取资源。下面是releaseShared()的源码： 1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; 此方法的流程也比较简单，一句话：释放掉资源后，唤醒后继。跟独占模式下的release()相似，但有一点稍微需要注意：独占模式下的tryRelease()在完全释放掉资源（state=0）后，才会返回true去唤醒其他线程，这主要是基于独占下可重入的考量；而共享模式下的releaseShared()则没有这种要求，共享模式实质就是控制一定量的线程并发执行，那么拥有资源的线程在释放掉部分资源时就可以唤醒后继等待结点。例如，资源总量是13，A（5）和B（7）分别获取到资源并发运行，C（4）来时只剩1个资源就需要等待。A在运行过程中释放掉2个资源量，然后tryReleaseShared(2)返回true唤醒C，C一看只有3个仍不够继续等待；随后B又释放2个，tryReleaseShared(2)返回true唤醒C，C一看有5个够自己用了，然后C就可以跟A和B一起运行。而ReentrantReadWriteLock读锁的tryReleaseShared()只有在完全释放掉资源（state=0）才返回true，所以自定义同步器可以根据需要决定tryReleaseShared()的返回值。 2.1 doReleaseShared()此方法主要用于唤醒后继。下面是它的源码：123456789101112131415161718private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125; 3. Semaphore一个具象化的例子：停车场运作，假设停车场有10个车位，刚开始都是空的。如果同时来了11辆车，看守者只能允许10辆车进入，另一辆排队等候，当有车为空出来，等候车辆进入填满空车位。Semaphore就相当于停车场看守者。 和RentrantLock不同Semaphore没有实现Lock接口，获取资源有响应中断模式和忽略中断模式，中断模式获取资源： 123456public void acquire() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125;public void acquire(int i) throws InterruptedException &#123; sync.acquireSharedInterruptibly(i);&#125; 释放资源统一使用： 123456public void release() &#123; sync.releaseShared(1);&#125;public void release(int i) &#123; sync.releaseShared(i);&#125; 内部同步器sync重载的tryAcquireShared-tryRealseShared源码如下，代码逻辑简单易懂，实现自定义的同步器一般也只需要实现这几个方法。 123456789101112131415161718192021222324252627282930313233//非公平final int nonfairTryAcquireShared(int acquires) &#123; for (;;) &#123; int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125;&#125;//公平protected int tryAcquireShared(int acquires) &#123; for (;;) &#123; if (hasQueuedPredecessors()) return -1; int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125;&#125;protected final boolean tryReleaseShared(int releases) &#123; for (;;) &#123; int current = getState(); int next = current + releases; if (next &lt; current) // overflow throw new Error(&quot;Maximum permit count exceeded&quot;); if (compareAndSetState(current, next)) return true; &#125;&#125;","categories":[],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"http://yoursite.com/child/tags/并发编程/"}],"keywords":[]},{"title":"nginx入门","slug":"nginx入门","date":"2018-04-23T07:17:36.000Z","updated":"2019-04-26T07:17:24.000Z","comments":true,"path":"2018/04/23/nginx入门/","link":"","permalink":"http://yoursite.com/child/2018/04/23/nginx入门/","excerpt":"","text":"Nginx是一款自由的、开源的、高性能的HTTP服务器和反向代理服务器；同时也是一个IMAP、POP3、SMTP代理服务器；Nginx可以作为一个HTTP服务器进行网站的发布处理，另外Nginx可以作为反向代理进行负载均衡的实现。 1、正向代理与反向代理1.1 正向代理：代理服务器代表的是客户端，代理对服务器端透明。正向代理的应用场景： vpn 缓存，加速访问资源 对客户端访问授权，上网进行认证 记录用户的上网记录，对外隐藏用户信息 正向代理产品：CCProxy 1.2 反向代理：代理服务器代表的是服务器端，代理对客户端透明反向代理的应用场景： 保证内网的安全，可以使用反向代理提供WAF功能，阻止web攻击 负载均衡 反向代理产品：Nginx 2、nginx安装2.1 安装环境 yum -y install wget #安装下载工具 yum install -y gcc gcc-c++ #安装gcc编译环境 yum install -y pcre-devel #安装PERE库 yum -y install openssl openssl-devel #安装OpenSsl库 2.2 准备安装nginx wget http://nginx.org/download/nginx-1.14.0.tar.gz #下载 tar -zxf nginx-1.14.0.tar.gz #解压 cd nginx-1.14.0 sed -i -e’s/1.14.0//g’ -e’ s/nginx\\//WS/g’ -e’s/“NGINX”/“WS”/g’ src/core/nginx.h #隐藏版本号(安全性考虑，爆出有些版本的nginx存在漏洞，容易被攻击) 2.3编译安装nginx useradd www #添加用户，不添加默认为nobody ./configure –user=www –group=www –prefix=/usr/local/nginx –with-http_ssl_module make &amp; make install 3、nginx的五种负载分配算法3.1 round robin（默认）轮询方式，依次将请求分配到各个后台服务器中，默认的负载均衡方式。适用于后台机器性能一致的情况。挂掉的机器可以自动从服务列表中剔除。 3.2 weight根据权重来分发请求到不同的机器中，指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。1234upstream bakend &#123; server 192.168.0.14 weight=10; server 192.168.0.15 weight=10; &#125; 3.3 IP_hash根据请求者ip的hash值将请求发送到后台服务器中，可以保证来自同一ip的请求被打到固定的机器上，可以解决session问题 12345upstream bakend &#123; ip_hash; server 192.168.0.14:88; server 192.168.0.15:80; &#125; 3.4 url_hash（第三方）根据请求的url的hash值将请求分到不同的机器中，当后台服务器为缓存的时候效率高。例如：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法 123456upstream backend &#123; server squid1:3128; server squid2:3128; hash $request_uri; hash_method crc32; &#125; 3.5 fair（第三方）根据后台响应时间来分发请求，响应时间短的分发的请求多。例如：12345upstream backend &#123; server server1; server server2; fair; &#125;","categories":[],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/child/tags/nginx/"}],"keywords":[]},{"title":"并发编程-独占式AQS源码详解","slug":"并发编程-独占式AQS源码详解","date":"2018-04-19T12:36:12.000Z","updated":"2019-06-12T09:07:40.730Z","comments":true,"path":"2018/04/19/并发编程-独占式AQS源码详解/","link":"","permalink":"http://yoursite.com/child/2018/04/19/并发编程-独占式AQS源码详解/","excerpt":"","text":"1. 框架概述AQS是AbstractQueuedSynchronizer的简称，抽象队列同步器，AQS定义了一套多线程访问共享资源的同步器框架，许多同步类的实现都依赖于它，比如常用的ReentrantLock/CountDownLatch/Semaphore… AQS维护了一个volatile int state 代表共享资源，一个FIFO线程等待队列用来记录争用资源而进入等待的线程，这里有一点需要强调，AQS同步队列中的线程是处于WAITING状态的，而竞争synchronized同步块的线程是处于BLOCKING状态的。 AQS定义了两种组员共享方式：Exclusive 和 Share 自定义同步器在实现时只需要实现共享资源state的获取与释放方式，至于具体的线程等待队列的维护，AQS已经实现好了。自定义同步器是现实需要实现的几个方法： isHeldExclusively() 该线程是否正在独占资源，只有用到Condition才需要实现它 tryAcquire(int) 独占方式获取资源，获取成功返回ture tryRelease(int) 独占方式释放资源，释放成功返回ture tryAcquireShared(int) 共享方式获取资源，负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。 tryReleaseShared(int) 共享方式释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。 以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。 再以CountDownLatch以例，任务分为N个子线程去执行，state也初始化为N（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS减1。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作。 一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。但AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。 2. 源码详解本节依照acquire-release、acquireShared-releaseShared的次序来讲解AQS的源码实现。 2.1 acquire(int)该方法是在独占模式下获取共享资源的顶层入口，如果获取资源成功tryAcquire返回true，该函数直接返回，且整个过程忽略中断的影响；否则调用addWaiter将线程包装成Node对象进入阻塞队列，并不断acquireQueued获取资源。12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 函数流程如下： tryAcquire() 尝试直接去获取资源，如果成功则直接返回； addWaiter() 将该线程加入等待队列的尾部，并标记为独占模式； acquireQueued() 使线程在等待队列中尝试获取资源，一直获取到资源后才返回。如果在整个等待过程中被中断过，则返回true，否则返回false。 如果线程在等待过程中被中断过，它是不响应的（关于中断的介绍请参考文章线程中断），获取资源后通过selfInterrupt()，将该线程的中断标志置为true。 2.1.1 tryAcquire(int)此方法尝试获取独占资源，如果成功返回true，否则返回false。123protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException();&#125; AQS中该方法没有具体的执行逻辑，这是因为这是AQS定义的一个方法模板，具体的实现需要自定义同步类自己完成，能不能重入，竞争资源时可不可以加塞，都需要子类自己设计。如果子类没有实现该方法，就会调用AQS的默认实现，如上直接抛出异常。 2.1.2 addWaiter(Node)此方法作用是将当前线程加入到阻塞队列的队尾，并返回当前线程所在节点。123456789101112131415private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // 尝试快速入队 Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; //快速入队失败，调用enq方法入队 enq(node); return node;&#125; 先介绍一下Node，Node节点是对每一个竞争同步代码的线程的封装，主要包含了当前线程对象以及线程的状态。变量waitStatus表示当前Node节点的等待状态，共有4中取值CANCELLED、SIGNAL、CONDITION、PROPAGATE CANCELLED ： 值为1，表示当前节点处于结束状态，在同步队列中等待的线程等待超时或被中断，需要从同步队列中取消该Node节点 SIGNAL 值为-1，表示当前节点线程取消或者释放资源的时候，需要unpark其后继节点 CONDITION 值为-2，表示当前节点处于条件队列，在转变（状态被设为0）之前不会被当做同步队列节点 PROPAGATE 值为-3，与共享模式相关，在共享模式中，该状态标识结点的线程处于可运行状态 0 代表初始状态。 2.1.3 enq(Node)此方法用于将node加入队尾。源码如下：123456789101112131415private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 如果你看过AtomicInteger.getAndIncrement()函数源码，那么相信你一眼便看出这段代码的精华。CAS自旋volatile变量，是一种很经典的用法。 2.1.4 acquireQueued(Node, int)通过tryAcquire()和addWaiter()，该线程获取资源失败，已经被放入等待队列尾部了，下一步该干什么？进入等待状态休息，直到其他线程彻底释放资源后唤醒自己，自己再拿到资源，然后就可以去干自己想干的事了。这个函数非常关键，上源码：1234567891011121314151617181920212223242526272829final boolean acquireQueued(final Node node, int arg) &#123; //获取资源失败了吗？ boolean failed = true; try &#123; //标识等待过程中是否被中断过 boolean interrupted = false; for (;;) &#123; //获得当前节点的前驱 final Node p = node.predecessor(); //如果前驱是head，那就有资格去尝试获取 if (p == head &amp;&amp; tryAcquire(arg)) &#123; //获取资源成功，将自己设置成head setHead(node); //help GC，原头结点断开与队列的链接，等待被回收 p.next = null; failed = false;//表示获取资源成功 return interrupted; &#125; //先判断此次获取失败后可不可以 WAITTING，如果不能，继续重复循环 //执行park让线程进入WAITTING状态，并判断等待过程中有没有中断，发生过就改状态 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 那么怎么判断线程是不是应该执行park()呢？继续看下面代码，shouldParkAfterFailedAcquire方法主要用于检查状态，看看自己是否真的可以去休息了（进入waiting状态），万一排在队列前边的线程都取消了只是瞎站着，那就需要往前加塞。 12345678910111213141516171819private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; //获取前驱节点的状态 int ws = pred.waitStatus; //如果前驱节点状态是SIGNAL，说明前驱节点释放资源后会通知本节点，可以安全的执行park() if (ws == Node.SIGNAL) return true; if (ws &gt; 0) &#123; //如果前驱节点是取消状态CANCELLED，执行加塞操作，跳过所有取消节点 do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; //如果前驱节点状态正常有效，那就把前驱节点的状态设置成SIGNAL，前驱节点执行完释放资源就会通知本节点 compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; //返回false表示此次循环不能更改线程状态，返回到acquireQueued方法即系执行循环获取资源 return false;&#125; 整个流程用一句话概括，如果前驱结点的状态不是SIGNAL，那么自己就不能放心去休息，需要去找个安全的休息点，找到安全点后可以再尝试下看能不能获取资源，再次获取失败就可以放心进入WAITTING状态。 parkAndCheckInterrupt方法就是让线程执行park()进入WAITTINGZ状态，并返回该线程的中断标志1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 注意，Thread.interrupted()方法在获取线程中断标志的同时会将该标志复位为false 2.1.5 小结源码再贴一遍：12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; 获取独占资源流程如下： 调用自定义同步器的tryAcquire()尝试直接去获取资源，如果成功则直接返回； 否则addWaiter()将该线程加入等待队列的尾部； acquireQueued()使线程在等待队列中休息，当前驱节点为head 会去尝试获取资源，获取到资源后将自己设置为head，获取失败寻找安全点等待。注意此处寻找到安全点后不会立即park()，而是在下一次循环尝试获取失败后才会执行park()。如果在整个等待过程中被中断过，则返回true，否则返回false。 如果线程在等待过程中被中断过，它是不响应的，并且中断标志被Thread.interrupted()重置为false了，所以获取资源后才再进行自我中断selfInterrupt()，将中断标志重置为true。 2.2 release(int)release是独占模式下线程释放共享资源的顶层接口。它会释放指定量的资源，如果彻底释放了（即state=0），它会唤醒等待队列里的其他线程来获取资源。源码： 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h);//唤醒后继节点 return true; &#125; return false; &#125; 逻辑并不复杂。它调用tryRelease()来释放资源。有一点需要注意的是，它是根据tryRelease()的返回值来判断该线程是否已经完成释放掉资源了。所以自定义同步器在设计tryRelease()的时候要明确这一点 2.2.1 tryRelease(int)123protected boolean tryRelease(int arg) &#123; throw new UnsupportedOperationException();&#125; 跟tryAcquire()一样，这个方法是需要独占模式的自定义同步器去实现的。正常来说，tryRelease()都会成功的，因为这是独占模式，该线程来释放资源，那么它肯定已经拿到独占资源了，直接减掉相应量的资源即可(state-=arg)，也不需要考虑线程安全的问题。但要注意它的返回值，上面已经提到了，release()是根据tryRelease()的返回值来判断该线程是否已经完成释放掉资源了！所以自义定同步器在实现时，如果已经彻底释放资源(state=0)，要返回true，否则返回false。 2.2.2 unparkSuccessor(Node)此方法用于唤醒等待队列中下一个线程。123456789101112131415161718private void unparkSuccessor(Node node) &#123; //获取当前节点的状态 int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0);//置0 //获取下一个将唤醒的节点 Node s = node.next; //若后继节点已取消，找到最靠近head的有效节点 if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) //waitStatus&lt;=0的都是有效节点，都可以唤醒 if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);//唤醒 &#125; 一句话概括，用用unpark()唤醒等待队列中最前边的那个有效线程。 3. ReentrantLockReentrantLock自身没有继承AQS，但是它持有一个AQS的子类Sync的对象实例sync，Sync又派生了两个子类 FairSync 和 NonfairSync。ReentrantLock实例化时，无参的默认构造函数会使用NonfairSync对sync进行初始化；而接受一个布尔型变量的构造函数根据用户传入的参数决定使用公平锁还是非公平锁。 公平性是针对锁获取而言的，如果是公平锁，那么锁的获取顺序应该符合请求的绝对时间顺序，也就是FIFO，该原则保证公平的代价是进行大量的线程切换。非公平锁虽然可能造成线程饥饿，但是极少的线程切换保证了其更大的吞吐量，因此ReentrantLock默认实现非公平锁。 3.1 获取锁下面代码是非公平锁和公平锁分别获取资源的操作：1234567891011121314151617181920final boolean nonfairTryAcquire(int acquires) &#123; //获取当前线程对象 final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123;//如果资源空闲，CAS设置状态量 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; //如果资源被占用，判断持有锁的线程是不是本线程，是的话重入 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false;&#125; 重入锁的意义就是持有锁的线程可以多次重复进入临界区，而不需要在同步队列中等待，每次进入状态量加1，进入几次就要释放几次，释放1次状态量减1，当状态量为0时，完全释放资源。 1234567891011121314151617181920protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; //注意与非公平锁的区别 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false;&#125; 比较以上两个获取资源的函数，发现唯一的区别在于公平锁在设置状态量之前多做了一次判断 !hasQueuedPredecessors()，该函数返回是否有线程排在当前线程前面，如果没有则可以获得锁。hasQueuedPredecessors源码如下123456789public final boolean hasQueuedPredecessors() &#123; Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; //队列中不止一个线程 //并且第二个线程节点为空或者第二个节点不是是自己 return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread()); &#125; 3.2 释放锁释放操作没有公平与非公平之分，所以释放操作是在父类Sync中实现，下面看源码： 1234567891011121314protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; //如果当前线程不是占用线程，抛异常 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; //状态量等于0，才是真正释放 if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 因为释放锁之前，当前线程还持有锁，其他线程无权访问，所以修改状态没有用CAS，直接使用setState 共享式同步器 请看下一篇 并发编程-共享式AQS源码详解","categories":[],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"http://yoursite.com/child/tags/并发编程/"}],"keywords":[]},{"title":"spring-HV参数校验","slug":"spring-HV参数校验","date":"2018-04-02T07:39:40.000Z","updated":"2019-05-23T02:59:16.742Z","comments":true,"path":"2018/04/02/spring-HV参数校验/","link":"","permalink":"http://yoursite.com/child/2018/04/02/spring-HV参数校验/","excerpt":"","text":"参数验证是一个常见的问题，无论是前端还是后台，都需对用户输入进行验证，以此来保证系统数据的正确性。对于web来说，有些人可能理所当然的想在前端验证就行了，但这样是非常错误的做法，前端代码对于用户来说是透明的，稍微有点技术的人就可以绕过这个验证，直接提交数据到后台。无论是前端网页提交的接口，还是提供给外部的接口，参数验证随处可见，也是必不可少的。前端做验证只是为了用户体验，比如控制按钮的显示隐藏，单页应用的路由跳转等等。后端才是最终的保障。总之，一切用户的输入都是不可信的。 1、gradle依赖1compile &apos;org.springframework.boot:spring-boot-starter-validation&apos; 2、常用约束123456789101112131415161718@Null 被注释的元素必须为 null @NotNull 被注释的元素必须不为 null @AssertTrue 被注释的元素必须为 true @AssertFalse 被注释的元素必须为 false @Min(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @Max(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @DecimalMin(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值@Size(max=, min=) 被注释的元素的大小必须在指定的范围内 @Digits (integer, fraction) 被注释的元素必须是一个数字，其值必须在可接受的范围内 @Past 被注释的元素必须是一个过去的日期 @Future 被注释的元素必须是一个将来的日期 @Pattern(regex=,flag=) 被注释的元素必须符合指定的正则表达式Hibernate Validator附加的constraint @NotBlank(message =) 验证字符串非null，且长度必须大于0 @Email 被注释的元素必须是电子邮箱地址 @Length(min=,max=) 被注释的字符串的大小必须在指定的范围内 @NotEmpty 被注释的字符串的必须非空 @Range(min=,max=,message=) 被注释的元素必须在合适的范围内 3、使用方法 在model类中使用注解约束字段 接口中需要校验的model对象前使用@Valid注解，并在接口方法参数列表中增加BindingResult对象来接受校验错误信息123456789@PostMapping(value = &quot;/demo&quot;) public Integer addDemo(@Valid @RequestBody Demo demo, BindingResult bindingResult)&#123; if(bindingResult.hasErrors())&#123; for(ObjectError error : bindingResult.getAllErrors())&#123; throw new DemoException(DemoExceptionEnum.PARAM_ERROR.getCode(),error.getDefaultMessage()); &#125; &#125; return demoService.insert(demo); &#125; 注意：如果在一个接口中有多个参数需要校验，那么每一个参数都需要定义一个BindingResult对象来接收校验结果 123public void test()(@RequestBody @Valid DemoModel demo, BindingResult result)public void test()(@RequestBody @Valid DemoModel demo, BindingResult result,@RequestBody @Valid DemoModel demo2, BindingResult result2) 4、深入使用4.1 配置校验模式 默认的校验模式为普通模式，普通模式下会校验完所有的属性然后返回所有的校验失败信息 可配置为快速失败返回模式，只要有一个属性校验失败则立即返回 配置方式 1234567891011121314@Configurationpublic class ValidatorConfiguration &#123; @Bean public Validator validator()&#123; ValidatorFactory validatorFactory = Validation.byProvider( HibernateValidator.class ) .configure() /**设置validator模式为快速失败返回*/ .addProperty( &quot;hibernate.validator.fail_fast&quot;, &quot;true&quot; ) .buildValidatorFactory(); Validator validator = validatorFactory.getValidator(); return validator; &#125;&#125; 4.2 分组校验 使用场景：针对同一个model类，不同的接口需要对不同的属性进行校验 例如，数据插入接口与数据更新接口需要校验的参数是不同的 使用方法 在model类中定义内部接口 约束增加组别属性1234&gt; public class Demo&#123;&gt; public interface AddGorup&#123;&#125;&gt; public interface UpdateGroup&#123;&#125;&gt; @Range(min = 1,max = Integer.MAX_VALUE,groups = {UpdateGroup.class}) private Integer id; @Email(groups = {AddGroup.class,UpdateGroup.class}) private String email; @Past(groups = {UpdateGroup.class}) private Date birthday; } 12345678 3. 在接口中使用@Validated(&#123;Demo.AddGroup.class&#125;)来注解参数，表示该参数使用AddGroup来进行校验 &gt;约束的groups属性中可以填写多个接口名，表示该参数加入多个组进行校验 4. #### 4.3 自定义约束- 创建约束标注 @Target({ElementType.METHOD,ElementType.ANNOTATION_TYPE,ElementType.FIELD,ElementType.PARAMETER})@Retention(RetentionPolicy.RUNTIME)@Constraint(validatedBy = DemoConstraintValidator.class)@Documentedpublic @interface DemoConstraint { String message() default “default message”; Class&lt;?&gt;[] groups() default {}; Class&lt;? extends Payload&gt;[] payload() default {}; E value();//约束中设置的value值}1- 实现一个验证器 /** T 自定义的约束注解类型DemoConstraint V 需要检验的参数类型public class DemoConstraintValidator implements ConstraintValidator&lt;T, V&gt;{ private E value;//注入设置的具体约束 @Override public void initialize(T t) { this.value = t.value(); } @Override public boolean isValid(V v, ConstraintValidatorContext constraintValidatorContext) { //根据value 对 参数v 进行一些判断 return true; if(!isValid) { constraintContext.disableDefaultConstraintViolation(); constraintContext.buildConstraintViolationWithTemplate(&quot;new default message&quot;).addConstraintViolation(); return false; } }} 1234567891011 &gt;T表示创建的注解，V表示该约束校验的数据类型- 定义默认的验证错误信息 可以通过ConstraintValidatorContext修改默认的message信息，一旦使用，在注解中给message赋值将不起作用（一般情况下不推荐使用）#### 4.4 检验组序列默认情况下，约束的计算没有特定的顺序，这与它们属于哪个组无关。然而，在某些情况下，控制约束求值的顺序是有用的，例如，我们可以要求在检查汽车的道路价值之前，首先通过所有默认的汽车约束。最后，在我们开车离开之前，我们检查了实际司机的约束条件。为了实现这样的顺序，需要定义一个新的接口，并使用@GroupSequence对其进行注释，以定义必须验证组的顺序。~~~注意：如果这个校验组序列中有一个约束条件没有通过验证的话, 那么此约束条件后面的都不会再继续被校验了.~~~ @GroupSequence({Default.class, CarChecks.class, DriverChecks.class})public interface OrderedChecks {}` 5、@Valid &amp; @Validated 用法 @valid @validated 类名前 √ 类属性前 √ 方法前 √ √ 入参前 √ √ 类名前是否加@Validated只影响@RequestParam注解的参数校验，如要进行校验，必须加。 不需要分组校验的情况下，接口入参之前只能注解@Valid才能正常校验 需要分组校验的时候，接口入参之前需要使用@Validated({GroupA.class,…})才能正常校验 @Valid用在类成员属性名之前，是为了实现嵌套校验 参考资料官方文档springboot使用hibernate validator校验@Validated和@Valid区别","categories":[],"tags":[{"name":"spring","slug":"spring","permalink":"http://yoursite.com/child/tags/spring/"}],"keywords":[]},{"title":"并发编程-锁","slug":"并发编程-锁","date":"2018-04-01T04:32:12.000Z","updated":"2019-05-28T14:57:42.154Z","comments":true,"path":"2018/04/01/并发编程-锁/","link":"","permalink":"http://yoursite.com/child/2018/04/01/并发编程-锁/","excerpt":"","text":"1 基础1.1 锁的类型锁从宏观上分类，分为悲观锁与乐观锁。 乐观锁是一种乐观思想，认为读多写少，遇到并发写的可能性低。每次读数据的时候，都认为别的线程没有修改过数据，所以不会上锁；但是写数据的时候会判断一下其他线程有没有更新过该数据。具体操作方式是：先读出当前版本号，然后加锁操作，如果跟之前的版本号一致则更新，否则重复 读-比较-写 的操作。java中的乐观锁基本上都是使用CAS实现的。 悲观锁就是一种悲观思想，认为写多读少，遇到并发写的可能性高。每次读数据的时候都认为会被其他线程修改，所以每次读写都会上锁。java中的 synchronized 即使悲观锁，而AQS框架下的锁先是尝试CAS乐观锁去获取，获取不到才会转换为悲观锁，如ReentrantLock。 1.2 java线程阻塞的代价java的线程是映射到操作系统原生线程上的，如果要阻塞或唤醒一个线程就需要操作系统介入，操作系统需要在用户态与核心态之间转换，这种切换会消耗大量的系统资源（因为用户态与核心态有各自的内存区域、寄存器等资源，用户态切换至内核态需要传递给许多变量、参数给内核，内核也需要保护好用户态在切换时的一些寄存器值、变量等，以便内核态调用结束后切换回用户态继续工作。） 如果线程状态切换是一个高频操作时，这将会消耗很多CPU处理时间； 如果对于那些需要同步的简单的代码块，获取锁挂起操作消耗的时间比用户代码执行的时间还要长，这种同步策略显然非常糟糕的。12java线程的 WAITING 和 BLOCKED 状态对于操作系统来说其实是一回事，都是暂停线程，都需要进行上下文切换。他们的区别在于唤醒方式不同，W 是用户主动唤醒，而 B 是系统自动唤醒。 synchronized会导致争用不到锁的线程进入阻塞状态，所以说它是java语言中一个重量级的同步操纵，被称为重量级锁，为了缓解上述性能问题，JVM从1.5开始，引入了轻量锁与偏向锁，默认启用了自旋锁，他们都属于乐观锁。 明确java线程切换的代价，是理解java中各种锁的优缺点的基础。 1.3 MarkWordmarkword是java对象数据结构中的一部分，对象的markword和java各种类型的锁密切相关。 markword数据的长度在32位和64位的虚拟机（未开启压缩指针）中分别为32bit和64bit，它的最后2bit是锁状态标志位，用来标记当前对象的状态，对象的所处的状态，决定了markword存储的内容，如下表所示: 状态 标志位 存储内容 未锁定 01 对象哈希码、对象分代年龄 轻量级锁定 00 指向锁记录的指针 膨胀(重量级锁定) 10 执行重量级锁定的指针 GC标记 11 空(不需要记录信息) 可偏向 01 偏向线程ID、偏向时间戳、对象分代年龄 32位虚拟机在不同状态下markword结构如下图所示：了解了markword结构，有助于后面了解java锁的加锁解锁过程； 小结：前面提到了java的4种锁，他们分别是重量级锁、自旋锁、轻量级锁和偏向锁，不同的锁有不同特点，每种锁只有在其特定的场景下，才会有出色的表现，java中没有哪种锁能够在所有情况下都能有出色的效率，引入这么多锁的原因就是为了应对不同的情况； 前面讲到了重量级锁是悲观锁的一种，自旋锁、轻量级锁与偏向锁属于乐观锁，所以现在你就能够大致理解了他们的适用范围，但是具体如何使用这几种锁呢，就要看后面的具体分析他们的特性； 2. java中的锁2.1 自旋锁自旋锁原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。 但是线程自旋是需要消耗cup的，说白了就是让cup在做无用功，线程不能一直占用cup自旋做无用功，所以需要设定一个自旋等待的最大时间。 如果持有锁的线程执行的时间超过自旋等待的最大时间扔没有释放锁，就会导致其它争用锁的线程在最大等待时间内还是获取不到锁，这时争用线程会停止自旋进入阻塞状态。 优缺点 自旋锁尽可能的减少线程的阻塞，这对于锁的竞争不激烈，且占用锁时间非常短的代码块来说性能能大幅度的提升，因为自旋的消耗会小于线程阻塞挂起操作的消耗！ 但是如果锁的竞争激烈，或者持有锁的线程需要长时间占用锁执行同步块，这时候就不适合使用自旋锁了，因为自旋锁在获取锁前一直都是占用cpu做无用功，占着XX不XX，线程自旋的消耗大于线程阻塞挂起操作的消耗，其它需要cup的线程又不能获取到cpu，造成cpu的浪费。 自旋锁时间阈值自旋锁的目的是为了占着CPU的资源不释放，等到获取到锁立即进行处理。但是如何去选择自旋的执行时间呢？如果自旋执行时间太长，会有大量的线程处于自旋状态占用CPU资源，进而会影响整体系统的性能。因此自旋的周期选的额外重要！ JVM对于自旋周期的选择，jdk1.5这个限度是一定的写死的，在1.6引入了适应性自旋锁，适应性自旋锁意味着自旋的时间不在是固定的了，而是由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定，基本认为一个线程上下文切换的时间是最佳的一个时间，同时JVM还针对当前CPU的负荷情况做了较多的优化 如果平均负载小于CPUs则一直自旋 如果有超过(CPUs/2)个线程正在自旋，则后来线程直接阻塞 如果正在自旋的线程发现Owner发生了变化则延迟自旋时间（自旋计数）或进入阻塞 如果CPU处于节电模式则停止自旋 自旋时间的最坏情况是CPU的存储延迟（CPU A存储了一个数据，到CPU B得知这个数据直接的时间差） 自旋时会适当放弃线程优先级之间的差异 2.2 重量级锁Synchronized2.2.1 Synchronized的作用在JDK1.5之前都是使用synchronized关键字保证同步的，它可以把任意一个非NULL的对象当作锁。 作用于方法时，锁住的是对象的实例(this)； 当作用于静态方法时，锁住的是Class实例，又因为Class的相关数据存储在永久带PermGen（jdk1.8则是metaspace），永久带是全局共享的，因此静态方法锁相当于类的一个全局锁，会锁所有调用该方法的线程； 当作用于一个对象实例时，锁住的是所有以该对象为锁的代码块。 2.2.2 Synchronized的实现它有多个队列，当多个线程一起访问某个对象监视器的时候，对象监视器会将这些线程存储在不同的容器中，如下如所示： Contention List：竞争队列，所有请求锁的线程首先被放在这个竞争队列中； Entry List：Contention List中那些有资格成为候选资源的线程被移动到Entry List中； Wait Set：哪些调用wait方法被阻塞的线程被放置在这里； OnDeck：任意时刻，最多只有一个线程正在竞争锁资源，该线程被成为OnDeck； Owner：当前已经获取到所资源的线程被称为Owner； !Owner：当前释放锁的线程。 JVM每次从队列的尾部取出一个数据用于锁竞争候选者（OnDeck），但是并发情况下，ContentionList会被大量的并发线程进行CAS访问，为了降低对尾部元素的竞争，JVM会将一部分线程移动到EntryList中作为候选竞争线程。Owner线程会在unlock时，将ContentionList中的部分线程迁移到EntryList中，并指定EntryList中的某个线程为OnDeck线程（一般是最先进去的那个线程）。Owner线程并不直接把锁传递给OnDeck线程，而是把锁竞争的权利交给OnDeck，OnDeck需要重新竞争锁。这样虽然牺牲了一些公平性，但是能极大的提升系统的吞吐量，在JVM中，也把这种选择行为称之为“竞争切换”。 OnDeck线程获取到锁资源后会变为Owner线程，而没有得到锁资源的仍然停留在EntryList中。如果Owner线程被wait方法阻塞，则转移到WaitSet队列中，直到某个时刻通过notify或者notifyAll唤醒，会重新进去EntryList中。 处于ContentionList、EntryList、WaitSet中的线程都处于阻塞状态，该阻塞是由操作系统来完成的（Linux内核下采用pthread_mutex_lock内核函数实现的）。 2.2.3 Synchronized的非公平性 Synchronized在线程进入ContentionList时，等待的线程会先尝试自旋获取锁，如果获取不到就进入ContentionList，这明显对于已经进入队列的线程是不公平的 自旋获取锁的线程还可能直接抢占OnDeck线程的锁资源。 2.3 偏向锁Java偏向锁(Biased Locking)是Java6引入的一项多线程优化。偏向锁，顾名思义，它会偏向于第一个访问锁的线程，如果在运行过程中，同步锁只有一个线程访问，不存在多线程争用的情况，则线程是不需要触发同步的，这种情况下，就会给线程加一个偏向锁。如果在运行过程中，遇到了其他线程抢占锁，则持有偏向锁的线程会被挂起，JVM会消除它身上的偏向锁，将锁恢复到标准的轻量级锁。 2.3.1 偏向锁的实现 偏向锁获取过程： 访问Mark Word中偏向锁的标识是否设置成1，锁标志位是否为01，确认为可偏向状态。 如果为可偏向状态，则测试线程ID是否指向当前线程，如果是，进入步骤5，否则进入步骤3。 如果线程ID并未指向当前线程，则通过CAS操作竞争锁。如果竞争成功，则将Mark Word中线程ID设置为当前线程ID，然后执行5；如果竞争失败，执行4。 如果CAS获取偏向锁失败，则表示有竞争。当到达全局安全点（safepoint）时获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码。（撤销偏向锁的时候会导致stop the word） 执行同步代码。1注意：第四步中到达安全点safepoint会导致stop the word，时间很短。 偏向锁的释放： 偏向锁的撤销在上述第四步骤中有提到。偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动去释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态，撤销偏向锁后恢复到未锁定（标志位为“01”）或轻量级锁（标志位为“00”）的状态。 2.3.2 偏向锁的适用场景始终只有一个线程在执行同步块，在它没有执行完释放锁之前，没有其它线程去执行同步块，在锁无竞争的情况下使用，一旦有了竞争就升级为轻量级锁，升级为轻量级锁的时候需要撤销偏向锁，撤销偏向锁的时候会导致stop the word操作；在有锁的竞争时，偏向锁会多做很多额外操作，尤其是撤销偏向所的时候会导致进入安全点，安全点会导致stw，导致性能下降，所以高并发的应用会禁用掉偏向锁。 2.3.3 jvm开启/关闭偏向锁开启偏向锁：-XX:+UseBiasedLocking -XX:BiasedLockingStartupDelay=0关闭偏向锁：-XX:-UseBiasedLocking 2.4 轻量级锁轻量级锁是由偏向所升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，偏向锁就会升级为轻量级锁； 轻量级锁的加锁过程： 在代码进入同步块之前，如果同步对象锁状态为无锁状态（偏向锁标志为“0”，锁标志位为“01”），JVM会在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的MarkWord复制到锁记录中，官方称为Displaced Mark Word。 然后线程尝试使用CAS将对象头中的Mark Word替换为指向该线程锁记录的指针。 如果成功，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00” 如果失败，表示有其他线程竞争锁，当前线程自旋来获取锁。 轻量级锁解锁过程： 轻量级解锁时，会使用CAS操作将Displaced Mark Word替换回对象头 如果替换失败，说明有其他线程尝试过获取该锁（此时锁已膨胀成重量级），那就要在释放锁的同时，唤醒被挂起的线程。 2.5 锁升级过程","categories":[],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"http://yoursite.com/child/tags/并发编程/"}],"keywords":[]},{"title":"Mybatis-批量操作数据库","slug":"Mybatis-批量操作数据库","date":"2018-03-21T02:01:21.000Z","updated":"2019-06-25T14:08:38.120Z","comments":true,"path":"2018/03/21/Mybatis-批量操作数据库/","link":"","permalink":"http://yoursite.com/child/2018/03/21/Mybatis-批量操作数据库/","excerpt":"","text":"批量插入12345678910111213@Insert(\"&lt;script&gt;\" + \"INSERT INTO patent_post_info(patent_id,post_time,post_information) values \"+ \"&lt;foreach collection =\\\"postInfos\\\" item=\\\"postInfo\\\" index= \\\"index\\\" separator =\\\",\\\"&gt;\" + \"(\"+ \"#&#123;patentId&#125;, \" + \"CAST (#&#123;postInfo.postTime&#125; AS timestamp),\"+ \"#&#123;postInfo.postInformation&#125;\"+ \")\" + \"&lt;/foreach &gt;\"+ \"&lt;/script&gt;\" ) Integer insertPatentPostInfo(@Param(\"patentId\")Integer id, @Param(\"postInfos\")List&lt;PatentPostInfo&gt; postInfos) throws SQLException; 批量更新以下示例展示了更新两个字段，每一个字段使用一个片段1234567891011121314151617@Update(\"&lt;script&gt;\"+ \"UPDATE order_items \" + \"SET \" + \"goods_total_price=\" + \"&lt;foreach collection=\\\"orderItems\\\" item=\\\"orderItem\\\"index=\\\"index\\\" separator=\\\" \\\" open=\\\"CASE id\\\" close=\\\"END\\\"&gt;\" + \"WHEN #&#123;orderItem.id&#125; THEN #&#123;orderItem.goodsTotalPrice&#125;\" + \"&lt;/foreach&gt;\" + \",goods_name=\"+ \"&lt;foreach collection=\\\"list\\\" item=\\\"orderItem\\\" index=\\\"index\\\" separator=\\\" \\\" open=\\\"CASE id\\\" close=\\\"END\\\"&gt;\" + \"WHEN #&#123;orderItem.id&#125; THEN #&#123;orderItem.goodsName&#125;\" + \"&lt;/foreach&gt;\" + \"WHERE id IN \" + \"&lt;foreach collection=\\\"list\\\" item=\\\"orderItem\\\" index=\\\"index\\\" separator=\\\",\\\" open=\\\"(\\\" close=\\\")\\\"&gt;\" + \"#&#123;orderItem.id&#125;\"+ \"&lt;/foreach&gt;\" + \"&lt;/script&gt;\") Integer bathUpdateOrderItem(@Param(\"orderItems\")List&lt;OrderItemCustom&gt; orderItems) throws SQLException; 批量删除使用数组接受参数12345678@Delete(\"&lt;script&gt;\" + \"DELETE FROM order_items WHERE id IN\" + \"&lt;foreach collection=\\\"ids\\\" item=\\\"itemId\\\" index=\\\"index\\\" separator=\\\",\\\" open=\\\"(\\\" close=\\\")\\\"&gt;\"+ \"#&#123;itemId&#125;\" + \"&lt;/foreach&gt;\"+ \"&lt;/script&gt;\" ) Integer bathdeleteOrderItem(@Param(\"ids\") Integer[] itemIds)throws SQLException; controller中使用 @RequestParam 注解修饰数组，请求时将参数拼接到url后面（类似Get请求）","categories":[],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://yoursite.com/child/tags/Mybatis/"}],"keywords":[]},{"title":"并发编程-线程中断","slug":"并发编程-线程中断","date":"2018-03-20T12:36:12.000Z","updated":"2019-06-09T12:12:10.193Z","comments":true,"path":"2018/03/20/并发编程-线程中断/","link":"","permalink":"http://yoursite.com/child/2018/03/20/并发编程-线程中断/","excerpt":"","text":"中断可以理解为现成的一个标识位属性，它表示一个运行中的线程是否被被其他线程进行了中断操作。中断好比其他线程对该线程打了个招呼，其他线程通过调用该线程的interrupt()方法对其进行中断操作。 线程通过检查自身是否被中断来进行响应，线程通过方法 isInterrupted()来进行判断是否被中断，也可以调用静态方法 Thread.interrupted() 对当前线程的中断标识进行复位，如果该线程已经处于中断状态，在调用该线程对象的isInterrupted()时依旧会返回false。 本篇将从以下两个方面来介绍Java中对线程中断机制的具体实现： Java中对线程中断所提供的API支持 线程在不同状态下对于中断所产生的反应 1. Java中线程中断的API在以前的jdk版本中，我们使用stop方法中断线程，但是现在的jdk版本中已经不再推荐使用该方法了，反而由以下三个方法完成对线程中断的支持。12345public boolean isInterrupted()public void interrupt()public static boolean interrupted() 每个线程都一个状态位用于标识当前线程对象是否是中断状态。isInterrupted是一个实例方法，主要用于判断当前线程对象的中断标志位是否被标记了，如果被标记了则返回true表示当前已经被中断，否则返回false。我们也可以看看它的实现源码：123public boolean isInterrupted() &#123; return isInterrupted(false);&#125; 1private native boolean isInterrupted(boolean ClearInterrupted); 底层调用的本地方法isInterrupted，传入一个boolean类型的参数，用于指定调用该方法之后是否需要清除该线程对象的中断标识位。从这里我们也可以看出来，调用isInterrupted并不会清除线程对象的中断标识位。 interrupt也是一个实例方法，该方法用于设置线程对象的中断标识位，只要能获取到实例对象，就能调用该方法。 interrupted()是一个静态的方法，用于返回当前线程是否被中断，并清空标志位。 123public static boolean interrupted() &#123; return currentThread().isInterrupted(true);&#125; 1private native boolean isInterrupted(boolean ClearInterrupted); 该方法用于判断当前线程是否被中断，并且该方法调用结束的时候会清空中断标识位。下面我们看看线程所处不同状态下对于中断操作的反应。 2. 线程在不同状态下对于中断所产生的反应线程一共6种状态，分别是NEW，RUNNABLE，BLOCKED，WAITING，TIMED_WAITING，TERMINATED（Thread类中有一个State枚举类型列举了线程的所有状态）。下面我们就将把线程分别置于上述的不同种状态，然后看看我们的中断操作对它们的影响。 2.1 NEW和TERMINATED线程的new状态表示还未调用start方法，还未真正启动。线程的terminated状态表示线程已经运行终止。这两个状态下调用中断方法来中断线程的时候，Java认为毫无意义，所以并不会设置线程的中断标识位，什么事也不会发生。例如：123456public static void main(String[] args) throws InterruptedException &#123; Thread thread = new MyThread(); System.out.println(thread.getState()); thread.interrupt(); System.out.println(thread.isInterrupted());&#125; 输出结果如下：12NEWfales terminated状态：12345678public static void main(String[] args) throws InterruptedException &#123; Thread thread = new MyThread(); thread.start(); thread.join(); System.out.println(thread.getState()); thread.interrupt(); System.out.println(thread.isInterrupted());&#125; 输出结果如下：12TERMINATEDfalse 从上述的两个例子来看，对于处于new和terminated状态的线程对于中断是屏蔽的，也就是说中断操作对这两种状态下的线程是无效的。 2.2 RUNNABLE如果线程处于运行状态，那么该线程的状态就是RUNNABLE，但是不一定所有处于RUNNABLE状态的线程都能获得CPU运行，在某个时间段，只能由一个线程占用CPU，那么其余的线程虽然状态是RUNNABLE，但是都没有处于运行状态。而我们处于RUNNABLE状态的线程在遭遇中断操作的时候只会设置该线程的中断标志位，并不会让线程实际中断，想要发现本线程已经被要求中断了则需要用程序去判断。例如： 1234567891011121314151617public class MyThread extends Thread&#123; @Override public void run()&#123; while(true)&#123; &#125; &#125;&#125;public static void main(String[] args) throws InterruptedException &#123; Thread thread = new MyThread(); thread.start(); System.out.println(thread.getState()); thread.interrupt(); Thread.sleep(1000);//等到thread线程被中断之后 System.out.println(thread.isInterrupted()); System.out.println(thread.getState());&#125; 我们定义的线程始终循环做一些事情，主线程启动该线程并输出该线程的状态，然后调用中断方法中断该线程并再次输出该线程的状态。总的输出结果如下： 123RUNNABLEtureRUNNABLE 可以看到在我们启动线程之后，线程状态变为RUNNABLE，中断之后输出中断标志，显然中断位已经被标记，但是当我们再次输出线程状态的时候发现，线程仍然处于RUNNABLE状态。很显然，处于RUNNBALE状态下的线程即便遇到中断操作，也只会设置中断标志位并不会实际中断线程运行。那么问题是，既然不能直接中断线程，我要中断标志有何用处？这里其实Java将这种权力交给了我们的程序，Java给我们提供了一个中断标志位，我们的程序可以通过if判断中断标志位是否被设置来中断我们的程序而不是系统强制的中断。例如： 12345678public void run()&#123; while(true)&#123; if (Thread.currentThread().isInterrupted())&#123; System.out.println(\"exit MyThread\"); break; &#125; &#125;&#125; 线程一旦发现自己的中断标志为被设置了，立马跳出死循环。这样的设计好处就在于给了我们程序更大的灵活性。 2.3 BLOCKED当线程处于BLOCKED状态说明该线程由于竞争某个对象的锁失败而被挂在了该对象的阻塞队列上了。那么此时发起中断操作不会对该线程产生任何影响，依然只是设置中断标志位。例如：1234567891011public class MyThread extends Thread&#123; public synchronized static void doSomething()&#123; while(true)&#123; //do something &#125; &#125; @Override public void run()&#123; doSomething(); &#125;&#125; 这里我们自定义了一个线程类，run方法中主要就做一件事情，调用一个有锁的静态方法，该方法内部是一个死循环（占用该锁让其他线程阻塞）。123456789101112131415public static void main(String[] args) throws InterruptedException &#123; Thread thread1 = new MyThread(); thread1.start(); Thread thread2 = new MyThread(); thread2.start(); Thread.sleep(1000); System.out.println(thread1.getState()); System.out.println(thread2.getState()); thread2.interrupt(); System.out.println(thread2.isInterrupted()); System.out.println(thread2.getState());&#125; 在我们的主线程中，我们定义了两个线程并按照定义顺序启动他们，显然thread1启动后便占用MyThread类锁，此后thread2在获取锁的时候一定失败，自然被阻塞在阻塞队列上，而我们对thread2进行中断，输出结果如下：1234RUNNABLEBLOCKEDtrueBLOCKED 从输出结果看来，thread2处于BLOCKED状态，执行中断操作之后，该线程仍然处于BLOCKED状态，但是中断标志位却已被修改。这种状态下的线程和处于RUNNABLE状态下的线程是类似的，给了我们程序更大的灵活性去判断和处理中断。 2.4 WAITING/TIMED_WAITING这两种状态本质上是同一种状态，只不过TIMED_WAITING在等待一段时间后会自动释放自己，而WAITING则是无限期等待，需要其他线程调用notify方法释放自己。但是他们都是线程在运行的过程中由于缺少某些条件而被挂起在某个对象的等待队列上。当这些线程遇到中断操作的时候，会抛出一个InterruptedException异常，并清空中断标志位。例如：123456789101112public class MyThread extends Thread&#123; @Override public void run()&#123; synchronized (this)&#123; try &#123; wait(); &#125; catch (InterruptedException e) &#123; System.out.println(\"i am waiting but facing interruptexception now\"); &#125; &#125; &#125;&#125; 我们定义了一个线程类，其中run方法让当前线程阻塞到条件队列上，并且针对InterruptedException 进行捕获，如果遇到InterruptedException 异常则输出一行信息。12345678910public static void main(String[] args) throws InterruptedException &#123; Thread thread = new MyThread(); thread.start(); Thread.sleep(500); System.out.println(thread.getState()); thread.interrupt(); Thread.sleep(1000); System.out.println(thread.isInterrupted());&#125; 在main线程中我们启动一个MyThread线程，然后对其进行中断操作。运行结果如下：123WAITINGi am waiting but facing interruptexception nowfalse 从运行结果看，当前程thread启动之后就被挂起到该线程对象的条件队列上，然后我们调用interrupt方法对该线程进行中断，输出了我们在catch中的输出语句，显然是捕获了InterruptedException异常，接着就看到该线程的中断标志位被清空。 3. 总结综上所述，我们分别介绍了不同种线程的不同状态下对于中断请求的反应。 NEW 和 TERMINATED对于中断操作几乎是屏蔽的。 RUNNABLE 和 BLOCKED类似，对于中断操作只是设置中断标志位并没有强制终止线程，对于线程的终止权利依然在程序手中。 WAITING / TIMED_WAITING 状态下的线程对于中断操作是敏感的，他们会抛出异常并清空中断标志位。","categories":[],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"http://yoursite.com/child/tags/并发编程/"}],"keywords":[]},{"title":"并发编程-基础学习","slug":"并发编程-基础","date":"2018-03-15T12:36:12.000Z","updated":"2019-05-28T14:55:05.766Z","comments":true,"path":"2018/03/15/并发编程-基础/","link":"","permalink":"http://yoursite.com/child/2018/03/15/并发编程-基础/","excerpt":"","text":"1. 线程状态转换重点q一下WAITING &amp; BLOCKED: 从linux内核来看，线程WAITING &amp; BLOCKED都是等待状态，没区别，区别只在于java的管理需要。通常我们在系统级别说线程的blocked，是说线程操作io，被暂停了，这种线程由linux内核来唤醒（io设备报告数据来了，内核把block的线程放进可运行的进程队列，依次得到处理器时间），而wait是说，等待一个内核mutex对象，另个线程signal这个mutex后，这个线程才可以运行。区别在于由谁唤醒，是操作系统，还是另一个线程，这里倒和java很相似。 sleep(long) 不释放锁，wait()会释放锁，都进入WAITING状态，wait()返回后，重新竞争锁，进入BLOCKED状态。 2. 如何减少上下文切换上下文切换指的是单个处理器处理多个线程时，时间片分配给不同的线程引起的处理器当前状态的保存和加载。发生在线程切换的时刻，保存当前线程运行状态，加载即将执行的线程状态。 锁竞争会引起上下文的切换，要减少上下文切换可以使用： 无锁并发编程，例如将数据分段处理 CAS算法，CAS没有竞争锁的过程，自然也不会引起线程切换。 避免创建不必要的线程 协程：在单线程里实现多任务调度，在单线程里维持多任务间的切换。 3. 避免死锁 避免一个线程同时获取多个锁 避免一个线程在一个锁内占用多个资源 尝试使用定时锁，使用lock.tryLock(timeout)来替代使用内部锁 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败 4. CAS操作compare and set 原子操作，实现不被打断的数据交换操作，避免多线程同时改写某数据时由于执行顺序不确定以及中断的不可预知性而产生数据不一致问题 操作方式：将内存中的值与预期值进行比较，如果两个值一致，可以写入新的值；否则什么都不做或者重试 12345678CAS有3个操作数：内存值V旧的预期值A要修改的新值B当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值(A和内存值V相同时，将内存值V修改为B)，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试(或者什么都不做)。 5. 重量级锁Synchronized在JDK1.5之前都是使用synchronized关键字保证同步的，Synchronized 的作用相信大家都已经非常熟悉了； 它可以把任意一个非NULL的对象当作锁： 作用于方法时，锁住的是对象的实例(this)； 当作用于静态方法时，锁住的是Class实例，又因为Class的相关数据存储在永久带PermGen（jdk1.8则是metaspace），永久带是全局共享的，因此静态方法锁相当于类的一个全局锁，会锁所有调用该方法的线程； synchronized作用于一个对象实例时，锁住的是所有以该对象为锁的代码块。 它有多个队列，当多个线程一起访问某个对象监视器的时候，对象监视器会将这些线程存储在不同的容器中。 Contention List：竞争队列，所有请求锁的线程首先被放在这个竞争队列中； Entry List：锁池，Contention List中那些有资格成为候选资源的线程被移动到Entry List中； Wait Set：等待池，哪些调用wait方法的线程被放置在这里进行WAITING； OnDeck：任意时刻，最多只有一个线程正在竞争锁资源，该线程被成为OnDeck； Owner：当前已经获取到所资源的线程被称为Owner； !Owner：当前释放锁的线程。 JVM每次从队列的尾部取出一个数据用于锁竞争候选者（OnDeck），但是并发情况下，ContentionList会被大量的并发线程进行CAS访问，为了降低对尾部元素的竞争，JVM会将一部分线程移动到EntryList中作为候选竞争线程。Owner线程会在unlock时，将ContentionList中的部分线程迁移到EntryList中，并指定EntryList中的某个线程为OnDeck线程（一般是最先进去的那个线程）。Owner线程并不直接把锁传递给OnDeck线程，而是把锁竞争的权利交给OnDeck，OnDeck需要重新竞争锁。这样虽然牺牲了一些公平性，但是能极大的提升系统的吞吐量，在JVM中，也把这种选择行为称之为“竞争切换”。 OnDeck线程获取到锁资源后会变为Owner线程，而没有得到锁资源的仍然停留在EntryList中。如果Owner线程调用wait方法，则转移到WaitSet队列中，直到某个时刻通过notify或者notifyAll唤醒，会重新进去EntryList中。 处于ContentionList、EntryList中的线程都处于阻塞状态，该阻塞是由操作系统来完成的（Linux内核下采用pthread_mutex_lock内核函数实现的）。 Synchronized是非公平锁。Synchronized在线程进入ContentionList时，等待的线程会先尝试自旋获取锁，如果获取不到就进入ContentionList，这明显对于已经进入队列的线程是不公平的，还有一个不公平的事情就是自旋获取锁的线程还可能直接抢占OnDeck线程的锁资源。 6.等待/通知机制帮助理解：每个对象都有一个等待池与锁池，并发编程访问临界资源时（共享对象）， 当共享对象调用wait函数时，当前线程阻塞进入等待池，等待池中的线程处于WAITING状态 当共享对象调用notify函数时，随机从等待池中唤醒一个线程，该线程进入到锁池参与锁竞争； 当共享对象调用notifyAll函数时，唤醒等待池中所有的线程，所有线程进入到锁池参与锁竞争。建议使用notifyAll()","categories":[],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"http://yoursite.com/child/tags/并发编程/"}],"keywords":[]},{"title":"源码分析-SimpleDateFormat的用法以及线程安全","slug":"源码分析-SimpleDateFormat的用法以及线程安全","date":"2017-12-21T01:02:32.000Z","updated":"2019-05-23T03:00:04.545Z","comments":true,"path":"2017/12/21/源码分析-SimpleDateFormat的用法以及线程安全/","link":"","permalink":"http://yoursite.com/child/2017/12/21/源码分析-SimpleDateFormat的用法以及线程安全/","excerpt":"","text":"开发中我们经常会用到时间相关类，我们有很多办法在Java代码中获取时间。但是不同的方法获取到的时间的格式都不尽相同，这时候就需要一种格式化工具，把时间显示成我们需要的格式。最常用的方法就是使用SimpleDateFormat类。这是一个看上去功能比较简单的类，但是，一旦使用不当也有可能导致很大的问题。 在阿里巴巴Java开发手册中，有如下明确规定：本文就围绕SimpleDateFormat的用法、原理等来深入分析下如何以正确使用它。 1. SimpleDateFormat用法1.1 基本用法SimpleDateFormat是java提供的能对时间格式化及解析的工具类。 格式化：将规范日期格式化成日期文本（时间字符串） 12SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);String dateStr = sdf.format(new Date()); 解析： 将文本日期解析成规范化的时间格式 1Date d = sdf.parse(dataStr); 用户可以自定义文本日期的格式，通过字母来描述时间元素，并组装成想要的日期和时间格式。常用的时间元素和字母的对应表如下：模式字母通常是重复的，其数量确定其精确表示。如下表是常用的输出格式的表示方法。 1.2 时区如何在Java代码中获取不同时区的时间呢？SimpleDateFormat可以实现这个功能。123456public static void main(String[] args)&#123; SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); System.out.println(sdf.format(Calendar.getInstance().getTime())); sdf.setTimeZone(TimeZone.getTimeZone(&quot;America/Los_Angeles&quot;)); System.out.println(sdf.format(Calendar.getInstance().getTime())); &#125; 以上代码，输出的结果 122019-04-24 09:26:382019-04-23 18:26:38 中国的时间第一行，而美国洛杉矶时间比中国北京时间慢了17个小时（这还和冬夏令时有关系）。当然，这不是显示其他时区的唯一方法 2. SimpleDateFormat线程安全性由于SimpleDateFormat比较常用，而且在一般情况下，一个应用中的时间显示模式都是一样的，所以很多人愿意使用如下方式定义SimpleDateFormat：1234567public class Main &#123; private static SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); public static void main(String[] args) &#123; sdf.setTimeZone(TimeZone.getTimeZone(&quot;America/New_York&quot;)); ... &#125;&#125; 这种定义方式，存在很大的线程安全隐患。 2.1 问题重现以下代码使用线程池来执行时间输出。12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class Main &#123; /** * 定义一个全局的SimpleDateFormat */ private static SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); /** * 使用ThreadFactoryBuilder定义一个线程池 */ private static ThreadFactory namedThreadFactory = new ThreadFactoryBuilder() .setNameFormat(&quot;demo-pool-%d&quot;).build(); private static ExecutorService pool = new ThreadPoolExecutor(5, 200, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(1024), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy()); /** * 定义一个CountDownLatch，保证所有子线程执行完之后主线程再执行 */ private static CountDownLatch countDownLatch = new CountDownLatch(100); public static void main(String[] args) &#123; //定义一个线程安全的HashSet Set&lt;String&gt; dates = Collections.synchronizedSet(new HashSet&lt;String&gt;()); for (int i = 0; i &lt; 100; i++) &#123; //获取当前时间 Calendar calendar = Calendar.getInstance(); int finalI = i; pool.execute(() -&gt; &#123; //时间增加 calendar.add(Calendar.DATE, finalI); //通过simpleDateFormat把时间转换成字符串 String dateString = sdf.format(calendar.getTime()); //把字符串放入Set中 dates.add(dateString); //countDown countDownLatch.countDown(); &#125;); &#125; //阻塞，直到countDown数量为0 countDownLatch.await(); //输出去重后的时间个数 System.out.println(dates.size()); &#125;&#125; 以上代码，其实比较容易理解。就是循环一百次，每次循环的时候都在当前时间基础上增加一个天数（这个天数随着循环次数而变化），然后把所有日期放入一个线程安全的、带有去重功能的Set中，然后输出Set中元素个数。 正常情况下，以上代码输出结果应该是100。但是实际执行结果是一个小于100的数字。 原因就是因为SimpleDateFormat作为一个非线程安全的类，被当做了共享变量在多个线程中进行使用，这就出现了线程安全问题。 2.2 线程不安全原因其实，JDK文档中已经明确表明了SimpleDateFormat不应该用在多线程场景中：123Date formats are not synchronized.It is recommended to create separate format instances for each thread.If multiple threads access a format concurrently, it must be synchronized externally. 那么为什么会出现这种问题，SimpleDateFormat底层到底是怎么实现的？跟踪一下SimpleDateFormat类中format方法的实现其实就能发现端倪。1234567891011121314151617181920212223242526272829303132333435363738394041@Override public StringBuffer format(Date date, StringBuffer toAppendTo, FieldPosition pos) &#123; pos.beginIndex = pos.endIndex = 0; return format(date, toAppendTo, pos.getFieldDelegate()); &#125; // Called from Format after creating a FieldDelegate private StringBuffer format(Date date, StringBuffer toAppendTo, FieldDelegate delegate) &#123; // Convert input date to time field list calendar.setTime(date); boolean useDateFormatSymbols = useDateFormatSymbols(); for (int i = 0; i &lt; compiledPattern.length; ) &#123; int tag = compiledPattern[i] &gt;&gt;&gt; 8; int count = compiledPattern[i++] &amp; 0xff; if (count == 255) &#123; count = compiledPattern[i++] &lt;&lt; 16; count |= compiledPattern[i++]; &#125; switch (tag) &#123; case TAG_QUOTE_ASCII_CHAR: toAppendTo.append((char)count); break; case TAG_QUOTE_CHARS: toAppendTo.append(compiledPattern, i, count); i += count; break; default: subFormat(tag, count, delegate, toAppendTo, useDateFormatSymbols); break; &#125; &#125; return toAppendTo; &#125; SimpleDateFormat中的format方法在执行过程中，会使用一个成员变量calendar来保存时间。这其实就是问题的关键。 由于我们在声明SimpleDateFormat的时候，使用的是static定义的。那么这个SimpleDateFormat就是一个共享变量，随之，SimpleDateFormat中的calendar也就可以被多个线程访问到。 假设线程1刚刚执行完calendar.setTime把时间设置成2018-11-11，还没等执行完，线程2又执行了calendar.setTime把时间改成了2018-12-12。这时候线程1继续往下执行，拿到的calendar.getTime得到的时间就是线程2改过之后的。 除了format方法以外，SimpleDateFormat的parse方法也有同样的问题。 3. 如何解决解决方法有很多，先介绍三个比较常用的方法。 3.1 使用局部变量SimpleDateFormat变成了局部变量，就不会被多个线程同时访问到了，就避免了线程安全问题。1234567891011121314151617for (int i = 0; i &lt; 100; i++) &#123; //获取当前时间 Calendar calendar = Calendar.getInstance(); int finalI = i; pool.execute(() -&gt; &#123; // SimpleDateFormat声明成局部变量 SimpleDateFormat simpleDateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); //时间增加 calendar.add(Calendar.DATE, finalI); //通过simpleDateFormat把时间转换成字符串 String dateString = simpleDateFormat.format(calendar.getTime()); //把字符串放入Set中 dates.add(dateString); //countDown countDownLatch.countDown(); &#125;);&#125; 3.2 加同步锁除了改成局部变量以外，还有一种方法大家可能比较熟悉的，就是对于共享变量进行加锁。12345678910111213141516171819for (int i = 0; i &lt; 100; i++) &#123; //获取当前时间 Calendar calendar = Calendar.getInstance(); int finalI = i; pool.execute(() -&gt; &#123; //时间增加 calendar.add(Calendar.DATE, finalI); //通过simpleDateFormat把时间转换成字符串 //加锁 synchronized (simpleDateFormat) &#123; String dateString = simpleDateFormat.format(calendar.getTime()); &#125; //把字符串放入Set中 dates.add(dateString); //countDown countDownLatch.countDown(); &#125;);&#125; 通过加锁，使多个线程排队顺序执行。避免了并发导致的线程安全问题。 3.3 使用ThreadLocal第三种方式，就是使用 ThreadLocal。 ThreadLocal 可以确保每个线程都可以得到单独的一个 SimpleDateFormat 的对象，那么自然也就不存在竞争问题了。1234567891011/*** 使用ThreadLocal定义一个全局的SimpleDateFormat*/private static ThreadLocal&lt;SimpleDateFormat&gt; simpleDateFormatThreadLocal = new ThreadLocal&lt;SimpleDateFormat&gt;() &#123; @Override protected SimpleDateFormat initialValue() &#123; return new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); &#125;&#125;;//用法String dateString = simpleDateFormatThreadLocal.get().format(calendar.getTime()); 当然，以上代码也有改进空间，就是，其实SimpleDateFormat的创建过程可以改为延迟加载。这里就不详细介绍了。 4. 使用DateTimeFormatter如果是Java8应用，可以使用DateTimeFormatter代替SimpleDateFormat，这是一个线程安全的格式化工具类。12345678910//解析日期String dateStr= &quot;2016年10月25日&quot;;DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;yyyy年MM月dd日&quot;);LocalDate date= LocalDate.parse(dateStr, formatter);//日期转换为字符串LocalDateTime now = LocalDateTime.now();DateTimeFormatter format = DateTimeFormatter.ofPattern(&quot;yyyy年MM月dd日 hh:mm a&quot;);String nowStr = now .format(format);System.out.println(nowStr); 5. 总结本文介绍了SimpleDateFormat的用法，SimpleDateFormat主要可以在String和Date之间做转换，还可以将时间转换成不同时区输出。同时提到在并发场景中SimpleDateFormat是不能保证线程安全的，需要开发者自己来保证其安全性。 主要的几个手段有改为局部变量、使用synchronized加锁、使用Threadlocal为每一个线程单独创建一个和使用Java8中的DateTimeFormatter类代替等。","categories":[],"tags":[{"name":"源码分析","slug":"源码分析","permalink":"http://yoursite.com/child/tags/源码分析/"}],"keywords":[]},{"title":"设计模式之策略模式","slug":"设计模式之策略模式","date":"2017-05-14T03:17:23.000Z","updated":"2019-07-22T01:31:28.157Z","comments":true,"path":"2017/05/14/设计模式之策略模式/","link":"","permalink":"http://yoursite.com/child/2017/05/14/设计模式之策略模式/","excerpt":"","text":"文章以jdk并发包中的一个策略模式实现作为开篇。 使用线程池处理并发任务时，当用户提交任务到线程池，线程池因为线程池已满或者线程池处于SHUTDOWN状态拒接任务的时候，会调用reject函数对任务进行后处理，代码如下： 123456789代码摘自：java.util.concurrent.ThreadPoolExecutorprivate volatile RejectedExecutionHandler handler;private static final RejectedExecutionHandler defaultHandler = new AbortPolicy(); final void reject(Runnable command) &#123; handler.rejectedExecution(command, this);&#125; 在线程池创建的时候，用户会初始化handler变量，或者使用默认的初始化defaultHandler，即AbortPolicy对象，AbortPolicy就是策略的一种实现，该策略丢弃被拒绝的任务，并抛出RejectedExecutionException异常。12345678910代码摘自：java.util.concurrent.ThreadPoolExecutorpublic static class AbortPolicy implements RejectedExecutionHandler &#123; public AbortPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; throw new RejectedExecutionException(\"Task \" + r.toString() + \" rejected from \" + e.toString()); &#125;&#125; 策略接口类：12345代码摘自：java.util.concurrent.RejectedExecutionHandlerpublic interface RejectedExecutionHandler &#123; void rejectedExecution(Runnable r, ThreadPoolExecutor executor);&#125; 所有的后处理策略都要实现该接口，ThreadPoolExecutor持有改接口对象，在初始化ThreadPoolExecutor的时候再指定使用哪种策略，下面我们看一下其他策略源码： 12345678910111213141516171819202122232425//该策略直接调用被拒绝任务的Run函数强制执行任务public static class CallerRunsPolicy implements RejectedExecutionHandler &#123; public CallerRunsPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; r.run(); &#125; &#125;&#125;//该策略忽略被拒任务，不做任何处理public static class DiscardPolicy implements RejectedExecutionHandler &#123; public DiscardPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; &#125;&#125;//该策略丢弃阻塞队列中等待最久的任务（下一个被执行的任务），再次提交被拒任务public static class implements RejectedExecutionHandler &#123; public DiscardOldestPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; e.getQueue().poll(); e.execute(r); &#125; &#125;&#125; 到此我们可以画一个简单的类图表示上述类型之间的关系：可以说这是一个很典型的策略模式类图了。 策略模式其思想是针对一组算法，将每一种算法都封装到具有共同接口的独立的类中，从而是它们可以相互替换。策略模式的最大特点是使得算法可以在不影响客户端的情况下发生变化，从而改变不同的功能。 下图所示为策略模式的UML图，上文所述的ThreadPoolExecutor就是Context，contextInterface指的就是reject函数。 策略模式的优缺点 优点 策略模式提供了管理相关的算法族的办法。策略类的等级结构定义了一个算法或行为族。恰当使用继承可以把公共的代码转移到父类里面，从而避免重复的代码。 策略模式提供了可以替换继承关系的办法。继承可以处理多种算法或行为。如果不是用策略模式，那么使用算法或行为的环境类就可能会有一些子类，每一个子类提供一个不同的算法或行为。但是，这样一来算法或行为的使用者就和算法或行为本身混在一起。决定使用哪一种算法或采取哪一种行为的逻辑就和算法或行为的逻辑混合在一起，从而不可能再独立演化。继承使得动态改变算法或行为变得不可能。 使用策略模式可以避免使用多重条件转移语句。多重转移语句不易维护，它把采取哪一种算法或采取哪一种行为的逻辑与算法或行为的逻辑混合在一起，统统列在一个多重转移语句里面，比使用继承的办法还要原始和落后。 缺点 客户端必须知道所有的策略类，并自行决定使用哪一个策略类。这就意味着客户端必须理解这些算法的区别，以便适时选择恰当的算法类。换言之，策略模式只适用于客户端知道所有的算法或行为的情况。 策略模式造成很多的策略类，每个具体策略类都会产生一个新类。有时候可以通过把依赖于环境的状态保存到客户端里面，而将策略类设计成可共享的，这样策略类实例可以被不同客户端使用。换言之，可以使用享元模式来减少对象的数量。 应用场景 多个类只区别在表现行为不同，可以使用Strategy模式，在运行时动态选择具体要执行的行为。 需要在不同情况下使用不同的策略(算法)，或者策略还可能在未来用其它方式来实现。 对客户隐藏具体策略(算法)的实现细节，彼此完全独立。 参考文档：www.w3sdesign.com/strategy_design_pattern.php","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/child/tags/设计模式/"}],"keywords":[]},{"title":"linux命令-tail","slug":"linux命令-tail","date":"2017-04-23T07:52:38.000Z","updated":"2019-05-23T03:03:01.787Z","comments":true,"path":"2017/04/23/linux命令-tail/","link":"","permalink":"http://yoursite.com/child/2017/04/23/linux命令-tail/","excerpt":"","text":"tail显示文件的末尾部分，默认显示10行 举例：看日志文件时 1tail -fn 30 xxxx.log","categories":[],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"http://yoursite.com/child/tags/linux命令/"}],"keywords":[]},{"title":"linux命令-nohup","slug":"linux命令-nohup","date":"2017-04-23T07:39:40.000Z","updated":"2019-05-23T03:03:26.891Z","comments":true,"path":"2017/04/23/linux命令-nohup/","link":"","permalink":"http://yoursite.com/child/2017/04/23/linux命令-nohup/","excerpt":"","text":"nohup 是 no hang up 的缩写，就是不挂断的意思。 nohup命令：如果你正在运行一个进程，而且你觉得在退出帐户时该进程还不会结束，那么可以 使用nohup命令,该命令可以在你退出帐户/关闭终端之后继续运行相应的进程。 在缺省情况下该作业的所有输出都被重定向到一个名为nohup.out的文件中。nohup 命令运行由 Command参数和任何相关的Arg参数指定的命令，忽略所有挂断（SIGHUP）信号。在注销后使用 nohup 命令运行后台中的程序。要运行后台中的 nohup 命令，添加 &amp; （表示“and”的符号）到命令的尾部。 案例1. nohup command &gt; myout.file 2&gt;&amp;1 &amp;在上面的例子中，0 – stdin (standard input)，1 – stdout (standard output)，2 – stderr (standard error) ；2&gt;&amp;1是将标准错误（2）重定向到标准输出（&amp;1），标准输出（&amp;1）再被重定向输入到myout.file文件中。 2. 0 22 * /usr/bin/python /home/pu/download_pdf/download_dfcf_pdf_to_oss.py &gt; /home/pu/download_pdf/download_dfcf_pdf_to_oss.log 2&gt;&amp;1这是放在crontab中的定时任务，晚上22点时候怕这个任务，启动这个python的脚本，并把日志写在download_dfcf_pdf_to_oss.log文件中 nohup和&amp;的区别&amp; ： 指在后台运行nohup ： 不挂断的运行，注意并没有后台运行的功能，就是指用nohup运行命令可以使命令永久的执行下去，和用户终端没有关系，例如我们断开SSH连接都不会影响他的运行 例如： sh test.sh &amp;将sh test.sh任务放到后台 ，关闭xshell，对应的任务也跟着停止。 nohup sh test.sh将sh test.sh任务放到后台，关闭标准输入，终端不再能够接收任何输入（标准输入），重定向标准输出和标准错误到当前目录下的nohup.out文件，即使关闭xshell退出当前session依然继续运行。 nohup sh test.sh &amp;将sh test.sh任务放到后台，但是依然可以使用标准输入，终端能够接收任何输入，重定向标准输出和标准错误到当前目录下的nohup.out文件，即使关闭xshell退出当前session依然继续运行。","categories":[],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"http://yoursite.com/child/tags/linux命令/"}],"keywords":[]},{"title":"数据库-postgreSQL 让主键自增","slug":"数据库-postgreSQL-让主键自增","date":"2017-03-21T01:48:56.000Z","updated":"2019-07-31T01:42:34.068Z","comments":true,"path":"2017/03/21/数据库-postgreSQL-让主键自增/","link":"","permalink":"http://yoursite.com/child/2017/03/21/数据库-postgreSQL-让主键自增/","excerpt":"","text":"1.建表时创建12345678CREATE TABLE test( test_id SERIAL primary key , test_name character varying, contactname character varying, phone character varying, country character varying ) 2.在已建表的情况下创建12345678CREATE SEQUENCE test_id_seq START WITH 1 INCREMENT BY 1 NO MINVALUE NO MAXVALUE CACHE 1; alter table test alter column id set default nextval(&apos;test_id_seq&apos;);","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/child/tags/数据库/"}],"keywords":[]},{"title":"java编程-移位操作符","slug":"Java编程-移位操作符","date":"2016-12-23T13:00:45.000Z","updated":"2019-05-23T02:57:03.740Z","comments":true,"path":"2016/12/23/Java编程-移位操作符/","link":"","permalink":"http://yoursite.com/child/2016/12/23/Java编程-移位操作符/","excerpt":"","text":"在java代码优化时一般会遵循一个原则， 尽量使用移位来代替’a/b’和’a*b’的操作，这两个操作代价很高，使用移位操作将会更快更有效。 1、三种移位操作 “&lt;&lt;” 不带符号左移，符号位不动，低位补0，高位丢失 “&gt;&gt;” 不带符号右移，符号位不动，正数高位补0，负数高位补1(机器数为补码)，低位丢失 “&gt;&gt;&gt;” 带符号右移，高位补0，低位丢失 2、五种左操作数类型左操作数有五种：long, int, short, byte, char int 移位时左操作数是32位的，此时移位操作作用到32bit上 long 移位时做操作数是64位的，此时移位操作作用到32bit上 short byte char 在移位之前先将左操作数转换成int，然后在32bit上进行移位最终得到一个int类型，所以用&gt;&gt;=,&gt;&gt;&gt;=, &lt;&lt;= 其实是将得到的int做低位截取得到的数值，这里往往容易犯错。 3、右操作数有坑 如果左操作数（转换之后的）是int,那么右操作数只有低5位有效，因为int只有32位，低5位最多可以移动31位 如果左边操作数是long，那么右边操作数只有低6位有效，同理 4、移位操作是对补码进行的 正数的 补码 = 原码 负数的 补码 = 反码 + 1 补码的补码等于原码","categories":[],"tags":[{"name":"java编程","slug":"java编程","permalink":"http://yoursite.com/child/tags/java编程/"}],"keywords":[]},{"title":"设计模式之代理模式","slug":"设计模式之代理模式","date":"2016-08-19T13:23:12.000Z","updated":"2019-05-17T04:52:20.000Z","comments":true,"path":"2016/08/19/设计模式之代理模式/","link":"","permalink":"http://yoursite.com/child/2016/08/19/设计模式之代理模式/","excerpt":"","text":"代理模式提供了目标对象另外的访问方式，在不修改目标类型的基础上对目标类型进行扩展，符合设计模式中遵循的开闭原则，对扩展开放，对修改关闭。 1. 静态代理静态代理在使用时需要定义接口或者超类，被代理对象与代理对象一起实现同一个接口或者是继承同一个超类。 下面举个例子说明：我们在购买火车票时可以到火车站购买，也可到各个代售点购买，火车站就是目标对象，代售点即是代理对象，他们都能完成购票，最主要的是代售点使用的售票接口就是车站官方的售票接口。 票务接口 TicketService.java1234public interface TicketService&#123; void buyTicket(); void refund();//退票&#125; 目标对象车站 Station.java12345678public class Station implement TicketService&#123; public void buyTicket()&#123; System.out.println(&quot;----买票-----&quot;); &#125; public void refund()&#123; System.out.println(&quot;----退票----&quot;); &#125;&#125; 代理对象代售处 Agency.java12345678910public class Agency implement TicketService&#123; private Station station; public void buyTicket()&#123; System.out.println(&quot;----这里是代售点-----&quot;); station.buyTicket(); &#125; public void refund()&#123; System.out.println(&quot;----代售点不支持退票----&quot;) &#125;&#125; 静态代理可以在不修改目标对象的前提下对目标扩展，但也存在缺点。 因为代理对象需要与目标对象实现一样的接口,所以会有很多代理类,类太多；此外，一旦接口增加方法,目标对象与代理对象都要维护。那么如何解决这些缺点呢，JDK中给出了动态代理的解决方案。 2. 动态代理动态代理又叫做JDK代理，接口代理 动态代理的特点： 代理对象不需要实现接口 代理对象的生成，是利用JDK中的api，动态的在内存中构建代理对象（需要我们指定创建代理对象/目标对象实现的接口类型） JDK中生成代理对象的API代理类所在包:java.lang.reflect.ProxyJDK实现代理只需要使用newProxyInstance方法，但是该方法需要接收三个参数，完整的写法是:1static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces,InvocationHandler h ) 注意该方法是在Proxy类中是静态方法,且接收的三个参数依次为: ClassLoader loader：指定当前目标对象使用类加载器,获取加载器的方法是固定的 Class&lt;?&gt;[] interfaces：目标对象实现的接口的类型,使用泛型方式确认类型 InvocationHandler h：事件处理,执行目标对象的方法时，会触发事件处理器的方法，会把当前执行目标对象的方法作为参数传入。 代码示例:接口类 TicketService.java以及接口实现类,目标对象Station是一样的，没有做修改。在这个基础上，增加一个代理工厂类(ProxyFactory.java)，将代理类写在这个地方，然后在测试类(需要使用到代理的代码)中先建立目标对象和代理对象的联系，然后代用代理对象的中同名方法代理工厂类:ProxyFactory.java 1234567891011121314151617181920212223242526public class ProxyFactory&#123; //维护一个目标对象 private Object target; public ProxyFactory(Object target)&#123; this.target=target; &#125; //给目标对象生成代理对象 public Object getProxyInstance()&#123; return Proxy.newProxyInstance( target.getClass().getClassLoader(), target.getClass().getInterfaces(), new InvocationHandler() &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(&quot;--这是代售点购票系统--&quot;); //执行目标对象方法 Object returnValue = method.invoke(target, args); return returnValue; &#125; &#125; ); &#125;&#125; 测试类:DynamicProxyTest.java123456789101112public class DynamicProxyTest &#123; public static void main(String[] args) &#123; // 目标对象 TicketService target = new Station(); System.out.println(target.getClass()); // 创建代理对象 TicketService proxy = (TicketService) new ProxyFactory(target).getProxyInstance(); System.out.println(proxy.getClass()); // 代理对象执行方法 proxy.buyTicket(); &#125;&#125; 总结：代理对象不需要实现接口，但是目标对象一定要实现接口，否则不能用动态代理。 3. Cglib代理上面的静态代理和动态代理模式都是要求目标对象是实现一个接口的目标对象，但是有时候目标对象只是一个单独的对象,并没有实现任何的接口，这个时候就可以使用以目标对象子类的方式类实现代理，这种方法就叫做:Cglib代理 Cglib代理，也叫作子类代理，它是在内存中构建一个子类对象从而实现对目标对象功能的扩展。 JDK的动态代理有一个限制，就是使用动态代理的对象必须实现一个或多个接口，如果想代理没有实现接口的类,就可以使用Cglib实现。 Cglib是一个强大的高性能的代码生成包，它可以在运行期扩展java类与实现java接口。它广泛的被许多AOP的框架使用，例如Spring AOP和synaop，为他们提供方法的interception(拦截)。 Cglib包的底层是通过使用一个小而块的字节码处理框架ASM来转换字节码并生成新的类。不鼓励直接使用ASM,因为它要求你必须对JVM内部结构包括class文件的格式和指令集都很熟悉。 Cglib子类代理实现方法: 需要引入cglib的jar文件，但是Spring的核心包中已经包括了Cglib功能,所以直接引入pring-core-3.2.5.jar即可。 引入功能包后，就可以在内存中动态构建子类 代理的类不能为final，否则报错 目标对象的方法如果为final/stati，那么就不会被拦截，即不会执行目标对象额外的业务方法。 代码示例:目标对象类 Station.java ，目标对象,没有实现任何接口123456public class Station &#123; public void buyTicket() &#123; System.out.println(&quot;----买票----&quot;); &#125;&#125; Cglib代理工厂 ProxyFactory.java123456789101112131415161718192021222324252627public class ProxyFactory implements MethodInterceptor&#123; private Object target; public ProxyFactory(Object target) &#123; this.target = target; &#125; //给目标对象创建一个代理对象 public Object getProxyInstance()&#123; //1.工具类 Enhancer en = new Enhancer(); //2.设置父类 en.setSuperclass(target.getClass()); //3.设置回调函数 en.setCallback(this); //4.创建子类(代理对象) return en.create(); &#125; @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; System.out.println(&quot;--这是代售点购票系统--&quot;); //执行目标对象的方法 Object returnValue = method.invoke(target, args); return returnValue; &#125;&#125; 测试类:1234567891011public class CglibProxyTest &#123; @Test public void test()&#123; //目标对象 Station target = new Station(); //代理对象 Station proxy = (Station)new ProxyFactory(target).getProxyInstance(); //执行代理对象的方法 proxy.buyTicket(); &#125;&#125; 在Spring的AOP编程中:如果加入容器的目标对象有实现接口，用JDK代理如果目标对象没有实现接口，用Cglib代理","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/child/tags/设计模式/"}],"keywords":[]},{"title":"设计模式之单例模式","slug":"设计模式之单例模式","date":"2016-08-04T07:15:31.000Z","updated":"2019-04-25T07:16:26.000Z","comments":true,"path":"2016/08/04/设计模式之单例模式/","link":"","permalink":"http://yoursite.com/child/2016/08/04/设计模式之单例模式/","excerpt":"","text":"许多时候整个系统只需要拥有一个的全局对象，这样有利于我们协调系统整体的行为。比如在某个服务器程序中，该服务器的配置信息存放在一个文件中，这些配置数据由一个单例对象统一读取，然后服务进程中的其他对象再通过这个单例对象获取这些配置信息。这种方式简化了在复杂环境下的配置管理。 1、什么是单例1.1 定义单例模式，也叫单子模式，是一种常用的软件设计模式。在应用这个模式时，单例对象的类必须保证只有一个实例存在。 1.2 实现思路面向对象编程中，我们通过类的构造器生成对象，只要内存足够就可以构造出很多个实例，所以要限制某个类型只有唯一的一个实例对象，那就要从构造函数着手。 需要声明一个能返回对象的引用，定义一个获得该对象引用的方法（必须是静态方法，通常使用getInstance这个名称) 当我们调用这个方法时，如果类持有的引用不为空就返回这个引用，如果类保持的引用为空就创建该类的实例并将实例的引用赋予该类保持的引用 最后将该类的构造函数定义为私有方法 2、懒汉式单例按照以上的实现思路，实现出第一个单例类型：1234567891011public class Singleton &#123; private static Singleton instance; //引用 private Singleton ()&#123;&#125; //私有构造器 public static Singleton getInstance() &#123; //静态方法 if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; &#125; 这种实现方式称为懒汉式，所谓懒汉，指的是只有在需要对象的时候才生成。 2.1 单例的线程安全单例的线程安全是指在并发环境中，不同的线程拿到的单例对象也必须保证是同一个实例。 上文实现的单例类型是线程不安全的，如果有两个线程同时执行到 if (instance == null) 这行代码，判断都通过，然后各自执行 new 语句并各自返回一个实例，这时候就产生了多个对象。 解决方法有两种： 给getInstance方法加互斥锁(不推荐使用) 12345678910public class Singleton &#123; private static Singleton instance; private Singleton ()&#123;&#125; public static synchronized Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; &#125; 缺点：效率太低了，每个线程在想获得类的实例时候，执行getInstance()方法都要进行同步。而其实这个方法只执行一次实例化代码就够了，后面的想获得该类实例，直接return就行了。方法进行同步效率太低要改进。 双重检验锁（推荐使用）1234567891011121314public class Singleton &#123; private volatile static Singleton singleton; private Singleton ()&#123;&#125; public static Singleton getSingleton() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125; &#125; Double-Check概念对于多线程开发者来说不会陌生，如代码中所示，我们进行了两次if (singleton == null)检查,这样实例化代码只用执行一次，后面再次访问时，判断if (singleton == null)，直接return实例化对象。 还有值得注意的是，双重校验锁的实现方式中，静态成员变量singleton必须通过volatile来修饰，保证其初始化的原子性，否则可能被引用到一个未初始化完成的对象。 3、饿汉式单例前面提到的懒汉模式，其实是一种lazy-loading思想的实践，这种实现有一个比较大的好处，就是只有真正用到的时候才创建，如果没被使用到，就一直不会被创建，这就避免了不必要的开销。 但是这种做法，其实也有一个小缺点，就是第一次使用的时候，需要进行初始化操作，可能会有比较高的耗时。如果是已知某一个对象一定会使用到的话，其实可以采用一种饿汉的实现方式。所谓饿汉，就是事先准备好，需要的时候直接给你就行了。 1234567891011121314151617public class Singleton &#123; private static Singleton instance = new Singleton(); private Singleton ()&#123;&#125; public static Singleton getInstance() &#123; return instance; &#125; &#125; public class Singleton &#123; private Singleton instance = null; static &#123; instance = new Singleton(); &#125; private Singleton ()&#123;&#125; public static Singleton getInstance() &#123; return this.instance; &#125; 以上两段代码都是通过定义静态的成员变量（懒汉式只有声明没有定义）。饿汉模式中的静态变量是随着类加载时被完成实例化的。饿汉变种中的静态代码块也会随着类的加载一块执行。 因为类的初始化是由ClassLoader完成的，这其实是利用了ClassLoader的线程安全机制。ClassLoader的loadClass方法在加载类的时候使用了synchronized关键字。也正是因为这样， 除非被重写，这个方法默认在整个装载过程中都是同步的（线程安全的） 除了以上两种饿汉方式，还有一种实现方式也是借助了calss的初始化来实现的，那就是通过静态内部类来实现的单例（推荐使用）： 123456789public class Singleton &#123; private static class SingletonHolder &#123; private static final Singleton INSTANCE = new Singleton(); &#125; private Singleton ()&#123;&#125; public static final Singleton getInstance() &#123; return SingletonHolder.INSTANCE; &#125; &#125; 前面提到的饿汉模式，只要Singleton类被装载了，那么instance就会被实例化。 而这种方式是Singleton类被装载了，instance不一定被初始化。因为SingletonHolder类没有被主动使用，只有显示通过调用getInstance方法时，才会显示装载SingletonHolder类，从而实例化instance。 使用静态内部类，借助了classloader来实现了线程安全，这与饿汉模式有着异曲同工之妙，但是他有兼顾了懒汉模式的lazy-loading功能，相比较之下，有很大优势。 4、枚举式单例Joshua Bloch大神在《Effective Java》中明确表达过的观点： 使用枚举实现单例的方法虽然还没有广泛采用，但是单元素的枚举类型已经成为实现Singleton的最佳方法。 枚举单例：（墙裂推荐）12345public enum Singleton &#123; INSTANCE; public void whateverMethod() &#123; &#125; &#125; 最精简的 线程安全的 可解决反序列化破坏单例的问题 5、应用场景 Windows的Task Manager（任务管理器）就是很典型的单例模式 windows的Recycle Bin（回收站）也是典型的单例应用。在整个系统运行过程中，回收站一直维护着仅有的一个实例。 操作系统的文件系统，也是大的单例模式实现的具体例子，一个操作系统只能有一个文件系统。 网站的计数器，一般也是采用单例模式实现，否则难以同步。 应用程序的日志应用，一般都何用单例模式实现，这一般是由于共享的日志文件一直处于打开状态，因为只能有一个实例去操作，否则内容不好追加。 Web应用的配置对象的读取，一般也应用单例模式，这个是由于配置文件是共享的资源。 数据库连接池的设计一般也是采用单例模式，因为数据库连接是一种数据库资源。数据库软件系统中使用数据库连接池，主要是节省打开或者关闭数据库连接所引起的效率损耗，这种效率上的损耗还是非常昂贵的，用单例模式来维护，就可以大大降低这种损耗。 多线程的线程池的设计一般也是采用单例模式，这是由于线程池要方便对池中的线程进行控制。 HttpApplication 也是单例的典型应用。","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/child/tags/设计模式/"}],"keywords":[]},{"title":"日志框架-logback配置详解","slug":"日志框架-logback配置详解","date":"2016-08-03T16:00:00.000Z","updated":"2019-08-04T14:57:11.374Z","comments":true,"path":"2016/08/04/日志框架-logback配置详解/","link":"","permalink":"http://yoursite.com/child/2016/08/04/日志框架-logback配置详解/","excerpt":"","text":"logback是java的日志开源组件，是log4j创始人写的，性能比log4j要好，目前主要分为3个模块 logback-core:核心代码模块 logback-classic:log4j的一个改良版本，同时实现了slf4j的接口，这样你如果之后要切换其他日志组件也是一件很容易的事 logback-access:访问模块与Servlet容器集成提供通过Http来访问日志的功能 1. logback的配置1.1 配置获取顺序logback在启动的时候，会按照下面的顺序加载配置文件 如果java程序启动时指定了logback.configurationFile属性，就用该属性指定的配置文件。如java -Dlogback.configurationFile=/path/to/mylogback.xml Test ，这样执行Test类的时候就会加载/path/to/mylogback.xml配置 在classpath中查找 logback.groovy 文件 在classpath中查找 logback-test.xml 文件 在classpath中查找 logback.xml 文件 如果是 jdk6+,那么会调用ServiceLoader 查找 com.qos.logback.classic.spi.Configurator接口的第一个实现类 自动使用ch.qos.logback.classic.BasicConfigurator，在控制台输出日志 上面的顺序表示优先级，使用java -D配置的优先级最高，只要获取到配置后就不会再执行下面的流程。相关代码可以看ContextInitializer#autoConfig()方法。 1.2 关于SLF4j的日志输出级别在slf4j中，从小到大的日志级别依旧是trace &lt; debug &lt; info &lt; warn &lt; error，级别越小输出信息越多。 1.3 logback.xml 配置样例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!--debug属性表示要不要打印 logback内部日志信息，true则表示要打印--&gt;&lt;configuration debug=\"false\" scan=\"true\" scanPeriod=\"1 seconds\"&gt; &lt;!--后面输出格式中可以通过 %contextName 来打印日志上下文名称--&gt; &lt;contextName&gt;logback&lt;/contextName&gt; &lt;!--定义参数,后面可以通过$&#123;app.name&#125;使用--&gt; &lt;property name=\"app.name\" value=\"effective\"/&gt; &lt;!--ConsoleAppender 用于在屏幕上输出日志--&gt; &lt;appender name=\"stdout\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;!--定义了一个过滤器,在LEVEL之下的日志输出不会被打印出来--&gt; &lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"/&gt; &lt;!-- encoder 默认配置为PatternLayoutEncoder --&gt; &lt;!--定义控制台输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d [%thread] %-5level %logger&#123;36&#125; [%file : %line] - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name=\"file\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!--定义日志输出的路径--&gt; &lt;!--这里的scheduler.manager.server.home 没有在上面的配置中设定，所以会使用java启动时配置的值--&gt; &lt;!--比如通过 java -Dscheduler.manager.server.home=/path/to XXXX 配置该属性--&gt; &lt;file&gt;../logs/$&#123;app.name&#125;.log&lt;/file&gt; &lt;!--定义日志滚动的策略--&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!--定义文件滚动时的文件名的格式--&gt; &lt;fileNamePattern&gt;../logs/$&#123;app.name&#125;.%d&#123;yyyy-MM-dd.HH&#125;.log.gz&lt;/fileNamePattern&gt; &lt;!--60天的时间周期，日志量最大20GB--&gt; &lt;maxHistory&gt;60&lt;/maxHistory&gt; &lt;!-- 该属性在 1.1.6版本后 才开始支持--&gt; &lt;totalSizeCap&gt;20GB&lt;/totalSizeCap&gt; &lt;/rollingPolicy&gt; &lt;triggeringPolicy class=\"ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy\"&gt; &lt;!--每个日志文件最大100MB--&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;!--定义输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d [%thread] %-5level %logger&#123;36&#125; [%file : %line] - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!--root是默认的logger 这里设定输出级别是info--&gt; &lt;root level=\"info\"&gt; &lt;!--定义了两个appender，日志会通过往这两个appender里面写--&gt; &lt;appender-ref ref=\"stdout\"/&gt; &lt;appender-ref ref=\"file\"/&gt; &lt;/root&gt; &lt;!--对于类路径以 com.panda 开头的Logger,并设置输出级别--&gt; &lt;!--这个logger没有指定appender，它会继承root节点中定义的那些appender--&gt; &lt;logger name=\"com.panda\" level=\"debug\"/&gt; &lt;!--通过 LoggerFactory.getLogger(\"mytest\") 可以获取到这个logger--&gt; &lt;!--由于这个logger自动继承了root的appender，root中已经有stdout的appender了，自己这边又引入了stdout的appender--&gt; &lt;!--如果没有设置 additivity=\"false\" ,就会导致一条日志在控制台输出两次的情况--&gt; &lt;!--additivity表示要不要使用rootLogger配置的appender进行输出--&gt; &lt;logger name=\"mytest\" level=\"info\" additivity=\"false\"&gt; &lt;appender-ref ref=\"stdout\"/&gt; &lt;/logger&gt; &lt;!--由于设置了 additivity=\"false\" ，所以输出时不会使用rootLogger的appender--&gt; &lt;!--但是这个logger本身又没有配置appender，所以使用这个logger输出日志的话就不会输出到任何地方--&gt; &lt;logger name=\"mytest2\" level=\"info\" additivity=\"false\"/&gt;&lt;/configuration&gt; 2. 配置详解2.1 configuration节点相关属性 属性名称 默认值 介绍 debug false 要不要打印 logback内部日志信息，true则表示要打印。建议开启 scan true 配置发送改变时，要不要重新加载 scanPeriod 1 seconds 检测配置发生变化的时间间隔。如果没给出时间单位，默认时间单位是毫秒 2.2 configuration子节点介绍2.2.1 contextName节点设置日志上下文名称，后面输出格式中可以通过定义 %contextName 来打印日志上下文名称 2.2.2 property节点用来设置相关变量,通过key-value的方式配置，然后在后面的配置文件中通过 ${key}来访问 2.2.3 appender 节点日志输出组件，主要负责日志的输出以及格式化日志。常用的属性有name和class 属性名称 默认值 介绍 name 无默认值 appender组件的名称，后面给logger指定appender使用 class 无默认值 appender的具体实现类。常用的有 ConsoleAppender、FileAppender、RollingFileAppender ConsoleAppender：向控制台输出日志内容的组件，只要定义好encoder节点就可以使用。 FileAppender：向文件输出日志内容的组件，用法也很简单，不过由于没有日志滚动策略，一般很少使用 RollingFileAppender：向文件输出日志内容的组件，同时可以配置日志文件滚动策略，在日志达到一定条件后生成一个新的日志文件。 appender节点中有一个子节点filter，配置具体的过滤器，比如上面的例子配置了一个内置的过滤器ThresholdFilter，然后设置了level的值为DEBUG。这样用这个appender输出日志的时候都会经过这个过滤器，日志级别低于DEBUG的都不会输出来。 在RollingFileAppender中，可以配置相关的滚动策略，具体可以看配置样例的注释。 2.2.4 logger以及root节点root节点和logger节点其实都是表示Logger组件。个人觉的可以把他们之间的关系可以理解为父子关系，root是最顶层的logger，正常情况getLogger(“name/class”)没有找到对应logger的情况下，都是使用root节点配置的logger。 如果配置了logger，并且通过getLogger(“name/class”)获取到这个logger，输出日志的时候，就会使用这个logger配置的appender输出，同时还会使用rootLogger配置的appender。我们可以使用logger节点的additivity=&quot;false&quot;属性来屏蔽rootLogger的appender。这样就可以不使用rootLogger的appender输出日志了。 关于logger的获取，一般logger是配置name的。我们再代码中经常通过指定的CLass来获取Logger，比如这样LoggerFactory.getLogger(Test.class);,其实这个最后也是转成对应的包名+类名的字符串com.kongtrio.Test.class。假设有一个logger配置的那么是com.kongtrio，那么通过LoggerFactory.getLogger(Test.class)获取到的logger就是这个logger。 也就是说，name可以配置包名，也可以配置自定义名称。 上面说的logger和root节点的父子关系只是为了方便理解，具体的底层实现本人并没有看，他们之间真正的关系读者有兴趣的话可以去看logback的源码","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://yoursite.com/child/tags/框架/"}],"keywords":[]},{"title":"设计模式之建造者模式","slug":"设计模式之建造者模式","date":"2016-08-02T05:35:36.000Z","updated":"2019-04-24T08:30:10.000Z","comments":true,"path":"2016/08/02/设计模式之建造者模式/","link":"","permalink":"http://yoursite.com/child/2016/08/02/设计模式之建造者模式/","excerpt":"","text":"静态工厂和构造器有一个共同的局限性：不能很好的扩展到大量的可选参数。对于初始化参数很多的类，常规的做法是使用重载构造器，但是当参数很多的时候，客户端代码会很难写，并且较难阅读。 这时，还有另外一种替代方案，使用javaBean模式，在这种模式下先默认构造器创建对象，然后用setter方法设置需要的参数。遗憾的是，JavaBean模式自身有着很严重的缺点，因为构造过程分成了好几个调用，在构造过程中JavaBean可能处于不一致的状态，类无法仅仅通过检查构造器参数的有效性来保证一致性。 最终还有第三种替代方案，既能确保安全性，也能保证可读性，那就是建造者模式。 1. 建造者模式直接看一个简单例子：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Person &#123; private final String name; private final String address; private final int age; private final int sex; private final String tel; public static class Builder &#123; //Required parameters private final String name; private final int age; private final int sex; //Optional parameters private String address = &quot;浙江杭州&quot;; private String tel = &quot;0571&quot;; public Builder(String name, int age, int sex) &#123; this.name = name; this.age = age; this.sex = sex; &#125; public Builder address(String address) &#123; this.address = address; return this; &#125; public Builder tel(String tel) &#123; this.tel = tel; return this; &#125; public Person build()&#123; return new Person(this); &#125; &#125; private Person(Builder builder)&#123; name = builder.name; address = builder.address; sex = builder.sex; age = builder.age; tel = builder.tel; &#125; public static void main(String[] args)&#123; Person p = new Builder(&quot;zhaozhengkang&quot;,25,1).address(&quot;yuhang&quot;).tel(&quot;123456789&quot;).build(); &#125;&#125; builder的设值方法返回builder本身，以便把调用连接起来形成一个流式的API. 2. 类层次中使用建造者模式 （effective java rule2,30）使用平行层次结构的builder时，各自嵌套在相应类中。抽象类有抽象类的builder，具体类有具体类的builder。12345678910111213141516171819public abstract class Pizza &#123; public enum Topping &#123; HAM, MUSHROOM, ONION, PEPPER, SAUSAGE &#125; final Set&lt;Topping&gt; toppings; abstract static class Builder&lt;T extends Builder&lt;T&gt;&gt;&#123; EnumSet&lt;Topping&gt; toppings = EnumSet.noneOf(Topping.class); public T addTopping(Topping topping)&#123; toppings.add(Objects.requireNonNull(topping)); return self(); &#125; abstract Pizza build(); protected abstract T self(); &#125; Pizza(Builder&lt;?&gt; builder)&#123; toppings = builder.toppings.clone(); &#125;&#125; Builder&lt;T extends Builder&gt;这一句使用了递归类型限制中的模拟自类型模拟自类型（自限定类型）所做的就是要求在继承关系中，强制要求将正在定义的类当做参数传递给基类，看下面代码： 1234567891011121314151617181920212223242526public class NyPizza extends Pizza &#123; public enum Size&#123;SMALL, MEDIUM, LARGER&#125; private final Size size; public static class NyPizzaBuilder extends Pizza.Builder&lt;NyPizzaBuilder&gt;&#123; private final Size size; public NyPizzaBuilder(Size size)&#123; this.size = Objects.requireNonNull(size); &#125; @Override public NyPizza build() &#123; return new NyPizza(this); &#125; @Override protected NyPizzaBuilder self() &#123; return this; &#125; &#125; private NyPizza(NyPizzaBuilder builder) &#123; super(builder); size = builder.size; &#125; public static void main(String[] args)&#123; NyPizza p = new NyPizzaBuilder(Size.SMALL).addTopping(Topping.SAUSAGE).addTopping(Topping.ONION).build(); &#125;&#125; 继承时，必须将正在定义的类NyPizzaBuilder作为类型参数传给基类Pizza.Builder，否则无法编译。自限定类型属于泛型知识，将另开一篇进行研究。 参考资料《Effcitive Java》","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/child/tags/设计模式/"}],"keywords":[]},{"title":"设计模式之工厂模式","slug":"设计模式之工厂模式","date":"2016-08-01T05:35:36.000Z","updated":"2019-04-24T08:34:02.000Z","comments":true,"path":"2016/08/01/设计模式之工厂模式/","link":"","permalink":"http://yoursite.com/child/2016/08/01/设计模式之工厂模式/","excerpt":"","text":"1. 简单工厂根据客户端传入的参数进行判断，再决定创建哪种实例，缺点很明显： 传参错误则不能创建正确的实例 扩展需要修改工厂方法 2.工厂方法在工厂类中定义若干的函数来创建实例，每个函数创建一种实例，解决的简单工厂需要传参的问题 3. 静态工厂方法3.1 定义将工厂类中的工厂方法定义为静态类型，使用静态工厂不需要创建工厂实例。1234567891011121314151617public class SendFactory &#123; public static Sender produceMail()&#123; return new MailSender(); &#125; public static Sender produceSms()&#123; return new SmsSender(); &#125; &#125; public class FactoryTest &#123; public static void main(String[] args) &#123; Sender sender = SendFactory.produceMail(); sender.Send(); &#125; &#125; （静态）工厂方法缺点是： 对于扩展需要修改工厂类 3.2 用静态工厂方法代替构造器（Effective java：rule 1）如果不通过共有构造器，或者说除了公有构造器之外，类还可以给他的客户端提供静态工厂方法，这样做既有优势又有劣势。优势在于： 第一点：它们有名称。使客户端代码更容易阅读，例如：构造器BigInteger(int,int,Random)返回的BigInteger可能是素数，如果用静态工厂方法BigInteger.probablePrime来表示，就会更清楚。 第二点：不必每次调用的时候都创建一个新对象。静态工厂方法能够为重复的调用返回相同的对象 第三点：静态工厂方法可以返回类型的任何子类型对象，构造器则做不到这一点。 第四点：每次调用返回对象的类可以变化，取决于静态工厂方法的参数 12345678910111213141516171819202122232425262728//该代码 解释以上四点优势public class Child &#123; protected String classId; public Child()&#123; classId = &quot;CHILD&quot;; &#125; public static class Son extends Child &#123; public Son()&#123; classId = &quot;SON&quot;; &#125; &#125; public static class Daughter extends Child &#123; public Daughter()&#123; classId = &quot;DAUGHTER&quot;; &#125; &#125; public static Child sonFactory()&#123; return new Son(); &#125; public static Child daughterFactory()&#123; return new Daughter(); &#125; public static Child childFactory(int sex)&#123; return sex == 1 ? new Son() : new Daughter(); &#125; public static void main(String[] args)&#123; Child son = Child.sonFactory(); Child child = Child.childFactory(2); System.out.println(son.classId + &quot;\\n&quot; + child.classId); &#125;&#125; 第五点：方法返回对象的类，在编写包含该静态方法的类时是可以不存在的。第五点的灵活性是构成服务提供者框架（Service Provider Framework）的基础，将另起一片单独研究。 静态工厂方法的劣势在于： 程序员很难发现这些静态工厂方法。 类如果没有公有或者受保护的构造器，就不能被子类化（不允许被继承）。 4.抽象工厂对每一个需要创建实例的类都配置了一个工厂类，需要扩展的时候，增加一个工厂类，实现工厂类的抽象方法进行实例创建，实现了开闭原则。","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/child/tags/设计模式/"}],"keywords":[]},{"title":"日志框架-Log4j配置文件详解","slug":"日志框架-Log4j 配置文件","date":"2016-07-22T16:00:00.000Z","updated":"2019-08-04T14:48:06.244Z","comments":true,"path":"2016/07/23/日志框架-Log4j 配置文件/","link":"","permalink":"http://yoursite.com/child/2016/07/23/日志框架-Log4j 配置文件/","excerpt":"","text":"1、简介Log4j有三个主要的组件： Loggers(记录器):日志类别和级别; Appenders (输出源):日志要输出的地方; Layouts(布局):日志以何种形式输出 1.1、Loggers Loggers组件在此系统中被分为五个级别,分别用来指定这条日志信息的重要程度：DEBUG、INFO、WARN、ERROR和FATAL; 这五个级别是有顺序的，DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL; Log4j有一个规则：只输出级别不低于设定级别的日志信息，假设Loggers级别设定为INFO，则INFO、WARN、ERROR和FATAL级别的日志信息都会输出，而级别比INFO低的DEBUG则不会输出。 1.2、Appenders禁用和使用日志请求只是Log4j的基本功能，Log4j日志系统还提供许多强大的功能，比如允许把日志输出到不同的地方，如控制台（Console）、文件（Files）等，可以根据天数或者文件大小产生新的文件，可以以流的形式发送到其它地方等等。 常使用的类如下： org.apache.log4j.ConsoleAppender（控制台） org.apache.log4j.FileAppender（文件） org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件） org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件） org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方） 配置模式1234log4j.appender.appenderName = classNamelog4j.appender.appenderName.Option1 = value1…log4j.appender.appenderName.OptionN = valueN 1.3、LayoutsLog4j可以在Appenders的后面附加Layouts来完成这个功能。Layouts提供四种日志输出样式，如根据HTML样式、自由指定样式、包含日志级别与信息的样式和包含日志时间、线程、类别等信息的样式。 常使用的类如下： org.apache.log4j.HTMLLayout（以HTML表格形式布局） org.apache.log4j.PatternLayout（可以灵活地指定布局模式） org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串） org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等信息） 配置模式： 1234log4j.appender.appenderName.layout =classNamelog4j.appender.appenderName.layout.Option1 = value1...log4j.appender.appenderName.layout.OptionN = valueN 2、配置详解在实际应用中，要使Log4j在系统中运行须事先设定配置文件。配置文件事实上也就是对Logger、Appender及Layout进行相应设定。Log4j支持两种配置文件格式: 一种是XML格式的文件， 一种是properties属性文件。 下面以properties属性文件为例介绍log4j.properties的配置。 2.1、配置根Logger12log4j.rootLogger = [ level ] , appenderName1, appenderName2, …log4j.additivity.org.apache=false：表示Logger不会在父Logger的appender里输出，默认为true。 level ：设定日志记录的最低级别，可设的值有OFF、FATAL、ERROR、WARN、INFO、DEBUG、ALL或者自定义的级别，Log4j建议只使用中间四个级别。通过在这里设定级别，您可以控制应用程序中相应级别的日志信息的开关，比如在这里设定了INFO级别，则应用程序中所有DEBUG级别的日志信息将不会被打印出来。 appenderName：就是指定日志信息要输出到哪里。可以同时指定多个输出目的地，用逗号隔开。例如：log4j.rootLogger＝INFO,A1,B2,C3 2.2、配置日志信息输出目的地（appender）1log4j.appender.appenderName = className appenderName：自定义appderName，在log4j.rootLogger设置中使用；className：可设值如下： org.apache.log4j.ConsoleAppender（控制台） org.apache.log4j.FileAppender（文件） org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件） org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件） org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方） ConsoleAppender选项 Threshold=WARN：指定日志信息的最低输出级别，默认为DEBUG。 ImmediateFlush=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。 Target=System.err：默认值是System.out。 FileAppender选项 Threshold=WARN：指定日志信息的最低输出级别，默认为DEBUG。 ImmediateFlush=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。 Append=false：true表示消息增加到指定文件中，false则将消息覆盖指定的文件内容，默认值是true。 File=D:/logs/logging.log4j：指定消息输出到logging.log4j文件中。 DailyRollingFileAppender选项 Threshold=WARN：指定日志信息的最低输出级别，默认为DEBUG。 ImmediateFlush=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。 Append=false：true表示消息增加到指定文件中，false则将消息覆盖指定的文件内容，默认值是true。 File=D:/logs/logging.log4j：指定当前消息输出到logging.log4j文件中。 DatePattern=’.’yyyy-MM：每月滚动一次日志文件，即每月产生一个新的日志文件。当前月的日志文件名为logging.log4j，前一个月的日志文件名为logging.log4j.yyyy-MM。另外，也可以指定按周、天、时、分等来滚动日志文件，对应的格式如下：123456&apos;.&apos;yyyy-MM：每月&apos;.&apos;yyyy-ww：每周&apos;.&apos;yyyy-MM-dd：每天&apos;.&apos;yyyy-MM-dd-a：每天两次&apos;.&apos;yyyy-MM-dd-HH：每小时&apos;.&apos;yyyy-MM-dd-HH-mm：每分钟 RollingFileAppender选项 Threshold=WARN：指定日志信息的最低输出级别，默认为DEBUG。 ImmediateFlush=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。 Append=false：true表示消息增加到指定文件中，false则将消息覆盖指定的文件内容，默认值是true。 File=D:/logs/logging.log4j：指定消息输出到logging.log4j文件中。 MaxFileSize=100KB：后缀可以是KB, MB 或者GB。在日志文件到达该大小时，将会自动滚动，即将原来的内容移到logging.log4j.1文件中。 MaxBackupIndex=2：指定可以产生的滚动文件的最大数，例如，设为2则可以产生logging.log4j.1，logging.log4j.2两个滚动文件和一个logging.log4j文件。 2.3、配置日志信息的输出格式（Layout）1log4j.appender.appenderName.layout=className className：可设值如下： org.apache.log4j.HTMLLayout（以HTML表格形式布局） org.apache.log4j.PatternLayout（可以灵活地指定布局模式） org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串） org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等等信息） HTMLLayout选项 LocationInfo=true：输出java文件名称和行号，默认值是false。 Title=My Logging： 默认值是Log4J Log Messages。 PatternLayout选项：ConversionPattern=%m%n：设定以怎样的格式显示消息。 格式化符号说明：12345678910111213%p：输出日志信息的优先级，即DEBUG，INFO，WARN，ERROR，FATAL。%d：输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，如：%d&#123;yyyy/MM/dd HH:mm:ss,SSS&#125;。%r：输出自应用程序启动到输出该log信息耗费的毫秒数。%t：输出产生该日志事件的线程名。%l：输出日志事件的发生位置，相当于%c.%M(%F:%L)的组合，包括类全名、方法、文件名以及在代码中的行数。例如：test.TestLog4j.main(TestLog4j.java:10)。%c：输出日志信息所属的类目，通常就是所在类的全名。%M：输出产生日志信息的方法名。%F：输出日志消息产生时所在的文件名称。%L:：输出代码中的行号。%m:：输出代码中指定的具体日志信息。%n：输出一个回车换行符，Windows平台为&quot;\\r\\n&quot;，Unix平台为&quot;\\n&quot;。%x：输出和当前线程相关联的NDC(嵌套诊断环境)，尤其用到像java servlets这样的多客户多线程的应用中。%%：输出一个&quot;%&quot;字符。 另外，还可以在%与格式字符之间加上修饰符来控制其最小长度、最大长度、和文本的对齐方式。如： 指定输出category的名称，最小的长度是20，如果category的名称长度小于20的话，默认的情况下右对齐。 %-20c：”-“号表示左对齐。 %.30c：指定输出category的名称，最大的长度是30，如果category的名称长度大于30的话，就会将左边多出的字符截掉，但小于30的话也不会补空格。 附：Log4j比较全面的配置Log4j配置文件实现了输出到控制台、文件、回滚文件、发送日志邮件、输出到数据库日志表、自定义标签等全套功能。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475log4j.rootLogger=DEBUG,console,dailyFile,imlog4j.additivity.org.apache=true# 控制台(console)log4j.appender.console=org.apache.log4j.ConsoleAppenderlog4j.appender.console.Threshold=DEBUGlog4j.appender.console.ImmediateFlush=truelog4j.appender.console.Target=System.errlog4j.appender.console.layout=org.apache.log4j.PatternLayoutlog4j.appender.console.layout.ConversionPattern=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n# 日志文件(logFile)log4j.appender.logFile=org.apache.log4j.FileAppenderlog4j.appender.logFile.Threshold=DEBUGlog4j.appender.logFile.ImmediateFlush=truelog4j.appender.logFile.Append=truelog4j.appender.logFile.File=D:/logs/log.log4jlog4j.appender.logFile.layout=org.apache.log4j.PatternLayoutlog4j.appender.logFile.layout.ConversionPattern=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n# 回滚文件(rollingFile)log4j.appender.rollingFile=org.apache.log4j.RollingFileAppenderlog4j.appender.rollingFile.Threshold=DEBUGlog4j.appender.rollingFile.ImmediateFlush=truelog4j.appender.rollingFile.Append=truelog4j.appender.rollingFile.File=D:/logs/log.log4jlog4j.appender.rollingFile.MaxFileSize=200KBlog4j.appender.rollingFile.MaxBackupIndex=50log4j.appender.rollingFile.layout=org.apache.log4j.PatternLayoutlog4j.appender.rollingFile.layout.ConversionPattern=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n# 定期回滚日志文件(dailyFile)log4j.appender.dailyFile=org.apache.log4j.DailyRollingFileAppenderlog4j.appender.dailyFile.Threshold=DEBUGlog4j.appender.dailyFile.ImmediateFlush=truelog4j.appender.dailyFile.Append=truelog4j.appender.dailyFile.File=D:/logs/log.log4jlog4j.appender.dailyFile.DatePattern=&apos;.&apos;yyyy-MM-ddlog4j.appender.dailyFile.layout=org.apache.log4j.PatternLayoutlog4j.appender.dailyFile.layout.ConversionPattern=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n# 应用于socketlog4j.appender.socket=org.apache.log4j.RollingFileAppenderlog4j.appender.socket.RemoteHost=localhostlog4j.appender.socket.Port=5001log4j.appender.socket.LocationInfo=true# Set up for Log Factor 5log4j.appender.socket.layout=org.apache.log4j.PatternLayoutlog4j.appender.socket.layout.ConversionPattern=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n# Log Factor 5 Appenderlog4j.appender.LF5_APPENDER=org.apache.log4j.lf5.LF5Appenderlog4j.appender.LF5_APPENDER.MaxNumberOfRecords=2000# 发送日志到指定邮件log4j.appender.mail=org.apache.log4j.net.SMTPAppenderlog4j.appender.mail.Threshold=FATALlog4j.appender.mail.BufferSize=10log4j.appender.mail.From = xxx@mail.comlog4j.appender.mail.SMTPHost=mail.comlog4j.appender.mail.Subject=Log4J Messagelog4j.appender.mail.To= xxx@mail.comlog4j.appender.mail.layout=org.apache.log4j.PatternLayoutlog4j.appender.mail.layout.ConversionPattern=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n# 应用于数据库log4j.appender.database=org.apache.log4j.jdbc.JDBCAppenderlog4j.appender.database.URL=jdbc:mysql://localhost:3306/testlog4j.appender.database.driver=com.mysql.jdbc.Driverlog4j.appender.database.user=rootlog4j.appender.database.password=log4j.appender.database.sql=INSERT INTO LOG4J (Message) VALUES(&apos;=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n&apos;)log4j.appender.database.layout=org.apache.log4j.PatternLayoutlog4j.appender.database.layout.ConversionPattern=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n# 自定义Appenderlog4j.appender.im = net.cybercorlin.util.logger.appender.IMAppenderlog4j.appender.im.host = mail.cybercorlin.netlog4j.appender.im.username = usernamelog4j.appender.im.password = passwordlog4j.appender.im.recipient = corlin@cybercorlin.netlog4j.appender.im.layout=org.apache.log4j.PatternLayoutlog4j.appender.im.layout.ConversionPattern=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n 附: 输出独立日志文件log4j的强大功能无可置疑，但实际应用中免不了遇到某个功能需要输出独立的日志文件的情况，怎样才能把所需的内容从原有日志中分离，形成单独的日志文件呢？其实只要在现有的log4j基础上稍加配置即可轻松实现这一功能。 常见先看一个常见的log4j.properties文件，它是在控制台和myweb.log文件中记录日志：123456789101112131415log4j.rootLogger=DEBUG, stdout, logfile log4j.category.org.springframework=ERRORlog4j.category.org.apache=INFO log4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%n log4j.appender.logfile=org.apache.log4j.RollingFileAppenderlog4j.appender.logfile.File=$&#123;myweb.root&#125;/WEB-INF/log/myweb.loglog4j.appender.logfile.MaxFileSize=512KBlog4j.appender.logfile.MaxBackupIndex=5log4j.appender.logfile.layout=org.apache.log4j.PatternLayoutlog4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n 不同类输出不同文件如果想对不同的类输出不同的文件(以cn.com.Test为例)，先要在Test.java中定义: 12345678private static Log logger = LogFactory.getLog(Test.class); 然后在log4j.properties中加入:log4j.logger.cn.com.Test= DEBUG, testlog4j.appender.test=org.apache.log4j.FileAppenderlog4j.appender.test.File=$&#123;myweb.root&#125;/WEB-INF/log/test.loglog4j.appender.test.layout=org.apache.log4j.PatternLayoutlog4j.appender.test.layout.ConversionPattern=%d %p [%c] - %m%n 也就是让cn.com.Test中的logger使用log4j.appender.test所做的配置。 同一类输出多个日志文件但是，如果在同一类中需要输出多个日志文件呢？其实道理是一样的，先在Test.java中定义: 12private static Log logger1 = LogFactory.getLog(&quot;myTest1&quot;);private static Log logger2 = LogFactory.getLog(&quot;myTest2&quot;); 然后在log4j.properties中加入: 1234567891011log4j.logger.myTest1= DEBUG, test1log4j.appender.test1=org.apache.log4j.FileAppenderlog4j.appender.test1.File=$&#123;myweb.root&#125;/WEB-INF/log/test1.loglog4j.appender.test1.layout=org.apache.log4j.PatternLayoutlog4j.appender.test1.layout.ConversionPattern=%d %p [%c] - %m%n log4j.logger.myTest2= DEBUG, test2log4j.appender.test2=org.apache.log4j.FileAppenderlog4j.appender.test2.File=$&#123;myweb.root&#125;/WEB-INF/log/test2.loglog4j.appender.test2.layout=org.apache.log4j.PatternLayoutlog4j.appender.test2.layout.ConversionPattern=%d %p [%c] - %m%n 也就是在用logger时给它一个自定义的名字(如这里的”myTest1”)，然后在log4j.properties中做出相应配置即可。别忘了不同日志要使用不同的logger如输出到test1.log的要用logger1.info(“abc”)。 还有一个问题，就是这些自定义的日志默认是同时输出到log4j.rootLogger所配置的日志中的，如何能只让它们输出到自己指定的日志中呢？别急，这里有个开关： 1log4j.additivity.myTest1 = false 它用来设置是否同时输出到log4j.rootLogger所配置的日志中，设为false就不会输出到其它地方啦！注意这里的”myTest1”是你在程序中给logger起的那个自定义的名字！如果你说，我只是不想同时输出这个日志到log4j.rootLogger所配置的logfile中，stdout里我还想同时输出呢！那也好办，把你的log4j.logger.myTest1 = DEBUG, test1改为下式就OK啦！ 1log4j.logger.myTest1=DEBUG, test1","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://yoursite.com/child/tags/框架/"}],"keywords":[]},{"title":"日志框架-Java中的日志框架","slug":"日志框架-Java中的日志框架","date":"2016-07-21T16:00:00.000Z","updated":"2019-08-04T14:58:38.685Z","comments":true,"path":"2016/07/22/日志框架-Java中的日志框架/","link":"","permalink":"http://yoursite.com/child/2016/07/22/日志框架-Java中的日志框架/","excerpt":"","text":"1 java常用日志框架类别介绍 Log4j Apache Log4j是一个基于Java的日志记录工具。它是由Ceki Gülcü首创的，现在则是Apache软件基金会的一个项目。 Log4j是几种Java日志框架之一。 Log4j 2 Apache Log4j 2是apache开发的一款Log4j的升级产品。 Commons Logging Apache基金会所属的项目，是一套Java日志接口，之前叫Jakarta Commons Logging，后更名为Commons Logging。 Slf4j 类似于Commons Logging，是一套简易Java日志门面，本身并无日志的实现。（Simple Logging Facade for Java，缩写Slf4j）。 Logback 一套日志组件的实现(slf4j阵营)。 Jul (Java Util Logging),自Java1.4以来的官方日志实现。 看了上面的介绍是否会觉得比较混乱，这些日志框架之间有什么异同，都是由谁在维护? 下文会逐一介绍。 2 Java常用日志框架历史 1996年早期，欧洲安全电子市场项目组决定编写它自己的程序跟踪API(Tracing API)。经过不断的完善，这个API终于成为一个十分受欢迎的Java日志软件包，即Log4j。后来Log4j成为Apache基金会项目中的一员。 期间Log4j近乎成了Java社区的日志标准。据说Apache基金会还曾经建议sun引入Log4j到java的标准库中，但Sun拒绝了。 2002年Java1.4发布，Sun推出了自己的日志库JUL(Java Util Logging),其实现基本模仿了Log4j的实现。在JUL出来以前，log4j就已经成为一项成熟的技术，使得log4j在选择上占据了一定的优势。 接着，Apache推出了Jakarta Commons Logging，JCL只是定义了一套日志接口(其内部也提供一个Simple Log的简单实现)，支持运行时动态加载日志组件的实现，也就是说，在你应用代码里，只需调用Commons Logging的接口，底层实现可以是log4j，也可以是Java Util Logging。 后来(2006年)，Ceki Gülcü不适应Apache的工作方式，离开了Apache。然后先后创建了slf4j(日志门面接口，类似于Commons Logging)和Logback(Slf4j的实现)两个项目，并回瑞典创建了QOS公司，QOS官网上是这样描述Logback的：The Generic，Reliable Fast&amp;Flexible Logging Framework(一个通用，可靠，快速且灵活的日志框架)。 现今，Java日志领域被划分为两大阵营：Commons Logging阵营和SLF4J阵营。Commons Logging在Apache大树的笼罩下，有很大的用户基数。但有证据表明，形式正在发生变化。2013年底有人分析了GitHub上30000个项目，统计出了最流行的100个Libraries，可以看出slf4j的发展趋势更好： Apache眼看有被Logback反超的势头，于2012-07重写了log4j 1.x，成立了新的项目Log4j 2。Log4j 2具有logback的所有特性。 3 java常用日志框架之间的关系 Log4j2与Log4j1发生了很大的变化，log4j2不兼容log4j1。 Commons Logging和Slf4j是日志门面(门面模式是软件工程中常用的一种软件设计模式，也被称为正面模式、外观模式。它为子系统中的一组接口提供一个统一的高层接口，使得子系统更容易使用)。log4j和Logback则是具体的日志实现方案。可以简单的理解为接口与接口的实现，调用这只需要关注接口而无需关注具体的实现，做到解耦。 比较常用的组合使用方式是Slf4j与Logback组合使用，Commons Logging与Log4j组合使用。 Logback必须配合Slf4j使用。由于Logback和Slf4j是同一个作者，其兼容性不言而喻。 4 Commons Logging与Slf4j实现机制对比4.1 Commons logging实现机制Commons logging是通过动态查找机制，在程序运行时，使用自己的ClassLoader寻找和载入本地具体的实现。详细策略可以查看commons-logging-*.jar包中的org.apache.commons.logging.impl.LogFactoryImpl.java文件。由于OSGi不同的插件使用独立的ClassLoader，OSGI的这种机制保证了插件互相独立, 其机制限制了commons logging在OSGi中的正常使用。 4.2 Slf4j实现机制Slf4j在编译期间，静态绑定本地的LOG库，因此可以在OSGi中正常使用。它是通过查找类路径下org.slf4j.impl.StaticLoggerBinder，然后绑定工作都在这类里面进。 5 如何选择日志框架如果是在一个新的项目中建议使用Slf4j与Logback组合，这样有如下的几个优点。 Slf4j实现机制决定Slf4j限制较少，使用范围更广。由于Slf4j在编译期间，静态绑定本地的LOG库使得通用性要比Commons logging要好。 Logback拥有更好的性能。Logback声称：某些关键操作，比如判定是否记录一条日志语句的操作，其性能得到了显著的提高。这个操作在Logback中需要3纳秒，而在Log4J中则需要30纳秒。LogBack创建记录器（logger）的速度也更快：13毫秒，而在Log4J中需要23毫秒。更重要的是，它获取已存在的记录器只需94纳秒，而Log4J需要2234纳秒，时间减少到了1/23。跟JUL相比的性能提高也是显著的。 Commons Logging开销更高 在使Commons Logging时为了减少构建日志信息的开销，通常的做法是：if(log.isDebugEnabled()){log.debug(“User name： “ +user.getName() + “ buy goods id ：” + good.getId());}在Slf4j阵营，你只需这么做：log.debug(“User name：{} ,buy goods id ：{}”, user.getName(),good.getId());也就是说，slf4j把构建日志的开销放在了它确认需要显示这条日志之后，减少内存和cup的开销，使用占位符号，代码也更为简洁 Logback文档免费。Logback的所有文档是全面免费提供的，不象Log4J那样只提供部分免费文档而需要用户去购买付费文档。","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://yoursite.com/child/tags/框架/"}],"keywords":[]},{"title":"数据库-Mysql5.7 windows下安装","slug":"数据库-Mysql-5-7-windows下安装","date":"2016-05-10T02:56:23.000Z","updated":"2019-07-31T01:41:23.019Z","comments":true,"path":"2016/05/10/数据库-Mysql-5-7-windows下安装/","link":"","permalink":"http://yoursite.com/child/2016/05/10/数据库-Mysql-5-7-windows下安装/","excerpt":"","text":"1. 下载选择zip格式的压缩包，解压到指定盘中D:\\mysql-5.7 2. 配置环境变量MYSQL_HOME:D:\\mysql-5.7在path 后面添加 ;%MYSQL_HOME%\\bin 3. 添加文件my.ini文件将如下代码放入my.ini文件中basedir和datadir，请根据实际安装目录进行修改 12345678910111213141516[mysql]# 设置mysql客户端默认字符集default-character-set=utf8[mysqld]#设置3306端口port = 3306# 设置mysql的安装目录basedir=D:\\mysql5.7# 设置mysql数据库的数据的存放目录datadir=D:\\mysql5.7\\data# 允许最大连接数max_connections=200# 服务端使用的字符集默认为8比特编码的latin1字符集character-set-server=utf8# 创建新表时将使用的默认存储引擎default-storage-engine=INNODB 4. 打开cmd.exe必须以管理员的身份运行，从c:/windows/systen32文件夹中找到cmd.exe，右击以管理员身份打开。 5. 初始化数据库mysqld –initialize –user=mysql –console记住分配的密码:最后一行（很重要） 6. 安装服务mysqld –install MySQL 7. 启动服务net start MySQL 8. 修改初始化密码使用初始密码登陆后,执行下面指令：set password for root@localhost=password(‘111111’); * 附录：相关指令 停止服务：net stop MySQL 删除服务：sc delete MySQL 移除mysql：mysqld -remove MySQL","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/child/tags/数据库/"}],"keywords":[]}]}