{"meta":{"title":"黑风雅过吟","subtitle":"不积跬步无以至千里","description":null,"author":"Zhao Zhengkang","url":"https://zzkenyon.github.io"},"pages":[{"title":"About","date":"2021-01-27T15:41:39.062Z","updated":"2020-05-22T09:48:28.962Z","comments":true,"path":"about/index.html","permalink":"https://zzkenyon.github.io/about/index.html","excerpt":"","text":""},{"title":"about","date":"2019-05-23T07:59:58.000Z","updated":"2019-05-23T07:59:58.731Z","comments":true,"path":"about-备份/index.html","permalink":"https://zzkenyon.github.io/about-备份/index.html","excerpt":"","text":""},{"title":"Categories","date":"2021-01-27T15:42:00.677Z","updated":"2020-05-22T09:48:28.963Z","comments":true,"path":"categories/index.html","permalink":"https://zzkenyon.github.io/categories/index.html","excerpt":"","text":""},{"title":"Tags","date":"2020-05-22T09:57:03.281Z","updated":"2020-05-22T09:48:28.963Z","comments":true,"path":"tags/index.html","permalink":"https://zzkenyon.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"redis-客户端redisson的使用","slug":"redis-客户端redisson的使用","date":"2020-12-03T16:00:00.000Z","updated":"2021-01-29T03:06:22.435Z","comments":true,"path":"2020/12/04/redis-客户端redisson的使用/","link":"","permalink":"https://zzkenyon.github.io/2020/12/04/redis-客户端redisson的使用/","excerpt":"","text":"中文文档（很详细） Redisson的中文文档写的非常详细，所以本文主要记录简单使用过程中遇到的一些问题 1. 原生api的使用依赖引入： 12345&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.14.1&lt;/version&gt;&lt;/dependency&gt; 配置： 两种方式：代码配置和配置文件 1234567891011private static RedissonClient redissonClient;static&#123; Config config = new Config(); //config.setCodec(new org.redisson.client.codec.StringCodec()); config.setCodec(new JsonJacksonCodec()); //指定使用单节点部署方式 config.useSingleServer() .setAddress(\"redis://storage.m.io:6379\") .setPassword(\"0gn736xl73083Vm6wwnBDJSI20duFIeLv068Q1kLM4u58GD8q4SEugmSFd8TfFTm\"); redissonClient = Redisson.create(config);&#125; 配置文件： 123456789101112131415161718192021#redisson-config.ymlsingleServerConfig: idleConnectionTimeout: 10000 connectTimeout: 10000 timeout: 3000 retryAttempts: 3 retryInterval: 1500 password: null subscriptionsPerConnection: 5 clientName: null address: \"redis://localhost:6379\" subscriptionConnectionMinimumIdleSize: 1 subscriptionConnectionPoolSize: 50 connectionMinimumIdleSize: 32 connectionPoolSize: 64 database: 0 dnsMonitoringInterval: 5000threads: 0nettyThreads: 0codec: !&lt;org.redisson.client.codec.StringCodec&gt; &#123;&#125;\"transportMode\": \"NIO\" 12345try &#123; Config config1 = Config.fromYAML(\"classpath:redisson-config.yml\");&#125; catch (IOException e) &#123; e.printStackTrace();&#125; 基本使用去看文档，写得很清楚 集群模式配置： 1234567891011121314151617181920212223242526272829303132clusterServersConfig: idleConnectionTimeout: 10000 connectTimeout: 10000 timeout: 3000 retryAttempts: 3 retryInterval: 1500 failedSlaveReconnectionInterval: 3000 failedSlaveCheckInterval: 60000 password: null subscriptionsPerConnection: 5 clientName: null loadBalancer: !&lt;org.redisson.connection.balancer.RoundRobinLoadBalancer&gt; &#123;&#125; subscriptionConnectionMinimumIdleSize: 1 subscriptionConnectionPoolSize: 50 slaveConnectionMinimumIdleSize: 24 slaveConnectionPoolSize: 64 masterConnectionMinimumIdleSize: 24 masterConnectionPoolSize: 64 readMode: \"SLAVE\" subscriptionMode: \"SLAVE\" nodeAddresses: - \"redis://127.0.0.1:7004\" - \"redis://127.0.0.1:7001\" - \"redis://127.0.0.1:7000\" scanInterval: 1000 pingConnectionInterval: 0 keepAlive: false tcpNoDelay: falsethreads: 16nettyThreads: 32codec: !&lt;org.redisson.codec.MarshallingCodec&gt; &#123;&#125;transportMode: \"NIO\" 2. spring集成在springboot中使用redisson需要引入另外一个包： 12345&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.14.0&lt;/version&gt;&lt;/dependency&gt; 该项目的地址如下： https://github.com/redisson/redisson/tree/master/redisson-spring-boot-starter 该包中已自动引入了redisson的原生jar包，此外还需要注意与版本兼容问题： redisson-spring-data module name Spring Boot version redisson-spring-data-16 1.3.x redisson-spring-data-17 1.4.x redisson-spring-data-18 1.5.x redisson-spring-data-20 2.0.x redisson-spring-data-21 2.1.x redisson-spring-data-22 2.2.x redisson-spring-data-23 2.3.x redisson-spring-data-24 2.4.x 配置使用： 在application.yml配置文件中进行如下配置： 1234spring: redis: redisson: file: classpath:redisson-config.yaml 注意，这样配置之后，redisTemplate也能正常使用，且使用的也是redisson的配置。 2.1 消息监听12345678910111213141516171819202122@Service@Slf4jpublic class TopicListener implements ApplicationRunner, Ordered &#123; @Autowired private RedissonClient redissonClient; @Override public void run(ApplicationArguments args) throws Exception &#123; RTopic topic = redissonClient.getTopic(\"__keyspace@0__:name\"); topic.addListener(String.class,new MessageListener&lt;String&gt;() &#123; @Override public void onMessage(CharSequence charSequence, String msg) &#123; log.info(\"Redisson监听器收到消息:&#123;&#125;\", msg); &#125; &#125;); &#125; @Override public int getOrder() &#123; return 1; &#125;&#125; 当然使用redis的消息机制需要对redis-server进行设置，设置属性notifiy-space-events的值 2.2 分布式锁在方法增加 @Lock 注解 123456//支持 spel 表达式 如果后面需要接字符串的话请用`+`连接. 字符串一定要打`单引号`@Lock(keys = \"#user.name+'locks'\")public String test(User user) &#123; System.out.println(\"进来了test\"); return \"test\";&#125; @Lock 注解参数介绍 1234567891011121314151617181920/** * REENTRANT(可重入锁),FAIR(公平锁),MULTIPLE(联锁),REDLOCK(红锁),READ(读锁), WRITE(写锁), * AUTO(自动模式,当参数只有一个.使用 REENTRANT 参数多个 MULTIPLE) */LockModel lockModel() default LockModel.AUTO;/** * 需要锁定的keys * @return */String[] keys() default &#123;&#125;;/** * 锁超时时间,默认30000毫秒(可在配置文件全局设置) * @return */long lockWatchdogTimeout() default 0;/** * 等待加锁超时时间,默认10000毫秒 -1 则表示一直等待(可在配置文件全局设置) * @return */long attemptTimeout() default 0; 3. 属性列表(基本都是官方参数.我将参数整合了下.分为 公共参数,单例模式参数,集群模式参数) 1.公共参数 属性名 默认值 备注 redisson.password 用于节点身份验证的密码。 redisson.attemptTimeout 10000L 等待获取锁超时时间,-1则是一直等待 redisson.lockModel 单个key默认可重入锁多个key默认联锁 锁的模式.如果不设置, REENTRANT(可重入锁),FAIR(公平锁),MULTIPLE(联锁),REDLOCK(红锁),READ(读锁), WRITE(写锁) redisson.model SINGLE 集群模式:SINGLE(单例),SENTINEL(哨兵),MASTERSLAVE(主从),CLUSTER(集群),REPLICATED(云托管) redisson.codec JsonJacksonCodec Redisson的对象编码类是用于将对象进行序列化和反序列化，以实现对该对象在Redis里的读取和存储 redisson.threads 当前处理核数量 * 2 这个线程池数量被所有RTopic对象监听器，RRemoteService调用者和RExecutorService任务共同共享。 redisson.nettyThreads 当前处理核数量 * 2 这个线程池数量是在一个Redisson实例内，被其创建的所有分布式数据类型和服务，以及底层客户端所一同共享的线程池里保存的线程数量。 redisson.transportMode NIO TransportMode.NIO,TransportMode.EPOLL - 需要依赖里有netty-transport-native-epoll包（Linux） TransportMode.KQUEUE - 需要依赖里有 netty-transport-native-kqueue包（macOS） redisson.idleConnectionTimeout 10000 如果当前连接池里的连接数量超过了最小空闲连接数，而同时有连接空闲时间超过了该数值，那么这些连接将会自动被关闭，并从连接池里去掉。时间单位是毫秒 redisson.connectTimeout 10000 同任何节点建立连接时的等待超时。时间单位是毫秒。 redisson.timeout 3000 等待节点回复命令的时间。该时间从命令发送成功时开始计时。 redisson.retryAttempts 3 如果尝试达到 retryAttempts（命令失败重试次数） 仍然不能将命令发送至某个指定的节点时，将抛出错误。如果尝试在此限制之内发送成功，则开始启用 timeout（命令等待超时） 计时。 redisson.retryInterval 1500 在一条命令发送失败以后，等待重试发送的时间间隔。时间单位是毫秒。 redisson.subscriptionsPerConnection 5 每个连接的最大订阅数量。 redisson.clientName 在Redis节点里显示的客户端名称。 redisson.sslEnableEndpointIdentification true 开启SSL终端识别能力。 redisson.sslProvider JDK 确定采用哪种方式（JDK或OPENSSL）来实现SSL连接。 redisson.sslTruststore 指定SSL信任证书库的路径。 redisson.sslTruststorePassword 指定SSL信任证书库的密码。 redisson.sslKeystore 指定SSL钥匙库的路径。 redisson.sslKeystorePassword 指定SSL钥匙库的密码。 redisson.lockWatchdogTimeout 30000 监控锁的看门狗超时时间单位为毫秒。该参数只适用于分布式锁的加锁请求中未明确使用leaseTimeout参数的情况。如果该看门口未使用lockWatchdogTimeout去重新调整一个分布式锁的lockWatchdogTimeout超时，那么这个锁将变为失效状态。这个参数可以用来避免由Redisson客户端节点宕机或其他原因造成死锁的情况。 redisson.keepPubSubOrder true 通过该参数来修改是否按订阅发布消息的接收顺序出来消息，如果选否将对消息实行并行处理，该参数只适用于订阅发布消息的情况。 单例模式参数 配置前缀：redisson.singleServerConfig 属性名 默认值 备注 address 服务器地址,必填ip:port database 0 尝试连接的数据库编号。 subscriptionConnectionMinimumIdleSize 1 用于发布和订阅连接的最小保持连接数（长连接）。Redisson内部经常通过发布和订阅来实现许多功能。长期保持一定数量的发布订阅连接是必须的。 subscriptionConnectionPoolSize 50 用于发布和订阅连接的连接池最大容量。连接池的连接数量自动弹性伸缩。 connectionMinimumIdleSize 32 最小保持连接数（长连接）。长期保持一定数量的连接有利于提高瞬时写入反应速度。 connectionPoolSize 64 连接池最大容量。连接池的连接数量自动弹性伸缩。 dnsMonitoringInterval 5000 用来指定检查节点DNS变化的时间间隔。使用的时候应该确保JVM里的DNS数据的缓存时间保持在足够低的范围才有意义。用-1来禁用该功能。 集群模式 配置前缀：redisson.multiple-server-config 属性名 默认值 备注 redisson.multiple-server-config.node-addresses 服务器节点地址.必填 loadBalancer RoundRobinLoadBalancer 在多Redis服务节点的环境里，可以选用以下几种负载均衡方式选择一个节点： WeightedRoundRobinBalancer - 权重轮询调度算法 RoundRobinLoadBalancer - 轮询调度算法 RandomLoadBalancer - 随机调度算法 slaveConnectionMinimumIdleSize 32 多从节点的环境里，每个 从服务节点里用于普通操作（非 发布和订阅）的最小保持连接数（长连接）。长期保持一定数量的连接有利于提高瞬时读取反映速度。 slaveConnectionPoolSize 64 多从节点的环境里，每个 从服务节点里用于普通操作（非 发布和订阅）连接的连接池最大容量。连接池的连接数量自动弹性伸缩。 masterConnectionMinimumIdleSize 32 多节点的环境里，每个 主节点的最小保持连接数（长连接）。长期保持一定数量的连接有利于提高瞬时写入反应速度。 masterConnectionPoolSize 64 多主节点的环境里，每个 主节点的连接池最大容量。连接池的连接数量自动弹性伸缩。 readMode SLAVE 设置读取操作选择节点的模式。 可用值为： SLAVE - 只在从服务节点里读取。 MASTER - 只在主服务节点里读取。 MASTER_SLAVE - 在主从服务节点里都可以读取。 subscriptionMode SLAVE 设置订阅操作选择节点的模式。 可用值为： SLAVE - 只在从服务节点里订阅。 MASTER - 只在主服务节点里订阅。 subscriptionConnectionMinimumIdleSize 1 用于发布和订阅连接的最小保持连接数（长连接）。Redisson内部经常通过发布和订阅来实现许多功能。长期保持一定数量的发布订阅连接是必须的。 redisson.multiple-server-config.subscriptionConnectionPoolSize dnsMonitoringInterval 5000 监测DNS的变化情况的时间间隔。 scanInterval 1000 (集群,哨兵,云托管模特特有) 对Redis集群节点状态扫描的时间间隔。单位是毫秒。 database 0 (哨兵模式,云托管,主从模式特有)尝试连接的数据库编号。 masterName (哨兵模式特有)主服务器的","categories":[{"name":"noSql","slug":"noSql","permalink":"https://zzkenyon.github.io/categories/noSql/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://zzkenyon.github.io/tags/redis/"}],"keywords":[{"name":"noSql","slug":"noSql","permalink":"https://zzkenyon.github.io/categories/noSql/"}]},{"title":"业务-接口鉴权设计与实现","slug":"业务-接口鉴权设计与实现","date":"2020-12-01T16:00:00.000Z","updated":"2021-01-25T09:24:54.851Z","comments":true,"path":"2020/12/02/业务-接口鉴权设计与实现/","link":"","permalink":"https://zzkenyon.github.io/2020/12/02/业务-接口鉴权设计与实现/","excerpt":"","text":"1. 需求分析难点在于，请求一个接口时，怎么确定当前请求的接口所对应的权限记录 request对象如下图： 所以可以根据request的path进行判断。 数据库中存储了接口的信息，如下图 permission表中的记录，会关联到具体的接口 如图resource_type=0表示该权限记录对应的限制资源时接口，resource_id就是关联到interface表的外键 token中有用户的Uid以及用户的角色，角色用List&lt;Integer&gt;表示，一个用户有多个角色，存储的是role表记录的主键id 所以鉴权时，可以直接从token中获取角色信息，也就能获取到所有能够访问的接口（role和permission关联）信息。 此时，在判断当前请求的接口在不在这个有限集合中，就能得到鉴权结果，那么要怎么才能知道当前请求的接口是哪一个接口呢？ 根据一个Request对象我们能得到的信息只有请求的method、uri等信息，所以初步考虑，根据请求uri的path进行判断。 潜在问题：请求url可能会被网关过滤器进行修改后再路由，所以要将可能修改url的filter放在tokenFilter的前面，保证TokenFilter拿到的path是最终要请求具体服务的Path。 此外，还要考虑到以下问题 Path中的@PathVariable参数对Path匹配会带来影响 需要支持前缀匹配，匹配到path前面指定一部分，则表示匹配成功 Restful风格的path设计，同一个url可能应不同方法的请求接口，所以请求方法也要考虑进去，采用method+uri确定接口的范式 功能接口组，对于管理员用户来说授权一个功能给某用户，意味着授权一组接口，与上面一条可能重复，实现方式不同 针对以上问题，提出以下设计： 对于PathVariable参数内嵌在path中，在存入interface表记录时，一律用*替代@PathVariable参数，*表示匹配任意一个单词 前缀匹配的问题，采用**表示匹配Path中的一个或多个单词 如果interface表中一条记录采用了前缀匹配的uri，那么这条记录对应的可能就不止一个接口了。 2. 缓存设计2.1 redis缓存TokenFilter拿到roleId之后，需要去缓存中查询当前请求的权限，这里使用缓存，一是为了提高性能，二是为了解耦，权限管理的接口并不在网关中，使用缓存解耦可以减少服务间调用。这种情况下，权限管理服务需要保证权限记录的缓存数据库读写一致性的问题。 使用String类型数据类型来存储 redisKey 为 passport:role:${roleId} value值为jsonArray，如下所示： 1234567[ \"POST:/passport/check/raise\", \"POST:/passport/login\", \"POST:/passport/check/code\", \"POST:/passport/reset\", \"POST:/passport/check/weixin\"] 2.2 本地二级缓存每次鉴权都需要访问缓存获取对应角色的ant表达式jason字串，然后解析成列表，所以可以将解析好的列表在本地进行缓存，生产环境中，角色对应的接口权限是一个读多写少的数据，所以使用本地缓存可以有效的提高效率。 需要考虑多级缓存一致性的问题：当redis中的缓存内容修改时，在redis中发布一个消息，网关服务监听到该消息，就将本地缓存中对应的roleId删除 由于redis消息是不可靠的通知机制，所以此处可以引入消息队列 此外还可以启动一个定时任务，定期清除本地缓存，但是这样一旦发生不一致的情况可能会有一个窗口期维持这种不一致。 3. 实现对于ant表达式，使用Spring自带的AntPathMatcher工具类进行匹配。","categories":[{"name":"随便写写","slug":"随便写写","permalink":"https://zzkenyon.github.io/categories/随便写写/"}],"tags":[{"name":"鉴权","slug":"鉴权","permalink":"https://zzkenyon.github.io/tags/鉴权/"}],"keywords":[{"name":"随便写写","slug":"随便写写","permalink":"https://zzkenyon.github.io/categories/随便写写/"}]},{"title":"数据库技术-liquibase使用和原理","slug":"数据库技术-liquibase使用和原理 ","date":"2020-11-30T16:00:00.000Z","updated":"2020-12-14T08:05:18.597Z","comments":true,"path":"2020/12/01/数据库技术-liquibase使用和原理 /","link":"","permalink":"https://zzkenyon.github.io/2020/12/01/数据库技术-liquibase使用和原理 /","excerpt":"","text":"LiquiBase是一个用于数据库重构和迁移的开源工具，通过日志文件的形式记录数据库的变更，然后执行日志文件中的修改，将数据库更新或回滚到一致的状态。 LiquiBase的主要特点有： 支持几乎所有主流的数据库，如MySQL, PostgreSQL, Oracle, Sql Server, DB2等； 支持多开发者的协作维护； 日志文件支持多种格式，如XML, YAML, JSON, SQL等； 支持多种运行方式，如命令行、Spring集成、Maven插件、Gradle插件等； 本文首先简单介绍一下LiquiBase的changelog文件的常用标签配置，然后介绍在Maven中集成并运行LiquiBase。 1. changelog文件格式changelog是LiquiBase用来记录数据库的变更，一般放在CLASSPATH下，然后配置到执行路径中。 changelog支持多种格式，主要有XML/JSON/YAML/SQL，其中XML/JSON/YAML除了具体格式语法不同，节点配置很类似，SQL格式中主要记录SQL语句，这里仅给出XML格式和SQL格式的示例，更多的格式示例请参考文档 changelog.xml 1234567&lt;changeSet id=\"2\" author=\"daniel\" runOnChange=\"true\"&gt; &lt;insert tableName=\"contest_info\"&gt; &lt;column name=\"id\"&gt;3&lt;/column&gt; &lt;column name=\"title\"&gt;title 3&lt;/column&gt; &lt;column name=\"content\"&gt;content 3&lt;/column&gt; &lt;/insert&gt;&lt;/changeSet&gt; changelog.sql 123456789--liquibase formatted sql--changeset daniel:16040707CREATE TABLE `role_authority_sum` ( `row_id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增id', `role_id` int(11) unsigned NOT NULL DEFAULT '0' COMMENT '关联role的role_id', `authority_sum` int(11) unsigned NOT NULL DEFAULT '0' COMMENT 'perms的值的和', `data_type_id` int(11) unsigned NOT NULL DEFAULT '0' COMMENT '关联data_type的id', PRIMARY KEY (`row_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='角色的权限值的和，如角色有RD权限，则和为2+8=10'; 2. 常用的标签及命令2.1 标签 一个&lt;changeSet&gt;标签对应一个变更集，由id、name、以及changelog的文件路径组成唯一标识。changelog在执行的时候并不是按照id的顺序，而是按照changeSet在changelog中出现的顺序。 LiquiBase在执行changelog时，会在数据库中插入两张表：DATABASECHANGELOG和DATABASECHANGELOGLOCK，分别记录changelog的执行日志和锁日志。 LiquiBase在执行changelog中的changeSet时，会首先查看DATABASECHANGELOG表，如果已经执行过，则会跳过（除非changeSet的runAlways属性为true，后面会介绍），如果没有执行过，则执行并记录changelog日志； changelog中的一个changeSet对应一个事务，在changeSet执行完后commit，如果出现错误则rollback； &lt;changeSet&gt;标签的主要属性有： runAlways：即使已经执行过，仍然每次都执行；注意: 由于DATABASECHANGELOG表中还记录了changeSet的MD5校验值MD5SUM，如果changeSet的id和name没变，而内容变了，则由于MD5值变了，即使runAlways的值为True，执行也是失败的，会报错。这种情况应该使用runOnChange属性。 runOnChange：第一次的时候执行以及当changeSet的内容发生变化时执行。不受MD5校验值的约束。 runInTransaction：是否作为一个事务执行，默认为true。设置为false时需要小心：如果执行过程中出错了则不会rollback，数据库很可能处于不一致的状态； &lt;changeSet&gt;下有一个重要的子标签&lt;rollback&gt;，即定义回滚的SQL语句。对于create table, rename column和add column等，LiquiBase会自动生成对应的rollback语句，而对于drop table、insert data等则需要显示定义rollback语句。 2.2 &lt;include&gt;与&lt;includeAll&gt;标签当changelog文件越来越多时，可以使用&lt;include&gt;将文件管理起来，如： 12345678&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;databaseChangeLog xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://www.liquibase.org/xml/ns/dbchangelog\" xsi:schemaLocation=\"http://www.liquibase.org/xml/ns/dbchangelog http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-3.1.xsd\"&gt; &lt;include file=\"logset-20160408/0001_authorization_init.sql\" relativeToChangelogFile=\"true\"/&gt;&lt;/databaseChangeLog&gt; &lt;include&gt;的file属性表示要包含的changelog文件的路径，这个文件可以是LiquiBase支持的任意格式，relativeToChangelogFile如果为true，则表示file属性表示的文件路径是相对于根changelog而不是CLASSPATH的，默认为false。 &lt;includeAll&gt;指定的是changelog的目录，而不是为文件，如： 1&lt;includeAll path=\"com/example/changelogs/\"/&gt; 2.3 diff命令diff命令用于比较数据库之间的异同。比如通过命令行执行： 1234567java -jar liquibase.jar --driver=com.mysql.jdbc.Driver \\ --classpath=./mysql-connector-java-5.1.29.jar \\ --url=jdbc:mysql://127.0.0.1:3306/test \\ --username=root --password=passwd \\ diff \\ --referenceUrl=jdbc:mysql://127.0.0.1:3306/authorization \\ --referenceUsername=root --referencePassword=passwd 2.4 generateChangeLog在已有的项目上使用LiquiBase，要生成当前数据库的changeset，可以采用两种方式，一种是使用数据库工具导出SQL数据，然后changelog文件以SQL格式记录即可；另一种方式就是用generateChangeLog命令，如： 1234567liquibase --driver=com.mysql.jdbc.Driver \\ --classpath=./mysql-connector-java-5.1.29.jar \\ --changeLogFile=liquibase/db.changelog.xml \\ --url=\"jdbc:mysql://127.0.0.1:3306/test\" \\ --username=root \\ --password=yourpass \\ generateChangeLog 不过generateChangeLog不支持以下功能：存储过程、函数以及触发器 3. Maven集成LiquiBase3.1 liquibase-maven-plugin的配置Maven中集成LiquiBase，主要是配置liquibase-maven-plugin，首先给出一个示例： 1234567891011121314151617181920&lt;plugin&gt; &lt;groupId&gt;org.liquibase&lt;/groupId&gt; &lt;artifactId&gt;liquibase-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.4.2&lt;/version&gt; &lt;configuration&gt; &lt;changeLogFile&gt;src/main/resources/liquibase/test_changelog.xml&lt;/changeLogFile&gt; &lt;driver&gt;com.mysql.jdbc.Driver&lt;/driver&gt; &lt;url&gt;jdbc:mysql://127.0.0.1:3306/test&lt;/url&gt; &lt;username&gt;root&lt;/username&gt; &lt;password&gt;passwd&lt;/password&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;process-resources&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;update&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 其中&lt;configuration&gt;节点中的配置可以放在单独的配置文件里。 如果需要在父项目中配置子项目共享的LiquiBase配置，而各个子项目可以定义自己的配置，并覆盖父项目中的配置，则只需要在父项目的pom中将propertyFileWillOverride设置为true即可，如： 123456789&lt;plugin&gt; &lt;groupId&gt;org.liquibase&lt;/groupId&gt; &lt;artifactId&gt;liquibase-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.4.2&lt;/version&gt; &lt;configuration&gt; &lt;propertyFileWillOverride&gt;true&lt;/propertyFileWillOverride&gt; &lt;propertyFile&gt;liquibase/liquibase.properties&lt;/propertyFile&gt; &lt;/configuration&gt;&lt;/plugin&gt; 3.2 liquibase:update执行changelog中的变更： 1$ mvn liquibase:update 3.3 liquibase:rollbackrollback有3中形式，分别是： 123- rollbackCount: 表示rollback的changeset的个数；- rollbackDate：表示rollback到指定的日期；- rollbackTag：表示rollback到指定的tag，需要使用LiquiBase在具体的时间点打上tag； rollbackCount比较简单，示例如： 1$ mvn liquibase:rollback -Dliquibase.rollbackCount=3 rollbackDate需要注意日期的格式，必须匹配当前平台上执行DateFormat.getDateInstance()得到的格式，比如我的格式为MMM d, yyyy，示例如： 1$ mvn liquibase:rollback -Dliquibase.rollbackDate=&quot;Apr 10, 2016&quot; rollbackTag使用tag标识，所以需要先打tag，示例如： 1$ mvn liquibase:tag -Dliquibase.tag=tag20160410 然后rollback到tag20160410，如： 1$ mvn liquibase:rollback -Dliquibase.rollbackTag=tag20160410","categories":[{"name":"数据库技术","slug":"数据库技术","permalink":"https://zzkenyon.github.io/categories/数据库技术/"}],"tags":[{"name":"liquibase","slug":"liquibase","permalink":"https://zzkenyon.github.io/tags/liquibase/"}],"keywords":[{"name":"数据库技术","slug":"数据库技术","permalink":"https://zzkenyon.github.io/categories/数据库技术/"}]},{"title":"任务调度-使用quartz","slug":"分布式-任务调度quartz","date":"2020-10-06T16:00:00.000Z","updated":"2020-11-15T09:43:53.761Z","comments":true,"path":"2020/10/07/分布式-任务调度quartz/","link":"","permalink":"https://zzkenyon.github.io/2020/10/07/分布式-任务调度quartz/","excerpt":"","text":"文章目标： 1、了解任务调度的应用场景和 Quartz 的基本特性 2、掌握 Quartz Java 编程和 Spring 集成的使用 3、掌握 Quartz 动态调度和集群部署的实现 1、任务调度场景在业务系统中有很多这样的场景: 1、账单日或者还款日上午 10 点，给每个信用卡客户发送账单通知，还款通知。如 何判断客户的账单日、还款日，完成通知的发送 2、银行业务系统，夜间要完成跑批的一系列流程，清理数据，下载文件，解析文件， 对账清算、切换结算日期等等。如何触发一系列流程的执行 3、金融机构跟人民银行二代支付系统对接，人民银行要求低于 5W 的金额(小额支付)半个小时打一次包发送，以缓解并发压力。所以，银行的跨行转账分成了多个流程: 录入、复核、发送。如何把半个小时以内的所有数据一次性发送 类似于这种 基于准确的时刻或者固定的时间间隔触发的任务 有批量数据需要处理 要实现两个动作解耦的场景 我们都可以用任务调度来实现。 2、任务调度需求分析 可以定义触发的规则，比如基于时刻、时间间隔、表达式。 可以定义需要执行的任务。比如执行一个脚本或者一段代码。任务和规则是 分开的。 集中管理配置，持久配置。不用把规则写在代码里面，可以看到所有的任务 配置，方便维护。重启之后任务可以再次调度——配置文件或者配置中心。 支持任务的串行执行，例如执行 A 任务后再执行 B 任务再执行 C 任务。 支持多个任务并发执行，互不干扰(例如 ScheduledThreadPoolExecutor)。 有自己的调度器，可以启动、中断、停止任务。 容易集成到 Spring。 3、任务调度工具和框架 Linux crontab，Windows 计划任务 MySQL、Oracle Kettle jdk自带的Timer、ScheduledThreadPool Spring Task--@Scheduled 也是使用ScheduledThreadPool实现的 quartz，XXL-JOB，Elastic-Job 4、Quartz使用入门4.1 基本介绍官网 Quartz 的意思是石英，像石英表一样精确。 Quartz 是一个老牌的任务调度系统，98 年构思，01 年发布到 sourceforge。现在更新比较慢，因为已经非常成熟了。 Quartz 的目的就是让任务调度更加简单，开发人员只需要关注业务即可。他是用 Java 语言编写的(也有.NET 的版本)。Java 代码能做的任何事情，Quartz 都可以调度。 特点： 精确到毫秒级别的调度 可以独立运行，也可以集成到容器中 支持事务(JobStoreCMT ) 支持集群 支持持久化 4.2 API使用引入依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt;&lt;/dependency&gt; 默认配置： org.quartz.core 包下，有一个默认的配置文件，quartz.properties。当我们没有 定义一个同名的配置文件的时候，就会使用默认配置文件里面的配置。 12345678910org.quartz.scheduler.instanceName: DefaultQuartzScheduler org.quartz.scheduler.rmi.export: falseorg.quartz.scheduler.rmi.proxy: false org.quartz.scheduler.wrapJobExecutionInUserTransaction: false org.quartz.threadPool.class: org.quartz.simpl.SimpleThreadPool org.quartz.threadPool.threadCount: 10org.quartz.threadPool.threadPriority: 5 org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread: true org.quartz.jobStore.misfireThreshold: 60000org.quartz.jobStore.class: org.quartz.simpl.RAMJobStore 创建三大对象： 创建Job：任务 12345public class MyJob implements Job &#123; public void execute(JobExecutionContext context) throws JobExecutionException &#123; System.out.println(\"假发在哪里买的\"); &#125;&#125; 在使用到 Job时，需要进一步包装成 JobDetail。必须要指定 JobName 和 groupName，两个合起 来是唯一标识符。可以携带 KV 的数据(JobDataMap)，用于扩展属性，在运行的时候可以从context 获取到。 创建Trigger：就是调度策略 创建Scheduler：调度器 通过 Factory 获取调度器的实例，把 JobDetail 和 Trigger 绑定，注册到容器中。Scheduler 先启动后启动无所谓，只要有 Trigger 到达触发条件，就会执行任务。 详细代码请见： 4.3 体系结构总结 4.3.1 JobDetail我们创建一个实现 Job 接口的类，使用 JobBuilder 包装成 JobDetail，它可以携带 KV 的数据。 4.3.2 Trigger定义任务的触发规则，Trigger，使用 TriggerBuilder 来构建。 JobDetail 跟 Trigger 是 1:N 的关系。 思考：为什么任务和规则要解耦？ 因为任务调度规则复杂的时候可以配置多个trigger来实现。 Trigger 接口在 Quartz 有 4 个继承的子接口: 子接口 描述 特点 SimpleTrigger 简单触发器 固定时刻或时间间隔，毫秒 CalendarIntervalTrigger 基于日历的触发器 比简单触发器更多时间单位，支持非固定时 间的触发，例如一年可能 365/366，一个月 可能28/29/30/31 DailyTimeIntervalTrigger 基于日期的触发器 每天的某个时间段 CronTrigger 基于 Cron 表达式的触发器 最常用的 SimpleTrigger SimpleTrigger 可以定义固定时刻或者固定时间间隔的调度规则(精确到毫秒)。 例如:每天 9 点钟运行;每隔 30 分钟运行一次。 CalendarIntervalTrigger CalendarIntervalTrigger 可以定义更多时间单位的调度需求，精确到秒。 好处是不需要去计算时间间隔，比如 1 个小时等于多少毫秒。 例如每年、每个月、每周、每天、每小时、每分钟、每秒。 每年的月数和每个月的天数不是固定的，这种情况也适用。 DailyTimeIntervalTrigger 每天的某个时间段内，以一定的时间间隔执行任务。 例如:每天早上 9 点到晚上 9 点，每隔半个小时执行一次，并且只在周一到周六执 行。 CronTrigger CronTirgger 可以定义基于 Cron 表达式的调度规则，是最常用的触发器类型。 Trigger示例代码 Cron 表达式 位置 时间域 取值范围 特殊值 1 秒 0-59 ,-*/ 2 分钟 0-59 ,-*/ 3 小时 0-23 ,-*/ 4 日期 1-31 ,-*?/ L W C 5 月份 1-12 ,-*/ 6 星期 1-7 ,-*?/ L W C 7 年份（可选） 1-31 ,-*/ 星号(*):可用在所有字段中，表示对应时间域的每一个时刻，例如，在分钟字段时，表示“每分钟”; 问号(?):该字符只在日期和星期字段中使用，它通常指定为“无意义的值”，相当于点位符; 减号(-):表达一个范围，如在小时字段中使用“10-12”，则表示从 10 到 12 点，即 10,11,12; 逗号(,):表达一个列表值，如在星期字段中使用“MON,WED,FRI”，则表示星期一，星期三和星期五; 斜杠(/):x/y 表达一个等步长序列，x 为起始值，y 为增量步长值。如在分钟字段中使用 0/15，则表示为 0,15,30 和45 秒，而 5/15 在分钟字段中表示 5,20,35,50，你也可以使用*/y，它等同于 0/y; L:该字符只在日期和星期字段中使用，代表“Last”的意思，但它在两个字段中意思不同。L 在日期字段中，表示 这个月份的最后一天，如一月的 31 号，非闰年二月的 28 号;如果 L 用在星期中，则表示星期六，等同于 7。但是，如 果 L 出现在星期字段里，而且在前面有一个数值 X，则表示“这个月的最后 X 天”，例如，6L 表示该月的最后星期五; W:该字符只能出现在日期字段里，是对前导日期的修饰，表示离该日期最近的工作日。例如 15W 表示离该月 15 号最近的工作日，如果该月 15 号是星期六，则匹配 14 号星期五;如果 15 日是星期日，则匹配 16 号星期一;如果 15 号是星期二，那结果就是 15 号星期二。但必须注意关联的匹配日期不能够跨月，如你指定 1W，如果 1 号是星期六， 结果匹配的是 3 号星期一，而非上个月最后的那天。W 字符串只能指定单一日期，而不能指定日期范围; LW 组合:在日期字段可以组合使用 LW，它的意思是当月的最后一个工作日; 井号(#):该字符只能在星期字段中使用，表示当月某个工作日。如 6#3 表示当月的第三个星期五(6 表示星期五， #3 表示当前的第三个)，而 4#5 表示当月的第五个星期三，假设当月没有第五个星期三，忽略不触发; C:该字符只在日期和星期字段中使用，代表“Calendar”的意思。它的意思是计划所关联的日期，如果日期没有 被关联，则相当于日历中所有日期。例如 5C 在日期字段中就相当于日历 5 日以后的第一天。1C 在星期字段中相当于 星期日后的第一天。 Cron 表达式对特殊字符的大小写不敏感，对代表星期的缩写英文大小写也不敏感。 上面我们定义的都是在什么时间执行，但是我们有一些在什么时间不执行的需求， 比如:理财周末和法定假日购买不计息;证券公司周末和法定假日休市。 基于 Calendar 的排除规则 如果要在触发器的基础上，排除一些时间区间不执行任务，就要用到 Quartz 的 Calendar 类(注意不是 JDK 的 Calendar)。可以按年、月、周、日、特定日期、Cron 表达式排除。 调用 Trigger 的 modifiedByCalendar()添加到触发器中，并且调用调度器的 addCalendar()方法注册排除规则。 Calendar的种类： BaseCalendar 为高级的 Calendar 实现了基本的功能，实现了 org.quartz.Calendar 接口 AnnualCalendar 排除年中一天或多天 CronCalendar 日历的这种实现排除了由给定的 CronExpression 表达的时间集合。 例如， 您可以使用此日历使用表达式“* * 0-7,18-23?* *”每天排除所有营业时间(上午 8 点至下午 5 点)。 如果 CronTrigger 具有给定的 cron 表达式并且与具有相同表达式的 CronCalendar 相关联，则日历将排除触发器包含的所有时间，并且它们将彼此抵消。 DailyCalendar 您可以使用此日历来排除营业时间(上午 8 点 - 5 点)每天。 每个 DailyCalendar 仅允许指定单个时间范围，并且该时间范围可能不会跨越每 日边界(即，您不能指定从上午 8 点至凌晨 5 点的时间范围)。 如果属 性 invertTimeRange 为 false(默认)，则时间范围定义触发器不允许触发 的时间范围。 如果 invertTimeRange 为 true，则时间范围被反转 - 也就是 排除在定义的时间范围之外的所有时间。 HolidayCalendar 特别的用于从 Trigger 中排除节假日 MonthlyCalendar 排除月份中的指定数天，例如，可用于排除每月的最后一天 WeeklyCalendar 排除星期中的任意周几，例如，可用于排除周末，默认周六和周日 Calendar示例代码 4.3.3 Scheduler调度器，是 Quartz 的指挥官，由 StdSchedulerFactory 产生。它是单例的。 并且是 Quartz 中最重要的 API，默认是实现类是 StdScheduler，里面包含了一个 QuartzScheduler。QuartzScheduler 里面又包含了一个 QuartzSchedulerThread。 Scheduler 中的方法主要分为三大类: 操作调度器本身，例如调度器的启动 start()、调度器的关闭 shutdown()。 操作 Trigger，例如 pauseTriggers()、resumeTrigger()。 操作 Job，例如 scheduleJob()、unscheduleJob()、rescheduleJob() 这些方法非常重要，可以实现任务的动态调度。 Scheduler示例代码 4.3.4 Listener我们有这么一种需求，在每个任务运行结束之后发送通知给运维管理员。那是不是 要在每个任务的最后添加一行代码呢?这种方式对原来的代码造成了入侵，不利于维护。 如果代码不是写在任务代码的最后一行，怎么知道任务执行完了呢?或者说，怎么监测 到任务的生命周期呢? 观察者模式:定义对象间一种一对多的依赖关系，使得每当一个对象改变状态，则 所有依赖它的对象都会得到通知并自动更新。 Quartz 中提供了三种 Listener，监听 Scheduler 的，监听 Trigger 的，监听 Job 的。 只需要创建类实现相应的接口，并在 Scheduler 上注册 Listener，便可实现对核心对象的监听。 JobListener 定义了4个方法： 方法 作用或执行实际 getName() 返回 JobListener 的名称 jobToBeExecuted() Scheduler 在 JobDetail 将要被执行时调用这个方法 jobExecutionVetoed() Scheduler 在 JobDetail 即将被执行，但又被 TriggerListener 否决了时调用这个 方法 jobWasExecuted() Scheduler 在 JobDetail 被执行之后调用这个方法 TriggerListener 方法 作用或执行实际 getName() 获取名称 triggerFired() Trigger 被触发，Job 上的 execute() 方法将要被执行时，Scheduler 就调用这个 方法 vetoJobExecution() 在 Trigger 触发后，Job 将要被执行时由 Scheduler 调用这个方法。 TriggerListener 给了一个选择去否决 Job 的执行。假如这个方法返回 true，这 个 Job 将不会为此次 Trigger 触发而得到执行 triggerMisfired() Trigger 错过触发时调用 triggerComplete() Trigger 被触发并且完成了 Job 的执行时，Scheduler 调用这个方法 SchedulerListener 方法很多，省略 Listener示例代码 4.3.5 JobStoreJobstore 用来存储任务和触发器相关的信息，例如所有任务的名称、数量、状态等 等。Quartz 中有两种存储任务的方式，一种在内存，一种是在数据库。 RAMJobStore Quartz 默认的 JobStore 是 RAMJobstore，也就是把任务和触发器信息运行的信息 存储在内存中，用到了 HashMap、TreeSet、HashSet 等等数据结构。 如果程序崩溃或重启，所有存储在内存中的数据都会丢失。所以我们需要把这些数 据持久化到磁盘。 JDBCJobStore JDBCJobStore 可以通过 JDBC 接口，将任务运行数据保存在数据库中。 JDBC 的实现方式有两种，JobStoreSupport 类的两个子类: JobStoreTX:在独立的程序中使用，自己管理事务，不参与外部事务。 JobStoreCMT:(Container Managed Transactions (CMT)，如果需要容器管理事务时，使用它。 使用 JDBCJobSotre 时，需要配置数据库信息: 12345678910111213org.quartz.jobStore.class:org.quartz.impl.jdbcjobstore.JobStoreTX org.quartz.jobStore.driverDelegateClass:org.quartz.impl.jdbcjobstore.StdJDBCDelegate# 使用 quartz.properties，不使用默认配置org.quartz.jobStore.useProperties:true#数据库中 quartz 表的表名前缀org.quartz.jobStore.tablePrefix:QRTZ_org.quartz.jobStore.dataSource:myDS#配置数据源org.quartz.dataSource.myDS.driver:com.mysql.jdbc.Driver org.quartz.dataSource.myDS.URL:jdbc:mysql://localhost:3306/quartz?useUnicode=true&amp;characterEncoding=utf8 org.quartz.dataSource.myDS.user:rootorg.quartz.dataSource.myDS.password:123456org.quartz.dataSource.myDS.validationQuery=select 0 from dual 问题来了?需要建什么表?表里面有什么字段?字段类型和长度是什么? 在官网的 Downloads 链接中，提供了 11 张表的建表语句: quartz-2.2.3-distribution\\quartz-2.2.3\\docs\\dbTables 2.3 的版本在这个路径下:src\\org\\quartz\\impl\\jdbcjobstore 表名与作用: 表名 作用 QRTZ_BLOB_TRIGGERS Trigger 作为 Blob 类型存储 QRTZ_CALENDARS 存储 Quartz 的 Calendar 信息 QRTZ_CRON_TRIGGERS 存储 CronTrigger，包括 Cron 表达式和时区信息 QRTZ_FIRED_TRIGGERS 存储与已触发的 Trigger 相关的状态信息，以及相关 Job 的执行信息 QRTZ_JOB_DETAILS 存储每一个已配置的 Job 的详细信息 QRTZ_LOCKS 存储程序的悲观锁的信息 QRTZ_PAUSED_TRIGGER_GRPS 存储已暂停的 Trigger 组的信息 QRTZ_SCHEDULER_STATE 存储少量的有关 Scheduler 的状态信息，和别的 Scheduler 实例 QRTZ_SIMPLE_TRIGGERS 存储 SimpleTrigger 的信息，包括重复次数、间隔、以及已触的次数 QRTZ_SIMPROP_TRIGGERS 存储 CalendarIntervalTrigger 和 DailyTimeIntervalTrigger 两种类型的触发器 QRTZ_TRIGGERS 存储已配置的 Trigger 的信息 5、与spring集成Spring-quartz 工程 Spring 在 spring-context-support.jar 中直接提供了对 Quartz 的支持。 使用三个FactoryBean配置核心对象 JobDetailFactoryBean 实现的是FactoryBean FactoryBean 对不同的Trigger实现有不同的FactoryBean SchedulerFactoryBean 实现的是FactoryBean 配置方式可以选择xml方式或者java注解配置。 6、动态调度传统的 Spring 方式集成，由于任务信息全部配置在 xml 文件中，如果需要操作任务 或者修改任务运行频率，只能重新编译、打包、部署、重启，如果有紧急问题需要处理， 会浪费很多的时间。 有没有可以动态调度任务的方法?比如停止一个 Job?启动一个 Job?修改 Job 的 触发频率? 读取配置文件、写入配置文件、重启 Scheduler 或重启应用明显是不可取的。 对于这种频繁变更并且需要实时生效的配置信息，我们可以放到哪里? ZK、Redis、DB tables。 并且，可以提供一个界面，实现对数据表的轻松操作。 6.1 配置管理这里我们用最简单的数据库的实现。 建一张什么样的表?参考 JobDetail 的属性。 1234567891011CREATE TABLE `sys_job` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT 'ID', `job_name` varchar(512) NOT NULL COMMENT '任务名称', `job_group` varchar(512) NOT NULL COMMENT '任务组名', `job_cron` varchar(512) NOT NULL COMMENT '时间表达式', `job_class_path` varchar(1024) NOT NULL COMMENT '类路径,全类型', `job_data_map` varchar(1024) DEFAULT NULL COMMENT '传递 map 参数', `job_status` int(2) NOT NULL COMMENT '状态:1 启用 0 停用', `job_describe` varchar(1024) DEFAULT NULL COMMENT '任务功能描述', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=25 DEFAULT CHARSET=utf8; 6.2 数据操作与任务调度操作数据表非常简单，SSM 增删改查。 但是在修改了表的数据之后，怎么让调度器知道呢? 调度器的接口：Scheduler 在我们的需求中，我们需要做的事情: 1、 新增一个任务 2、 删除一个任务 3、 启动、停止一个任务 4、 修改任务的信息(包括调度规律) 因此可以把相关的操作封装到一个工具类中。 代码 6.3 容器启动与Service注入6.3.1 容器启动因为任务没有定义在 ApplicationContext.xml 中，而是放到了数据库中，Spring Boot 启动时，怎么读取任务信息? 或者，怎么在 Spring 启动完成的时候做一些事情? 创建一个类，实现 CommandLineRunner 接口，实现 run 方法。 从表中查出状态是 1 的任务，然后构建。 6.3.2 Service 类注入到 Job 中Spring的 Bean 如何注入到实现了 Job 接口的类中? 例如在 SendMailTask 中，需要注入 ISysJobService，查询数据库发送邮件。 如果没有任何配置，注入会报空指针异常。 原因: 因为定时任务 Job 对象的实例化过程是在 Quartz 中进行的，而 Service Bean 是由Spring 容器管理的，Quartz 察觉不到 Service Bean 的存在，所以无法将 Service Bean 装配到 Job 对象中。 分析: Quartz 集成到 Spring 中，用到 SchedulerFactoryBean，其实现了 InitializingBean 方法，在唯一的方法 afterPropertiesSet()在 Bean 的属性初始化后调用。 调度器用 AdaptableJobFactory 对 Job 对象进行实例化。所以，如果我们可以把这 个 JobFactory 指定为我们自定义的工厂的话，就可以在 Job 实例化完成之后，把 Job 纳入到 Spring 容器中管理。 解决这个问题的步骤: 1、定义一个 AdaptableJobFactory，实现 JobFactory 接口，实现接口定义的newJob 方法，在这里面返回 Job 实例 2、定义一个 MyJobFactory，继承 AdaptableJobFactory。使用 Spring 的 AutowireCapableBeanFactory，把 Job 实例注入到容器中。 3、指定 Scheduler 的 JobFactory 为自定义的 JobFactory。 7、集群部署为什么需要集群? 1、防止单点故障，减少对业务的影响 2、减少节点的压力，例如在 10 点要触发 1000 个任务，如果有 10 个节点，则每个 节点之需要执行 100 个任务 集群需要解决的问题? 1、任务重跑，因为节点部署的内容是一样的，到 10 点的时候，每个节点都会执行 相同的操作，引起数据混乱。比如跑批，绝对不能执行多次。 2、任务漏跑，假如任务是平均分配的，本来应该在某个节点上执行的任务，因为节 点故障，一直没有得到执行。 3、水平集群需要注意时间同步问题 4、Quartz 使用的是随机的负载均衡算法，不能指定节点执行 如何解决？ 所以必须要有一种共享数据或者通信的机制。在分布式系统的不同节点中，我们可 以采用什么样的方式，实现数据共享? 两两通信，或者基于分布式的服务，实现数据共享。 例如:ZK、Redis、DB。 在 Quartz 中，提供了一种简单的方式，基于数据库共享任务执行信息。也就是说，一个节点执行任务的时候，会操作数据库，其他的节点查询数据库，便可以感知到了。 同样的问题:建什么表?哪些字段? 依旧使用quartz系统自带的 11 张表。 集群配置与验证 quartz.properties 配置 四个配置:集群实例 ID、集群开关、数据库持久化、数据源信息 注意先清空 quartz 所有表、改端口、两个任务频率改成一样 验证 1:先后启动 2 个节点，任务是否重跑 验证 2:停掉一个节点，任务是否漏跑","categories":[{"name":"分布式架构技术","slug":"分布式架构技术","permalink":"https://zzkenyon.github.io/categories/分布式架构技术/"}],"tags":[{"name":"quartz","slug":"quartz","permalink":"https://zzkenyon.github.io/tags/quartz/"}],"keywords":[{"name":"分布式架构技术","slug":"分布式架构技术","permalink":"https://zzkenyon.github.io/categories/分布式架构技术/"}]},{"title":"netty源码分析之executionMask","slug":"nio-netty源码分析之executionMask","date":"2020-09-07T16:00:00.000Z","updated":"2020-09-08T03:12:42.670Z","comments":true,"path":"2020/09/08/nio-netty源码分析之executionMask/","link":"","permalink":"https://zzkenyon.github.io/2020/09/08/nio-netty源码分析之executionMask/","excerpt":"","text":"老版本的netty，AbstractChannelHandlerContext 有两个bool属性InBound 和outBound，InBound=true表示该节点是inBound，outBound=true表示该节点是outBound，当然也可能同时为true。在我阅读的源代码版本（4.1.50）中已经删除了这两个属性，取而代之的是属性executionMask，通过使用该属性可以在事件传播时，快速的判断出该节点中的Handler在inBound方向和outBound方向有没有重载某事件处理逻辑。 之前分析过Pipeline的源码，在向Pipeline添加节点的时候，会创建DefaultChannelHandlerContext对象，调用其父类构造函数时 1234567891011import static io.netty.channel.ChannelHandlerMask.mask;AbstractChannelHandlerContext(DefaultChannelPipeline pipeline, EventExecutor executor, String name, Class&lt;? extends ChannelHandler&gt; handlerClass) &#123; this.name = ObjectUtil.checkNotNull(name, \"name\"); this.pipeline = pipeline; this.executor = executor; // null this.executionMask = mask(handlerClass); // 生成一个掩码 可以快读判断这个Handler重载了哪些方法 // Its ordered if its driven by the EventLoop or the given Executor is an instanceof OrderedEventExecutor. ordered = executor == null || executor instanceof OrderedEventExecutor; // ture&#125; 会用mask方法给其成员executionMask赋值，mask是ChannelHandlerMask类的静态方法，本文主要分析这类的源码，该类的源码并不复杂，之所以要拿出来分析，完全是因为这种设计思想还是值得借鉴的。 首先看这个类定义了许多的int型静态变量，作为标记，每一个事件处理方法对应了17位中的一位 12345678910111213141516171819static final int MASK_EXCEPTION_CAUGHT = 1;static final int MASK_CHANNEL_REGISTERED = 1 &lt;&lt; 1; //2 static final int MASK_CHANNEL_UNREGISTERED = 1 &lt;&lt; 2; //4static final int MASK_CHANNEL_ACTIVE = 1 &lt;&lt; 3; //8static final int MASK_CHANNEL_INACTIVE = 1 &lt;&lt; 4; //16static final int MASK_CHANNEL_READ = 1 &lt;&lt; 5; //32static final int MASK_CHANNEL_READ_COMPLETE = 1 &lt;&lt; 6; //64static final int MASK_USER_EVENT_TRIGGERED = 1 &lt;&lt; 7; //128static final int MASK_CHANNEL_WRITABILITY_CHANGED = 1 &lt;&lt; 8; //256static final int MASK_BIND = 1 &lt;&lt; 9; //512static final int MASK_CONNECT = 1 &lt;&lt; 10; //1024static final int MASK_DISCONNECT = 1 &lt;&lt; 11; //2048static final int MASK_CLOSE = 1 &lt;&lt; 12; //4096static final int MASK_DEREGISTER = 1 &lt;&lt; 13; //8192static final int MASK_READ = 1 &lt;&lt; 14; //16384static final int MASK_WRITE = 1 &lt;&lt; 15; //32768static final int MASK_FLUSH = 1 &lt;&lt; 16; //65536 根据以上的定义 123static final int MASK_ONLY_INBOUND = MASK_CHANNEL_REGISTERED | MASK_CHANNEL_UNREGISTERED | MASK_CHANNEL_ACTIVE | MASK_CHANNEL_INACTIVE | MASK_CHANNEL_READ | MASK_CHANNEL_READ_COMPLETE | MASK_USER_EVENT_TRIGGERED | MASK_CHANNEL_WRITABILITY_CHANGED; 计算出纯纯的In事件方法掩码为510（1 1111 1110） 加上异常处理方法： 1private static final int MASK_ALL_INBOUND = MASK_EXCEPTION_CAUGHT | MASK_ONLY_INBOUND; 所有的In事件方法掩码为511 （1 1111 1111） 同理计算纯纯的out事件方法掩码为：130559 （1 1111 1111 0000 0000） 12static final int MASK_ONLY_OUTBOUND = MASK_BIND | MASK_CONNECT | MASK_DISCONNECT | MASK_CLOSE | MASK_DEREGISTER | MASK_READ | MASK_WRITE | MASK_FLUSH; 加上异常处理方法为: 130560 (1 1111 1111 0000 0001) 1private static final int MASK_ALL_OUTBOUND = MASK_EXCEPTION_CAUGHT | MASK_ONLY_OUTBOUND; 重要的线程私有对象： 1234567private static final FastThreadLocal&lt;Map&lt;Class&lt;? extends ChannelHandler&gt;, Integer&gt;&gt; MASKS = new FastThreadLocal&lt;Map&lt;Class&lt;? extends ChannelHandler&gt;, Integer&gt;&gt;() &#123; @Override protected Map&lt;Class&lt;? extends ChannelHandler&gt;, Integer&gt; initialValue() &#123; return new WeakHashMap&lt;Class&lt;? extends ChannelHandler&gt;, Integer&gt;(32); &#125; &#125;; 很显然这个对象是用来存储ChannelHandler和其掩码之间的映射，注意线程私有属性。 mask方法 123456789static int mask(Class&lt;? extends ChannelHandler&gt; clazz) &#123; Map&lt;Class&lt;? extends ChannelHandler&gt;, Integer&gt; cache = MASKS.get(); Integer mask = cache.get(clazz); if (mask == null) &#123; mask = mask0(clazz); cache.put(clazz, mask); &#125; return mask;&#125; 首先尝试从map中获取掩码，求而不得再调用mask0方法计算掩码，存入map并返回 mask0方法 假设某Handler实现了两个方法MASK_CHANNEL_ACTIVE 和MASK_CHANNEL_REGISTERED 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283private static int mask0(Class&lt;? extends ChannelHandler&gt; handlerType) &#123; int mask = MASK_EXCEPTION_CAUGHT; // mask=1 try &#123; if (ChannelInboundHandler.class.isAssignableFrom(handlerType)) &#123; mask |= MASK_ALL_INBOUND; //mask= 0 0000 0001 | 1 1111 1111 = 1 1111 1111 // isSkippable的逻辑就是 如果我在Handler中重写了channelRegistered方法 则返回false if (isSkippable(handlerType, \"channelRegistered\", ChannelHandlerContext.class)) &#123; // 由于重载了channelRegistered，这里不执行 后面同理 mask &amp;= ~MASK_CHANNEL_REGISTERED; &#125; if (isSkippable(handlerType, \"channelUnregistered\", ChannelHandlerContext.class)) &#123; // mask = 1 1111 1111 &amp; 1 1111 1011 = 1 1111 1011 mask &amp;= ~MASK_CHANNEL_UNREGISTERED; &#125; if (isSkippable(handlerType, \"channelActive\", ChannelHandlerContext.class)) &#123;、 // 跳过 mask &amp;= ~MASK_CHANNEL_ACTIVE; &#125; if (isSkippable(handlerType, \"channelInactive\", ChannelHandlerContext.class)) &#123; // mask = 1 1111 1011 &amp; 1 1110 1111 = 1 1110 1011 mask &amp;= ~MASK_CHANNEL_INACTIVE; &#125; if (isSkippable(handlerType, \"channelRead\", ChannelHandlerContext.class, Object.class)) &#123; // mask = 1 1110 1011 &amp; 1 1101 1111 = 1 1100 1011 mask &amp;= ~MASK_CHANNEL_READ; &#125; if (isSkippable(handlerType, \"channelReadComplete\", ChannelHandlerContext.class)) &#123; // mask = 1 1100 1011 &amp; 1 1011 1111 = 1 1000 1011 mask &amp;= ~MASK_CHANNEL_READ_COMPLETE; &#125; if (isSkippable(handlerType, \"channelWritabilityChanged\", ChannelHandlerContext.class)) &#123; // mask = 1 1000 1011 &amp; 1 0111 1111 = 1 0000 1011 mask &amp;= ~MASK_CHANNEL_WRITABILITY_CHANGED; &#125; if (isSkippable(handlerType, \"userEventTriggered\", ChannelHandlerContext.class, Object.class)) &#123; // mask = 1 0000 1011 &amp; 0 1111 1111 = 0 0000 1011 mask &amp;= ~MASK_USER_EVENT_TRIGGERED; &#125; // 最终得到的 mask 是重写的所有方法对应位为1的一个int值 &#125; if (ChannelOutboundHandler.class.isAssignableFrom(handlerType)) &#123; mask |= MASK_ALL_OUTBOUND; if (isSkippable(handlerType, \"bind\", ChannelHandlerContext.class, SocketAddress.class, ChannelPromise.class)) &#123; mask &amp;= ~MASK_BIND; &#125; if (isSkippable(handlerType, \"connect\", ChannelHandlerContext.class, SocketAddress.class, SocketAddress.class, ChannelPromise.class)) &#123; mask &amp;= ~MASK_CONNECT; &#125; if (isSkippable(handlerType, \"disconnect\", ChannelHandlerContext.class, ChannelPromise.class)) &#123; mask &amp;= ~MASK_DISCONNECT; &#125; if (isSkippable(handlerType, \"close\", ChannelHandlerContext.class, ChannelPromise.class)) &#123; mask &amp;= ~MASK_CLOSE; &#125; if (isSkippable(handlerType, \"deregister\", ChannelHandlerContext.class, ChannelPromise.class)) &#123; mask &amp;= ~MASK_DEREGISTER; &#125; if (isSkippable(handlerType, \"read\", ChannelHandlerContext.class)) &#123; mask &amp;= ~MASK_READ; &#125; if (isSkippable(handlerType, \"write\", ChannelHandlerContext.class, Object.class, ChannelPromise.class)) &#123; mask &amp;= ~MASK_WRITE; &#125; if (isSkippable(handlerType, \"flush\", ChannelHandlerContext.class)) &#123; mask &amp;= ~MASK_FLUSH; &#125; &#125; if (isSkippable(handlerType, \"exceptionCaught\", ChannelHandlerContext.class, Throwable.class)) &#123; mask &amp;= ~MASK_EXCEPTION_CAUGHT; &#125; &#125; catch (Exception e) &#123; // Should never reach here. PlatformDependent.throwException(e); &#125; return mask;&#125; 在pipeline节点中，有两个方法，用于查找重载了指定方法的下一个或前一个节点 1234567891011121314151617181920private AbstractChannelHandlerContext findContextInbound(int mask) &#123; AbstractChannelHandlerContext ctx = this; EventExecutor currentExecutor = executor(); do &#123; ctx = ctx.next; &#125; while (skipContext(ctx, currentExecutor, mask, MASK_ONLY_INBOUND)); return ctx;&#125;/** * mask 是需要匹配的方法的mask */private AbstractChannelHandlerContext findContextOutbound(int mask) &#123; AbstractChannelHandlerContext ctx = this; EventExecutor currentExecutor = executor(); do &#123; ctx = ctx.prev; &#125; while (skipContext(ctx, currentExecutor, mask, MASK_ONLY_OUTBOUND)); return ctx;&#125; 传入的参数mask是指定方法的掩码，例如ChannelHandlerMask.MASK_CHANNEL_ACTIVE 重要的逻辑还是在skipContext()方法中 12345private static boolean skipContext( AbstractChannelHandlerContext ctx, EventExecutor currentExecutor, int mask, int onlyMask) &#123; return (ctx.executionMask &amp; (onlyMask | mask)) == 0 || (ctx.executor() == currentExecutor &amp;&amp; (ctx.executionMask &amp; mask) == 0);&#125; mask = 0 0000 1000 onlyMask = 1 1111 1110 mask | onlyMask = 1 1111 1110 此处假设handler重载了channelActive方法 executionMask = 0 0000 1011 1230 0000 1011 &amp; 1 1111 1110 = 0 0000 1010 第一个判断0 0000 1010 == 0 为 false 第二次判断主要看后面 executionMask &amp; mask 1230 0000 1011 &amp;0 0000 1000 = 0 0000 1000 0 0000 1000 == 0 也为 false 此时skipContext方法可以返回 false findContextInbound结束循环。","categories":[{"name":"I/O和网络编程","slug":"I-O和网络编程","permalink":"https://zzkenyon.github.io/categories/I-O和网络编程/"}],"tags":[{"name":"netty","slug":"netty","permalink":"https://zzkenyon.github.io/tags/netty/"}],"keywords":[{"name":"I/O和网络编程","slug":"I-O和网络编程","permalink":"https://zzkenyon.github.io/categories/I-O和网络编程/"}]},{"title":"Nacos(三)心跳与服务更新","slug":"Nacos(3)心跳与服务更新","date":"2020-08-21T16:00:00.000Z","updated":"2021-01-14T05:22:28.894Z","comments":true,"path":"2020/08/22/Nacos(3)心跳与服务更新/","link":"","permalink":"https://zzkenyon.github.io/2020/08/22/Nacos(3)心跳与服务更新/","excerpt":"","text":"nacos通过pull+push结合的方式，来保证服务状态的更新，大致流程如下图所示 消费者应用启动时，会开启一个UpdateTask，每隔10s会向nacos-server发送一个pull请求，拉取最新的服务实例信息 服务提供者，注册时与nacos-server建立了心跳检查，默认是5s发送一次心跳，nacos-server会开启一个心跳检查任务，不停的检查服务心跳，超过15秒没有收到心跳，则将对应实例设置为非健康状态，超过30秒还没有收到心跳，做下线处理，删除实例。 下面，分别对以上两个流程进行源码分析 1 pull请求更新在上一篇笔记《Nacos(二)注册中心核心源码分析》中，讲到HostReactor.getServiceInfo()方法，在获取到nacos-server的服务实例信息之后，通过一套事件发送响应机制，将实例信息注入到Spring-Boot中，那么在首次获取到实例信息之后，考虑到服务端的实例信息可能会发生改变，所以要建立一个任务，定时的pull服务端信息。 HostReactor.getServiceInfo 12345678910111213141516171819202122232425public ServiceInfo getServiceInfo(final String serviceName, final String clusters) &#123; NAMING_LOGGER.debug(\"failover-mode: \" + failoverReactor.isFailoverSwitch()); String key = ServiceInfo.getKey(serviceName, clusters); if (failoverReactor.isFailoverSwitch()) &#123; return failoverReactor.getService(key); &#125; //从本地缓存中取 ServiceInfo serviceObj = getServiceInfo0(serviceName, clusters); if (null == serviceObj) &#123;// 本地没有，两步走 // 1、创建一个空的ServiceInfo放入缓存 serviceObj = new ServiceInfo(serviceName, clusters); serviceInfoMap.put(serviceObj.getKey(), serviceObj); // 2、将远程服务信息更新到ServiceInfo中，updatingMap看来只是其到标记作用的 updatingMap.put(serviceName, new Object()); // &gt;&gt; 关键点 updateServiceNow(serviceName, clusters); updatingMap.remove(serviceName); //更新完毕删除标记 &#125; else if (updatingMap.containsKey(serviceName)) &#123; ... // 若有其他线程已经创建了标记说明其他线程正在更新，同步等待 &#125; // 开启定时更新任务 scheduleUpdateIfAbsent(serviceName, clusters); return serviceInfoMap.get(serviceObj.getKey());&#125; 上面代码已经分析过了，直接看到倒数第二行： scheduleUpdateIfAbsent(serviceName, clusters) 1234567891011121314public void scheduleUpdateIfAbsent(String serviceName, String clusters) &#123; if (futureMap.get(ServiceInfo.getKey(serviceName, clusters)) != null) &#123; return; &#125; synchronized (futureMap) &#123; if (futureMap.get(ServiceInfo.getKey(serviceName, clusters)) != null) &#123; return; &#125; ScheduledFuture&lt;?&gt; future = addTask(new UpdateTask(serviceName, clusters)); futureMap.put(ServiceInfo.getKey(serviceName, clusters), future); &#125;&#125; futureMap是存放serviceName与定时更新任务异步结果Future映射关系的地方，futureMap中要是存在serviceName对应的Future说明定时任务已经开启了，直接返回，这里做了双重校验。 调用addTask添加一个UpdateTask给定时任务执行，看主要看UpdateTask的run函数做了些什么 123456789101112131415161718192021222324252627282930313233343536373839@Overridepublic void run() &#123; try &#123; // 从本地缓存获取ServiceInfo ServiceInfo serviceObj = serviceInfoMap.get(ServiceInfo.getKey(serviceName, clusters)); // 本地没有，立即执行更新 if (serviceObj == null) &#123; updateServiceNow(serviceName, clusters); // DEFAULT_DELAY = 1000L ，1s后再次执行这个任务 executor.schedule(this, DEFAULT_DELAY, TimeUnit.MILLISECONDS); return; &#125; // 本地有但是过期了，立即更新 lastRefTime默认值是MaxValue if (serviceObj.getLastRefTime() &lt;= lastRefTime) &#123; updateServiceNow(serviceName, clusters); serviceObj = serviceInfoMap.get(ServiceInfo.getKey(serviceName, clusters)); &#125; else &#123; // if serviceName already updated by push, we should not override it // since the push data may be different from pull through force push // 如果服务被基于push机制的流程做了更新，那么我们不需要覆盖本地服务 // 因为push过来的数据和pull来的数据不同，所以这里只是调用接口刷新服务 refreshOnly(serviceName, clusters); &#125; // 最后刷新时间 lastRefTime = serviceObj.getLastRefTime(); // 如果没有完成订阅或者futureMap中不包含指定服务信息，则中断更新 if (!eventDispatcher.isSubscribed(serviceName, clusters) &amp;&amp; !futureMap.containsKey(ServiceInfo.getKey(serviceName, clusters))) &#123; // abort the update task: NAMING_LOGGER.info(\"update task is stopped, service:\" + serviceName + \", clusters:\" + clusters); return; &#125; // 10s后再次执行本任务 executor.schedule(this, serviceObj.getCacheMillis(), TimeUnit.MILLISECONDS); &#125; catch (Throwable e) &#123; NAMING_LOGGER.warn(\"[NA] failed to update serviceName: \" + serviceName, e); &#125;&#125; 看一下两个更新接口 updateServiceNow 123456789101112131415161718public void updateServiceNow(String serviceName, String clusters) &#123; ServiceInfo oldService = getServiceInfo0(serviceName, clusters); try &#123; // 发送http请求获取实例信息列表 String result = serverProxy.queryList(serviceName, clusters, pushReceiver.getUDPPort(), false); if (StringUtils.isNotEmpty(result)) &#123; processServiceJSON(result); // 处理结果，更新本地缓存 &#125; &#125; catch (Exception e) &#123; NAMING_LOGGER.error(\"[NA] failed to update serviceName: \" + serviceName, e); &#125; finally &#123; if (oldService != null) &#123; synchronized (oldService) &#123; oldService.notifyAll(); &#125; &#125; &#125;&#125; refreshOnly 1234567public void refreshOnly(String serviceName, String clusters) &#123; try &#123; serverProxy.queryList(serviceName, clusters, pushReceiver.getUDPPort(), false); &#125; catch (Exception e) &#123; NAMING_LOGGER.error(\"[NA] failed to update serviceName: \" + serviceName, e); &#125;&#125; refreshOnly并没有处理结果，那么这里好像唯一的作用，就是将pushReceiver.getUDPPort()传给了server 因为nacos-server不会永久存储消费者的udp信息，后面的分析会详细介绍。 2. push推送更新还记得上一篇笔记《Nacos(二)注册中心核心源码分析》分析过，在服务提供者发起服务注册时，nacos-server收到注册请求，处理请求时，会调用createEmptyService方法来创建一个空的服务。 12345678910public void registerInstance(String namespaceId, String serviceName, Instance instance) throws NacosException &#123; // &gt;&gt; createEmptyService(namespaceId, serviceName, instance.isEphemeral()); Service service = getService(namespaceId, serviceName); if (service == null) &#123; throw new NacosException(NacosException.INVALID_PARAM, \"service not found, namespace: \" + namespaceId + \", service: \" + serviceName); &#125; addInstance(namespaceId, serviceName, instance.isEphemeral(), instance);&#125; createEmptyService方法最终会调用到service.init() 12345678public void init() &#123; // 开启心跳检查任务 HealthCheckReactor.scheduleCheck(clientBeatCheckTask); for (Map.Entry&lt;String, Cluster&gt; entry : clusterMap.entrySet()) &#123; entry.getValue().setService(this); entry.getValue().init(); &#125;&#125; 下面就来看一下这个健康检查任务时怎么执行的. lientBeatCheckTask.run 1234567891011121314151617181920212223242526272829303132333435@Overridepublic void run() &#123; try &#123; ... List&lt;Instance&gt; instances = service.allIPs(true); // first set health status of instances: for (Instance instance : instances) &#123; // 遍历服务节点心跳检测 if (System.currentTimeMillis() - instance.getLastBeat() &gt; instance.getInstanceHeartBeatTimeOut()) &#123; // getInstanceHeartBeatTimeOut 默认15秒 if (!instance.isMarked()) &#123; if (instance.isHealthy()) &#123; instance.setHealthy(false); ..//log getPushService().serviceChanged(service); // 推送服务变更事件 ApplicationUtils.publishEvent(new InstanceHeartbeatTimeoutEvent(this, instance)); &#125; &#125; &#125; &#125; if (!getGlobalConfig().isExpireInstance()) &#123; return; &#125; // then remove obsolete instances: for (Instance instance : instances) &#123; if (instance.isMarked()) &#123; continue; &#125; if (System.currentTimeMillis() - instance.getLastBeat() &gt; instance.getIpDeleteTimeout()) &#123; // getIpDeleteTimeout 默认30s // delete instance ...//log deleteIp(instance); &#125; &#125; &#125; ...&#125; getPushService().serviceChanged(service) 监听服务状态变更事件，然后遍历所有的客户端，通过udp协议进行消息的广播通知 123456789public void serviceChanged(Service service) &#123; // merge some change events to reduce the push frequency: if (futureMap .containsKey(UtilsAndCommons.assembleFullServiceName(service.getNamespaceId(), service.getName()))) &#123; return; &#125; this.applicationContext.publishEvent(new ServiceChangeEvent(this, service));&#125; 发出了ServiceChangeEvent事件，该事件时Spring事件 PushService既是事件发送方，也是事件监听方，所以定位到响应函数 clientMap nacos-client在调用queryList时，会传一个udp端口号给nacos-server，nacos-server会创建一个udp连接连接到nacos-client，存放在clientMap 中 clientMap 是一个两层的map结构 第一层的key是：namespaceId##serviceName，将不同的namespace分开 第二层的key是：serviceName:xxx,clusters:xxx,address:xxx,agent:xxx，通过address能够定位到一个服务消费者的ip地址， 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566@Overridepublic void onApplicationEvent(ServiceChangeEvent event) &#123; Service service = event.getService(); String serviceName = service.getName(); String namespaceId = service.getNamespaceId(); Future future = GlobalExecutor.scheduleUdpSender(() -&gt; &#123; try &#123; Loggers.PUSH.info(serviceName + \" is changed, add it to push queue.\"); //拿到服务对应的PushClient key 是namespaceId##serviceName ConcurrentMap&lt;String, PushClient&gt; clients = clientMap .get(UtilsAndCommons.assembleFullServiceName(namespaceId, serviceName)); if (MapUtils.isEmpty(clients)) &#123; return; &#125; Map&lt;String, Object&gt; cache = new HashMap&lt;&gt;(16); long lastRefTime = System.nanoTime(); for (PushClient client : clients.values()) &#123; if (client.zombie()) &#123; // 距离上次推送超过10秒 Loggers.PUSH.debug(\"client is zombie: \" + client.toString()); clients.remove(client.toString()); //移除client Loggers.PUSH.debug(\"client is zombie: \" + client.toString()); continue; &#125; Receiver.AckEntry ackEntry; Loggers.PUSH.debug(\"push serviceName: &#123;&#125; to client: &#123;&#125;\", serviceName, client.toString()); String key = getPushCacheKey(serviceName, client.getIp(), client.getAgent()); byte[] compressData = null; Map&lt;String, Object&gt; data = null; if (switchDomain.getDefaultPushCacheMillis() &gt;= 20000 &amp;&amp; cache.containsKey(key)) &#123; org.javatuples.Pair pair = (org.javatuples.Pair) cache.get(key); compressData = (byte[]) (pair.getValue0()); data = (Map&lt;String, Object&gt;) pair.getValue1(); Loggers.PUSH.debug(\"[PUSH-CACHE] cache hit: &#123;&#125;:&#123;&#125;\", serviceName, client.getAddrStr()); &#125; // 收到nacos-client的响应数据， if (compressData != null) &#123; ackEntry = prepareAckEntry(client, compressData, data, lastRefTime); &#125; else &#123; ackEntry = prepareAckEntry(client, prepareHostsData(client), lastRefTime); if (ackEntry != null) &#123; cache.put(key, new org.javatuples.Pair&lt;&gt;(ackEntry.origin.getData(), ackEntry.data)); &#125; &#125; Loggers.PUSH.info(\"serviceName: &#123;&#125; changed, schedule push for: &#123;&#125;, agent: &#123;&#125;, key: &#123;&#125;\", client.getServiceName(), client.getAddrStr(), client.getAgent(), (ackEntry == null ? null : ackEntry.key)); udpPush(ackEntry); &#125; &#125; catch (Exception e) &#123; Loggers.PUSH.error(\"[NACOS-PUSH] failed to push serviceName: &#123;&#125; to client, error: &#123;&#125;\", serviceName, e); &#125; finally &#123; futureMap.remove(UtilsAndCommons.assembleFullServiceName(namespaceId, serviceName)); &#125; &#125;, 1000, TimeUnit.MILLISECONDS); futureMap.put(UtilsAndCommons.assembleFullServiceName(namespaceId, serviceName), future); &#125; 从代码中可以了解到 nacos-server端保存的消费者udp连接，并不是一直存储的，当超过一定时间（10秒）没有更新（client请求queryList的时候会创建一个udp连接放到clientsMap中），就会被移除。 因此，面pull更新的时候，有一个refreshOnly接口，就是专门用于刷新server端的udp。 那么，server端push了数据之后，client端又是怎么处理的呢？ 在Client端构造HostReactor的时候： 1234567891011121314151617181920212223242526public HostReactor(EventDispatcher eventDispatcher, NamingProxy serverProxy, String cacheDir, boolean loadCacheAtStart, int pollingThreadCount) &#123; executor = new ScheduledThreadPoolExecutor(pollingThreadCount, new ThreadFactory() &#123; @Override public Thread newThread(Runnable r) &#123; Thread thread = new Thread(r); thread.setDaemon(true); thread.setName(\"com.alibaba.nacos.client.naming.updater\"); return thread; &#125; &#125;); this.eventDispatcher = eventDispatcher; this.serverProxy = serverProxy; this.cacheDir = cacheDir; if (loadCacheAtStart) &#123; this.serviceInfoMap = new ConcurrentHashMap&lt;String, ServiceInfo&gt;(DiskCache.read(this.cacheDir)); &#125; else &#123; this.serviceInfoMap = new ConcurrentHashMap&lt;String, ServiceInfo&gt;(16); &#125; this.updatingMap = new ConcurrentHashMap&lt;String, Object&gt;(); this.failoverReactor = new FailoverReactor(this, cacheDir); this.pushReceiver = new PushReceiver(this); //&#125; 看到最后一行，创建了一个PushReceiver 1234567891011121314151617181920public PushReceiver(HostReactor hostReactor) &#123; try &#123; this.hostReactor = hostReactor; udpSocket = new DatagramSocket(); //创建了一个 executorService = new ScheduledThreadPoolExecutor(1, new ThreadFactory() &#123; @Override public Thread newThread(Runnable r) &#123; Thread thread = new Thread(r); thread.setDaemon(true); thread.setName(\"com.alibaba.nacos.naming.push.receiver\"); return thread; &#125; &#125;); executorService.execute(this); &#125; catch (Exception e) &#123; NAMING_LOGGER.error(\"[NA] init udp socket failed\", e); &#125;&#125; PushReceiver中开启了一个线程池，任务逻辑就是PushReceiver的run函数： 12345678910111213141516171819202122232425262728293031323334353637383940414243@Overridepublic void run() &#123; while (true) &#123; try &#123; // byte[] is initialized with 0 full filled by default byte[] buffer = new byte[UDP_MSS]; DatagramPacket packet = new DatagramPacket(buffer, buffer.length); udpSocket.receive(packet); String json = new String(IoUtils.tryDecompress(packet.getData()), \"UTF-8\").trim(); NAMING_LOGGER.info(\"received push data: \" + json + \" from \" + packet.getAddress().toString()); PushPacket pushPacket = JSON.parseObject(json, PushPacket.class); String ack; if (\"dom\".equals(pushPacket.type) || \"service\".equals(pushPacket.type)) &#123; hostReactor.processServiceJSON(pushPacket.data); // send ack to server ack = \"&#123;\\\"type\\\": \\\"push-ack\\\"\" + \", \\\"lastRefTime\\\":\\\"\" + pushPacket.lastRefTime + \"\\\", \\\"data\\\":\" + \"\\\"\\\"&#125;\"; &#125; else if (\"dump\".equals(pushPacket.type)) &#123; // dump data to server ack = \"&#123;\\\"type\\\": \\\"dump-ack\\\"\" + \", \\\"lastRefTime\\\": \\\"\" + pushPacket.lastRefTime + \"\\\", \\\"data\\\":\" + \"\\\"\" + StringUtils.escapeJavaScript(JSON.toJSONString(hostReactor.getServiceInfoMap())) + \"\\\"&#125;\"; &#125; else &#123; // do nothing send ack only ack = \"&#123;\\\"type\\\": \\\"unknown-ack\\\"\" + \", \\\"lastRefTime\\\":\\\"\" + pushPacket.lastRefTime + \"\\\", \\\"data\\\":\" + \"\\\"\\\"&#125;\"; &#125; udpSocket.send(new DatagramPacket(ack.getBytes(Charset.forName(\"UTF-8\")), ack.getBytes(Charset.forName(\"UTF-8\")).length, packet.getSocketAddress())); &#125; catch (Exception e) &#123; NAMING_LOGGER.error(\"[NA] error while receiving push data\", e); &#125; &#125;&#125; 开启了一个udp监听，收到DatagramPacket后进行反序列化，解析，通过processServiceJSON()方法进行处理，最后还响应出一个ack。 大致的流程就分析完了，一些细节部分略过了，有时间会继续跟。","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/tags/SpringCloud/"}],"keywords":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}]},{"title":"Nacos(四)数据一致性","slug":"Nacos(4)集群的数据一致性","date":"2020-08-19T16:00:00.000Z","updated":"2021-01-14T15:17:11.291Z","comments":true,"path":"2020/08/20/Nacos(4)集群的数据一致性/","link":"","permalink":"https://zzkenyon.github.io/2020/08/20/Nacos(4)集群的数据一致性/","excerpt":"","text":"两种一致性策略如何在nacos中共存 或许会有疑问，为什么早先的cp模式的Zookeeper或者AP模式的Eureka，都只有支持CAP理论下大家常用的AP实现或者CP实现，而nacos却能够两个都实现呢？ 其实CAP理论，仅仅是针对分布式下数据的一致性而言，如果你对于数据的一致性要求不高，可忍受最终一致性，那么AP模式的Eureka就可以满足你了，如果说你对数据的一致性要求很高，那么就使用CP模式的Zookeeper，而追其根本，并不是说Eureka是AP的，或者说Zookeeper是CP的，而是他们存储的数据的一致性，满足AP或者CP，因此也就不难实现在一个组件中实现AP模式与CP模式共存 DelegateConsistencyServiceImpl是一个一致性策略选择的类，根据不同的策略触发条件(在nacos中，CP与AP切换的条件是注册的服务实例是否是临时实例)，选择PersistentConsistencyService策略或者EphemeralConsistencyService策略，而EphemeralConsistencyService对应的是DistroConsistencyServiceImpl，采用的协议是阿里自研的Distro，我个人觉得就像gossip协议；PersistentConsistencyService对应的是RaftConsistencyServiceImpl，其底层采用的是Raft协议；这两种一致性策略下的数据存储互不影响，所以nacos实现了AP模式与CP模式在一个组件中同时存在 分析流程之前，插上网图一张，此图逻辑清晰，有助于理解 1. AP实现1.1 Eureka的一致性策略Eureka是一个AP模式的服务发现框架，在Eureka集群模式下，Eureka采取的是Server之间互相广播各自的数据进行数据复制、更新操作；并且Eureka在客户端与注册中心出现网络故障时，依然能够获取服务注册信息——Eureka实现了客户端对于服务注册信息的缓存 正因为Eureka为了能够在Eureka集群无法工作时不影响消费者调用服务提供者而设置的客户端缓存，因此Eureka无法保证服务注册信息的强一致性（CP模式），只能满足数据的最终一致性（AP模式） 1.2 Nacos-AP的一致性策略DistroNacos在AP模式下的一致性策略就类似于Eureka，采用Server之间互相的数据同步来实现数据在集群中的同步、复制操作。 1.2.1 触发数据广播12345678//DistroConsistencyServiceImpl.java@Overridepublic void put(String key, Record value) throws NacosException &#123; onPut(key, value); // 写入本地DistroStore，并通知ServiceManager //同步给其他兄弟 distroProtocol.sync(new DistroKey(key, KeyBuilder.INSTANCE_LIST_KEY_PREFIX), DataOperation.CHANGE,globalConfig.getTaskDispatchPeriod() / 2);&#125; 当调用ConsistencyService接口定义的put、remove方法时，涉及到了Server端数据的变更，此时会创建一个任务，将数据的key传入taskDispatcher.addTask方法中，用于后面数据变更时数据查找操作 12345//TaskDispatcher.javapublic void addTask(String key) &#123; taskSchedulerList.get(UtilsAndCommons.shakeUp(key, cpuCoreCount)).addTask(key);&#125; 这里有一个方法需要注意——shakeUp，查看官方代码注解可知这是将key（key可以看作是一次数据变更事件）这里应该是将任务均匀的路由到不同的TaskScheduler对象，确保每个TaskScheduler所承担的任务都差不多。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class TaskScheduler implements Runnable &#123; private int dataSize = 0; private long lastDispatchTime = 0L; private BlockingQueue&lt;String&gt; queue = new LinkedBlockingQueue&lt;&gt;(128 * 1024); ... public void addTask(String key) &#123; queue.offer(key); &#125; @Override public void run() &#123; List&lt;String&gt; keys = new ArrayList&lt;&gt;(); while (true) &#123; try &#123; String key = queue.poll(partitionConfig.getTaskDispatchPeriod(),TimeUnit.MILLISECONDS); if (Loggers.EPHEMERAL.isDebugEnabled() &amp;&amp; StringUtils.isNotBlank(key)) &#123; Loggers.EPHEMERAL.debug(&quot;got key: &#123;&#125;&quot;, key); &#125; if (dataSyncer.getServers() == null || dataSyncer.getServers().isEmpty()) &#123; continue; &#125; if (StringUtils.isBlank(key)) &#123; continue; &#125; if (dataSize == 0) &#123; keys = new ArrayList&lt;&gt;(); &#125; keys.add(key); dataSize++; if (dataSize == partitionConfig.getBatchSyncKeyCount() || (System.currentTimeMillis() - lastDispatchTime) &gt; partitionConfig.getTaskDispatchPeriod()) &#123; for (Server member : dataSyncer.getServers()) &#123; // 自己不需要进行数据广播操作 if (NetUtils.localServer().equals(member.getKey())) &#123; continue; &#125; SyncTask syncTask = new SyncTask(); syncTask.setKeys(keys); syncTask.setTargetServer(member.getKey()); if (Loggers.EPHEMERAL.isDebugEnabled() &amp;&amp; StringUtils.isNotBlank(key)) &#123; Loggers.EPHEMERAL.debug(&quot;add sync task: &#123;&#125;&quot;, JSON.toJSONString(syncTask)); &#125; dataSyncer.submit(syncTask, 0); &#125; lastDispatchTime = System.currentTimeMillis(); dataSize = 0; &#125; &#125; catch (Exception e) &#123; Loggers.EPHEMERAL.error(&quot;dispatch sync task failed.&quot;, e); &#125; &#125; &#125;&#125; 核心方法就是for (Server member : dataSyncer.getServers()) {..}循环体内的代码，此处就是将数据在Nacos Server中进行广播操作；具体步骤如下 123- 创建`SyncTask`，并设置事件集合（就是`key`集合）- 将目标`Server`信息设置到`SyncTask`中——`syncTask.setTargetServer(member.getKey())`- 将数据广播任务提交到`DataSyncer`中 执行数据广播——DataSyncer12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public void submit(SyncTask task, long delay) &#123; // If it&apos;s a new task: if (task.getRetryCount() == 0) &#123; Iterator&lt;String&gt; iterator = task.getKeys().iterator(); while (iterator.hasNext()) &#123; String key = iterator.next(); if (StringUtils.isNotBlank(taskMap.putIfAbsent(buildKey(key, task.getTargetServer()), key))) &#123; // associated key already exist: if (Loggers.EPHEMERAL.isDebugEnabled()) &#123; Loggers.EPHEMERAL.debug(&quot;sync already in process, key: &#123;&#125;&quot;, key); &#125; iterator.remove(); &#125; &#125; &#125; if (task.getKeys().isEmpty()) &#123; // all keys are removed: return; &#125; GlobalExecutor.submitDataSync(new Runnable() &#123; @Override public void run() &#123; try &#123; if (servers == null || servers.isEmpty()) &#123; Loggers.SRV_LOG.warn(&quot;try to sync data but server list is empty.&quot;); return; &#125; List&lt;String&gt; keys = task.getKeys(); if (Loggers.EPHEMERAL.isDebugEnabled()) &#123; Loggers.EPHEMERAL.debug(&quot;sync keys: &#123;&#125;&quot;, keys); &#125; Map&lt;String, Datum&gt; datumMap = dataStore.batchGet(keys); if (datumMap == null || datumMap.isEmpty()) &#123; // clear all flags of this task: for (String key : task.getKeys()) &#123; taskMap.remove(buildKey(key, task.getTargetServer())); &#125; return; &#125; byte[] data = serializer.serialize(datumMap); long timestamp = System.currentTimeMillis(); boolean success = NamingProxy.syncData(data, task.getTargetServer()); if (!success) &#123; SyncTask syncTask = new SyncTask(); syncTask.setKeys(task.getKeys()); syncTask.setRetryCount(task.getRetryCount() + 1); syncTask.setLastExecuteTime(timestamp); syncTask.setTargetServer(task.getTargetServer()); retrySync(syncTask); &#125; else &#123; // clear all flags of this task: for (String key : task.getKeys()) &#123; taskMap.remove(buildKey(key, task.getTargetServer())); &#125; &#125; &#125; catch (Exception e) &#123; Loggers.EPHEMERAL.error(&quot;sync data failed.&quot;, e); &#125; &#125; &#125;, delay);&#125; GlobalExecutor.submitDataSync(Runnable runnable)提交一个数据广播任务；首先通过SyncTask中的key集合去DataStore中去查询key所对应的数据集合，然后对数据进行序列化操作，转为byte[]数组后，执行Http请求操作——NamingProxy.syncData(data, task.getTargetServer())；如果数据广播失败，则将任务重新打包再次压入GlobalExecutor中 （这里有一个疑问，SyncTask记录了任务重试的次数，但是却没有根据该次数做一些判断，比如超过多少次server未响应可能是server挂掉了，这里仅仅是记录了重试的次数） 123456789101112131415161718192021222324252627public static boolean syncData(byte[] data, String curServer) throws Exception &#123; try &#123; Map&lt;String, String&gt; headers = new HashMap&lt;&gt;(128); headers.put(&quot;Client-Version&quot;, UtilsAndCommons.SERVER_VERSION); headers.put(&quot;User-Agent&quot;, UtilsAndCommons.SERVER_VERSION); headers.put(&quot;Accept-Encoding&quot;, &quot;gzip,deflate,sdch&quot;); headers.put(&quot;Connection&quot;, &quot;Keep-Alive&quot;); headers.put(&quot;Content-Encoding&quot;, &quot;gzip&quot;); HttpClient.HttpResult result = HttpClient.httpPutLarge(&quot;http://&quot; + curServer + RunningConfig.getContextPath() + UtilsAndCommons.NACOS_NAMING_CONTEXT + DATA_ON_SYNC_URL, headers, data); if (HttpURLConnection.HTTP_OK == result.code) &#123; return true; &#125; if (HttpURLConnection.HTTP_NOT_MODIFIED == result.code) &#123; return true; &#125; throw new IOException(&quot;failed to req API:&quot; + &quot;http://&quot; + curServer + RunningConfig.getContextPath() + UtilsAndCommons.NACOS_NAMING_CONTEXT + DATA_ON_SYNC_URL + &quot;. code:&quot; + result.code + &quot; msg: &quot; + result.content); &#125; catch (Exception e) &#123; Loggers.SRV_LOG.warn(&quot;NamingProxy&quot;, e); &#125; return false;&#125; 这里将数据提交到了URL为PUT http://ip:port/nacos/v1/ns//distro/datum中，而该URL对应的处理器为DistroController中的public String onSyncDatum(HttpServletRequest request, HttpServletResponse response)方法 12345678910111213141516171819202122public String onSyncDatum(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; String entity = IOUtils.toString(request.getInputStream(), &quot;UTF-8&quot;); if (StringUtils.isBlank(entity)) &#123; Loggers.EPHEMERAL.error(&quot;[onSync] receive empty entity!&quot;); throw new NacosException(NacosException.INVALID_PARAM, &quot;receive empty entity!&quot;); &#125; Map&lt;String, Datum&lt;Instances&gt;&gt; dataMap = serializer.deserializeMap(entity.getBytes(), Instances.class); for (Map.Entry&lt;String, Datum&lt;Instances&gt;&gt; entry : dataMap.entrySet()) &#123; if (KeyBuilder.matchEphemeralInstanceListKey(entry.getKey())) &#123; String namespaceId = KeyBuilder.getNamespace(entry.getKey()); String serviceName = KeyBuilder.getServiceName(entry.getKey()); if (!serviceManager.containService(namespaceId, serviceName) &amp;&amp; switchDomain.isDefaultInstanceEphemeral()) &#123; serviceManager.createEmptyService(namespaceId, serviceName, true); &#125; consistencyService.onPut(entry.getKey(), entry.getValue().value); &#125; &#125; return &quot;ok&quot;;&#125; 这里会调用consistencyService.onPut(entry.getKey(), entry.getValue().value)方法进行数据的更新，注意，onPut方法并不会涉及taskDispatcher.addTask(key);操作，而是将数据更新压入了Notifier的Task列表中（Notifier的作用看Nacos Server端注册一个服务实例流程）；至此完成了Nacos Server在AP模式下的数据的最终一致性操作。 1. 集群选举Nacos支持集群模式，很显然。 而一旦涉及到集群，就涉及到主从，那么nacos是一种什么样的机制来实现的集群呢? nacos的集群类似于zookeeper， 它分为leader角色和follower角色， 那么从这个角色的名字可以看出 来，这个集群存在选举的机制。 因为如果自己不具备选举功能，角色的命名可能就是master/slave了， 当然这只是我基于这么多组件的命名的一个猜测 1.1 选举算法Nacos集群采用raft算法来实现，它是相对zookeeper的选举算法较为简单的一种。 选举算法的核心在RaftCore 中，包括数据的处理和数据同步 raft算法演示地址 在Raft中，节点有三种角色: Leader:负责接收客户端的请求 Candidate:用于选举Leader的一种角色 Follower:负责响应来自Leader或者Candidate的请求 选举分为两个节点 服务启动的时候 leader挂了的时候 所有节点启动的时候，都是follower状态。 如果在一段时间内如果没有收到leader的心跳(可能是没有 leader，也可能是leader挂了)，那么follower会变成Candidate。然后发起选举，选举之前，会增加 term，这个term和zookeeper中的epoch的道理是一样的。 follower会投自己一票，并且给其他节点发送票据vote，等到其他节点回复 在这个过程中，可能出现几种情况 收到过半的票数通过，则成为leader 被告知其他节点已经成为leader，则自己切换为follower 一段时间内没有收到过半的投票，则重新发起选举 约束条件：在任一term中，单个节点最多只能投一票 选举的几种情况 第一种情况，赢得选举之后，leader会给所有节点发送消息，避免其他节点触发新的选举 第二种情况，比如有三个节点A B C。A B同时发起选举，而A的选举消息先到达C，C给A投了一票，当B的消息到达C时，已经不能满足上面提到的第一个约束，即C不会给B投票，而A和B显然都不会给对方投票。A胜出之后，会给B,C发心跳消息，节点B发现节点A的term不低于自己的term， 知道有已经有Leader了，于是转换成follower 第三种情况， 没有任何节点获得majority投票，可能是平票的情况。加入总共有四个节点 (A/B/C/D)，Node C、Node D同时成为了candidate，但Node A投了NodeD一票，NodeB投 了Node C一票，这就出现了平票 split vote的情况。这个时候大家都在等啊等，直到超时后重新发 起选举。如果出现平票的情况，那么就延长了系统不可用的时间,因此raft引入了randomized election timeouts来尽量避免平票情况 nacos是如何实现CP(raft)的 RaftController RaftController控制器是raft集群内部节点间通信使用的，具体的信息如下 1234567891011121314151617181920212223POST HTTP://&#123;ip:port&#125;/v1/ns/raft/vote : 进行投票请求POST HTTP://&#123;ip:port&#125;/v1/ns/raft/beat : Leader向Follower发送心跳信息GET HTTP://&#123;ip:port&#125;/v1/ns/raft/peer : 获取该节点的RaftPeer信息PUT HTTP://&#123;ip:port&#125;/v1/ns/raft/datum/reload : 重新加载某日志信息POST HTTP://&#123;ip:port&#125;/v1/ns/raft/datum : Leader接收传来的数据并存入DELETE HTTP://&#123;ip:port&#125;/v1/ns/raft/datum : Leader接收传来的数据删除操作GET HTTP://&#123;ip:port&#125;/v1/ns/raft/datum : 获取该节点存储的数据信息GET HTTP://&#123;ip:port&#125;/v1/ns/raft/state : 获取该节点的状态信息&#123;UP or DOWN&#125;POST HTTP://&#123;ip:port&#125;/v1/ns/raft/datum/commit : Follower节点接收Leader传来得到数据存入操作DELETE HTTP://&#123;ip:port&#125;/v1/ns/raft/datum : Follower节点接收Leader传来的数据删除操作GET HTTP://&#123;ip:port&#125;/v1/ns/raft/leader : 获取当前集群的Leader节点信息GET HTTP://&#123;ip:port&#125;/v1/ns/raft/listeners : 获取当前Raft集群的所有事件监听者 RaftPeerSet 这个对象存储的是所有raft协议下的节点信息，存储的元素如下 1234567891011121314151617// 集群节点地址管理private ServerListManager serverListManager;// 周期数private AtomicLong localTerm = new AtomicLong(0L);// 当前周期内的Leaderprivate RaftPeer leader = null;// 所有的节点信息private Map&lt;String, RaftPeer&gt; peers = new HashMap&lt;String, RaftPeer&gt;();// 暂时不清楚用途private Set&lt;String&gt; sites = new HashSet&lt;&gt;();// 本节点是否已准备完毕private boolean ready = false; 同时还具备了raft协议下必要的方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879// 当前IP对应的节点是否是Leaderpublic boolean isLeader(String ip) &#123; if (STANDALONE_MODE) &#123; return true; &#125; if (leader == null) &#123; Loggers.RAFT.warn(&quot;[IS LEADER] no leader is available now!&quot;); return false; &#125; return StringUtils.equals(leader.ip, ip);&#125;// 决定Leader节点，根据投票结果以及是否满足majorityCount机制public RaftPeer decideLeader(RaftPeer candidate) &#123; peers.put(candidate.ip, candidate); SortedBag ips = new TreeBag(); int maxApproveCount = 0; String maxApprovePeer = null; for (RaftPeer peer : peers.values()) &#123; if (StringUtils.isEmpty(peer.voteFor)) &#123; continue; &#125; // 选票计数 ips.add(peer.voteFor); // 如果某节点的得票数大于当前的最大得票数，则更新候选Leader信息 if (ips.getCount(peer.voteFor) &gt; maxApproveCount) &#123; maxApproveCount = ips.getCount(peer.voteFor); maxApprovePeer = peer.voteFor; &#125; &#125; // 是否满足majorityCount数量的限制 if (maxApproveCount &gt;= majorityCount()) &#123; // 若满足则设置Leader节点信息 RaftPeer peer = peers.get(maxApprovePeer); peer.state = RaftPeer.State.LEADER; if (!Objects.equals(leader, peer)) &#123; leader = peer; Loggers.RAFT.info(&quot;&#123;&#125; has become the LEADER&quot;, leader.ip); &#125; &#125; return leader;&#125;public RaftPeer makeLeader(RaftPeer candidate) &#123; // 如果当前Leader与Candidate节点不一样，则进行Leader信息更改 if (!Objects.equals(leader, candidate)) &#123; leader = candidate; Loggers.RAFT.info(&quot;&#123;&#125; has become the LEADER, local: &#123;&#125;, leader: &#123;&#125;&quot;, leader.ip, JSON.toJSONString(local()), JSON.toJSONString(leader)); &#125; for (final RaftPeer peer : peers.values()) &#123; Map&lt;String, String&gt; params = new HashMap&lt;String, String&gt;(1); // 如果当前节点与远程Leader节点不等且是Follower节点 if (!Objects.equals(peer, candidate) &amp;&amp; peer.state == RaftPeer.State.LEADER) &#123; try &#123; // 获取每个节点的RaftPeer节点信息对象数据 String url = RaftCore.buildURL(peer.ip, RaftCore.API_GET_PEER); HttpClient.asyncHttpGet(url, null, params, new AsyncCompletionHandler&lt;Integer&gt;() &#123; @Override public Integer onCompleted(Response response) throws Exception &#123; if (response.getStatusCode() != HttpURLConnection.HTTP_OK) &#123; Loggers.RAFT.error(&quot;[NACOS-RAFT] get peer failed: &#123;&#125;, peer: &#123;&#125;&quot;, response.getResponseBody(), peer.ip); peer.state = RaftPeer.State.FOLLOWER; return 1; &#125; update(JSON.parseObject(response.getResponseBody(), RaftPeer.class)); return 0; &#125; &#125;); &#125; catch (Exception e) &#123; peer.state = RaftPeer.State.FOLLOWER; Loggers.RAFT.error(&quot;[NACOS-RAFT] error while getting peer from peer: &#123;&#125;&quot;, peer.ip); &#125; &#125; &#125; return update(candidate);&#125; RaftCore 该对象是nacos中raft协议的主要实现，在启动之初，会进行一系列初始化的操作 12345678910111213141516171819202122232425262728@PostConstructpublic void init() throws Exception &#123; Loggers.RAFT.info(&quot;initializing Raft sub-system&quot;); executor.submit(notifier); long start = System.currentTimeMillis(); // 进行日志文件的加载到内存数据对象Datums的操作 datums = raftStore.loadDatums(notifier); // 设置当前的周期数 setTerm(NumberUtils.toLong(raftStore.loadMeta().getProperty(&quot;term&quot;), 0L)); Loggers.RAFT.info(&quot;cache loaded, datum count: &#123;&#125;, current term: &#123;&#125;&quot;, datums.size(), peers.getTerm()); while (true) &#123; // 等待上一步的数据加载任务全部完成 if (notifier.tasks.size() &lt;= 0) &#123; break; &#125; Thread.sleep(1000L); &#125; // 初始化标识更改 initialized = true; Loggers.RAFT.info(&quot;finish to load data from disk, cost: &#123;&#125; ms.&quot;, (System.currentTimeMillis() - start)); // 开启定时的Leader选举任务 GlobalExecutor.registerMasterElection(new MasterElection()); // 开启定时的Leader心跳服务 GlobalExecutor.registerHeartbeat(new HeartBeat()); Loggers.RAFT.info(&quot;timer started: leader timeout ms: &#123;&#125;, heart-beat timeout ms: &#123;&#125;&quot;, GlobalExecutor.LEADER_TIMEOUT_MS, GlobalExecutor.HEARTBEAT_INTERVAL_MS);&#125; 初始化的一系列操作完成后，此时集群还无法对外提供服务，因为此时Leader还未选举出来，需要在MasterElection选举Leader成功后才可以对外提供服务 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// Leader 选举任务public class MasterElection implements Runnable &#123; @Override public void run() &#123; try &#123; // 当前节点是否已准备完毕 if (!peers.isReady()) &#123; return; &#125; // 获取自身节点信息 RaftPeer local = peers.local(); // 本地存储的Leader任期时间 local.leaderDueMs -= GlobalExecutor.TICK_PERIOD_MS; // 如果Leader任期时间还在允许范围内，则不进行Leader选举 if (local.leaderDueMs &gt; 0) &#123; return; &#125; // reset timeout local.resetLeaderDue(); local.resetHeartbeatDue(); // 向其他节点发起投票请求 sendVote(); &#125; catch (Exception e) &#123; Loggers.RAFT.warn(&quot;[RAFT] error while master election &#123;&#125;&quot;, e); &#125; &#125; public void sendVote() &#123; RaftPeer local = peers.get(NetUtils.localServer()); Loggers.RAFT.info(&quot;leader timeout, start voting,leader: &#123;&#125;, term: &#123;&#125;&quot;, JSON.toJSONString(getLeader()), local.term); // Raft node cluster rest peers.reset(); local.term.incrementAndGet(); // 设置给自己投票 local.voteFor = local.ip; // update node status to CANDIDATE local.state = RaftPeer.State.CANDIDATE; Map&lt;String, String&gt; params = new HashMap&lt;String, String&gt;(1); params.put(&quot;vote&quot;, JSON.toJSONString(local)); // 遍历所有的节点信息(除了自己之外) for (final String server : peers.allServersWithoutMySelf()) &#123; final String url = buildURL(server, API_VOTE); try &#123; HttpClient.asyncHttpPost(url, null, params, new AsyncCompletionHandler&lt;Integer&gt;() &#123; @Override public Integer onCompleted(Response response) throws Exception &#123; if (response.getStatusCode() != HttpURLConnection.HTTP_OK) &#123; Loggers.RAFT.error(&quot;NACOS-RAFT vote failed: &#123;&#125;, url: &#123;&#125;&quot;, response.getResponseBody(), url); return 1; &#125; // 获取投票结果，并进行Leader的选举工作 RaftPeer peer = JSON.parseObject(response.getResponseBody(), RaftPeer.class); Loggers.RAFT.info(&quot;received approve from peer: &#123;&#125;&quot;, JSON.toJSONString(peer)); peers.decideLeader(peer); return 0; &#125; &#125;); &#125; catch (Exception e) &#123; Loggers.RAFT.warn(&quot;error while sending vote to server: &#123;&#125;&quot;, server); &#125; &#125; &#125;&#125; 每个节点启动时，都会认为自己可以作为Leader，因此都会以自去己作为被选举人，向其他节点发起投票请求，而其他节点在接收到投票请求后的工作流程如下 1234567891011121314151617181920212223242526// 其他节点接收到投票请求后的反应public RaftPeer receivedVote(RaftPeer remote) &#123; // 被选举人是否在raft集群节点列表中 if (!peers.contains(remote)) &#123; throw new IllegalStateException(&quot;can not find peer: &quot; + remote.ip); &#125; // 获取自身节点信息 RaftPeer local = peers.get(NetUtils.localServer()); // 如果被选举节点的周期数小于本节点的周期数，则将自己的投票投给自己并告诉被选举者 if (remote.term.get() &lt;= local.term.get()) &#123; String msg = &quot;received illegitimate vote&quot; + &quot;, voter-term:&quot; + remote.term + &quot;, votee-term:&quot; + local.term; Loggers.RAFT.info(msg); if (StringUtils.isEmpty(local.voteFor)) &#123; local.voteFor = local.ip; &#125; return local; &#125; // 满足投票条件后，本节点确认将自己的票投给被选举者 local.resetLeaderDue(); local.state = RaftPeer.State.FOLLOWER; local.voteFor = remote.ip; local.term.set(remote.term.get()); Loggers.RAFT.info(&quot;vote &#123;&#125; as leader, term: &#123;&#125;&quot;, remote.ip, remote.term); return local;&#125; 通过以上步骤，最终选举出了Leader节点，接下来，就可以对外提供服务了 因为是CP模式，所以操作都是通过Leader节点进行传达的，Follower节点本身不与Client进行联系，Follower只能接受来自Leader的操作请求，因此就存在请求转发的问题。因此在RaftCore中的singlePublish以及singleDelete中，存在着对Leader节点的判断以及请求转发的逻辑 123456789101112131415161718192021222324252627public void signalPublish(String key, Record value) throws Exception &#123; if (!isLeader()) &#123; JSONObject params = new JSONObject(); params.put(&quot;key&quot;, key); params.put(&quot;value&quot;, value); Map&lt;String, String&gt; parameters = new HashMap&lt;&gt;(1); parameters.put(&quot;key&quot;, key); // 请求转发 raftProxy.proxyPostLarge(getLeader().ip, API_PUB, params.toJSONString(), parameters); return; &#125; ...&#125;public void signalDelete(final String key) throws Exception &#123; OPERATE_LOCK.lock(); try &#123; if (!isLeader()) &#123; Map&lt;String, String&gt; params = new HashMap&lt;&gt;(1); params.put(&quot;key&quot;, URLEncoder.encode(key, &quot;UTF-8&quot;)); // 删除请求进行转发给 leader 进行处理 raftProxy.proxy(getLeader().ip, API_DEL, params, HttpMethod.DELETE); return; &#125; ... &#125;&#125; 同时，还有一个重要的机制——心跳机制，raft通过心跳机制来维持Leader以及Follower的关系 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101// 心跳任务，如果成为Leader，需要对 follower 发送心跳信息public class HeartBeat implements Runnable &#123; @Override public void run() &#123; try &#123; // 程序是否已准备完毕 if (!peers.isReady()) &#123; return; &#125; RaftPeer local = peers.local(); local.heartbeatDueMs -= GlobalExecutor.TICK_PERIOD_MS; // 心跳周期判断 if (local.heartbeatDueMs &gt; 0) &#123; return; &#125; // 重置心跳发送周期 local.resetHeartbeatDue(); // 发送心跳信息 sendBeat(); &#125; catch (Exception e) &#123; Loggers.RAFT.warn(&quot;[RAFT] error while sending beat &#123;&#125;&quot;, e); &#125; &#125; public void sendBeat() throws IOException, InterruptedException &#123; RaftPeer local = peers.local(); // 如果自己不是Leader节点或者处于单机模式下，则直接返回 if (local.state != RaftPeer.State.LEADER &amp;&amp; !STANDALONE_MODE) &#123; return; &#125; Loggers.RAFT.info(&quot;[RAFT] send beat with &#123;&#125; keys.&quot;, datums.size()); // 重置Leader任期时间 local.resetLeaderDue(); // build data JSONObject packet = new JSONObject(); packet.put(&quot;peer&quot;, local); JSONArray array = new JSONArray(); if (switchDomain.isSendBeatOnly()) &#123; Loggers.RAFT.info(&quot;[SEND-BEAT-ONLY] &#123;&#125;&quot;, String.valueOf(switchDomain.isSendBeatOnly())); &#125; if (!switchDomain.isSendBeatOnly()) &#123; // 如果开启了在心跳包中携带Leader存储的数据进行发送，则对数据进行打包操作 for (Datum datum : datums.values()) &#123; JSONObject element = new JSONObject(); if (KeyBuilder.matchServiceMetaKey(datum.key)) &#123; element.put(&quot;key&quot;, KeyBuilder.briefServiceMetaKey(datum.key)); &#125; else if (KeyBuilder.matchInstanceListKey(datum.key)) &#123; element.put(&quot;key&quot;, KeyBuilder.briefInstanceListkey(datum.key)); &#125; element.put(&quot;timestamp&quot;, datum.timestamp); array.add(element); &#125; &#125; else &#123; Loggers.RAFT.info(&quot;[RAFT] send beat only.&quot;); &#125; packet.put(&quot;datums&quot;, array); // broadcast Map&lt;String, String&gt; params = new HashMap&lt;String, String&gt;(1); params.put(&quot;beat&quot;, JSON.toJSONString(packet)); // 将参数信息进行 Gzip算法压缩，降低网络消耗 String content = JSON.toJSONString(params); ByteArrayOutputStream out = new ByteArrayOutputStream(); GZIPOutputStream gzip = new GZIPOutputStream(out); gzip.write(content.getBytes(&quot;UTF-8&quot;)); gzip.close(); byte[] compressedBytes = out.toByteArray(); String compressedContent = new String(compressedBytes, &quot;UTF-8&quot;); Loggers.RAFT.info(&quot;raw beat data size: &#123;&#125;, size of compressed data: &#123;&#125;&quot;, content.length(), compressedContent.length()); // 遍历所有的Follower节点进行发送心跳数据包 for (final String server : peers.allServersWithoutMySelf()) &#123; try &#123; final String url = buildURL(server, API_BEAT); Loggers.RAFT.info(&quot;send beat to server &quot; + server); // 采用异步HTTP请求进行心跳数据发送 HttpClient.asyncHttpPostLarge(url, null, compressedBytes, new AsyncCompletionHandler&lt;Integer&gt;() &#123; @Override public Integer onCompleted(Response response) throws Exception &#123; if (response.getStatusCode() != HttpURLConnection.HTTP_OK) &#123; Loggers.RAFT.error(&quot;NACOS-RAFT beat failed: &#123;&#125;, peer: &#123;&#125;&quot;, response.getResponseBody(), server); MetricsMonitor.getLeaderSendBeatFailedException().increment(); &#125; // 成功后接收Follower节点的心跳回复(Follower节点的当前信息)进行节点更新操作 peers.update(JSON.parseObject(response.getResponseBody(), RaftPeer.class)); Loggers.RAFT.info(&quot;receive beat response from: &#123;&#125;&quot;, url); return 0; &#125; @Override public void onThrowable(Throwable t) &#123; Loggers.RAFT.error(&quot;NACOS-RAFT error while sending heart-beat to peer: &#123;&#125; &#123;&#125;&quot;, server, t); MetricsMonitor.getLeaderSendBeatFailedException().increment(); &#125; &#125;); &#125; catch (Exception e) &#123; Loggers.RAFT.error(&quot;error while sending heart-beat to peer: &#123;&#125; &#123;&#125;&quot;, server, e); MetricsMonitor.getLeaderSendBeatFailedException().increment(); &#125; &#125; &#125;&#125; 至于心跳接收的回复操作基本就是Follower节点将自己当前的信息进行数据打包发送给Leader节点，同时也会重置当前Leader的任期时间信息，并且根据接收到心跳信息，进行拉取Leader节点的最新数据信息 为什么要同时实现CP和AP两套一致性策略模式？或许有的人会问，为什么Nacos要同时实现CP以及AP两种数据的一致性策略。其实在一个组件中同时实现两种数据一致性策略，我觉得这样在做服务注册中心选型时，就不必操心AP选什么组件，CP选什么组件，直接采用nacos就好了，同时满足你AP以及CP的数据一致性需求；直接在一个组件中，享受Zookeeper以及Eureka组件的服务，避免了需要同时维护两种不同的组件的运维代价，只需要根据自己的实例需求，选择不同的注册模式即可。 1.2 源码分析1.2.1 RaftCore初始化Raft选举算法，是在RaftCore这个类中实现的。 1234567891011121314151617181920212223242526272829303132333435@PostConstructpublic void init() throws Exception &#123; Loggers.RAFT.info(\"initializing Raft sub-system\"); final long start = System.currentTimeMillis(); //遍历/nacos/data/naming/data/文件,也就是从磁盘中加载Datum到内存，用来做数据恢复。 //数据同步采用2pc协议，leader收到请求会写写入到磁盘日志，然后再进行数据同步 raftStore.loadDatums(notifier, datums); //从/nacos_home/data/naming/meta.properties文件中读取term,term表示当前的时钟周期。 setTerm(NumberUtils.toLong(raftStore.loadMeta().getProperty(\"term\"), 0L)); Loggers.RAFT.info(\"cache loaded, datum count: &#123;&#125;, current term: &#123;&#125;\", datums.size(), peers.getTerm()); initialized = true; Loggers.RAFT.info(\"finish to load data from disk, cost: &#123;&#125; ms.\", (System.currentTimeMillis() - start)); masterTask = GlobalExecutor.registerMasterElection(new MasterElection()); heartbeatTask = GlobalExecutor.registerHeartbeat(new HeartBeat()); versionJudgement.registerObserver(isAllNewVersion -&gt; &#123; stopWork = isAllNewVersion; if (stopWork) &#123; try &#123; shutdown(); &#125; catch (NacosException e) &#123; throw new NacosRuntimeException(NacosException.SERVER_ERROR, e); &#125; &#125; &#125;, 100); NotifyCenter.registerSubscriber(notifier); Loggers.RAFT.info(\"timer started: leader timeout ms: &#123;&#125;, heart-beat timeout ms: &#123;&#125;\", GlobalExecutor.LEADER_TIMEOUT_MS, GlobalExecutor.HEARTBEAT_INTERVAL_MS);&#125;","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/tags/SpringCloud/"}],"keywords":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}]},{"title":"Nacos(二)注册中心核心源码分析","slug":"Nacos(2)注册中心核心源码分析","date":"2020-08-16T16:00:00.000Z","updated":"2021-01-13T02:39:29.296Z","comments":true,"path":"2020/08/17/Nacos(2)注册中心核心源码分析/","link":"","permalink":"https://zzkenyon.github.io/2020/08/17/Nacos(2)注册中心核心源码分析/","excerpt":"","text":"注册中心需要的核心功能： 服务提供者将服务信息发布到注册中心，此处涉及到服务信息的数据结构设计及存储 服务消费者能够从注册中心获取所需服务的实例信息 注册中心需要感知服务的健康状况，心跳机制 服务消费者需要动态更新依赖的服务列表信息 nacos服务信息数据结构设计与存储 1234/** * Map(namespace, Map(group::serviceName, Service)). */private final Map&lt;String, Map&lt;String, Service&gt;&gt; serviceMap = new ConcurrentHashMap&lt;&gt;(); 一个服务Service中，可以包含多个集群 1234/** * map(clustrtName,Cluster) */private Map&lt;String, Cluster&gt; clusterMap = new HashMap&lt;&gt;(); 一个集群Cluster中，可以包含多个实例 12345@JsonIgnore // 持久化节点private Set&lt;Instance&gt; persistentInstances = new HashSet&lt;&gt;();@JsonIgnore //临时节点private Set&lt;Instance&gt; ephemeralInstances = new HashSet&lt;&gt;(); 一个实例Instance 中存储了该实例的所有信息。 1. 服务提供者注册服务1.1 时机 启动时注册，springboot启动时，会执行dubbo服务发布以及注册流程 启动后注册，此时使用的是事件监听机制，在 DubboServiceRegistrationNonWebApplicationAutoConfiguration 这个类中，会监听ApplicationStartedEvent 事件，这个事件是spring boot在2.0新增的，就是当spring boot应用启动完成之后会发布这个事件。而此时监听到这个事件之后，会触发注册的动作。 1234567891011121314//DubboServiceRegistrationNonWebApplicationAutoConfiguration @EventListener(ApplicationStartedEvent.class)public void onApplicationStarted() &#123; setServerPort(); register();&#125;private void register() &#123; if (registered) &#123; return; &#125; serviceRegistry.register(registration); registered = true;&#125; 1.2 流程NacosServiceRegistry.register 1234567891011121314151617181920212223//NacosServiceRegistry@Overridepublic void register(Registration registration) &#123; if (StringUtils.isEmpty(registration.getServiceId())) &#123; log.warn(\"No service to register for nacos client...\"); return; &#125; String serviceId = registration.getServiceId(); //对应当前应用的application.name String group = nacosDiscoveryProperties.getGroup();//表示nacos上的分组配置 Instance instance = getNacosInstanceFromRegistration(registration);//表示服务实例信息 try &#123; namingService.registerInstance(serviceId, group, instance); log.info(\"nacos registry, &#123;&#125; &#123;&#125; &#123;&#125;:&#123;&#125; register finished\", group, serviceId, instance.getIp(), instance.getPort()); &#125; catch (Exception e) &#123; log.error(\"nacos registry, &#123;&#125; register failed...&#123;&#125;,\", serviceId, registration.toString(), e); // rethrow a RuntimeException if the registration is failed. // issue : https://github.com/alibaba/spring-cloud-alibaba/issues/1132 rethrowRuntimeException(e); &#125;&#125; NamingService.registerInstance 123456789101112131415161718@Overridepublic void registerInstance(String serviceName, String groupName, Instance instance) throws NacosException &#123; if (instance.isEphemeral()) &#123; // 若是临时节点，需要构建心跳信息 BeatInfo beatInfo = new BeatInfo(); beatInfo.setServiceName(NamingUtils.getGroupedName(serviceName, groupName)); beatInfo.setIp(instance.getIp()); beatInfo.setPort(instance.getPort()); beatInfo.setCluster(instance.getClusterName()); beatInfo.setWeight(instance.getWeight()); beatInfo.setMetadata(instance.getMetadata()); beatInfo.setScheduled(false); beatInfo.setPeriod(instance.getInstanceHeartBeatInterval()); // 添加心跳信息进行处理 beatReactor.addBeatInfo(NamingUtils.getGroupedName(serviceName, groupName), beatInfo); &#125; serverProxy.registerService(NamingUtils.getGroupedName(serviceName, groupName), groupName, instance);&#125; 心跳是nacos客户端发送给nacos服务器的 serverProxy是一个NamingProxy类实例，封装了调用nacos server的api BeatReactor 心跳发送反应堆。 NamingProxy.registerService 12345678910111213141516public void registerService(String serviceName, String groupName, Instance instance) throws NacosException &#123; final Map&lt;String, String&gt; params = new HashMap&lt;String, String&gt;(9); params.put(CommonParams.NAMESPACE_ID, namespaceId); params.put(CommonParams.SERVICE_NAME, serviceName); params.put(CommonParams.GROUP_NAME, groupName); params.put(CommonParams.CLUSTER_NAME, instance.getClusterName()); params.put(\"ip\", instance.getIp()); params.put(\"port\", String.valueOf(instance.getPort())); params.put(\"weight\", String.valueOf(instance.getWeight())); params.put(\"enable\", String.valueOf(instance.isEnabled())); params.put(\"healthy\", String.valueOf(instance.isHealthy())); params.put(\"ephemeral\", String.valueOf(instance.isEphemeral())); params.put(\"metadata\", JSON.toJSONString(instance.getMetadata())); // UtilAndComs.NACOS_URL_SERVICE = /nacos/v1/ns/instance reqAPI(UtilAndComs.NACOS_URL_INSTANCE, params, HttpMethod.POST);&#125; 注册时请求的open api 是/nacos/v1/ns/instance 构建的请求参数有： reqAPI reqAPI构建POST请求，发送给nacos-server api: nacos server open api params: 请求参数 body: method: 请求方法类型 servers: nacos server地址 123456789101112131415161718192021222324252627282930313233343536373839404142434445// NamingProxypublic String reqAPI(String api, Map&lt;String, String&gt; params, String body, List&lt;String&gt; servers, String method) throws NacosException &#123; params.put(CommonParams.NAMESPACE_ID, getNamespaceId()); if (CollectionUtils.isEmpty(servers) &amp;&amp; StringUtils.isEmpty(nacosDomain)) &#123; throw new NacosException(NacosException.INVALID_PARAM, \"no server available\"); &#125; NacosException exception = new NacosException(); // 如果nacos-server服务地址不为null，可能为列表 if (servers != null &amp;&amp; !servers.isEmpty()) &#123; Random random = new Random(System.currentTimeMillis()); int index = random.nextInt(servers.size());//随机获取一个nacos-server节点 for (int i = 0; i &lt; servers.size(); i++) &#123; // 确定了server还要用循环处理，为了防止选定的server不靠谱 String server = servers.get(index); try &#123; // 调用指定server的接口，一旦调用成功表示注册成功，返回 return callServer(api, params, body, server, method); &#125; catch (NacosException e) &#123; exception = e; if (NAMING_LOGGER.isDebugEnabled()) &#123; NAMING_LOGGER.debug(\"request &#123;&#125; failed.\", server, e); &#125; &#125; index = (index + 1) % servers.size(); //调用失败则轮询调用其他server &#125; &#125; if (StringUtils.isNotBlank(nacosDomain)) &#123; for (int i = 0; i &lt; UtilAndComs.REQUEST_DOMAIN_RETRY_COUNT; i++) &#123; try &#123; return callServer(api, params, body, nacosDomain, method); &#125; catch (NacosException e) &#123; exception = e; if (NAMING_LOGGER.isDebugEnabled()) &#123; NAMING_LOGGER.debug(\"request &#123;&#125; failed.\", nacosDomain, e); &#125; &#125; &#125; &#125; // 失败时 写日志。抛出异常 NAMING_LOGGER.error(\"request: &#123;&#125; failed, servers: &#123;&#125;, code: &#123;&#125;, msg: &#123;&#125;\", api, servers, exception.getErrCode(), exception.getErrMsg()); throw new NacosException(exception.getErrCode(), \"failed to req API:/api/\" + api + \" after all servers(\" + servers + \") tried: \" + exception.getMessage());&#125; callServer 该方法用于发起nacos-server的api调用 12345678910111213141516171819202122232425262728public String callServer(String api, Map&lt;String, String&gt; params, String body, String curServer, String method) throws NacosException &#123; long start = System.currentTimeMillis(); long end = 0; injectSecurityInfo(params); // 添加签名，防止恶意篡改或者网络丢包 List&lt;String&gt; headers = builderHeaders(); // 添加头信息 String url; // 拼接url if (curServer.startsWith(UtilAndComs.HTTPS) || curServer.startsWith(UtilAndComs.HTTP)) &#123; url = curServer + api; &#125; else &#123; if (!curServer.contains(UtilAndComs.SERVER_ADDR_IP_SPLITER)) &#123; curServer = curServer + UtilAndComs.SERVER_ADDR_IP_SPLITER + serverPort; &#125; url = HttpClient.getPrefix() + curServer + api; &#125; //使用HttpClient发起请求 HttpClient.HttpResult result = HttpClient.request(url, headers, params, body, UtilAndComs.ENCODING, method); end = System.currentTimeMillis(); MetricsMonitor.getNamingRequestMonitor(method, url, String.valueOf(result.code)) .observe(end - start); // 埋点监控 if (HttpURLConnection.HTTP_OK == result.code) &#123; // 成功 返回服务端结果 return result.content; &#125; if (HttpURLConnection.HTTP_NOT_MODIFIED == result.code) &#123; return StringUtils.EMPTY; &#125; throw new NacosException(result.code, result.content);&#125; 2. nacos 处理注册请求处理注册请求的controller在naming子模块中，InstanceController类中的register方法： 123456789101112@CanDistro@PostMapping@Secured(parser = NamingResourceParser.class, action = ActionTypes.WRITE)public String register(HttpServletRequest request) throws Exception &#123; final String namespaceId = WebUtils .optional(request, CommonParams.NAMESPACE_ID, Constants.DEFAULT_NAMESPACE_ID); final String serviceName = WebUtils.required(request, CommonParams.SERVICE_NAME); NamingUtils.checkServiceNameFormat(serviceName); final Instance instance = parseInstance(request); // 从请求中解析出Instance serviceManager.registerInstance(namespaceId, serviceName, instance); // 写内存 return \"ok\";&#125; ServiceManager.registerInstance serviceManager中有一map，就是文章开头介绍的用于存储服务实例信息的地方，这个map的名字是serviceMap 123456789101112public void registerInstance(String namespaceId, String serviceName, Instance instance) throws NacosException &#123; //serviceMap中如果没有该服务，则创建一个空的服务放进去 createEmptyService(namespaceId, serviceName, instance.isEphemeral()); //从serviceMap中，根据namespaceId和serviceName得到一个服务对象 Service service = getService(namespaceId, serviceName); if (service == null) &#123; throw new NacosException(NacosException.INVALID_PARAM, \"service not found, namespace: \" + namespaceId + \", service: \" + serviceName); &#125; addInstance(namespaceId, serviceName, instance.isEphemeral(), instance);&#125; createServiceIfAbsent 12345678910111213141516171819202122232425public void createServiceIfAbsent(String namespaceId, String serviceName, boolean local, Cluster cluster) throws NacosException &#123; //从serviceMap中获取namespaceId, serviceName指定的服务 Service service = getService(namespaceId, serviceName); if (service == null) &#123; // 没有的话就创建一个 Loggers.SRV_LOG.info(\"creating empty service &#123;&#125;:&#123;&#125;\", namespaceId, serviceName); service = new Service(); service.setName(serviceName); service.setNamespaceId(namespaceId); service.setGroupName(NamingUtils.getGroupName(serviceName)); // now validate the service. if failed, exception will be thrown service.setLastModifiedMillis(System.currentTimeMillis()); service.recalculateChecksum(); if (cluster != null) &#123; cluster.setService(service); service.getClusterMap().put(cluster.getName(), cluster); &#125; service.validate(); // &gt;&gt; putServiceAndInit(service); if (!local) &#123; addOrReplaceService(service); &#125; &#125;&#125; putServiceAndInit 12345678910private void putServiceAndInit(Service service) throws NacosException &#123; putService(service); // 把服务信息保存到serviceMap集合 service.init(); // 建立心跳检测机制 // 实现数据一致性监听，ephemeral=true表示采用raft协议，false表示采用Distro consistencyService .listen(KeyBuilder.buildInstanceListKey(service.getNamespaceId(), service.getName(), true), service); consistencyService .listen(KeyBuilder.buildInstanceListKey(service.getNamespaceId(), service.getName(), false), service); Loggers.SRV_LOG.info(\"[NEW-SERVICE] &#123;&#125;\", service.toJson());&#125; 这里比较感兴趣的点就是心跳检测，将在进阶篇与客户端的心跳发送一起分析 addInstance 12345678910111213public void addInstance(String namespaceId, String serviceName, boolean ephemeral, Instance... ips) throws NacosException &#123; String key = KeyBuilder.buildInstanceListKey(namespaceId, serviceName, ephemeral); Service service = getService(namespaceId, serviceName); synchronized (service) &#123; List&lt;Instance&gt; instanceList = addIpAddresses(service, ephemeral, ips); Instances instances = new Instances(); instances.setInstanceList(instanceList); // nacos数据一致性put consistencyService.put(key, instances); &#125;&#125; 如果nacos-server是集群部署的话，服务注册的实例信息要同步到所有的nacos-server上，所以这里使用consistencyService来完成一致性需求，这里将在进阶篇分析 3. 服务消费者拉取服务列表服务注册成功之后，消费者就可以从nacos-server中获取到服务提供者的地址，然后进行服务的调用。 在服务消费中，有一个核心的类 NacosDiscoveryClient 来负责和nacos交互，去获得服务提供者的地 址信息。之前在分析dubbo源码的时候已经分析过服务的订阅过程。 NacosDiscoveryClient 中提供了一个 getInstances 方法用来根据服务提供者名称获取服务提供者的 url地址的方法。 3.1 时机应用启动之时，会执行根据配置的依赖服务名称，进行远程服务代理创建并注入Ioc的流程。在创建代理对象时，会执行服务列表拉取的逻辑。详见《dubbo-服务消费过程分析》 3.2 流程12345678910111213141516@Overridepublic List&lt;ServiceInstance&gt; getInstances(String serviceId) &#123; try &#123; return serviceDiscovery.getInstances(serviceId); &#125; catch (Exception e) &#123; throw new RuntimeException( \"Can not get hosts from nacos server. serviceId: \" + serviceId, e); &#125;&#125;public List&lt;ServiceInstance&gt; getInstances(String serviceId) throws NacosException &#123; String group = discoveryProperties.getGroup(); List&lt;Instance&gt; instances = discoveryProperties.namingServiceInstance() .selectInstances(serviceId, group, true); return hostToServiceInstanceList(instances, serviceId); &#125; 调用NamingService，根据serviceId、group获得服务实例列表。 然后把instance转化为ServiceInstance对象 NacosNamingService.selectInstances 1234567891011@Overridepublic List&lt;Instance&gt; selectInstances(String serviceName, String groupName, List&lt;String&gt; clusters, boolean healthy, boolean subscribe) throws NacosException &#123; ServiceInfo serviceInfo; if (subscribe) &#123; serviceInfo = hostReactor.getServiceInfo(NamingUtils.getGroupedName(serviceName, groupName), StringUtils.join(clusters, \",\")); &#125; else &#123; serviceInfo = hostReactor.getServiceInfoDirectlyFromServer(NamingUtils.getGroupedName(serviceName, groupName), StringUtils.join(clusters, \",\")); &#125; return selectInstances(serviceInfo, healthy);&#125; selectInstances首先从hostReactor获取serviceInfo， 然后再从serviceInfo.getHosts()剔除非healty、 非enabled、weight小于等于0的instance再返回; 如果subscribe为true，则执行 hostReactor.getServiceInfo获取serviceInfo 否则执行 hostReactor.getServiceInfoDirectlyFromServer获取serviceInfo HostReactor.getServiceInfo 12345678910111213141516171819202122232425public ServiceInfo getServiceInfo(final String serviceName, final String clusters) &#123; NAMING_LOGGER.debug(\"failover-mode: \" + failoverReactor.isFailoverSwitch()); String key = ServiceInfo.getKey(serviceName, clusters); if (failoverReactor.isFailoverSwitch()) &#123; return failoverReactor.getService(key); &#125; //从本地缓存中取 ServiceInfo serviceObj = getServiceInfo0(serviceName, clusters); if (null == serviceObj) &#123;// 本地没有，两步走 // 1、创建一个空的ServiceInfo放入缓存 serviceObj = new ServiceInfo(serviceName, clusters); serviceInfoMap.put(serviceObj.getKey(), serviceObj); // 2、将远程服务信息更新到ServiceInfo中，updatingMap看来只是其到标记作用的 updatingMap.put(serviceName, new Object()); // &gt;&gt; 关键点 updateServiceNow(serviceName, clusters); updatingMap.remove(serviceName); //更新完毕删除标记 &#125; else if (updatingMap.containsKey(serviceName)) &#123; ... // 若有其他线程已经创建了标记说明其他线程正在更新，同步等待 &#125; // 开启定时更新任务 scheduleUpdateIfAbsent(serviceName, clusters); return serviceInfoMap.get(serviceObj.getKey());&#125; updateServiceNow(serviceName, clusters) 123456789101112131415public void updateServiceNow(String serviceName, String clusters) &#123; // 获取旧的服务信息，应用启动阶段为null ServiceInfo oldService = getServiceInfo0(serviceName, clusters); try &#123; // 拉取nacos-server上的实例信息，该方法传入的参数 pushReceiver.getUDPPort() 有讲究 String result = serverProxy.queryList(serviceName, clusters, pushReceiver.getUDPPort(), false); if (StringUtils.isNotEmpty(result)) &#123; processServiceJSON(result); //&gt;&gt; 处理返回的结果 &#125; &#125; catch (Exception e) &#123; ... &#125; finally &#123; ... &#125;&#125; processServiceJSON 很长的方法，大致逻辑就是，获取新信息，如果存在老信息，则进行比较，分别记录修改的，新增的，删除的实例信息，记录日志，并发出服务修改事件；若旧信息不存在，将新信息 添加到本地缓存并发出服务修改事件。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495public ServiceInfo processServiceJSON(String json) &#123; ServiceInfo serviceInfo = JSON.parseObject(json, ServiceInfo.class);//解析json ServiceInfo oldService = serviceInfoMap.get(serviceInfo.getKey());//本地缓存获取旧服务 if (serviceInfo.getHosts() == null || !serviceInfo.validate()) &#123; //若nacos-server返回的信息为null或不合法，返回老信息 return oldService; &#125; boolean changed = false; // 旧信息不为null，更新阶段 if (oldService != null) &#123; if (oldService.getLastRefTime() &gt; serviceInfo.getLastRefTime()) &#123;//旧信息时间不能晚于新信息 NAMING_LOGGER.warn(\"out of date data received, old-t: \" + oldService.getLastRefTime() + \", new-t: \" + serviceInfo.getLastRefTime()); &#125; // 新信息入缓存 serviceInfoMap.put(serviceInfo.getKey(), serviceInfo); // 获取旧信息中所有的实例对象 Map&lt;String, Instance&gt; oldHostMap = new HashMap&lt;String, Instance&gt;(oldService.getHosts().size()); for (Instance host : oldService.getHosts()) &#123; oldHostMap.put(host.toInetAddr(), host); &#125; // 获取信息中所有的实例对象 Map&lt;String, Instance&gt; newHostMap = new HashMap&lt;String, Instance&gt;(serviceInfo.getHosts().size()); for (Instance host : serviceInfo.getHosts()) &#123; newHostMap.put(host.toInetAddr(), host); &#125; Set&lt;Instance&gt; modHosts = new HashSet&lt;Instance&gt;(); Set&lt;Instance&gt; newHosts = new HashSet&lt;Instance&gt;(); Set&lt;Instance&gt; remvHosts = new HashSet&lt;Instance&gt;(); List&lt;Map.Entry&lt;String, Instance&gt;&gt; newServiceHosts = new ArrayList&lt;Map.Entry&lt;String, Instance&gt;&gt;( newHostMap.entrySet()); for (Map.Entry&lt;String, Instance&gt; entry : newServiceHosts) &#123; Instance host = entry.getValue(); String key = entry.getKey(); if (oldHostMap.containsKey(key) &amp;&amp; !StringUtils.equals(host.toString(), oldHostMap.get(key).toString())) &#123; modHosts.add(host); // 记录前后不一致的实例 continue; &#125; if (!oldHostMap.containsKey(key)) &#123; newHosts.add(host); // 记录新增实例 &#125; &#125; for (Map.Entry&lt;String, Instance&gt; entry : oldHostMap.entrySet()) &#123; Instance host = entry.getValue(); String key = entry.getKey(); if (newHostMap.containsKey(key)) &#123; continue; &#125; if (!newHostMap.containsKey(key)) &#123; remvHosts.add(host); // 记录删除实例 &#125; &#125; if (newHosts.size() &gt; 0) &#123; changed = true; NAMING_LOGGER.info(\"new ips(\" + newHosts.size() + \") service: \" + serviceInfo.getKey() + \" -&gt; \" + JSON.toJSONString(newHosts)); &#125; if (remvHosts.size() &gt; 0) &#123; changed = true; NAMING_LOGGER.info(\"removed ips(\" + remvHosts.size() + \") service: \" + serviceInfo.getKey() + \" -&gt; \" + JSON.toJSONString(remvHosts)); &#125; if (modHosts.size() &gt; 0) &#123; changed = true; NAMING_LOGGER.info(\"modified ips(\" + modHosts.size() + \") service: \" + serviceInfo.getKey() + \" -&gt; \" + JSON.toJSONString(modHosts)); &#125; serviceInfo.setJsonFromServer(json); if (newHosts.size() &gt; 0 || remvHosts.size() &gt; 0 || modHosts.size() &gt; 0) &#123; eventDispatcher.serviceChanged(serviceInfo); DiskCache.write(serviceInfo, cacheDir); &#125; &#125; else &#123; // 旧信息为null changed = true; ...//log serviceInfoMap.put(serviceInfo.getKey(), serviceInfo); // 新信息添加到缓存 eventDispatcher.serviceChanged(serviceInfo); // 发布服务changed事件 serviceInfo.setJsonFromServer(json); DiskCache.write(serviceInfo, cacheDir); // 磁盘缓存 &#125; MetricsMonitor.getServiceInfoMapSizeMonitor().set(serviceInfoMap.size()); if (changed) &#123; NAMING_LOGGER.info(\"current ips:(\" + serviceInfo.ipCount() + \") service: \" + serviceInfo.getKey() + \" -&gt; \" + JSON.toJSONString(serviceInfo.getHosts())); &#125; return serviceInfo;&#125; 总结：到此为止，服务信息已经拿到了，并存放在HostReactor的本地缓存中，但存在这里没用啊，应用要使用这些信息，还需要将其进行一些列处理后注入到spring容器中，所以这里需要发送一个事件通知spring，此处的数据已经进行了修改。 接下来我们看看事件是怎发出和处理的，非常巧妙 EventDispatcher.serviceChanged(serviceInfo) 1234567public void serviceChanged(ServiceInfo serviceInfo) &#123; if (serviceInfo == null) &#123; return; &#125; // 仅仅只是将服务信息添加到了一个List中 changedServices.add(serviceInfo);&#125; changedServices是一个LinkedBlockingQueue阻塞对列，EventDispatcher在构造的时候啊，启动了一个线程来处理这个阻塞队列中的元素 123456789101112131415161718192021222324252627282930private class Notifier implements Runnable &#123; @Override public void run() &#123; while (true) &#123; ServiceInfo serviceInfo = null; try &#123; // 取出元素 serviceInfo = changedServices.poll(5, TimeUnit.MINUTES); &#125; catch (Exception ignore) &#123; &#125; if (serviceInfo == null) &#123; continue; &#125; try &#123; // 从observerMap中取出监听器，并执行 List&lt;EventListener&gt; listeners = observerMap.get(serviceInfo.getKey()); if (!CollectionUtils.isEmpty(listeners)) &#123; for (EventListener listener : listeners) &#123; List&lt;Instance&gt; hosts = Collections.unmodifiableList(serviceInfo.getHosts()); listener.onEvent(new NamingEvent(serviceInfo.getName(), serviceInfo.getGroupName(), serviceInfo.getClusters(), hosts)); &#125; &#125; &#125; catch (Exception e) &#123; NAMING_LOGGER.error(\"[NA] notify error for service: \" + serviceInfo.getName() + \", clusters: \" + serviceInfo.getClusters(), e); &#125; &#125; &#125;&#125; observerMap中的监听器是什么时候加进去的呢？ 在DubboServiceDiscoveryAutoConfiguration.NacosConfiguration中注册了一个事件监听，监听SubscribedServicesChangedEvent事件： 123456@EventListener(SubscribedServicesChangedEvent.class)public void onSubscribedServicesChangedEvent(SubscribedServicesChangedEvent event) throws Exception &#123; // subscribe EventListener for each service event.getNewSubscribedServices().forEach(this::subscribeEventListener);&#125; 当接受到事件时，会执行subscribeEventListener方法 12345678910111213141516171819private void subscribeEventListener(String serviceName) &#123; if (listeningServices.add(serviceName)) &#123; try &#123; String group = nacosDiscoveryProperties.getGroup(); namingService.subscribe(serviceName, group, event -&gt; &#123; if (event instanceof NamingEvent) &#123; NamingEvent namingEvent = (NamingEvent) event; List&lt;ServiceInstance&gt; serviceInstances = hostToServiceInstanceList( namingEvent.getInstances(), serviceName); // 将Changed事件转发给spring-boot dispatchServiceInstancesChangedEvent(serviceName,serviceInstances); &#125; &#125;); &#125; catch (NacosException e) &#123; ReflectionUtils.rethrowRuntimeException(e); &#125; &#125;&#125; 我们看subscribe方法： 12345@Override//NacosNamingServicepublic void subscribe(String serviceName, String groupName, List&lt;String&gt; clusters, EventListener listener) throws NacosException &#123; eventDispatcher.addListener(hostReactor.getServiceInfo(NamingUtils.getGroupedName(serviceName, groupName), StringUtils.join(clusters, \",\")), StringUtils.join(clusters, \",\"), listener);&#125; subscribe做了两件事： 主要的工作是将hostReactor中的服务实例信息取出来 兼职是向eventDispatcher添加了一个Listener，该Listener是通过lamda表达式定义的，见上上段代码。 这个Listener监听NamingEvent类型的事件。 那我们再回到EventDispatcher的监听逻辑中： 12345678910111213141516171819202122232425262728293031private class Notifier implements Runnable &#123; @Override public void run() &#123; while (true) &#123; ServiceInfo serviceInfo = null; try &#123; // 取出元素 serviceInfo = changedServices.poll(5, TimeUnit.MINUTES); &#125; catch (Exception ignore) &#123; &#125; if (serviceInfo == null) &#123; continue; &#125; try &#123; // 从observerMap中取出监听器，并执行 List&lt;EventListener&gt; listeners = observerMap.get(serviceInfo.getKey()); if (!CollectionUtils.isEmpty(listeners)) &#123; for (EventListener listener : listeners) &#123; List&lt;Instance&gt; hosts = Collections.unmodifiableList(serviceInfo.getHosts()); // 向监听器发出NamingEvent listener.onEvent(new NamingEvent(serviceInfo.getName(), serviceInfo.getGroupName(), serviceInfo.getClusters(), hosts)); &#125; &#125; &#125; catch (Exception e) &#123; NAMING_LOGGER.error(\"[NA] notify error for service: \" + serviceInfo.getName() + \", clusters: \" + serviceInfo.getClusters(), e); &#125; &#125; &#125;&#125; 可以看到，EventDispatcher向监听器发出的正是NamingEvent 这个NamingEvent被接收后，响应逻辑会创建出一个SubscribedServicesChangedEvent发出： 1234567891011private void dispatchServiceInstancesChangedEvent(String serviceName, Collection&lt;ServiceInstance&gt; serviceInstances) &#123; if (!hasText(serviceName) || serviceInstances == null) &#123; return; &#125; // 创建事件并发布 ServiceInstancesChangedEvent event = new ServiceInstancesChangedEvent(serviceName, serviceInstances); 。。。 applicationEventPublisher.publishEvent(event);&#125; 然后被Spring-boot接收到处理： 123456@EventListener(SubscribedServicesChangedEvent.class)public void onSubscribedServicesChangedEvent(SubscribedServicesChangedEvent event) throws Exception &#123; // subscribe EventListener for each service event.getNewSubscribedServices().forEach(this::subscribeEventListener);&#125; 这里的事件发送监听形成了一个闭环。 scheduleUpdateIfAbsent 添加一个定时任务，更新服务信息，在下一篇笔记《Nacos(三)心跳与服务更新》中分析 4. 核心对象NacosNamingServiceNacosNamingService是NamingService接口的实现类。实现了上面提到的那些方法。此外，NacosNamingService还起到了初始化其他核心类的作用，因为对外提供的方法都是委托给其他核心类处理的。按顺序将依次初始化EventDispatcher、NamingProxy、BeatReactor、HostReactor。从NacosNamingService的构造函数我们也可以了解到，可以进行一些参数的自定义，总结如下（部分概念的含义可参考官方文档）： EventDispatcherEventDispatcher与其他事件分发的组件没什么不同，用于处理subscribe、unsubscribe等等与服务监听相关的方法，并分发NamingEvent到各Listener。成员变量ConcurrentMap&lt;String, List&gt; observerMap保存了注册的Listener，key为{服务名}@@{集群名}，value为各个EventListener的列表。EventDispatcher会启动1个名为com.alibaba.nacos.naming.client.listener的线程用于处理事件的分发。 注意点： 分发NamingEvent时，按照subscribe(…)方法的调用顺序串行依次调用EventListener的onEvent(…)方法。 调用subscribe(…)方法会引起对应Service的事件分发。 NamingProxyNamingProxy用于与Nacos服务端通信，注册服务、注销服务、发送心跳等都经由NamingProxy来请求服务端。NamingProxy会启动1个名为com.alibaba.nacos.client.naming.serverlist.updater的线程，用于定期调用refreshSrvIfNeed()方法更新Nacos服务端地址，默认间隔为30秒，对服务端API的调用将在后文总结。 注意点：refreshSrvIfNeed()方法对Nacos服务端地址的更新仅在使用endpoint的时候才会进行实际更新，如果是通过serverAddr配置的Nacos服务端地址，refreshSrvIfNeed()方法将不会进行任何操作。 BeatReactorBeatReactor用于向Nacos服务端发送已注册服务的心跳。成员变量Map&lt;String, BeatInfo&gt; dom2Beat中保存了需要发送的BeatInfo，key为{serviceName}#{ip}#{port}，value为对应的BeatInfo。BeatReactor会启动名为com.alibaba.nacos.naming.beat.sender的线程来发送心跳，默认线程数为1~CPU核心数的一半，可由namingClientBeatThreadCount参数指定。默认情况下每5秒发送一次心跳，可根据Nacos服务端返回的clientBeatInterval的值调整心跳间隔。 心跳请求的是nacos-server的注册接口，这也就是意味着，每隔5秒，服务都会重新注册一次。 HostReactorHostReactor用于获取、保存、更新各Service实例信息。成员变量Map&lt;String, ServiceInfo&gt; serviceInfoMap中保存了已获取到的服务的信息，key为{服务名}@@{集群名}。HostReactor会启动名为com.alibaba.nacos.client.naming.updater的线程来更新服务信息，默认线程数为1~CPU核心数的一半，可由namingPollingThreadCount参数指定。定时任务UpdateTask会根据服务的cacheMillis值定时更新服务信息，默认值为10秒。该定时任务会在获取某一服务信息时创建，保存在成员变量Map&lt;String, ScheduledFuture&lt;?&gt;&gt; futureMap中。","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/tags/SpringCloud/"}],"keywords":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}]},{"title":"Nacos(一)部署及使用","slug":"Nacos(1)部署及使用","date":"2020-08-09T16:00:00.000Z","updated":"2021-01-12T07:34:17.765Z","comments":true,"path":"2020/08/10/Nacos(1)部署及使用/","link":"","permalink":"https://zzkenyon.github.io/2020/08/10/Nacos(1)部署及使用/","excerpt":"","text":"单节点部署下载最新版本的nacos release包，官方给的百度云盘连接： https://pan.baidu.com/s/1186nmlqPGows9gUZKAx8Zw#list/path=%2F 提取码： rest 下载tar.gz文件 解压： tar -xvf nacos…. 修改配置文件conf/application.properties 1234567891011#*************** Config Module Related Configurations ***************#### If user MySQL as datasource:spring.datasource.platform=mysql### Count of DB:db.num=1### Connect URL of DB:db.url.0=jdbc:mysql://192.168.2.117:3306/nacos?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true&amp;useUnicode=true&amp;useSSL=false&amp;serverTimezone=UTCdb.user=rootdb.password=pJp&amp;Zzk3213 启动： cd bin sh startup.sh -m standalone 由于nacos没有依赖mysql8.0的driver包，所以启动时会报错，连接不上数据库 1234562020-08-09 13:07:15,048 INFO Root WebApplicationContext: initialization completed in 10238 msorg.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection; nested exception is com.mysql.jdbc.exceptions.jdbc4.MySQLNonTransientConnectionException: Could not create connection to database server. Attempted reconnect 3 times. Giving up. at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:81) at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:371) at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:523) 解决办法：在nacos安装目录下新建plugins/mysql文件夹，并放入8.0+版本的mysql-connector-java-8.0.xx.jar，重启nacos即可。启动时会提示更换了mysql的driver-class类。 最后访问xxx.xxx.xxx.xxx:8848 用户名密码是： nacos nacos","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/tags/SpringCloud/"}],"keywords":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}]},{"title":"java-Reactor编程入门","slug":"java-reactor编程入门","date":"2020-07-20T16:00:00.000Z","updated":"2021-01-12T07:25:35.678Z","comments":true,"path":"2020/07/21/java-reactor编程入门/","link":"","permalink":"https://zzkenyon.github.io/2020/07/21/java-reactor编程入门/","excerpt":"","text":"https://developer.ibm.com/zh/articles/j-cn-with-reactor-response-encode/ 1. 理论基础反应式编程来源于数据流和变化的传播，意味着由底层的执行模型负责通过数据流来自动传播变化。比如求值一个简单的表达式 c=a+b，当 a 或者 b 的值发生变化时，传统的编程范式需要对 a+b 进行重新计算来得到 c 的值。如果使用反应式编程，当 a 或者 b 的值发生变化时，c 的值会自动更新。反应式编程最早由 .NET 平台上的 Reactive Extensions (Rx) 库来实现。后来迁移到 Java 平台之后就产生了著名的 RxJava 库，并产生了很多其他编程语言上的对应实现。在这些实现的基础上产生了后来的反应式流（Reactive Streams）规范。该规范定义了反应式流的相关接口，并将集成到 Java 9 中。 在传统的编程范式中，我们一般通过迭代器（Iterator）模式来遍历一个序列。这种遍历方式是由调用者来控制节奏的，采用的是拉的方式。每次由调用者通过 next()方法来获取序列中的下一个值。使用反应式流时采用的则是推的方式，即常见的发布者-订阅者模式。当发布者有新的数据产生时，这些数据会被推送到订阅者来进行处理。在反应式流上可以添加各种不同的操作来对数据进行处理，形成数据处理链。这个以声明式的方式添加的处理链只在订阅者进行订阅操作时才会真正执行。 反应式流中第一个重要概念是负压（backpressure）。在基本的消息推送模式中，当消息发布者产生数据的速度过快时，会使得消息订阅者的处理速度无法跟上产生的速度，从而给订阅者造成很大的压力。当压力过大时，有可能造成订阅者本身的奔溃，所产生的级联效应甚至可能造成整个系统的瘫痪。负压的作用在于提供一种从订阅者到生产者的反馈渠道。订阅者可以通过 request()方法来声明其一次所能处理的消息数量，而生产者就只会产生相应数量的消息，直到下一次 request()方法调用。这实际上变成了推拉结合的模式。 前面提到的 RxJava 库是 JVM 上反应式编程的先驱，也是反应式流规范的基础。RxJava 2 在 RxJava 的基础上做了很多的更新。不过 RxJava 库也有其不足的地方。RxJava 产生于反应式流规范之前，虽然可以和反应式流的接口进行转换，但是由于底层实现的原因，使用起来并不是很直观。RxJava 2 在设计和实现时考虑到了与规范的整合，不过为了保持与 RxJava 的兼容性，很多地方在使用时也并不直观。Reactor 则是完全基于反应式流规范设计和实现的库，没有 RxJava 那样的历史包袱，在使用上更加的直观易懂。Reactor 也是 Spring 5 中反应式编程的基础。学习和掌握 Reactor 可以更好地理解 Spring 5 中的相关概念。 在 Java 程序中使用 Reactor 库非常的简单，只需要通过 Maven 或 Gradle 来添加对 io.projectreactor:reactor-core 的依赖即可，目前的版本是 3.0.5.RELEASE。 2. Flux 和 MonoFlux 和 Mono 是 Reactor 中的两个基本概念z。Flux 表示的是包含 0 到 N 个元素的异步序列。在该序列中可以包含三种不同类型的消息通知：正常的包含元素的消息、序列结束的消息和序列出错的消息。当消息通知产生时，订阅者中对应的方法 onNext(), onComplete()和 onError()会被调用。Mono 表示的是包含 0 或者 1 个元素的异步序列。该序列中同样可以包含与 Flux 相同的三种类型的消息通知。Flux 和 Mono 之间可以进行转换。对一个 Flux 序列进行计数操作，得到的结果是一个 Mono对象。把两个 Mono 序列合并在一起，得到的是一个 Flux 对象。 2.1 Mono创建2.1.1 静态创建方法 empty()：创建一个不包含任何元素，只发布结束消息的序列。 just()：可以指定序列中包含的全部元素。创建出来的 Mono序列在发布这些元素之后会自动结束。 justOrEmpty()：从一个 Optional 对象或可能为 null 的对象中创建 Mono。只有 Optional 对象中包含值或对象不为 null 时，Mono 序列才产生对应的元素。 error(Throwable error)：创建一个只包含错误消息的序列。 never()：创建一个不包含任何消息通知的序列。 fromCallable()、fromCompletionStage()、fromFuture()、fromRunnable()和 fromSupplier()：分别从 Callable、CompletionStage、CompletableFuture、Runnable 和 Supplier 中创建 Mono。 delay(Duration duration)和 delayMillis(long duration)：创建一个 Mono 序列，在指定的延迟时间之后，产生数字 0 作为唯一值。 2.1.2 动态创建方法通过 create()方法来使用 MonoSink 来创建 Mono。 1234567891011121314151617181920@Testpublic void monoCreateTest_1()&#123; Mono.create(sink -&gt; &#123; SimpleRequest msg = new SimpleRequest(); msg.setRequestMessage(\"hello zzk\"); String requestMessage = msg.getRequestMessage(); SimpleResponse response = SimpleResponse.newBuilder().setResponseMessage(requestMessage).build(); sink.success(response); &#125;) .subscribe(System.out::println);&#125;@Testpublic void monoCreateTest_2()&#123; CityService cityService = new CityService(); Mono.create(cityMonoSink -&gt; &#123; int id = 1; cityMonoSink.success(cityService.findCityById(id)); // 此处可做增删改查 &#125;).subscribe(System.out::println);&#125; 3. 操作符Reactor可以在反应式流上通过 声明 的方式添加多种不同的操作符。 3.1 buffer 和 bufferTimeout作用：将当前流中的元素收集到集合中，并将集合对象作为流中的新元素 在进行收集时可以指定不同的条件： 所包含的元素的最大数量； 收集的时间间隔。（事件间隔使用Duration对象表示） 方法buffer()仅使用一个条件，而bufferTimeout可以使用两个条件 除了元素数量和时间间隔之外，还可以通过bufferUntil和bufferWhile操作符来进行收集。这两个操作符的参数是表示每个集合中的元素所要满足的条件的predicate对象。 bufferUtils会一只手机知道predicate返回为true，使得predicate返回true的那个元素可以选择添加到当前集合或者下一个集合中 bufferWhile则至于当Predicate返回为true时才会收集，一旦返回false，会立即开始下一次收集。 测试： 1234567public static void bufferTest()&#123; Flux.range(1,10).bufferWhile(i-&gt;i&gt;5).subscribe(System.out::println); Flux.range(1,10).bufferUntil(integer -&gt; integer % 2 ==0).subscribe(System.out::println); Flux.range(1,10).buffer().subscribe(System.out::println);&#125; 理解：按一定的条件，将流中元素分类，聚合成新的集合元素 3.2 filter作用：对流中包含的元素进行过滤，只满足Predicate指定条件的元素。 测试： 123public static void filterTest()&#123; Flux.range(1,10).filter(integer -&gt; integer%2==0).subscribe(System.out::println);&#125; 3.3 window作用：类似于buffer，不同的是window操作符吧当前流中的元素收集到另外的Flux序列中，因此返回值是 Flux。 测试： 123public static void windowTest()&#123; Flux.range(1,100).window(20).subscribe(System.out::println);&#125; 在代码中，输出结果分别是 5 个和 2 个 UnicastProcessor 字符。这是因为 window 操作符所产生的流中包含的是 UnicastProcessor 类的对象，而 UnicastProcessor 类的 toString 方法输出的就是 UnicastProcessor 字符。 3.4 zipWith作用：把当前流中的元素与另一个流中的元素按照一对一的方式进行合并。 在合并时，可以不作任何处理，由此得到的是一个元素类型为Tuple2的流 也可以通过一个BiFuction函数对合并的元素进行处理，的到的流元素为该函数的返回值 测试： 1234public static void zipWithTest()&#123; Flux.just(\"a\",\"b\").zipWith(Flux.just(\"c\",\"d\")).subscribe(System.out::println); Flux.just(\"a\",\"b\").zipWith(Flux.just(\"c\",\"d\"),(s1,s2)-&gt;s1+s2).subscribe(System.out::println);&#125; 3.5 take作用：用于从当提前流中提取元素，提取方式有多种： take(long n)，take(Duration timespan)：按照指定的数量或时间间隔来提取。 takeLast(long n)：提取流中的最后 N 个元素。 takeUntil(Predicate&lt;? super T&gt; predicate)：提取元素直到 Predicate 返回 true。 takeWhile(Predicate&lt;? super T&gt; continuePredicate)： 当 Predicate 返回 true 时才进行提取。 takeUntilOther(Publisher&lt;?&gt; other)：提取元素直到另外一个流开始产生元素。 测试： 12345678910public static void takeTest()&#123; // 获取前10个元素 Flux.range(1,1000).take(10).subscribe(System.out::println); // 获取后10个元素 Flux.range(1,1000).takeLast(10).subscribe(System.out::println); // 提取元素直到Predicate返回true Flux.range(1,1000).takeUntil(integer -&gt; integer==100).subscribe(System.out::println); //当Predicate返回true时，提取元素 Flux.range(1,100).takeWhile(integer -&gt; integer&lt;10).subscribe(System.out::println);&#125; 3.6 reduce 和 reduceWith作用：对流中包含的所有元素进行累积操作，得到一份包含计算结果的Mono序列。累积操作是通过一份BiFunction来表示的 在操作的时候可以指定一个初始值，如果没有初始值，序列中的第一个元素作为初始值 123456public static void reduceTest()&#123; // 累加 返回5050 Flux.range(1,100).reduce((x,y)-&gt;x+y).subscribe(System.out::println); // 在50的基础上累加 返回5100 Flux.range(1,100).reduceWith(()-&gt;50,(x,y)-&gt;x+y).subscribe(System.out::println);&#125; 3.7 merge 和 mergeSequential作用：用于把多个流合并成一个Flux序列。 merge 按照所有流中元素的实际生产顺序进行合并 mergeSequential 按照所有流被订阅的顺序，以流为单位进行合并 测试： 123456789public static void mergeTest()&#123; Flux.merge(Flux.interval(Duration.of(1, ChronoUnit.SECONDS)).take(10), Flux.interval(Duration.of(2,ChronoUnit.SECONDS)).take(10)) .toStream().forEach(System.out::println); Flux.mergeSequential(Flux.interval(Duration.of(1, ChronoUnit.SECONDS)).take(10), Flux.interval(Duration.of(2,ChronoUnit.SECONDS)).take(10)) .toStream().forEach(System.out::println);&#125; 第一句：两个序列交叉输出 第二句：先输出第一个序列，第二个序列虽然没输出但是已经发射的元素存在内存中了，序列一输出完成立即输出以发射的序列二元素，再继续按照序列二的节奏输出。 3.8 flatMap 和 flatMapSequential作用：把流中的每个元素转换成一个流，再把所有流中的元素进行合并。 flatMap 与flatMapSequential的区别，和上文介绍的merge操作符一致 1234public static void flatMapTest()&#123; Flux.just(3,5).flatMap(x-&gt;Flux.interval(Duration.of(x,ChronoUnit.SECONDS)).take(x)).toStream() .forEach(System.out::println);&#125; 3.9 concatMap作用：也是把流中的每个元素转换成一个流，再把所有流进行合并。 与 flatMap 不同的是，concatMap 会根据原始流中的元素顺序依次把转换之后的流进行合并； 与 flatMapSequential 不同的是，concatMap 对转换之后的流的订阅是动态进行的，而 flatMapSequential 在合并之前就已经订阅了所有的流。 123456public static void concatMapTest()&#123; Flux.just(3, 4) .concatMap(x -&gt; Flux.interval(Duration.of(x,ChronoUnit.SECONDS)).take(x)) .toStream() .forEach(System.out::println);&#125; 3.10 combineLatest作用：把所有流中的最新产生的元素合并成一个新的元素，作为返回结果流中的元素。只要其中任何一个流中产生了新的元素，合并操作就会被执行一次，结果流中就会产生新的元素。 在下面代码，流中最新产生的元素会被收集到一个数组中，通过 Arrays.toString 方法来把数组转换成 String。 1234567public static void combineLatestTest()&#123; Flux.combineLatest( Arrays::toString, Flux.interval(Duration.of(4,ChronoUnit.SECONDS)).take(5), Flux.interval(Duration.of(8,ChronoUnit.SECONDS)).take(5) ).toStream().forEach(System.out::println);&#125; 3.11 defermono defer方法创建数据源属于懒汉型，与Mono.just等创建数据源则是恶汉型，下面看一个例子： 123456789101112131415public void defer()&#123; //声明阶段创建DeferClass对象 Mono&lt;Date&gt; m1 = Mono.just(new Date()); Mono&lt;Date&gt; m2 = Mono.defer(()-&gt;Mono.just(new Date())); m1.subscribe(System.out::println); m2.subscribe(System.out::println); //延迟5秒钟 try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; m1.subscribe(System.out::println); m2.subscribe(System.out::println); &#125; 输出结果 Fri Feb 07 10:22:51 GMT+08:00 2020Fri Feb 07 10:22:51 GMT+08:00 2020Fri Feb 07 10:22:51 GMT+08:00 2020Fri Feb 07 10:22:56 GMT+08:00 2020 我们可以看到，创建了两个数据源，一个使用Mono.just创建，一个用Mono.defer创建，然后分别通过lambda表达式订阅这两个publisher，可以看到两个输出的时间都是10:22：51，延迟5秒钟后重新订阅，Mono.just创建的数据源时间没变，但是Mono.defer创建的数据源时间相应的延迟了5秒钟，原因在于Mono.just会在声明阶段构造Date对象，只创建一次，但是Mono.defer却是在subscribe阶段才会创建对应的Date对象，每次调用subscribe方法都会创建Date对象，在webflux中 4. 消息处理当需要处理Flux和Mono中的消息时，可以通过subscribe方法来添加相应的订阅逻辑。在调用subscribe方法时可以指定需要处理的消息类型。可以只处理其中包含的正常消息，也可以同时处理错误消息和完成消息。 通过subscribe()方法处理正常和错误消息 123Flux.just(1, 2) .concatWith(Mono.error(new IllegalStateException())) .subscribe(System.out::println, System.err::println); 输出： 12312java.lang.IllegalStateException 出现错误是返回默认值 正常的消息处理相对简单。当出现错误时，有多种不同的处理策略。第一种策略是通过 onErrorReturn()方法返回一个默认值。 1234Flux.just(1, 2) .concatWith(Mono.error(new IllegalStateException())) .onErrorReturn(-1) .subscribe(System.out::println); 输出： 12312-1","categories":[{"name":"不知如何分类","slug":"不知如何分类","permalink":"https://zzkenyon.github.io/categories/不知如何分类/"}],"tags":[{"name":"java","slug":"java","permalink":"https://zzkenyon.github.io/tags/java/"}],"keywords":[{"name":"不知如何分类","slug":"不知如何分类","permalink":"https://zzkenyon.github.io/categories/不知如何分类/"}]},{"title":"SpringBoot-事务源码分析","slug":"SpringBoot-事务源码分析","date":"2020-06-20T16:00:00.000Z","updated":"2020-07-16T09:30:33.512Z","comments":true,"path":"2020/06/21/SpringBoot-事务源码分析/","link":"","permalink":"https://zzkenyon.github.io/2020/06/21/SpringBoot-事务源码分析/","excerpt":"","text":"复习总结： 注解式事务是通过aop实现的，底层是cglib动态代理实现的 事务aop场景中的Advice是TransactionInterceptor PointCut是TransactionAttributeSourcePointcut，它通过TransactionAttributeSource来检测@Transactional注解，因此注解可以理解为切面 TransactionInterceptor作为事务增强逻辑的封装类，需要持有逻辑事务管理器引用，不同的数据持久化平台都实现了自己的事务管理器 项目中使用多种持久化平台时，建议在事务注解中显示的指定事务管理器 1. springboot事务自动装配spring-boot-autoconfigurae 包中对事物有自动配置的支持，自动配置类为TransactionAutoConfiguration，在spring.factories文件中可以找到这条自动配置项，源码分析先从自动装配开始，看看spring-boot装配了哪些事务相关的bean。 TransactionAutoConfiguration中只显示定义了以下的三个bean，辅助bean 1234567/** * 这是一个PlatformTransactionManagerCustomizer列表 * springboot提供的扩展点，使用它可以对事务管理器进行一些配置， **/TransactionManagerCustomizers TransactionalOperator //简化程序化事务界定和事务异常处理的操作符类。TransactionTemplate // 简化程序化事务界定和事务异常处理的模板类。 TransactionAutoConfiguration里的重点配置是在内部类EnableTransactionManagementConfiguration中 12345678910111213141516171819202122@Configuration(proxyBeanMethods = false)@ConditionalOnBean(TransactionManager.class)@ConditionalOnMissingBean(AbstractTransactionManagementConfiguration.class)public static class EnableTransactionManagementConfiguration &#123; @Configuration(proxyBeanMethods = false) @EnableTransactionManagement(proxyTargetClass = false) @ConditionalOnProperty(prefix = \"spring.aop\", name = \"proxy-target-class\", havingValue = \"false\", matchIfMissing = false) public static class JdkDynamicAutoProxyConfiguration &#123; &#125; @Configuration(proxyBeanMethods = false) @EnableTransactionManagement(proxyTargetClass = true) @ConditionalOnProperty(prefix = \"spring.aop\", name = \"proxy-target-class\", havingValue = \"true\", matchIfMissing = true) public static class CglibAutoProxyConfiguration &#123; &#125;&#125; 该类对Jdk动态代理和CGlib动态代理两种方式分别作了配置，此类中并没有配置事务相关的bean，其关键是在@EnableTransactionManagement注解中 1.1 EnableTransactionManagement12345@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(TransactionManagementConfigurationSelector.class)public @interface EnableTransactionManagement &#123;...&#125; EnableTransactionManagement使用@Import注解导入了一个TransactionManagementConfigurationSelector，这种用法已经不陌生，常用于动态的装配bean，也就是根据应用的环境或配置装载不同类型的bean，进入该选择器代码： 123456789101112// `TransactionManagementConfigurationSelector`protected String[] selectImports(AdviceMode adviceMode) &#123; switch (adviceMode) &#123; case PROXY: return new String[] &#123;AutoProxyRegistrar.class.getName(), ProxyTransactionManagementConfiguration.class.getName()&#125;; case ASPECTJ: return new String[] &#123;determineTransactionAspectClass()&#125;; default: return null; &#125;&#125; springboot启动时会执行者这段逻辑，当adviceMode是动态代理模式，装配的是TransactionManagementConfiguration，当adviceMode是aspectj织入模式，装配的是其他的，本文只讨论动态代理的情况。 TransactionManagementConfiguration是此时真正的配置类，那么配置了哪些bean呢？ 12345678910111213141516171819202122@Bean(name = TransactionManagementConfigUtils.TRANSACTION_ADVISOR_BEAN_NAME)@Role(BeanDefinition.ROLE_INFRASTRUCTURE)public BeanFactoryTransactionAttributeSourceAdvisor transactionAdvisor( ...&#125;@Bean@Role(BeanDefinition.ROLE_INFRASTRUCTURE)public TransactionAttributeSource transactionAttributeSource() &#123; return new AnnotationTransactionAttributeSource();&#125;@Bean@Role(BeanDefinition.ROLE_INFRASTRUCTURE)public TransactionInterceptor transactionInterceptor(TransactionAttributeSource transactionAttributeSource) &#123; TransactionInterceptor interceptor = new TransactionInterceptor(); interceptor.setTransactionAttributeSource(transactionAttributeSource); if (this.txManager != null) &#123; interceptor.setTransactionManager(this.txManager); &#125; return interceptor;&#125; 第一个是BeanFactoryTransactionAttributeSourceAdvisor。它以Advisor结尾说明它是Spring AOP范畴里的东西。在AOP里，Advisor = Pointcut + Advice，Pointcut是切入点，表示要拦截的方法，Advice是增强，表示要加进去的事物功能。在BeanFactoryTransactionAttributeSourceAdvisor中有一个成员TransactionAttributeSourcePointcut，看名字就知道这是一个PointCut，它通过第三个bean—TransactionAttributeSource检测一个类的方法上是否有@Transactional注解，来确定该方法是否需要事物增强。 第二个bean是TransactionInterceptor，他就是一个Advice，因为它实现了Advice接口，包含了把事物加进去的逻辑。 1.2 TransactionInterceptor事务拦截器TransactionInterceptor用于拦截添加了事务注解的方法或类，对其执行事务管理器txManager的相关操作，那么事务管理器又是什么时候装载的呢？ 我们看到该配置类的父类中自动注入了一个TransactionManager，这里注入的是默认的事务管理器。当我们项目用到不止一个事务管理器的时候，开启事务时需要指定使用哪一个事务管理器，此时可以实现TransactionManagementConfigurer接口来指定一个默认的事务管理器，对有的系统，为了避免不必要的问题，在业务中必须要明确指定 @Transactional 的 value 值的情况下。不建议实现接口 TransactionManagementConfigurer，这样控制台会明确抛出异常，开发人员就不会忘记主动指定。 12345678910111213141516public abstract class AbstractTransactionManagementConfiguration implements ImportAware &#123; @Nullable protected TransactionManager txManager; @Autowired(required = false) void setConfigurers(Collection&lt;TransactionManagementConfigurer&gt; configurers) &#123; if (CollectionUtils.isEmpty(configurers)) &#123; return; &#125; if (configurers.size() &gt; 1) &#123; throw new IllegalStateException(\"Only one TransactionManagementConfigurer may exist\"); &#125; TransactionManagementConfigurer configurer = configurers.iterator().next(); this.txManager = configurer.annotationDrivenTransactionManager(); &#125;&#125; 当没有实现TransactionManagementConfigurer指定默认管理器时，上面的自动注入可能为空。 实时上关于事务管理器，不管是JPA还是JDBC等都实现自接口 PlatformTransactionManager 如果你添加的是 spring-boot-starter-jdbc 依赖，框架会默认注入 DataSourceTransactionManager 实例。如果你添加的是 spring-boot-starter-data-jpa 依赖，框架会默认注入 JpaTransactionManager 实例。 TransactionInterceptor的核心逻辑是invoke()方法，具体的执行逻辑我会在下文执行流程中分析。 2. spring事物的执行流程spring-boot完成了事务bean的自动装配之后，下面来分析事务方法执行时，事务管理器的执行过程。 定义事务管理器的接口是PlatformTransactionManager，这个接口定义了三个方法，官方给出的注释很详细： 123456789public interface PlatformTransactionManager extends TransactionManager &#123; //根据指定的传播行为，返回当前活动的事务或创建新的事务。 TransactionStatus getTransaction(@Nullable TransactionDefinition definition) throws TransactionException; //提交给定事务的状态。如果事务以编程方式标记为仅回滚，则执行回滚。 void commit(TransactionStatus status) throws TransactionException; //执行给定事务的回滚。 void rollback(TransactionStatus status) throws TransactionException;&#125; 接口PlatformTransactionManager的一个抽象实现类就是AbstractPlatformTransactionManager，这个类实现了事务管理的整个逻辑关系流程，但是把与具体事务打交道的东西又定义为抽象方法让子类去实现（模板设计模式）。 2.1 事务管理器涉及的关键对象事务定义 TransactionDefinition 这是一个接口，然而并没有需要实现的方法，接口中定义了spring事务支持的传播属性、隔离级别、超时时间、只读标记等事务属性的可选值，并制定了默认值。其派生接口为TransactionAttribute 事务对象 SmartTransactionObject 不同数据源框架定义的事务对象不同，SmartTransactionObject只是spring-tx包定义的接口标准，不同框架对其都有自己的实现，这里我们以DataSourceTransactionObject为例，它是jdbc定义的事务对象 DataSourceTransactionObject是DataSourceTransactionManager的内部类，看下面简单的类继承图 这个事务对象中最重要的成员是抽象类JdbcTransactionObjectSupport中定义的ConnectionHolder对象，它存储了该执行逻辑事务的数据库连接，也就是物理事务。 事务状态 TransactionStatus TransactionStatus是一个接口，它继承了其他的三个接口： 常用的实现类是DefaultTransactionStatus，继承自AbstractTransactionStatus 123456789101112131415public class DefaultTransactionStatus extends AbstractTransactionStatus &#123; @Nullable private final Object transaction; // 事务对象 private final boolean newTransaction; // 标记--是否为新创建的事务 private final boolean newSynchronization; // 标记--是否开启了新事务的同步 private final boolean readOnly; // 标记--是否为只读事务 private final boolean debug; @Nullable private final Object suspendedResources; // 当事务被挂起后存放挂起事务状态 // 继承的属性 private boolean rollbackOnly = false; //事务是否只支持回滚 private boolean completed = false; // 事务是否已完成 @Nullable private Object savepoint; // 保存点&#125; 重要的属性： 持有一个事务对象的引用Object transaction，还记录了一些事务的状态信息 Object suspendedResources ，保存被挂起事务的状态，后文会详细分析 2.2 事务执行流程分析2.2.1 aop动态代理阶段当调用的方法注解了事务，调用之前会通过cglib产生一个代理对象，cglib的动态代理的关键是实现MethodInterceptor接口，找到这个类，它是CglibAopProxy的一个私有的内部类： 1234567891011121314// CglibAopProxyprivate static class DynamicAdvisedInterceptor implements MethodInterceptor, Serializable &#123; private final AdvisedSupport advised; public DynamicAdvisedInterceptor(AdvisedSupport advised) &#123; this.advised = advised; &#125; public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable&#123; ... retVal = new CglibMethodInvocation(proxy, target, method, args, targetClass, chain, methodProxy).proceed(); &#125;&#125; intercept() 是spring aop 进行拦截的方法，spring事务基于aop实现，所以事务增强会被aop拦截，执行intercept方法 intercept方法中不会直接开启事务或关闭事务，因为事务不一定是方法上唯一的增强点（可能存在其他增强，比如记录审计日志、开启分布式锁等等），所以事务增强逻辑肯定是封装成了一个Advisor，交给aop统一管理。 那么我们就去找这个Advisor 上面的代码创建了CglibMethodInvocation对象后执行了proceed()方法，进入该方法发现他调用了父类ReflectiveMethodInvocation的proceed()，这是一个反射方法调用器的执行过程， 由于在同一个切点可能会存在多个增强，所以动态代理也可能代理多次，每次代理都将增强的逻辑存放到一个容器中，在执行时逐个执行。 123456789101112131415161718// ReflectiveMethodInvocationpublic Object proceed() throws Throwable &#123; // interceptorsAndDynamicMethodMatchers是拦截器链，同一个切点可能被多个advice拦截 // currentInterceptorIndex初始为-1，这条判断其实是若拦截器链中没有拦截器，直接调用invokeJoinpoint if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) &#123; return invokeJoinpoint(); &#125; // currentInterceptorIndex先加1，再获取拦截器，此处获取到的就是事务拦截器 Object interceptorOrInterceptionAdvice = this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex); if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) &#123; ... &#125; else &#123; // 事务拦截会执行到这里 return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this); &#125;&#125; 跟代码可以看到获取到的拦截器是TransactionInterceptor类型的，中间的判断都不满足，直接运行到代码的最后一行，调用Invoke(this) 注意：TransactionInterceptor 实现的MethodInterceptor接口与上面cglib的不是同一个： cglib的MethodInterceptor接口是为了让代理对象执行代理逻辑，需要实现的是intercept方法 此处的MethodInterceptor接口是为了调用代理逻辑中的增强方法，需要实现的是invoke方法，因为增强逻辑是被封装过的。 2.2.2 TransactionInterceptor.invoke方法123456789// TransactionInterceptorpublic Object invoke(MethodInvocation invocation) throws Throwable &#123; // 参数invocation就是上面创建的CglibMethodInvocation // 获取被代理对象的类型 Class&lt;?&gt; targetClass = (invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null); // 终于开始进入正题了,在事务中调用方法&gt;&gt; return invokeWithinTransaction(invocation.getMethod(), targetClass, invocation::proceed);&#125; invokeWithinTransaction方法是定义在父类TransactionAspectSupport中的，此方法代码有点长，这里节选一些关键代码： 1234567891011121314151617181920212223242526272829303132333435363738protected Object invokeWithinTransaction(Method method, @Nullable Class&lt;?&gt; targetClass, final InvocationCallback invocation) throws Throwable &#123; ... // 获取注解属性源，此处获取到的是AnnotationTransactionAttributeSource对象 TransactionAttributeSource tas = getTransactionAttributeSource(); // 从属性源中拿到事务的属性，RuleBasedTransactionAttribute对象 final TransactionAttribute txAttr = (tas != null ? tas.getTransactionAttribute(method, targetClass) : null); // 根据事务属性，创建事务管理器，如果没有配置事务管理器，自适应创建 final PlatformTransactionManager tm = determineTransactionManager(txAttr); // com.pd.service.AccountService.transferAccount 就是方法的名称 final String joinpointIdentification = methodIdentification(method, targetClass, txAttr); if (txAttr == null || !(tm instanceof CallbackPreferringPlatformTransactionManager)) &#123; // 创建事务，开启事务 &gt;&gt; TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification); Object retVal; try &#123; // 调用方法逻辑 retVal = invocation.proceedWithInvocation(); &#125; catch (Throwable ex) &#123; // 目标方法抛出异常，结束事务。可能回滚，可能啥也不做 completeTransactionAfterThrowing(txInfo, ex); throw ex; &#125; finally &#123; // 清理事务现场 cleanupTransactionInfo(txInfo); &#125; ... // 提交事务 commitTransactionAfterReturning(txInfo); return retVal; &#125; ...&#125; 在这里找到事务创建的方法createTransactionIfNecessary，跟进方法： DelegatingTransactionAttribute是TransactionAttribute的代理实现类，这里用静态代理。为什么要用代理类？因为TransactionAttribute是接口，不能实例化 12345678910111213141516171819202122protected TransactionInfo createTransactionIfNecessary(@Nullable PlatformTransactionManager tm, @Nullable TransactionAttribute txAttr, final String joinpointIdentification) &#123; // 事务如果没有指定名称，用之前生成的方法切入点id作为事务名称 if (txAttr != null &amp;&amp; txAttr.getName() == null) &#123; txAttr = new DelegatingTransactionAttribute(txAttr) &#123; @Override public String getName() &#123; return joinpointIdentification; &#125; &#125;; &#125; TransactionStatus status = null; if (txAttr != null) &#123; if (tm != null) &#123; // 就是在这里创建事务开启事务了，事务的属性传进去 status = tm.getTransaction(txAttr); &#125; ... // 日志操作 &#125; return prepareTransactionInfo(tm, txAttr, joinpointIdentification, status);&#125; 跟进方法getTransaction，该方法将返回一个TransactionStatus类型的结果，这个叫事务状态的返回结果持有创建的事务对象（逻辑事务），以及该事务对象的一些状态信息。 那我们来看一下这个获取事务的方法的整一个流程： 12345678910111213141516171819202122232425262728293031323334353637383940414243@Overridepublic final TransactionStatus getTransaction(@Nullable TransactionDefinition definition) throws TransactionException &#123; TransactionDefinition def = (definition != null ? definition : TransactionDefinition.withDefaults()); // doGetTransaction()从当前上下文中获取事务对象，这是一个抽象方法，子类实现 &gt;&gt; Object transaction = doGetTransaction(); boolean debugEnabled = logger.isDebugEnabled(); //若被调用的事务方法已处于事务之中（事务方法A调用事务方法B） if (isExistingTransaction(transaction)) &#123; // 根据当前事务的传播属性，来决定下一步处理 &gt;&gt; return handleExistingTransaction(def, transaction, debugEnabled); &#125; //-----------------------当前还没有事务会往下走----------------------- // 检查超时设置是否合理 if (def.getTimeout() &lt; TransactionDefinition.TIMEOUT_DEFAULT) &#123; throw new InvalidTimeoutException(\"Invalid transaction timeout\", def.getTimeout()); &#125; // 若配置的事务传播属性是MANDATORY（该配置表示当前存在事务则加入，否则），抛异常 if (def.getPropagationBehavior() == TransactionDefinition.PROPAGATION_MANDATORY) &#123; throw new IllegalTransactionStateException( \"No existing transaction found for transaction marked with propagation 'mandatory'\"); &#125; else if (def.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRED || def.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRES_NEW || def.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NESTED) &#123; SuspendedResourcesHolder suspendedResources = suspend(null); if (debugEnabled) &#123; logger.debug(\"Creating new transaction with name [\" + def.getName() + \"]: \" + def); &#125; try &#123; boolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER); DefaultTransactionStatus status = newTransactionStatus( def, transaction, true, newSynchronization, debugEnabled, suspendedResources); doBegin(transaction, def); // 开启一个新事务 prepareSynchronization(status, def); return status; &#125; ... &#125;else ...&#125; 在分析以上代码之前，首先需要明白几个概念，最终要搞清楚几个问题： 物理事务就是到数据库的一个物理链接（数据库连接），那么这个链接是什么时候获取的？建立连接后又是如何保存起来的？ 逻辑事务就是一个带有spring事务注解的方法，它需要关联到一个物理事务上。那它们之间如何进行关联？ 多个逻辑事务可以映射到一个物理事务上，逻辑事务是各自提交的，如何处理逻辑事务提交和物理事务提交间的关系呢，至少所有的逻辑事务都提交了才可以提交物理事务。 带着问题来分析获取事务的方法： 2.2.3 doGetTransaction接下来的分析都是以数据源事务管理器为列进行的，首先来看doGetTransaction()这个方法，这个方法首先会创建一个逻辑事务对象DataSourceTransactionObject 12345678910111213// DataSourceTransactionManager@Overrideprotected Object doGetTransaction() &#123; // 创建事务对象（逻辑事务） DataSourceTransactionObject txObject = new DataSourceTransactionObject(); txObject.setSavepointAllowed(isNestedTransactionAllowed()); // 从线程私有变量中获取物理事务，没有事务嵌套，获取到的是null ConnectionHolder conHolder = (ConnectionHolder) TransactionSynchronizationManager.getResource(obtainDataSource()); // 将获取到的物理事务 绑定给 逻辑事务对象 false表示这个物理事务不是新创建的 txObject.setConnectionHolder(conHolder, false); return txObject;&#125; 逻辑事务对象中到底有哪些内容呢 1234567891011121314private static class DataSourceTransactionObject extends JdbcTransactionObjectSupport &#123; // 新连接标志，当事务对象新获取一个数据库连接是，设为true private boolean newConnectionHolder; // 当数据库连接开启自动提交，逻辑事务关闭它之前，会先保存这个状态 private boolean mustRestoreAutoCommit; /*------------- 继承到的属性----------------*/ @Nullable // 数据库连接封装类对象 private ConnectionHolder connectionHolder; @Nullable // 隔离级别 private Integer previousIsolationLevel; //是否允许设置保存点 private boolean savepointAllowed = false;&#125; 数据源事务对象中最重要的成员变量是就是ConnectionHolder，它是数据库连接的封装类，创建逻辑事务时，它为null。也就是说逻辑事务创建的时候并没有关联到物理事务（数据库连接） 现在回到doGetTransaction方法，接下来的关键点是尝试获取线程中已经获得的物理事务，在事务同步管理器TransactionSynchronizationManager中，有几个线程私有的变量（ThreadLocal）： 123456789101112131415public abstract class TransactionSynchronizationManager &#123; // 存储事务资源 map的key是数据源DataSource，value是ConnectionHolder（内含数据库连接） private static final ThreadLocal&lt;Map&lt;Object, Object&gt;&gt; resources = new NamedThreadLocal&lt;&gt;(\"Transactional resources\"); private static final ThreadLocal&lt;Set&lt;TransactionSynchronization&gt;&gt; synchronizations = new NamedThreadLocal&lt;&gt;(\"Transaction synchronizations\"); private static final ThreadLocal&lt;String&gt; currentTransactionName = new NamedThreadLocal&lt;&gt;(\"Current transaction name\"); private static final ThreadLocal&lt;Boolean&gt; currentTransactionReadOnly = new NamedThreadLocal&lt;&gt;(\"Current transaction read-only status\"); private static final ThreadLocal&lt;Integer&gt; currentTransactionIsolationLevel = new NamedThreadLocal&lt;&gt;(\"Current transaction isolation level\"); private static final ThreadLocal&lt;Boolean&gt; actualTransactionActive = new NamedThreadLocal&lt;&gt;(\"Actual transaction active\");&#125; 事务性资源是存储在Map&lt;Object, Object&gt;里，key就是DataSource对象，value就是ConnectionHolder对象，那么是怎么知道key和value的类型的呢？往下看会看到map的put操作 事务同步这个集合Set，只有在多个数据源的分布式事务时才使用。 剩下的是四个和事务相关的变量，事务名称/是否只读/隔离级别/是否激活。 此处重点关注叫resources 的ThreadLocal变量，该变量一个Map，key是DataSource对象，value是ConnectionHolder对象，那么这就意味着每个线程在同一个数据源上只能获取一个连接绑定到这个变量中 TransactionSynchronizationManager.getResource(obtainDataSource())这一句执行完如果能够获取到一个连接说明什么？说明当前已经有一个逻辑事务获取了同一个数据源的连接并绑定到了map中，说明现在正在获取的逻辑事务在另一个逻辑事务之中。 如果没有事务嵌套的话，这一句代码执行获取到的肯定是null。 2.2.4 handleExistingTransaction获取事务对象之后，继续往下将执行isExistingTransaction()方法，该方法判断获取到的事务对象是否已经存在 12345protected boolean isExistingTransaction(Object transaction) &#123; DataSourceTransactionObject txObject = (DataSourceTransactionObject) transaction; return (txObject.hasConnectionHolder() &amp;&amp; txObject.getConnectionHolder().isTransactionActive());&#125; 这里主要是检查事务对象中是否设置了ConnectionHolder，并判断该物理事务是不是已经被激活。 如果此方法返回true，表明当前获取到的物理事务已经存在，从而表明此处肯定存在逻辑事务的嵌套，这时候应该根据配置的事务传播属性来进行处理，handleExistingTransaction处理逻辑如下： 如果此时事务传播特性是NEVER，则抛出异常。（never表示以非事务的方式执行，存在事务则抛异常） 如果此时事务的传播特性是NOT_SUPPORTED，则调用suspend(transaction)挂起当前事务，将被挂起的资源suspendedResources放入事务状态里。（not_supported表示以非事务方式运行，若存在事务则挂起事务） 如果此时事务状态是REQUIRES_NEW，则调用suspend(transaction)挂起当前事务，将事务对象transaction和被挂起的资源suspendedResources放入事务状态里。然后调用doBegin(transaction, definition)方法去真正打开事务。最后调用prepareSynchronization(status, definition)方法准备一下事务同步。 如果此时事务的传播特性是NESTED，又分三种情况： 如果不允许嵌套事务，直接抛出异常。 如果使用保存点（Savepoint）来实现嵌套事务，那直接使用当前事务，创建一个保存点就可以了。 如果使用新的事务来实现嵌套事务，那就调用doBegin(transaction, definition)开启新的事务，此时不需要挂起当前事务。 对于剩下三种传播特性REQUIRED/MANDATORY/SUPPORTS，则不需要创建新事务，直接使用当前事务就可以了。 2.2.5 dobegin()上面也分析了，在首次执行事务方法时，事务肯定是不存在的，因为从线程的ThreadLocal里没有取出ConnectionHolder对象。那此时就要新开一个物理事务，新开物理事务是在doBegin()方法中进行的： 123456789101112131415161718192021222324252627282930313233343536373839protected void doBegin(Object transaction, TransactionDefinition definition) &#123; DataSourceTransactionObject txObject = (DataSourceTransactionObject) transaction; Connection con = null; try &#123; // 若事务对象没有绑定物理资源 或者 持有的物理资源还没有和事务对象同步 if (!txObject.hasConnectionHolder() || txObject.getConnectionHolder().isSynchronizedWithTransaction()) &#123; // 创建新连接，封装成物理资源赋值给事务对象 Connection newCon = obtainDataSource().getConnection(); txObject.setConnectionHolder(new ConnectionHolder(newCon), true); &#125; txObject.getConnectionHolder().setSynchronizedWithTransaction(true); con = txObject.getConnectionHolder().getConnection(); Integer previousIsolationLevel = DataSourceUtils.prepareConnectionForTransaction(con, definition); txObject.setPreviousIsolationLevel(previousIsolationLevel); // 若物理连接开启了自动提交（默认开启） if (con.getAutoCommit()) &#123; txObject.setMustRestoreAutoCommit(true); // 存储物理连接的自动提交状态 con.setAutoCommit(false); // 关闭物理连接自动提交 &#125; prepareTransactionalConnection(con, definition); // 激活物理事务 txObject.getConnectionHolder().setTransactionActive(true); ... // 将物理事务绑定到ThreadLocal变量，这里是map的put操作 if (txObject.isNewConnectionHolder()) &#123; TransactionSynchronizationManager.bindResource (obtainDataSource(), txObject.getConnectionHolder()); &#125; &#125;catch (Throwable ex) &#123; if (txObject.isNewConnectionHolder()) &#123; DataSourceUtils.releaseConnection(con, obtainDataSource()); txObject.setConnectionHolder(null, false); &#125; throw new CannotCreateTransactionException( \"Could not open JDBC Connection for transaction\", ex); &#125;&#125; 新事务开启之后，继续回到getTransaction()方法，这个方法返回的是一个事务状态对象，继续看返回值创建的代码： 12345678910protected DefaultTransactionStatus newTransactionStatus( TransactionDefinition definition, @Nullable Object transaction, boolean newTransaction, boolean newSynchronization, boolean debug, @Nullable Object suspendedResources) &#123; boolean actualNewSynchronization = newSynchronization &amp;&amp; !TransactionSynchronizationManager.isSynchronizationActive(); return new DefaultTransactionStatus( transaction, newTransaction, actualNewSynchronization, definition.isReadOnly(), debug, suspendedResources);&#125; 这个对象有很重要的三点： 它需要包含逻辑事务对象（已关联了物理事务）。 它需要表明这个事务是一个新开启的物理事务，还是参与到已有的物理事务。 它需要包含被挂起的（上一个）物理事务连接（如果有的话）。 2.3 物理事务与逻辑事务的对应关系 当事务A调用事务B并且传播属性允许两个逻辑事务合并时，用一个物理事务执行就可以执行两个逻辑事务，此时物理事务与逻辑事务是1对多的关系。 事务A中调用事务B，B的传播属性为Propagation.REQUIRES_NEW，物理事务与逻辑事务是1对1的关系 不存在1个逻辑事务对应多个物理事务的情况。 2.4 事务的挂起在一些事务的传播模式下，可能会挂起当前的事务，举例： 事务A中调用事务B，B的传播属性为Propagation.REQUIRES_NEW，这时候需要将事务A挂起，创建事务B运行，创建事务B的时候会将挂起的事务A资源放到事务B的TransactionStatus对象中，事务B结束（提交或回滚）之后，恢复事务A继续执行 挂起做了哪些工作？ 12345protected Object doSuspend(Object transaction) &#123; DataSourceTransactionObject txObject = (DataSourceTransactionObject) transaction; txObject.setConnectionHolder(null); return TransactionSynchronizationManager.unbindResource(obtainDataSource());&#125; 将事务对象中的ConnectionHolder清空 将ThreadLocal中的数据源对应的ConnectionHolder清除，并返回被清除的ConnectionHolder 将返回的ConnectionHolder封装成SuspendedResourcesHolder，保存到创建的新事务对象中 为什么要这么做？ ThreadLocal资源虽然是一个map，但是这个map的数据源是key，这意味着每个线程在同一个数据源上只能使用一个连接（可以持有多个连接，但同一时间只能使用一个，单线程）。事务A在挂起的时候将物理连接保存起来，然后事务B再重新获取一个连接执行操作，事务B结束之后，再取出事务A对应的物理资源，继续执行事务A。 因此可以得出结论：逻辑事务没有结束之前，对应的物理事务是不能执行其他事务操作的，物理事务上应该是保存了事务的状态信息（未提交），不能串着用 https://mp.weixin.qq.com/s/i0QmrEDZ6aTsZFFahYC_ow https://mp.weixin.qq.com/s/sysm3AY7PG9MV9584UTasg","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/tags/SpringBoot/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/categories/SpringBoot/"}]},{"title":"redis-高可用架构集解析","slug":"redis-高可用架构解析","date":"2020-06-01T16:00:00.000Z","updated":"2021-01-26T00:54:04.243Z","comments":true,"path":"2020/06/02/redis-高可用架构解析/","link":"","permalink":"https://zzkenyon.github.io/2020/06/02/redis-高可用架构解析/","excerpt":"","text":"目标： 1、掌握redis主从复制的配置和原理 2、掌握redis哨兵机制的原理和实战 3、掌握redis分布式的各种方案对比，包括客户端sharding、代理Proxy、和redis cluster 为什么要分布式部署redis？ 在分布式环境下，任何组件都要保证以下三点 性能 高可用 可扩展 要做到以上三点需要依赖两种关键技术，一种是分片，一种是冗余。 分片就是把所有数据拆分到多个节点存储。 冗余就是在每个节点都有一个或者多个副本。 那么redis必须要提供数据分片和主从复制的功能，副本有不同的角色，如果主节点发生故障，则把某个从节点自动升级为主节点 所以本文主要围绕三点进行讨论： 1、主从复制怎么实现 2、主从切换怎么实现 3、数据分片怎么实现 1、redis主从复制跟kafka、rocketmq等分布式组件一样，redis支持集群架构，集群的节点有主从之分，主节点叫master，从节点叫slave。slave会通过复制技术，自动同步master的数据 1.1 主从复制配置redis的主从复制配置非常简单，有三种方式， 第一种：只需要在从节点的配置文件redis.conf中添加一行配置： 1replicaof ip port 从节点启动之后，就会自动的连接到master节点开始同步数据。 如果master节点宕机了，选举出了新的master，这个配置在内存中会被重写。 第二种方式，就是在启动redis服务时通过参数指定master节点： 1./redis-server --slaveof ip port 一个正在运行中的节点，也可以变成其他节点的从节点，这就是第三种方式：在客户端执行命令 1slaveof ip port 需要注意的是，一个从节点也可以是其他从节点的主节点，形成级联复制的关系。 通过以下命令查看集群状态： 1redis&gt; info replication 从节点是只读的，不能执行写操作，执行写命令会报错： 1（error）READONLY 在主节点写入后，slave会自动从master同步数据 从节点也可以改变从属关系，自己单飞 将redis.conf中的replica of配置去掉并重启，或者在客户端直接断开复制： 1redis&gt; slaveof no one MySql的主从复制原理我们是清楚地，依赖binglog文件，然后还有几个线程。那么redis呢？ 接下来研究主从复制到底是怎么实现的 1.2 主从复制原理主从复制分为两类：全量复制 和 增量复制。 全量复制就是一个从节点第一次连接到主节点，需同步全部的数据； 增量复制就是从节点网络断开了或者宕机了，重启之后缺了一部分数据需要同步。 1.2.1 连接阶段​ 1、slave节点启动时，或者执行slaveof命令是，会在自己本地保存master节点的信息，包括master 节点的host和port ​ 2、slave节点内部有个定时任务replicationCron，每隔1秒检查是否有新的master节点要连接和复制，见源码replication.c 3132line ​ 如果发现有master节点，就跟master节点建立连接，如果连接成功，从节点就为连接，为了让主节点感知到slave节点的存活，从节点会定时给主节点发送ping请求 ​ 建立连接之后就可以同步数据了，这里分为两个阶段 1.2.2 数据同步阶段​ 如果是新加入的slave节点，那就需要全量复制。master通过bgsave命令在本地生成一份RDB快照文件，将快照发给slave节点（如果超时会重连，可以调大repl-timeout的值） ​ 问题：如果slave节点自己本来有数据怎么办？ ​ slave节点首先需要清除自己的旧数据，然后用RDB文件加载数据。 ​ 问题：master节点生成RDB期间，接收到的写命令怎么处理？ ​ 开始生成快照文件是，master会把所有的新命令缓存在内存中。在slave节点保存了RDB之后，再将新的写命令复制给slave节点（跟AOF重写rewrite期间接收到的命令处理思路是一样的） ​ 第一次全量同步完了，主从已经保持一致了，后面的就是持续把接收到的命令发送给slave节点。 1.2.3 命令传播阶段​ 主节点持续吧命令异步复制给从节点。 ​ 总结起来很简单，前面用RDB文件，后面把命令发给slave节点，就实现了主从复制。 ​ 注意：一般情况下我们不会用redis做读写分离，因为redis的吞吐量已经够高了，做集群分片之后并发问题更少，所以不需要考虑主从延迟的问题 ​ 与Mysql一样，主从复制延迟是不可避免的，只能通过优化网络来改善 ​ 第二种情况：增量复制 ​ slave通过master_repl_offset记录的偏移量，来记录上次复制到哪里，用命令 1redis&gt;info replication 可以查看到这个偏移量属性。 redis从2.8.18版本开始支持无盘复制 1repl-diskless-sync=no 为了降低主节点的磁盘开销，Redis支持无盘复制，master生成的RDB文件不保存到磁盘而是直接通过网络发送给从节点。无盘复制适用于主节点所在的机器磁盘性能较差但是带宽比较充裕的的场景。 1.3 主从复制的不足redis主从复制解决了数据备份和一部分性能的问题，但是没有解决高可用的问题，在一主一从或者一主多从的情况下，如果主服务器挂了，对外提供的服务就不可用了，单点问题没有得到解决。 如果每次都是手动把之前的从服务切换成主服务器，然后把剩余节点设置成它的从节点，太费时费力，还会造成一定时间服务器不可用。 2、可用性保证之哨兵Sentinel配置和使用：https://www.jianshu.com/p/06ab9daf921d 2.1 Sentinel原理怎么实现高可用呢？ 对于服务起来说，能够实现主从自动切换 对于客户端来说，能够获取最新的master 要实现以上两点，我们就必须引入一个第三方来管理redis节点的存活状态，而且具备路由功能，例如rocketmq的nameserver 思路： 创建一台监控服务器监控所有的redis服务节点的状态，比如，master节点超过一定时间没有给监控服务发送心跳报文，就将master下线，然后把某一个slave提升为master。应用每一次都是从这个监控服务器拿到master地址的。 问题：如果监控服务器出问题怎么办，那还要创建一个监控服务器来监控监控服务器吗。。。这似乎陷入了死循环。 redis的高可用是通过哨兵Sentinel来保证的。它的思路就是通过运行监控服务器来保证服务的可用性。 从redis2.8开始，redis就提供了一个稳定版本的Sentinel来解决高可用问题。 我们一般会启动奇数个的Sentinel服务 用脚本启动 1./redis-sentinel ../sentinel.con 或者 1./redis-server ../sentinel.con --sentinel 它本质上是一个运行在特殊模式下的redis。Sentinel通过info命令得到被监听Redis机器的master，slave信息。 为了保证可用性，会对Sentinel做集群部署。Sentinel既监控所有的Redis服务，Sentinel之间也会互相监控。 注意：Sentinel本身没有主从之分 问题：Sentinel之间唯一的联系就是他们监控相同的redis节点，那他们怎么知道相互之间存在的？ 答案是使用redis的发布订阅功能： Sentinel上线时，给所有的Redis节点的__sentinel__:hello频道（channel）发送消息； 每个Sentinel节点都订阅了所有redis节点的__sentinel__:hello频道，所以能互相感知对方的存在。 2.1.1 服务下线问题：Sentinel如何感知master下线了？ Sentinel默认每秒1次的频率向Redis服务节点发送Ping命令，如果指定时间没有收到回复（默认30秒。可配置）Sentinel将该节点标记为下线（主观下线） 时间配置： 1sentinel down-after-milliseconds &lt;master-name&gt; &lt;milliseconds&gt; 但是，自己发现master下线不能代表真的下线，万一是你自己网络问题呢，这时候Sentinel会询问其他的Sentinel节点，确认是否真的下线，如果多数Sentinel节点都认为该master下线了，那才真的下线（客观下线） 确认下线后，要重新选举master 2.1.2 故障转移redis的选举和故障转移都是由Sentinel完成的。 问题：有这么多的Sentinel节点，谁来做呢？ 故障转移的第一步就是在Sentinel集群选择一个Leader，由Leader完成故障转移流程、Sentinel通过Raft算法，实现leader选举。 问题：那么Sentinel leader又是根据什么来选举redis的呢？ 对于所有的slave节点，一共有四个因素会影响选举的结果，分别是断开连接时长，优先级排序，复制数量和进程id 如果节点与哨兵连接断开的比较久，超过某个阈值，直接失去选举权 有选举权，再看谁的优先级高，这个在配置文件中可以配置（replica-priority 100），数字越小优先级越大 优先级相同，比较谁的偏移量大 最后再比较谁的进程id小 master节点确定之后，要将其他的节点设置为他的从节点， Sentinel leader向master节点发送命令 slaveof no one 再向其他节点发送slaveof ip port，让他成为主节点的从节点，故障转移完成。 2.2 Sentinel功能总结监控：Sentinel会不断检查节点是否正常运行 通知：若某节点被监控到出问题，Sentinel会通过api发出通知 自动故障转移 配置管理：客户端只需要连接到Sentinel集群，就能获取当前redis集群的master 哨兵机制的不足： 主从切换过程会丢失数据，因为只有一个master 只能单点写，没有解决水平扩容 如果数据量非常大，这时候就要对redis进行数据分片 这时候我们需要多个master-slave的group ，把数据分布到不同的group中。 问题：怎么分片？分片后怎么路由？ 3、redis数据分片方案三种方案： 第一种：在客户端实现相关分片逻辑，例如用取模或者一致性哈希对key进行分片，查询和修改都先判断key路由 第二种：把做分片处理的逻辑抽取出来，运行一个独立的代理服务，客户端连接到这个代理服务，代理服务做请求的转发。 第三种：基于服务端实现。 3.1 客户端分片​ Jedis客户端中就支持分片功能，Jedis是Spring Boot 2.X版本之前默认的Redis客户端，RedisTemplate就是对Jedis的封装 3.1.1 ShardedJedis3.1.2 一致性hash算法把所有的哈希值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织。因为是环形空间，0和2^32-1是重叠的。 每个节点在哈希环上都有一个位置， 先对key进行hash，根据hash值落在环上的位置按照顺时针的方向找，找到第一个节点就将该key存入。 虚拟节点–解决节点分布不均匀的问题 jedis对一致性hash的实现： 12 3.2 代理分片典型的代理分区方案有： Twitter开源的Twemproxy 豌豆荚开源的codis 3.2.1 Twemproxy优点：比较稳定，可用性高 不足： 出现故障不能自动转移，架构复杂，需要借助其他组件实现高可用（LVS/HAProxy + Keepalived) 扩缩绒需要修改配置，不能实现平滑的扩缩绒 3.2.2 codis​ Codis是一个代理中间件，豌豆荚用GO语言开发，跟Mycat是一类的组件。 ​ 功能：客户端连接Codis和连接Redis没有区别 ​ 分片原理：Codis把所有的key分成了N个槽（例如1024），每个槽对应一个分组，一个分组对应一个或者一组Redis实例。Codis对key进行CRC32运算，得到一个32位的数字，然后模以N，得到余数，这个余数就是key对应的槽，槽能对应道redis节点，跟Mycat的先取模后范围思想类似。 ​ Codis的槽位映射关系是保存在proxy中的，如果要解决单点故障问题，Codis也要组集群部署，多个Codis节点要同步槽和节点映射关系需要运行一个zookeeper。 ​ 再新增节点的时候，可以为节点指定特定的槽位，Codis也提供了自动均衡策略。 ​ Codis不支持事务，其他一些命令也不支持 ​ 获取数据原理：以mget为例，在各个节点中获取到符合的key，然后在汇总到Codis中返回给客户端 ​ Codis是第三方提供的分布式解决方案，在官网的集群功能稳定前，Codis也得到了大量的应用。 3.3 redis cluster​ Redis Cluster是在Redis3.0的版本正式推出的，用来解决分布式的需求，同时也可以实现高可用。跟Codis不一样，它是去中心化的，客户端可以连接到任意一个可用的节点。 ​ 数据分片需要解决的问题： - 数据怎么相对均匀的分片 - 客户端怎么访问到相应的节点 - 重新分片的过程，怎么保证正常服务 3.3.1 架构Redis Cluster 可以看成由多个节点组成的数据集合。客户端不需要关注数据的子集到底存在哪个节点，只需要关注这个集合整体。 3.3.2 搭建3.3.3 数据分布使用虚拟槽位实现数据的分片 Redis创建了16384个槽（slot），每个redis group负责一定区间的slot 对象分布到Redis节点上时，对Key用CRC16算法计算再模以16384，得到slot值，数据落到负责该槽位的节点上。 集群的每个master节点都会维护自己负责的slot，用一个bit序列实现，比如：序列的第0位是1，代表第一个sloat由他负责，为0表示不负责。 查看key属于哪个slot： 1redis&gt;cluster keyslot zzk 问题：如何让相关的数据落到一个节点上？ 比如有些multi key操作是不能跨节点的， 在key里面加入{hash tag}即可。redis在计算slot时只会获取{}之间的字符串进行slot计算， 3.3.4 客户端重定向问题：客户端连接到那一台服务器？访问的数据不再当前节点上怎么办？ jedis等客户端会在本地维护一份slot–node的映射关系，大部分时候不需要重定向，所以叫smart jedis（需要客户端支持） 3.3.5 数据迁移问题：新增或下线了master节点，数据如何迁移？ 添加新节点： 1redis-cli --cluster add-node localip localport newip newport 新增的节点没有hash槽，不能分配数据，在原来任意一个节点上执行 1redis-cli --cluster reshard localip localport 输入需要分配的哈希槽的数量和哈希槽的来源节点 3.3.6 高可用和主从切换原理当slave发现自己的master变为FAIL状态时，会尝试进行Failover，以期成为新的master。由于挂掉的master可能有多个slave，从而存在slave竞争上岗的过程： slave发现自己的master变为Fail 将自己记录的集群currentEpoch+1，并广播FAILOVER_AUTH_REQUEST信息 其他节点收到该信息，只有master（其他group的master）响应，判断请求者的合法性，并发送FAILOVER_AUTH_ACK,，对每个epoch只发送一个一次ack 尝试failover的slaver收集FAILOVER_AUTH_ACK 超过半数后变成新的master 广播PONG通知其他集群节点。 总结：Redis Cluster既能实现主从角色分配，又能实现主从切换，相当于继承了Replication和Sentinel的功能 3.3.7 总结redis cluster特点： 无中心架构 数据按照slot存储分布在多个节点，节点间数据共享，可动态调整数据分布。 可扩展性，可线性扩展到1000个节点，官方推荐不超过1000个，节点可动态添加或删除 高可用性，部分节点不可用时，集群仍可用。通过增加slave做standby数据副本，能够实现故障自动failover，节点之间通过gossip协议贾环状态信息，用投票机制完成slave到master的角色提升 运维成本极低 深入理解Redis Cluster 那些年用过的Redis集群架构（含面试解析）","categories":[{"name":"noSql","slug":"noSql","permalink":"https://zzkenyon.github.io/categories/noSql/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://zzkenyon.github.io/tags/redis/"}],"keywords":[{"name":"noSql","slug":"noSql","permalink":"https://zzkenyon.github.io/categories/noSql/"}]},{"title":"SpringCloud-分布式事务Seate-AT","slug":"SpringCloud-分布式事务Seate-AT","date":"2020-05-16T16:00:00.000Z","updated":"2020-11-27T01:15:06.712Z","comments":true,"path":"2020/05/17/SpringCloud-分布式事务Seate-AT/","link":"","permalink":"https://zzkenyon.github.io/2020/05/17/SpringCloud-分布式事务Seate-AT/","excerpt":"","text":"Seata 是一款开源的分布式事务解决方案，致力于在微服务架构下提供高性能和简单易用的分布 式事务服务。在 Seata 开源之前，Seata 对应的内部版本在阿里经济体内部一直扮演着分布式一 致性中间件的角色，帮助经济体平稳的度过历年的双11，对各BU业务进行了有力的支撑。经过多 年沉淀与积累，商业化产品先后在阿里云、金融云进行售卖。2019.1 为了打造更加完善的技术生 态和普惠技术成果，Seata 正式宣布对外开源，未来 Seata 将以社区共建的形式帮助其技术更加 可靠与完备。 Seata 将 为用户提供了 AT、TCC、SAGA 和 XA 事务模式，为用户打造一站式的分布式解决方案。 1、基本流程Seata AT模式实际上是2PC协议的一种演变方式，也是通过两个阶段的提交或者回滚来保证多节点事务的一致性。 第一个阶段， 应用系统会把一个业务数据的事务操作和回滚日志记录在同一个本地事务中提交， 在提交之前，会向TC(seata server)注册事务分支，并申请针对本次事务操作的表的全局锁。 接着提交本地事务，本地事务会提交业务数据的事务操作以及UNDO_LOG，放在一个事务中提交。 第二个阶段，这一个阶段会根据参与到同一个XID下所有事务分支在第一个阶段的执行结果来决定事务的提交或者回滚，这个回滚或者提交是TC来决定的，它会告诉当前XID下的所有事务分支，提交或者回滚。 如果是提交， 则把提交请求放入到一个异步任务队列，并且马上返回提交成功给到TC，这样可以避免阻塞问题。而这个异步任务，只需要删除UNDO_LOG就行，因为原本的业务事务已经提交了。 如果是回滚，则开启一个本地事务，执行以下操作 通过XID和Branch ID查找到响应的UNDO_LOG记录 数据校验，拿到UNDO_LOG中after image(修改之后的数据)和当前数据进行比较， 如果有不同，说明数据被当前全局事务之外的动作做了修改，这种情况需要根据配置策略来做处理。 根据UNDO_LOG中的before image和业务SQL的相关信息生成并执行回滚语句 提交本地事务，并把本地事务的执行结果上报给TC 2、基本使用seata提供了各种环境中使用的样例，本文样例基于spring-cloud-alibaba 2.1 seata server部署下载seata-server seata-server 修改配置文件 12345678910registry &#123; # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type = &quot;nacos&quot; nacos &#123; serverAddr = &quot;localhost&quot; namespace = &quot;piblic&quot; cluster = &quot;default&quot; &#125;&#125; 在实际中遇到问题，注册到nacos上时，默认获取到的是虚拟ip，不能跨网段访问，最终使用file方式配置。 12 2.2 seata client端配置遇到的各种问题汇总： 1、【服务ip不稳定问题】使用dubbo作为微服务框架，服务注册时获取到的是ip地址是127.0.0.1，导致服务间不能互相调用 2、【seata-server注册到nacos，ip不稳定】发布的总是虚拟网段的ip地址，导致外域的服务不能访问seata-server 3、没有配置dubbo.scan属性，导致服务不能被dubbo发布 4、服务超时事件配置太短（或者没有配置），导致在一个调用链总是超时失败 5、数据库配置不正确，导致工程启动总是报一个错误：关键字importRegister 2.3 AT运行原理AT模式属于强一致事务模型，工作时离不开几个表： 3.1 undo_log12345678910111213CREATE TABLE undo_log( id BIGINT(20) NOT NULL AUTO_INCREMENT, branch_id BIGINT(20) NOT NULL, xid VARCHAR(100) NOT NULL, context VARCHAR(128) NOT NULL, rollback_info LONGBLOB NOT NULL, log_status INT(11) NOT NULL, log_created DATETIME NOT NULL, log_modified DATETIME NOT NULL, PRIMARY KEY (id), UNIQUE KEY ux_undo_log (xid, branch_id)) ENGINE = InnoDB AUTO_INCREMENT = 1 DEFAULT CHARSET = utf8; 该表每个业务库需要有一个，用于记录全局事务在提交之前，当前库的事务分支的处理前后的现场 3.2 三表global_table 存储全局事务 branch_table 存储事务分支 lock_table 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849-- -------------------------------- The script used when storeMode is 'db' ---------------------------------- the table to store GlobalSession dataCREATE TABLE IF NOT EXISTS `global_table`( `xid` VARCHAR(128) NOT NULL, `transaction_id` BIGINT, `status` TINYINT NOT NULL, `application_id` VARCHAR(32), `transaction_service_group` VARCHAR(32), `transaction_name` VARCHAR(128), `timeout` INT, `begin_time` BIGINT, `application_data` VARCHAR(2000), `gmt_create` DATETIME, `gmt_modified` DATETIME, PRIMARY KEY (`xid`), KEY `idx_gmt_modified_status` (`gmt_modified`, `status`), KEY `idx_transaction_id` (`transaction_id`)) ENGINE = InnoDB DEFAULT CHARSET = utf8;-- the table to store BranchSession dataCREATE TABLE IF NOT EXISTS `branch_table`( `branch_id` BIGINT NOT NULL, `xid` VARCHAR(128) NOT NULL, `transaction_id` BIGINT, `resource_group_id` VARCHAR(32), `resource_id` VARCHAR(256), `branch_type` VARCHAR(8), `status` TINYINT, `client_id` VARCHAR(64), `application_data` VARCHAR(2000), `gmt_create` DATETIME(6), `gmt_modified` DATETIME(6), PRIMARY KEY (`branch_id`), KEY `idx_xid` (`xid`)) ENGINE = InnoDB DEFAULT CHARSET = utf8; -- the table to store lock data CREATE TABLE IF NOT EXISTS `lock_table`( `row_key` VARCHAR(128) NOT NULL, `xid` VARCHAR(96), `transaction_id` BIGINT, `branch_id` BIGINT NOT NULL, `resource_id` VARCHAR(256), `table_name` VARCHAR(32), `pk` VARCHAR(36), `gmt_create` DATETIME, `gmt_modified` DATETIME, PRIMARY KEY (`row_key`), KEY `idx_branch_id` (`branch_id`) ) ENGINE = InnoDB DEFAULT CHARSET = utf8; http://www.iocoder.cn/Dubbo/Seata/?self 3、事务隔离那这种事务的隔离级别是什么样的呢?我们在学习数据库的事务特性时，必须会涉及到的就是事务的隔 离级别，不同的隔离级别，会产生一些并发性的问题，比如 脏读 – A事务读到B事物update后未提交的数据，B事务回滚后，A读到的数据是脏数据 不可重复读 – A事务在第一次读后，B事务修改了数据，A事务继续第二次读，两次数据不一致 幻读 –与脏读类似，脏读针对的是同一条记录的更新，幻读是范围数据多了或少了 我们知道mysql的数据库隔离级别有4种 读未提交 RU – 会出现所有读一致性问题 读已提交 RC – 解决了脏读 可重复读 RR –解决了不可重复度 序列化读 3.1 写隔离所谓的写隔离，就是多个事务对同一个表的同一条数据做修改的时候，需要保证对于这个数据更新操作的隔离性，在传统事务模型中，我们一般是采用锁（LBCC）的方式来实现。 那么在分布式事务中，如果存在多个全局事务对于同一个数据进行修改，为了保证写操作的隔离，也需要通过一种方式来实现隔离性，自然也是用到锁的方法，具体来说。 在第一阶段本地事务提交之前，需要确保先拿到全局锁，如果拿不到全局锁，则不能提交本地事务 拿到全局锁的尝试会被限制在一定范围内，超出范围会被放弃并回滚本地事务并释放本地锁。 举一个具体的例子，假设有两个全局事务tx1和tx2，分别对a表的m字段进行数据更新操作，m的初始 值是1000。 tx1先开始执行，按照AT模式的流程，先开启本地事务，然后更新m=1000-100=900。在本地事务 更新之前，需要拿到这个记录的全局锁。 如果tx1拿到了全局锁，则提交本地事务并释放本地锁。 接着tx2后开始执行，同样先开启本地事务拿到本地锁，并执行m=900-100的更新操作。在本地事 务提交之前，先尝试去获取这个记录的全局锁。而此时tx1全局事务还没提交之前，全局锁的持有 者是tx1，所以tx2拿不到全局锁，需要等待 接着, tx1在第二阶段完成事务提交或者回滚，并释放全局锁。此时tx2就可以拿到全局锁来提交本地事务。 如果tx1的第二阶段是全局回滚，则tx1需要重新获取这个数据的本地锁， 然后进行反向补偿更新实现事务分支的回滚。此时，如果tx2仍然在等待这个数据的全局锁并且同时持有本地锁，那么tx1的分支事务回滚会失败，分支的回滚会一直重试直到tx2的全局锁等待超时，放弃全局锁并回滚本地事务并释放本地锁之后，tx1的 分支事务才能最终回滚成功。 由于在整个过程中, 全局锁在tx1结束之前一直被tx1持有，所以并不会发生脏写问题。 3.2 读隔离在数据库本地事务隔离级别 读已提交（Read Committed） 或以上的基础上，Seata（AT 模式）的默认全局隔离级别是 读未提交（Read Uncommitted） 。 如果应用在特定场景下，必需要求全局的 读已提交 ，目前 Seata 的方式是通过 SELECT FOR UPDATE 语句的代理。 SELECT FOR UPDATE 语句的执行会申请 全局锁 ，如果 全局锁 被其他事务持有，则释放本地锁（回滚 SELECT FOR UPDATE 语句的本地执行）并重试。这个过程中，查询是被 block 住的，直到 全局锁 拿到，即读取的相关数据是 已提交 的，才返回。 出于总体性能上的考虑，Seata 目前的方案并没有对所有 SELECT 语句都进行代理，仅针对 FOR UPDATE 的 SELECT 语句。","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/tags/SpringCloud/"}],"keywords":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}]},{"title":"分库分表-mycat升华","slug":"数据库技术-Mycat-mycat升华","date":"2020-05-13T16:00:00.000Z","updated":"2020-11-15T09:47:43.376Z","comments":true,"path":"2020/05/14/数据库技术-Mycat-mycat升华/","link":"","permalink":"https://zzkenyon.github.io/2020/05/14/数据库技术-Mycat-mycat升华/","excerpt":"","text":"目标： 1、读写分离 2、XA事务 3、总计架构流程分析","categories":[{"name":"数据库技术","slug":"数据库技术","permalink":"https://zzkenyon.github.io/categories/数据库技术/"}],"tags":[{"name":"Mycat","slug":"Mycat","permalink":"https://zzkenyon.github.io/tags/Mycat/"}],"keywords":[{"name":"数据库技术","slug":"数据库技术","permalink":"https://zzkenyon.github.io/categories/数据库技术/"}]},{"title":"分库分表-mycat进阶","slug":"数据库技术-Mycat-mycat进阶","date":"2020-05-11T16:00:00.000Z","updated":"2020-11-15T09:48:00.763Z","comments":true,"path":"2020/05/12/数据库技术-Mycat-mycat进阶/","link":"","permalink":"https://zzkenyon.github.io/2020/05/12/数据库技术-Mycat-mycat进阶/","excerpt":"","text":"目标： 1、掌握不同数据分片策略的配置方式与特点 2、Mycat扩缩容与数据导入导出 3、理解Mycat注解的作用于应用场景 1. 分片策略详解1.1 Mycat分片策略详解总体上分为连续分片和离散分片，还有一种是连续分片和离散分片的结合，例如先范围后取模。比如范围分片(id 或者时间)就是典型的连续分片，单个分区的数量和边 界是确定的。离散分片的分区总数量和边界是确定的，例如对 key 进行哈希运算，或者再取模。 1.1.1 连续分片缺点：会出现冷热数据，热数据分布在同一个节点，分库没有起到分摊数据访问压力的作用。 示例1：按自然月分片123CREATE TABLE `sharding_by_month` ( `create_time` timestamp NULL DEFAULT NULL ON UPDATE CURRENT_TIMESTAMP, `db_nm` varchar(20) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8; mycat配置： 1&lt;table name=\"sharding_by_month\" dataNode=\"72-imall,74-imall,76-imall\" rule=\"pd-sharding-by-month\" /&gt; 分片规则： 123456&lt;tableRule name=\"pd-sharding-by-month\"&gt; &lt;rule&gt; &lt;columns&gt;create_time&lt;/columns&gt; &lt;algorithm&gt;pd-partbymonth&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt; 分片算法： 12345&lt;function name=\"pd-partbymonth\" class=\"io.mycat.route.function.PartitionByMonth\"&gt; &lt;property name=\"dateFormat\"&gt;yyyy-MM-dd&lt;/property&gt; &lt;property name=\"sBeginDate\"&gt;2025-10-01&lt;/property&gt; &lt;property name=\"sEndDate\"&gt;2025-12-31&lt;/property&gt;&lt;/function&gt; columns 标识将要分片的表字段，字符串类型，与 dateFormat 格式一致。 algorithm 为分片函数。 dateFormat 为日期字符串格式 sBeginDate 为开始日期。 sEndDate 为结束日期 注意：节点个数要大于月份的个数 测试语句： 1234567truncate table sharding_by_month;INSERT INTO sharding_by_month (create_time,db_nm) VALUES ('2024-10-16', database()); INSERT INTO sharding_by_month (create_time,db_nm) VALUES ('2025-10-27', database()); INSERT INTO sharding_by_month (create_time,db_nm) VALUES ('2026-11-04', database()); INSERT INTO sharding_by_month (create_time,db_nm) VALUES ('2027-11-11', database()); INSERT INTO sharding_by_month (create_time,db_nm) VALUES ('2029-12-25', database()); INSERT INTO sharding_by_month (create_time,db_nm) VALUES ('2030-12-31', database()); 注意：以上跟年度没有关系，只跟月度有关。 问题：不在 10 月和 12 月之间的数据，路由到哪个节点？结果不一定。可以在本地 调试一下。 另外还有按天分片(可以指定多少天一个分片)、按小时分片 1.1.2 离散分片特点：分布很均匀，但是节点扩容需要迁移已分片的数据 示例1：十进制取模分片根据分片键进行十进制求模运算。sharding_by_mod 表。 123456&lt;tableRule name=\"mod-long\"&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;mod-long&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt; 1234&lt;function name=\"mod-long\" class=\"io.mycat.route.function.PartitionByMod\"&gt; &lt;!-- how many data nodes --&gt; &lt;property name=\"count\"&gt;3&lt;/property&gt;&lt;/function&gt; 测试数据： 1234567truncate table sharing_by_mod;INSERT INTO `sharding_by_mod` (`id`, `db_nm`) VALUES (1, '1'); INSERT INTO `sharding_by_mod` (`id`, `db_nm`) VALUES (2, '2'); INSERT INTO `sharding_by_mod` (`id`, `db_nm`) VALUES (3, '3'); INSERT INTO `sharding_by_mod` (`id`, `db_nm`) VALUES (4, '4'); INSERT INTO `sharding_by_mod` (`id`, `db_nm`) VALUES (5, '5'); INSERT INTO `sharding_by_mod` (`id`, `db_nm`) VALUES (6, '6'); 示例2：枚举分片，根据年龄将所有可能出现的值列举出来，指定分片。例如：全国 34 个省，要将不同的省的数 据存放在不同的节点，可用枚举的方式。 三个节点 imall 库创建 sharding_by_intfile 表 1234CREATE TABLE `sharding_by_intfile` (`age` int(11) NOT NULL,`db_nm` varchar(20) DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8; 逻辑表： 1&lt;table name=\"sharding_by_intfile\" dataNode=\"72-imall,74-imall,76-imall\" rule=\"pd-sharding-by-intfile\" /&gt; 分片规则： 123456&lt;tableRule name=\"pd-sharding-by-intfile\"&gt; &lt;rule&gt; &lt;columns&gt;age&lt;/columns&gt; &lt;algorithm&gt;hash-int&lt;/algorithm&gt; &lt;/rule&gt; &lt;/tableRule&gt; 分片算法： 12345&lt;function name=\"hash-int\" class=\"org.opencloudb.route.function.PartitionByFileMap\"&gt; &lt;property name=\"mapFile\"&gt;partition-hash-int.txt&lt;/property&gt; &lt;property name=\"type\"&gt;0&lt;/property&gt; &lt;property name=\"defaultNode\"&gt;0&lt;/property&gt;&lt;/function&gt; type：默认值为 0，0 表示 Integer，非零表示 String。 PartitionByFileMap.java，通过 map 来实现。 策略文件：partition-hash-int.txt 12316=017=118=2 插入数据测试 1234truncate table sharding_by_intfile;INSERT INTO `sharding_by_intfile` (age,db_nm) VALUES (16, database()); INSERT INTO `sharding_by_intfile` (age,db_nm) VALUES (17, database()); INSERT INTO `sharding_by_intfile` (age,db_nm) VALUES (18, database()); 特点：适用于枚举值固定的场景。 示例3：一致性哈希分片一致性 hash 有效解决了分布式数据的扩容问题，可以一定程度减少数据的迁移。 建表语句： 分片规则 1234CREATE TABLE `sharding_by_murmur` ( `id` int(10) DEFAULT NULL, `db_nm` varchar(20) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8; 1&lt;table name=\"sharding_by_murmurhash\" primaryKey=\"id\" dataNode=\"72-imall,74-imall,76-imall\" rule=\"sharding-by-murmur\" /&gt; 分片规则： 123456&lt;tableRule name=\"pd-sharding-by-murmur\"&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;pd-murmur&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt; 分片算法 12345&lt;function name=\"pd-murmur\" class=\"io.mycat.route.function.PartitionByMurmurHash\"&gt; &lt;property name=\"seed\"&gt;0&lt;/property&gt; &lt;property name=\"count\"&gt;3&lt;/property&gt; &lt;property name=\"virtualBucketTimes\"&gt;160&lt;/property&gt;&lt;/function&gt; 测试语句： 123456789101112131415161718192021truncate table sharding_by_murmur;INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (1, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (2, database());INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (3, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (4, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (5, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (6, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (7, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (8, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (9, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (10, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (11, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (12, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (13, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (14, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (15, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (16, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (17, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (18, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (19, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (20, database()); 示例4：固定分片哈希这是先求模得到逻辑分片号，再根据逻辑分片号直接映射到物理分片的一种散列算法。 特点：在一定范围内 id 是连续分布的。 建表语句： 1234CREATE TABLE `sharding_by_long` ( `id` int(10) DEFAULT NULL,`db_nm` varchar(20) DEFAULT NULL); 逻辑表 1&lt;table name=\"sharding_by_long\" dataNode=\"72-imall,74-imall,76-imall\" rule=\"pd-sharding-by-long\" /&gt; 分片规则： 123456&lt;tableRule name=\"pd-sharding-by-long\"&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;pd-sharding-by-long&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt; 分片算法：平均分成 8片(%1024 的余数，1024=128*8) 1234&lt;function name=\"pd-sharding-by-long\" class=\"io.mycat.route.function.PartitionByLong\"&gt; &lt;property name=\"partitionCount\"&gt;8&lt;/property&gt; &lt;property name=\"partitionLength\"&gt;128&lt;/property&gt;&lt;/function&gt; partitionCount 为指定分片个数列表。 partitionLength 为分片范围列表。 如果要不均匀的分布到不同节点，那就如下： 1234&lt;function name=\"pd-sharding-by-long\" class=\"io.mycat.route.function.PartitionByLong\"&gt; &lt;property name=\"partitionCount\"&gt;2,1&lt;/property&gt; &lt;property name=\"partitionLength\"&gt;256,512&lt;/property&gt;&lt;/function&gt; 参数表示前2个节点分片长度256，第三个节点分片长度512 测试语句： 12truncate table sharding_by_long;INSERT INTO `sharding_by_long` (id,db_nm) VALUES (222, database()); INSERT INTO `sharding_by_long` (id,db_nm) VALUES (333, database()); INSERT INTO `sharding_by_long` (id,db_nm) VALUES (666, database()); 示例5：取模范围分片先对键取模，然后按照结果所在范围进行分片 特点：可以调整节点的数据分布，适合存储能力不同的节点组成的集群 节点扩容需迁移数据 建表： 1234CREATE TABLE `sharding_by_pattern` ( `id` varchar(20) DEFAULT NULL, `db_nm` varchar(20) DEFAULT NULL ); 逻辑表： 1&lt;table name=\"sharding_by_pattern\" primaryKey=\"id\" dataNode=\"72-imall,74-imall,76-imall\" rule=\"sharding-by-pattern\" /&gt; 分片规则： 123456&lt;tableRule name=\"sharding-by-pattern\"&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;sharding-by-pattern&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt; 分片算法： 12345&lt;function name=\"sharding-by-pattern\" class=\" io.mycat.route.function.PartitionByPattern\"&gt; &lt;property name=\"patternValue\"&gt;100&lt;/property&gt; &lt;property name=\"defaultNode\"&gt;0&lt;/property&gt; &lt;property name=\"mapFile\"&gt;partition-pattern.txt&lt;/property&gt;&lt;/function&gt; patternValue 取模基数，这里设置成 100 partition-pattern.txt，一共 3 个节点 123id=19%100=19，在 dn1; id=222%100=22，dn2;id=371%100=71，dn3 测试语句： 12truncate table sharding_by_pattern;INSERT INTO `sharding_by_pattern` (id,db_nm) VALUES (19, database()); INSERT INTO `sharding_by_pattern` (id,db_nm) VALUES (222, database()); INSERT INTO `sharding_by_pattern` (id,db_nm) VALUES (371, database()); 示例6：范围取模分片先范围后取模 特点：扩容的时候旧数据无需迁移 建表： 1234CREATE TABLE `sharding_by_rang_mod` ( `id` bigint(20) DEFAULT NULL,`db_nm` varchar(20) DEFAULT NULL); 逻辑表配置： 1&lt;table name=\"sharding_by_rang_mod\" dataNode=\"72-imall,74-imall,76-imall\" rule=\"pd-sharding-by-rang-mod\" /&gt; 分片规则： 123456&lt;tableRule name=\"pd-sharding-by-rang-mod\"&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;pd-rang-mod&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt; 分片算法： 123&lt;function name=\"pd-rang-mod\" class=\"io.mycat.route.function.PartitionByRangeMod\"&gt; &lt;property name=\"mapFile\"&gt;partition-range-mod.txt&lt;/property&gt;&lt;/function&gt; partition-range-mod.txt 123# range start-end ,data node group size0-20000=1 20001-40000=2 Id 在 20000 以内的，全部分布到 dn1。Id 在 20001-40000 的，%2 分布到 dn2,dn3。 测试语句： 123truncate table sharding_by_rang_mod;INSERT INTO `sharding_by_rang_mod` (id,db_nm) VALUES (666, database()); INSERT INTO `sharding_by_rang_mod` (id,db_nm) VALUES (6667, database()); INSERT INTO `sharding_by_rang_mod` (id,db_nm) VALUES (16666, database()); INSERT INTO `sharding_by_rang_mod` (id,db_nm) VALUES (21111, database()); INSERT INTO `sharding_by_rang_mod` (id,db_nm) VALUES (22222, database());INSERT INTO `sharding_by_rang_mod` (id,db_nm) VALUES (23333, database()); INSERT INTO `sharding_by_rang_mod` (id,db_nm) VALUES (24444, database()); 其他分片规则 应用指定分片 PartitionDirectBySubString 日期范围哈希 PartitionByRangeDateHash 冷热数据分片 PartitionByHotDate 也可以自定义分片规则： 1extends AbstractPartitionAlgorithm implements RuleAlgorithm。 1.1.3 连续和离散的特点连续分片优点： 范围查询消耗资源少，不需要汇总数据 扩容无需迁移数据 连续分片缺点： ​ 存在热点数据导致并发访问能力受限于单一或少量节点 离散分片优点： 并发访问能力强 范围条件查询性能提升（并行计算） 离散分片缺点： 数据扩容涉及数据迁移问题 数据库连接消耗大 1.1.4 切分规则的选择步骤： 找到需要切分的大表和关联的表 确定分片字段（尽量使用主键），一般用最频繁使用的查询条件 考虑单个分片的存储容量和请求、数据增长、扩容和数据迁移问题 问题： ​ 按照上面递增？序号还是日期？主键是否有业务意义？ 举例：3.7 亿的数据怎么分表？我是不是分成 3 台服务器？ 1、一年内到达多少？两年内到达多少？(数据的增长速度)？ 答：一台设备每秒钟往 3 张表各写入一条数据，一共 4 台设备。每张表一天86400*4=345600 条。每张表一个月 10368000 条。 分析：增长速度均匀，可以用日期切分，每个月分一张表。 2、什么业务？所有的数据都会访问，还是访问新数据为主？ 答：访问新数据为主，但是所有的数据都可能会访问到 3、表结构和表数据是什么样的？一个月消耗多少空间？ 答：字段不多，算过了，三年数据量有 3.7 亿，30G。 分析：30G 没必要分库，浪费磁盘空间。 4、访问量怎么样？并发压力大么？ 答：并发有一点吧 分析：如果并发量不大，不用分库，只需要在单库分表。不用引入 Mycat 中间件了。如果要自动路由的话可以用 Sharding-JDBC，否则就是自己拼装表名。 5、3 张表有没有关联查询之类的操作？ 答：没有。 分析：还是拼装表名简单一点。 如果从单库变成分库分表，或者节点数的增加和减少，都会涉及到数据迁移的问题。数据迁移有两种，一种是在线不停机的迁移，还有一种是停机的。 2. Mycat扩缩容2.1 在线扩缩容思路流程： 把历史数据通过中间件迁移到新库 新的写请求，发送到消息队列，不消费 数据迁移完毕，迁移程序下线 消费信息，将增量数据写入新库 数据一致性验证 旧数据下线，切换到新库，重启应用。 2.2 mysqldump方式系统第一次上线，把单张表迁移到 Mycat，可以用 mysqldump。 MySQL 导出命令 1mysqldump -uroot -p123456 -h127.0.0.1 -P3306 -c -t --skip-extended-insert imall &gt; mysql-1107.sql -c 代表带列名 -t 代表只要数据，不要建表语句 –skip-extended-insert 代表生成多行 insert(mycat childtable 不支持多行插入 ChildTable multi insert not provided) Mycat 导入命令 1mysql -uroot -p123456 -h127.0.0.1 -P8066 imall &lt; mysql-1107.sql 2.3 Mycat自带的离线扩缩容工具如果是已有分片表，可以用mycat自带的工具，实际上是对mysqldump进行了包装。 2.3.1 准备工作 mycat所在环境安装mysql客户端程序 mycat的lib目录下添加mysql的jdbc驱动包 对扩容表的所有节点数据进行备份，以便前以失败后的数据恢复。 2.3.2 步骤以取模分片表 sharding-by-mod 缩容为例。 时间 数据 迁移前数据 72-imall 3, 6 74-imall 1,4 76-imall 2,5 迁移后数据 72-imall 2,4,6 74-imall 1,3,5 1、复制 schema.xml、rule.xml 并重命名为 newSchema.xml、newRule.xml 放 于 conf 目录下。 2、修改 newSchema.xml 和 newRule.xml 配置文件为扩容缩容后的 mycat 配 置参数(表的节点数、数据源、路由规则)。 注意： 只有节点变化的表才会进行迁移。仅分片配置变化不会迁移。 newSchema.xml 1&lt;table name=\"sharding_by_mod\" dataNode=\"72-imall,74-imall,76-imall\" rule=\"pd-sharding-by-mod\" /&gt; 改成： 1&lt;table name=\"sharding_by_mod\" dataNode=\"72-imall,74-imall\" rule=\"pd-sharding-by-mod\" /&gt; newRule.xml 修改 count 个数 123&lt;function name=\"pd-sharding-by-mod-long\" class=\"io.mycat.route.function.PartitionByMod\"&gt; &lt;property name=\"count\"&gt;2&lt;/property&gt;&lt;/function&gt; 3、修改 conf 目录下的 migrateTables.properties 配置文件，告诉工具哪些表需 要进行扩容或缩容,没有出现在此配置文件的 schema 表不会进行数据迁移，格式： 1imall=sharding-by-mod 注意 1)不迁移的表，不要修改 dn 个数，否则会报错。 2)ER 表，因为只有主表有分片规则，子表不会迁移。 4、dataMigrate.sh 中这个必须要配置 通 过 命 令 “find / -name mysqldump” 查 找 mysqldump 路 径 为 “/usr/bin/mysqldump”，指定#mysql bin 路径为”/usr/bin/“ 12#mysql bin 路径RUN_CMD=\"$RUN_CMD -mysqlBin= /usr/bin/\" 5、停止 mycat 服务 6、执行执行 bin/dataMigrate.sh 脚本，注意：必须要配置 Java 环境变量，不能用 openjdk 7、脚本执行完成，如果最后的数据迁移验证通过，就可以将之前的 newSchema.xml 和 newRule.xml 替换之前的 schema.xml 和 rule.xml 文件，并重启 mycat 即可。 2.3.3 注意事项 保证分片表迁移数据前后路由规则一致(取模——取模)。 保证分片表迁移数据前后分片字段一致。 全局表将被忽略。 不要将非分片表配置到 migrateTables.properties 文件中。 暂时只支持分片表使用 MySQL 作为数据源的扩容缩容。 migrate 限制比较多，还可以使用 mysqldump。 总结：离线或者在线，主要看数据量，和对于业务的影响程度决定。 3. Mysql 主从复制用 mycat 实现了 MySQL 数据的分片存储，第一个可以实现负载 均衡，不同的读写发生在不同的节点上。第二可以实现横向扩展，如果数据持续增加， 加机器就 OK 了。 当然，一个分片只有一台机器还不够。为了防止节点宕机或者节点损坏，都要用副本机制来实现。MySQL 数据库同样可以集群部署，有了多个节点之后，节点之间数据又是个大问题。 3.1 主从复制的含义在 MySQL 多服务器的架构中，主节点，也就是产生数据的节点叫 master 节点。其 他的副本，向主节点同步数据的节点，叫做 slave(默认是异步的，客户端的数据在 master 刷盘就返回)。一个集群里面至少要有一个 master。slave 可以有多个。 3.2 主从复制的用途数据备份：把数据复制到不同的机器上，以免单台服务器发生故障时数据丢失。 负载均衡：结合负载的机制，均摊所有的应用访问请求，降低单机 IO。 高可用 HA：当节点故障时，自动转移到其他节点，提高可用性。 主从复制的架构可以有多种 3.3 主从复制的形式 一主一从/一主多从 双主复制(互为主从) 级联复制 不过在，MySQL 自身并没有自动选举和故障转移的功能，需要依赖其他的中间件或架构实现，比如 MMM，MHA，percona，mycat。 主从复制是怎么实现的呢？ 3.4 binlog客户端对 MySQL 数据库进行操作的时候，包括 DDL 和 DML 语句，服务端会在日 志文件中用事件的形式记录所有的操作记录，这个文件就是 binlog 文件(属于逻辑日志， 跟 Redis 的 AOF 文件类似)。Binary log，二进制日志。 基于 binlog，我们可以实现主从复制和数据恢复。 binlog 默认是不开启的，需要在服务端手动配置。注意有一定的性能损耗。 3.4.1 binlog配置编辑 /etc/my.cnf 12log-bin=/var/lib/mysql/mysql-bin server-id=1 重启 MySQL 服务 12345service mysqld stop service mysqld start## 如果出错查看日志 vi /var/log/mysqld.log cd /var/lib/mysql 是否开启 binlog 1show variables like 'log_bin%'; 3.4.2 binlog 格式STATEMENT：记录每一条修改数据的 SQL 语句(减少日志量，节约 IO)。 ROW：记录哪条数据被修改了，修改成什么样子了(5.7 以后默认)。 MIXED：结合两种方式，一般的语句用 STATEMENT，函数之类的用 ROW。 查看 binlog 格式： 1show global variables like '%binlog_format%'; Binlog 文件超过一定大小就会产生一个新的，查看 binlog 列表： 1show binary logs; 大小： 1show binlog events in 'mysql-bin.000001'; 用 mysqlbinlog 工具，基于时间查看 binlog (注意这个是 Linux 命令, 不是 SQL) 1/usr/bin/mysqlbinlog --start-datetime='2025-08-22 13:30:00' --stop-datetime='2025-08-22 14:01:01' -d gupao /var/lib/mysql/mysql-bin.000001 3.5 主从复制的原理3.5.1 主从复制配置 主库开启binlog，设置server-id 在主库创建具有复制权限的用户，允许从库连接 12GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'repl'@'10.0.12.77' IDENTIFIED BY '123456';FLUSH PRIVILEGES; 从库配置/etc/my.cnf ，并重启数据库 12345server-id=2 log-bin=mysql-bin relay-log=mysql-relay-bin read-only=1 log-slave-updates=1 开启log-slave-updates参数后，从库从主库复制的数据会写入从库的log-bin日志文件里，这样可以实现互为主备或者级联复制 在从库执行 123stop slave;change master to master_host='10.0.12.78',master_user='repl',master_password='123456',master_log_file='mysql-bin.00000 1', master_log_pos=4;start slave; 5、查看同步状态 1SHOW SLAVE STATUS \\G Slave_IO_Running 和 Slave SQL Running 都为 yes 为正常。 3.5.2 主从复制原理这里面涉及到几个线程： 1、slave 服务器执行 start slave，开启主从复制开关， slave 服务器的 IO 线程请 求从 master 服务器读取 binlog(如果该线程追赶上了主库，会进入睡眠状态)。 2、master 服务器创建 Log Dump 线程，把 binlog 发送给 slave 服务器。slave 服 务器把读取到的 binlog 日志内容写入中继日志 relay log(会记录位置信息，以便下次继 续读取)。 3、slave 服务器的 SQL 线程会实时检测 relay log 中新增的日志内容，把 relay log 解析成 SQL 语句，并执行。 为什么需要 relay log？为什么不把接收到的 binlog 数据直接写入从库？ 同步转异步，Relay log 相当于一个中转站，也记录了 master 和 slave 的同步信息。 3.5.3 mycat 读写分离配置添加： 12345678&lt;dataHost name=\"host122\" maxCon=\"1000\" minCon=\"10\" balance=\"0\"writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\" slaveThreshold=\"100\"&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=\"hostM1\" url=\"10.0.12.72:3306\" user=\"root\"password=\"123456\"&gt; &lt;readHost host=\"hostS1\" url=\"10.0.12.78:3306\" user=\"root\" password=\"123456\" /&gt; &lt;/writeHost&gt; &lt;/dataHost&gt;","categories":[{"name":"数据库技术","slug":"数据库技术","permalink":"https://zzkenyon.github.io/categories/数据库技术/"}],"tags":[{"name":"Mycat","slug":"Mycat","permalink":"https://zzkenyon.github.io/tags/Mycat/"}],"keywords":[{"name":"数据库技术","slug":"数据库技术","permalink":"https://zzkenyon.github.io/categories/数据库技术/"}]},{"title":"分库分表-mycat基础","slug":"数据库技术-Mycat-mycat基础","date":"2020-05-10T16:00:00.000Z","updated":"2020-11-15T09:48:08.797Z","comments":true,"path":"2020/05/11/数据库技术-Mycat-mycat基础/","link":"","permalink":"https://zzkenyon.github.io/2020/05/11/数据库技术-Mycat-mycat基础/","excerpt":"","text":"目标： 1、通过实际案例掌握 Mycat 特性与详细配置含义 2、了解 Mycat 监控与日志查看 1. Mycat 概念与配置1.1 Mycat介绍与核心概念1.1.1 基本介绍历史：从阿里 cobar 升级而来，由开源组织维护(兼职)。 定位：运行在应用和数据库之间，可以当做一个 MySQL 服务器使用(不论是在工具 还是在代码或者命令行中都可以直接连接)。实现对 MySQL 数据库的分库分表，也可以通过 JDBC 支持其他的数据库。 Mycat 的关键特性(官网首页) 可以当做一个 MySQL 数据库来使用 支持 MySQL 之外的数据库，通过 JDBC 实现 解决了我们提到的所有问题，多表 join、分布式事务、全局序列号、翻页排序 支持 ZK 配置，带监控 mycat-web(已经停止维护) 2.0 已经发布;文档许久没有更新 关键特性： 只是SQL92标准 支持MySQL、Oracle、DB2、SQL Server、PostgreSQL 遵守MySQL原生协议，跨语言，跨平台，跨数据库的通用中间件代理 基于心跳的自动故障切换，支持读写分离，支持MySQL主从模式，以及galera cluster集群 支持Galera for MySQL集群，Percona Cluster或者MariaDB Cluster 基于Nio实现，有效管理线程，解决高并发问题。 支持数据库的多片自动路由与聚合，支持sum/count/max等常用的聚合函数，支持跨库分页。 支持单库内部任意join，支持跨库2表join，甚至基于caltlet的夺标join 支持通过全局表，ER关系的分片策略，实现了搞笑的夺标join查询。 支持多租户方案。 支持分布式事务（弱xa） 支持XA分布式事务（1.6.5） 支持全局id，解决分布式下的主键生成问题 分片规则丰富，插件化开发，易于扩展。 1.1.2 核心概念 概念 含义 主机 物理主机，一台服务器，一个数据库服务，一个 3306 端口 物理数据库 真实的数据库，例如 146、150、151 的 gpcat 数据库 物理表 真实的表，例如 146、150、151 的 gpcat 数据库的 order_info 表 分片 将原来单个数据库的数据切分后分散存储在不同的数据库节点 分片节点 分片以后数据存储的节点 分片键 分片依据的字段，例如 order_info 表以 id 为依据分片,id 就是分片键，通常是主键 分片算法 分片的规则，例如随机、取模、范围、哈希、枚举以及各种组合算法 逻辑表 相对于物理表，是分片表聚合后的结果，对于客户端来说跟真实的表没有区别 逻辑数据库 相对于物理数据库，是数据节点聚合后的结果 一个逻辑表可以映射到多个节点的一张表(分片表)，也可以映射到一个节点的表 (非分片表)，也可以映射到一个节点的多张表(单库分表)。 下载、解压 Mycat(有 Windows 版本，可以在本地数据库测试) 1wget http://dl.mycat.org.cn/1.6.7.3/20190927161129/Mycat-server-1.6.7.3-release-20190927161129-linux.tar.gz tar -xzvf Mycat-server-1.6.7.3-release-20190927161129-linux.tar.gz Mycat 解压以后有 5 个目录 目录 作用 bin 启动目录 catlet 空目录 conf 配置目录 lib jar 包依赖 logs 日志目录 1.2 Mycat配置详解主要的配置文件 server.xml、schema.xml、rule.xml 和具体的分片配置文件。 坑非常多，配置错误会导致无法启动，这个时候要看 wrapper 日志! 文件一定要注意备份，不知道什么时候就跑不起来了…… 1.2.1 server.xml包含系统配置信息。 标签：例如字符集、线程数、心跳、分布式事务开关等等。 标签：配置登录用户和权限。 1234&lt;user name=\"root\" defaultAccount=\"true\"&gt; &lt;property name=\"password\"&gt;123456&lt;/property&gt; &lt;property name=\"schemas\"&gt;imall&lt;/property&gt;&lt;/user&gt; mycat 对密码加密： 1java -cp Mycat-server-1.6.7.3-release.jar io.mycat.util.DecryptUtil 0:root:123456 1.2.2 schema.xmlschema 在 MySQL 里面跟数据库是等价的。 schema.xml 包括逻辑库、表、分片规则、分片节点和数据源，可以定义多个 schema。 这里面有三个主要的标签(table、dataNode、dataHost) schema 在 MySQL 里面跟数据库是等价的。 表名和库名最好都用小写 定义了逻辑表，以及逻辑表分布的节点和分片规则 123456789&lt;schema name=\"imall\" checkSQLschema=\"false\" sqlMaxLimit=\"100\"&gt; &lt;table name=\"customer\" primaryKey=\"id\" dataNode=\"122-imall,123-imall,124-imall\" rule=\"auto-sharding-long\" /&gt; &lt;table name=\"order_info\" dataNode=\"122-imall,123-imall,124-imall\" rule=\"mod-long-order\" &gt; &lt;childTable name=\"order_detail\" primaryKey=\"id\" joinKey=\"order_id\" parentKey=\"order_id\"/&gt; &lt;/table&gt;&lt;/schema&gt;&lt;schema name=\"gupao\" checkSQLschema=\"false\" sqlMaxLimit=\"100\"&gt; &lt;table name=\"student\" primaryKey=\"sid\" dataNode=\"122-gupao,123-gupao,124-gupao\" rule=\"mod-long\" /&gt; &lt;/schema&gt; 属性： checkSQLschema：在查询 SQL 中去掉逻辑库名 sqlMaxLimit：自动加上 limit 控制数据的返回 primaryKey：指定该逻辑表对应真实表的主键。MyCat 会缓存主键(通过 primaryKey 属性配置)与 具体 dataNode 的信息。当分片规则(rule)使用非主键进行分片时，那么在使用主键进行查询时，MyCat 就会通过缓存先确定记录在哪个 dataNode 上，然后再在该 dataNode 上执行查询。 如果没有缓存/缓存并没有命中的话，还是会发送语句给所有的 dataNode。 dataNode：数据分片的节点 autoIncrement：自增长(全局序列)，true 代表主键使用自增长策略 type：全局表：global。其他表：不配置 ：数据节点与物理数据库的对应关系。 1234567&lt;dataNode name=\"122-imall\" dataHost=\"host122\" database=\"imall\" /&gt; &lt;dataNode name=\"123-imall\" dataHost=\"host123\" database=\"imall\" /&gt; &lt;dataNode name=\"124-imall\" dataHost=\"host124\" database=\"imall\" /&gt; &lt;dataNode name=\"122-gupao\" dataHost=\"host122\" database=\"gupao\" /&gt; &lt;dataNode name=\"123-gupao\" dataHost=\"host123\" database=\"gupao\" /&gt; &lt;dataNode name=\"124-gupao\" dataHost=\"host124\" database=\"gupao\" /&gt; ：配置物理主机的信息，readhost 是从属于 writehost 的。 123456789101112131415&lt;dataHost name=\"host122\" maxCon=\"1000\" minCon=\"10\" balance=\"0\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\" slaveThreshold=\"100\"&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=\"hostM1\" url=\"192.168.44.122:3306\" user=\"root\" password=\"123456\"&gt;&lt;/writeHost&gt; &lt;/dataHost&gt;&lt;dataHost name=\"host123\" maxCon=\"1000\" minCon=\"10\" balance=\"0\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\" slaveThreshold=\"100\"&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=\"hostM1\" url=\"192.168.44.123:3306\" user=\"root\" password=\"123456\"&gt; &lt;!-- &lt;readHost host=\"hostS1\"&gt;&lt;/readHost&gt; --&gt; &lt;/writeHost&gt; &lt;/dataHost&gt;&lt;dataHost name=\"host124\" maxCon=\"1000\" minCon=\"10\" balance=\"0\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\" slaveThreshold=\"100\"&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=\"hostM1\" url=\"192.168.44.124:3306\" user=\"root\" password=\"123456\"&gt;&lt;/writeHost&gt; &lt;/dataHost&gt; balance：负载的配置，决定 select 语句的负载 0：不开启读写分离机制，所有操作都会发送到当前可用的writeHost上。 1：所有读操作都随机发送到当前的writeHost对用的readHost和备用的writeHost上 2：所有读操作都随机发送到所有的writeHost，readHost上 3：所有读操作都只发送到writeHost的readHost上 writeType：读写分离的配置，决定 update、delete、insert 语句的负载 0：所有写操作都发送到可用的writeHost上（默认第一个，第一个挂了以后发到第二个） 1：所有写操作都随机发送到writeHost上 switchType：主从切换配置 -1： 表示不自动切换 1： 默认值，表示自动切换 2：基于MySQL主从同步的状态决定了是否切换，心跳语句为show slave status 3：基于MySQL galera cluster的切换机制（适合集群），心跳语句为show statu like ‘wsrep%’ 1.2.3 rule.xml定义了分片规则和算法分片规则： 123456&lt;tableRule name=\"rang-long-cust\"&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;func-rang-long-cust&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt; 分片算法： 12&lt;function name=\"func-rang-long-cust\" class=\"io.mycat.route.function.AutoPartitionByLong\"&gt; &lt;property name=\"mapFile\"&gt;rang-long-cust.txt&lt;/property&gt;&lt;/function&gt; 分片配置：rang-long-cust.txt 12310001-20000=1 0-10000=0 20001-100000=2 以上是最重要的三个配置文件。 1.2.4 ZK 配置除了本地文件之外，Mycat 也支持 ZK 配置(管理配置和全局 ID)，用于实现集群扩展。 启用 ZK 配置： mycat/conf/myid.properties 12345678loadZk=truezkURL=127.0.0.1:2181clusterId=010myid=01001clusterSize=1clusterNodes=mycat_gp_01\\#server booster ; booster install on db same server,will reset all minCon to 2 type=serverboosterDataHosts=dataHost1 执行 bin 目录下 init_zk_data.sh，会自动将 zkconf 下的所有配置文件上传到 zk(先 拷贝过去)。 123cd /usr/local/soft/mycat/confcp *.txt *.xml *.properties zkconf/ cd /usr/local/soft/mycat/bin ./init_zk_data.sh 注意：如果执行 init_zk_data.sh 脚本报错的话，代表未写入成功，此时不要启用 ZK 配置并重启，否则本地文件会被覆盖。 启动时如果 loadzk=true 启动时，会自动从 zk 下载配置文件覆盖本地配置。 在这种情况下如果修改配置，需要先修改 conf 目录的配置，copy 到 zkconf，再执 行上传。 1.2.5 启动停止检查环境变量配置： 12conf/wrapper.conf wrapper.java.command=/usr/local/soft/java/jdk1.8.0_40/bin/java 进入 mycat/bin 目录(注意要先启动物理数据库)： 如果直接用解压包，需要对 bin 目录下所有执行文件 chmod777。 启动命令：./mycat start 停止命令：./mycat stop 重启命令：./mycat restart 查看状态：./mycat status 前台运行：./mycat console 应用连接： mysql -uroot -p123456 -h 192.168.44.122 -P8066 imall 1.3 Mycat分片验证准备三个数据库 customer：范围分片 student 表：取模分片 order_info order_detail ER 表。 dict 表：全局表。 noshard 表：不分片表。 feedetail 表：库内分表 在三个数据库中建表： 1234567891011121314151617181920212223242526272829303132CREATE TABLE `customer` ( `id` int(11) DEFAULT NULL, `name` varchar(255) DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `order_info` ( `order_id` int(11) NOT NULL COMMENT '订单 ID', `uid` int(11) DEFAULT NULL COMMENT '用户 ID', `nums` int(11) DEFAULT NULL COMMENT '商品数量', `state` int(2) DEFAULT NULL COMMENT '订单状态', `create_time` datetime DEFAULT NULL ON UPDATE CURRENT_TIMESTAMP COMMENT '创建时间', `update_time` datetime DEFAULT NULL ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间', PRIMARY KEY (`order_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `order_detail` (`order_id` int(11) NOT NULL COMMENT '订单号',`id` int(11) NOT NULL COMMENT '订单详情',`goods_id` int(11) DEFAULT NULL COMMENT '货品 ID',`price` decimal(10,2) DEFAULT NULL COMMENT '价格',`is_pay` int(2) DEFAULT NULL COMMENT '支付状态',`is_ship` int(2) DEFAULT NULL COMMENT '是否发货',`status` int(2) DEFAULT NULL COMMENT '订单详情状态',PRIMARY KEY (`order_id`,`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `student` (`sid` int(8) NOT NULL AUTO_INCREMENT,`name` varchar(255) DEFAULT NULL,`qq` varchar(255) DEFAULT NULL,PRIMARY KEY (`sid`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 非分片表，在第一个节点上创建： 1234CREATE TABLE `noshard` (`id` int(11) DEFAULT NULL,`name` varchar(255) COLLATE utf8mb4_bin DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin; 1.3.1 范围分片imall 库 customer 表：范围分片 1&lt;table name=\"customer\" primaryKey=\"id\" dataNode=\"72-imall,74-imall,76-imall\" rule=\"auto-sharding-long\" /&gt; 在rule.xml中可以查看到，名为auto-sharding-long 的分片规则使用的是rang-long算法，而该算法需要接收一个名为autopartition-long.txt的文件作为参数； 12345678910&lt;!-- 来源 rule.xml --&gt;&lt;tableRule name=\"auto-sharding-long\"&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;rang-long&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name=\"rang-long\" class=\"io.mycat.route.function.AutoPartitionByLong\"&gt; &lt;property name=\"mapFile\"&gt;autopartition-long.txt&lt;/property&gt;&lt;/function&gt; 在conf目录创建autopartition-long.txt文件： 123456# range start-end ,data node index# K=1000,M=10000.# 未使用0-10000=010001-20000=120001-30000=2 那么当在customer表中插入如下数据。 123456INSERT INTO `customer` (`id`, `name`) VALUES (6666, '赵先生'); --72-mallINSERT INTO `customer` (`id`, `name`) VALUES (7777, '钱先生'); --72-mallINSERT INTO `customer` (`id`, `name`) VALUES (16666, '孙先生'); --74-mallINSERT INTO `customer` (`id`, `name`) VALUES (17777, '李先生'); --74-mallINSERT INTO `customer` (`id`, `name`) VALUES (26666, '周先生'); --76-mallINSERT INTO `customer` (`id`, `name`) VALUES (27777, '吴先生'); --76-mall 问题：超过范围会怎么样？找不到节点。 1.3.2 取模分片表panda 数据库，student 表：取模分片 1&lt;table name=\"student\" dataNode=\"72-panda,74-panda,76-panda\" rule=\"mod-long\" /&gt; 12345678910&lt;tableRule name=\"mod-long\"&gt; &lt;rule&gt; &lt;columns&gt;sid&lt;/columns&gt; &lt;algorithm&gt;mod-long&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name=\"mod-long\" class=\"io.mycat.route.function.PartitionByMod\"&gt; &lt;!-- how many data nodes ,这里要根据实际需要进行配置 --&gt; &lt;property name=\"count\"&gt;3&lt;/property&gt;&lt;/function&gt; 123456INSERT INTO `student` (`sid`, `name`, `qq`) VALUES (1, '李大彪', '166669999'); INSERT INTO `student` (`sid`, `name`, `qq`) VALUES (4, '菜狗子', '655556666');INSERT INTO `student` (`sid`, `name`, `qq`) VALUES (2, '等候那場雪', '466669999');INSERT INTO `student` (`sid`, `name`, `qq`) VALUES (5, '猫老公', '265286999'); INSERT INTO `student` (`sid`, `name`, `qq`) VALUES (3, 'tj-大白', '368828888');INSERT INTO `student` (`sid`, `name`, `qq`) VALUES (6, '大郎', '516895555'); 1.3.3 取模分片（ER表）我们有些表的数据是存在逻辑的主外键关系的，比如订单表 order_info，存的是汇 总的商品数，商品金额;订单明细表 order_detail，是每个商品的价格，个数等等。或者 叫做从属关系，父表和子表的关系。 他们之间会经常有关联查询的操作，如果父表的数据和子表的数据分别存储在不同的数据库，跨库关联查询也比较麻烦。所以我们能不能把父表和数据和从属于父表的数 据落到一个节点上呢？ 比如 order_id=1001 的数据在 node1，它所有的明细数据也放到 node1; order_id=1002 的数据在 node2，它所有的明细数据都放到 node2，这样在关联查询的 时候依然是在一个数据库。 注意，这个也是一种避免跨库关联的重要手段。 123&lt;table name=\"order_info\" dataNode=\"72-imall,74-imall,76-imall\" rule=\"mod-long-order\" &gt; &lt;childTable name=\"order_detail\" primaryKey=\"id\" joinKey=\"order_id\" parentKey=\"order_id\"/&gt;&lt;/table&gt; 去rule.xml 12345678910&lt;tableRule name=\"mod-long-order\"&gt; &lt;rule&gt; &lt;columns&gt;order_id&lt;/columns&gt; &lt;!--此处需配置--&gt; &lt;algorithm&gt;mod-long&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name=\"mod-long\" class=\"io.mycat.route.function.PartitionByMod\"&gt; &lt;!-- how many data nodes ,这里要根据实际需要进行配置 --&gt; &lt;property name=\"count\"&gt;3&lt;/property&gt;&lt;/function&gt; imall 库，order_info 123INSERT INTO `order_info` (`order_id`, `uid`, `nums`, `state`, `create_time`, `update_time`) VALUES (1, 1000001, 1, 2, '2025-9-23 14:35:37', '2025-9-23 14:35:37');INSERT INTO `order_info` (`order_id`, `uid`, `nums`, `state`, `create_time`, `update_time`) VALUES (2, 1000002, 1, 2, '2025-9-24 14:35:37', '2025-9-24 14:35:37');INSERT INTO `order_info` (`order_id`, `uid`, `nums`, `state`, `create_time`, `update_time`) VALUES (3, 1000003, 3, 1, '2025-9-25 11:35:49', '2025-9-25 11:35:49'); imall库，order_detail 123456INSERT INTO `order_detail` (`order_id`, `id`, `goods_id`, `price`, `is_pay`, `is_ship`, `status`) VALUES (3, 20180001, 85114752, 19.99, 1, 1, 1);INSERT INTO `order_detail` (`order_id`, `id`, `goods_id`, `price`, `is_pay`, `is_ship`, `status`) VALUES (1, 20180002, 25411251, 1280.00, 1, 1, 0);INSERT INTO `order_detail` (`order_id`, `id`, `goods_id`, `price`, `is_pay`, `is_ship`, `status`) VALUES (1, 20180003, 62145412, 288.00, 1, 1, 2);INSERT INTO `order_detail` (`order_id`, `id`, `goods_id`, `price`, `is_pay`, `is_ship`, `status`) VALUES (2, 20180004, 21456985, 399.00, 1, 1, 2);INSERT INTO `order_detail` (`order_id`, `id`, `goods_id`, `price`, `is_pay`, `is_ship`, `status`) VALUES (2, 20180005, 21457452, 1680.00, 1, 1, 2);INSERT INTO `order_detail` (`order_id`, `id`, `goods_id`, `price`, `is_pay`, `is_ship`, `status`) VALUES (2, 20180006, 65214789, 9999.00, 1, 1, 3); 1.3.4 全局表panda 数据库，dict 表：全局表 1&lt;table name=\"dict\" primaryKey=\"id\" type=\"global\" dataNode=\"72-panda,74-panda,76-panda\" /&gt; 注意没有配置rule属性，默认就是写到每个配置了的节点 1INSERT INTO `dict` (`id`, `param_code`, `param_name`) VALUES (1, '0731', '长沙市'); 1.3.5 非分片表panda数据库，noshard 表 1&lt;table name=\"noshard\" primaryKey=\"id\" autoIncrement=\"true\" dataNode=\"72-panda\" /&gt; 没有配置rule属性，并且只配置一个节点 1INSERT INTO `noshard` (`id`, `name`) VALUES (1, '这是一条没有分片的数据'); 1.3.6 库内分表1&lt;table name=\"fee\" primaryKey=\"id\" subTables=\"fee2025$1-3\" dataNode=\"72-panda\" rule=\"sharding-by-month\" /&gt; 根据时间路由到不同的表中 注意，逻辑表也要创建，即使没有数据，否则会报错。需要在 122-gupao 清空所有数据(bug，mycat 无法 truncate) 123INSERT INTO `fee` (`id`, `create_time`) VALUES (1, '2025-1-1 14:46:19'); INSERT INTO `fee` (`id`, `create_time`) VALUES (2, '2025-2-1 14:46:19'); INSERT INTO `fee` (`id`, `create_time`) VALUES (3, '2025-3-1 14:46:19'); 1.4 Mycat全局IDMycat 全局序列实现方式主要有 4 种： 本地文件方式 数据库方式 本地时间戳算 法 ZK 也可以自定义业务序列。 注意获取的前缀都是：MYCATSEQ_ 参考资料 首先全局id实现方式的选择在server.xml中配置 配置sequnceHandlerType 值：0-文件 1-数据库 2-本地时间戳 3-ZK 1.4.1 文件方式配置 conf/sequence_conf.properties 1234CUSTOMER.HISIDS= CUSTOMER.MINID=10000001 CUSTOMER.MAXID=20000000 CUSTOMER.CURID=10000001 语法：select next value for MYCATSEQ_CUSTOMER; 在插入时使用 1INSERT INTO `noshard` (`id`, `name`) VALUES (8, next value for MYCATSEQ_CUSTOMER); 优点：本地加载，读取速度较快。 缺点：当 Mycat 重新发布后，配置文件中的 sequence 需要替换(还原)。Mycat 不能做集群部署。 1.4.2 数据库方式这种方式需要一个表和 3 个存储过程。 配置： sequence_db_conf.properties 1234GLOBAL=72-imall COMPANY=72-imall CUSTOMER=72-imall ORDERS=72-imall 把这张表创建在第一个节点(72)上，所以是 72-imall 在第一个数据库节点(72)imall 数据库上创建 MYCAT_SEQUENCE 表： 12345DROP TABLE IF EXISTS MYCAT_SEQUENCE; CREATE TABLE MYCAT_SEQUENCE (name VARCHAR(50) NOT NULL,current_value INT NOT NULL,increment INT NOT NULL DEFAULT 1, remark varchar(100),PRIMARY KEY(name)) ENGINE=InnoDB; 注：可以在 schema.xml 配置文件中配置这张表，供外部访问。 1&lt;table name=\"mycat_sequence\" dataNode=\"122-imall\" autoIncrement=\"true\" primaryKey=\"id\"&gt;&lt;/table&gt; 72-imall 数据库创建存储过程：获取当前 sequence 的值 123456789101112DROP FUNCTION IF EXISTS `mycat_seq_currval`;DELIMITER ;;CREATE DEFINER=`root`@`%` FUNCTION `mycat_seq_currval`(seq_name VARCHAR(50)) RETURNS varchar(64) CHARSET latin1DETERMINISTICBEGINDECLARE retval VARCHAR(64);SET retval=\"-999999999,null\";SELECT concat(CAST(current_value AS CHAR),\",\",CAST(increment AS CHAR) ) INTO retval FROM MYCAT_SEQUENCE WHERE name = seq_name;RETURN retval ;END;;DELIMITER ; 72-imall 数据库创建存储过程：获取下一个 sequence 1234567891011DROP FUNCTION IF EXISTS `mycat_seq_nextval`;DELIMITER ;;CREATE DEFINER=`root`@`%` FUNCTION `mycat_seq_nextval`(seq_name VARCHAR(50)) RETURNS varchar(64) CHARSET latin1DETERMINISTICBEGINUPDATE MYCAT_SEQUENCESET current_value = current_value + increment WHERE name = seq_name;RETURN mycat_seq_currval(seq_name);END;;DELIMITER ; 72-mall数据库创建存储过程：设置 sequence 1234567891011DROP FUNCTION IF EXISTS `mycat_seq_setval`;DELIMITER ;;CREATE DEFINER=`root`@`%` FUNCTION `mycat_seq_setval`(seq_name VARCHAR(50), value INTEGER) RETURNS varchar(64) CHARSET latin1DETERMINISTICBEGINUPDATE MYCAT_SEQUENCESET current_value = valueWHERE name = seq_name;RETURN mycat_seq_currval(seq_name); END;;DELIMITER ; 72-imall 数据库插入记录 1INSERT INTO MYCAT_SEQUENCE(name,current_value,increment,remark) VALUES ('GLOBAL', 1, 100,''); INSERT INTO MYCAT_SEQUENCE(name,current_value,increment,remark) VALUES ('ORDERS', 1, 100,' 订单表使用'); 测试： 1select next value for MYCATSEQ_ORDERS 1.4.3 本地时间戳方式ID= 64 位二进制 (42(毫秒)+5(机器 ID)+5(业务编码)+12(重复累加) ，长度为 18 位 配置文件 sequence_time_conf.properties 123#sequence depend on TIMEWORKID=01 DATAACENTERID=01 验证： 1select next value for MYCATSEQ_GLOBAL 1.4.4 ZK 方式修改 conf/myid.properties 设置 loadZk=true(启动时会从 ZK 加载配置，一定要注意备份配置文件，并且先用 bin/init_zk_data.sh,把配置文件写入到 ZK) 配置文件：sequence_distributed_conf.properties 123# 代表使用 zkINSTANCEID=ZK# 与 myid.properties 中的 CLUSTERID 设置的值相同 CLUSTERID=010 复制配置文件 123456cd /usr/local/soft/mycat/confcp *.txt *.xml *.properties zkconf/ chown -R zkconf/cd /usr/local/soft/mycat/bin ./init_zk_data.sh 验证： 1select next value for MYCATSEQ_GLOBAL 1.4.5 使用每次获取都要 next value 吗？可以自动自增吗？ 在 schema.xml 的 table 标签上配置 autoIncrement=”true”，不需要获取和指定序 列的情况下，就可以使用全局 ID 了。 例如非分片表： 1INSERT INTO `noshard` (`name`) VALUES ( '自动获取自增值'); 2. Mycat 监控与日志查看2.1 监控2.1.1 命令行监控连接到管理端口 9066(注意不是 8066)，注意必须要带 IP 1mysql -uroot -h127.0.0.1 -p123456 -P9066 全部命令: 1mysql&gt;show @@help; 命令 作用 show @@server; 查看服务器状态，包括占用内存等 show @@database; 查看数据库 show @@datanode; 查看数据节点 show @@datasource; 查看数据源 show @@connection; 该命令用于获取 Mycat 的前端连接状态，即应用与 mycat 的连接 show @@backend; 查看后端连接状态 show @@cache; 查看缓存使用情况 SQLRouteCache:sql 路由缓存。 TableID2DataNodeCache : 缓存表主键与分片对应关系。 ER_SQL2PARENTID : 缓存 ER 分片中子表与父表关系 reload @@config; 重新加载基本配置(热加载)，使用这个命令时 mycat 服务不可用 show @@sysparam; 查询 mycat 服务的系统参数 show @@sql.high; 执行频率高的 SQL show @@sql.slow; 慢 SQL设置慢 SQL 的命令:reload @@sqlslow=5 ; show @@syslog limit=50; 查看最近 50 条系统日志 ##### 2.1.2 命令行监控 mycatweb 监控https://github.com/MyCATApache/Mycat-download/tree/master/mycat-web-1.0 Mycat-eye 是 mycat 提供的一个监控工具，它依赖于 ZK。 本地必须要运行一个 ZK，必须先启动 ZK。 参考:https://gper.club/articles/7e7e7f7ff7g59gc3g64 下载 mycat-web 12cd /usr/local/soft wget http://dl.mycat.io/mycat-web-1.0/Mycat-web-1.0-SNAPSHOT-20170102153329-linux.tar.gz tar -xzvf Mycat-web-1.0-SNAPSHOT-20170102153329-linux.tar.gz 启动 mycat-web 12cd mycat-web nohup ./start.sh &amp; 停止:kill start.jar 相关的进程 访问端口 8082 http://10.0.12.72:8082/mycat/ mycat server.xml 配置 12&lt;!-- 1 为开启实时统计、0 为关闭 --&gt; &lt;property name=\"useSqlStat\"&gt;1&lt;/property&gt; 重启 mycat 服务生效 2.2 日志log4j 的 level 配置要改成 debug 2.2.1 wrapper.log 日志wrapper 日志：mycat 启动，停止，添加为服务等都会记录到此日志文件，如果系 统环境配置错误或缺少配置时，导致 Mycat 无法启动，可以通过查看 wrapper.log 定位 具体错误原因。 2.2.2 mycat.log 日志mycat.log 为 mycat 主要日志文件，记录了启动时分配的相关 buffer 信息，数据源 连接信息，连接池，动态类加载信息等等。 在 conf/log4j2.xml 文件中进行相关配置，如保留个数，大小，字符集，日志文件大 小等。","categories":[{"name":"数据库技术","slug":"数据库技术","permalink":"https://zzkenyon.github.io/categories/数据库技术/"}],"tags":[{"name":"Mycat","slug":"Mycat","permalink":"https://zzkenyon.github.io/tags/Mycat/"}],"keywords":[{"name":"数据库技术","slug":"数据库技术","permalink":"https://zzkenyon.github.io/categories/数据库技术/"}]},{"title":"分库分表-为什么要分库分表","slug":"数据库技术-Mycat-为什么要分库分表","date":"2020-05-10T02:56:23.000Z","updated":"2020-11-15T09:48:21.379Z","comments":true,"path":"2020/05/10/数据库技术-Mycat-为什么要分库分表/","link":"","permalink":"https://zzkenyon.github.io/2020/05/10/数据库技术-Mycat-为什么要分库分表/","excerpt":"","text":"目标： 1、理解分库分表的意义 2、理解数据切分的不同方式，以及带来的问题与解决方案 1、为什么要分库分表随着业务变得越来越复杂，用户越来越多，集中式的架构性能会出现巨大的问题，比如系统会越来越慢，而且时不时会宕机，所以必须要解决高性能和可用性的问题。 不仅仅是应用，作为所有业务数据的管理者，数据库也会遇到一样的问题，而且很 多时候应用系统出现问题，就是数据库变慢了或者数据库挂掉了导致的。 1.1 数据库瓶颈的出现一般来说哦会出现哪些问题呢？比如在高并发的情况下连接数不够用；或者数据量太大，查询效率变得越来越低；或者是因为存储的问题，数据库所在的及其性能下降 这些问题归根到底都是收到了硬件的限制，cpu内存磁盘网络等等。在集中式架构里面，我们怎么解决硬件带来的性能瓶颈问题呢？加配置。换cpu，升级内存，扩展磁盘，升级带宽等等 这种优化方式有两个问题 随着业务量变大容易遇到新的瓶颈 收效投入比太低 那我们思考一下，把升级硬件放在一边，如果数据库的性能出现问题了，我们可以从哪些方面进行优化呢？有没有成本更低收效更好的方式？ 1.2 数据库优化方案对比第一招：重启——重启是释放资源最好的方法 1.2.1 SQL与索引当SQL写的非常复杂，比如关联的表非常多，条件非常多，查询消耗的事件非常长，这样的一个SQL就要慢SQL。以为SQL语句是我们自己写的，可控性最高，所以第一步就是检查SQL。在很多情况下我们优化的目标就是为了用到索引。 1.2.2 表与存储引擎如果sql语句没什么问题，那就接着检查我们查询的目标，也就是表结构的设计有没有问题。比如对于字段类型和长度的选择，或者表结构是不是需要拆分或者合并，不同的表应该选择什么存储引擎是不是需要分区等等。 1.2.3 架构优化表结构也没问题了，就要上升到数据库服务的层面，从架构层面进行优化。 因为数据都是在磁盘上存储，如果加了索引还是很慢，干脆可以把数据在内存里面缓存起来，这个时候可以部署缓存中间件。 如果一台数据库服务器承受不了访问压力，可以部署集群做负载均衡。当然这些数据库节点用该有自动同步的机制。有了主从同步之后就可以主从复制实现读写分离。让写的服务都访问master节点，请的请求都访问slaver节点。 有了读写分离以后问题并没有完全解决： 1、只有一个master，写的压力没有得到分摊 2、所有的节点都存储相同的数据，在一个节点出现存储瓶颈的时候，磁盘不够用了，其他节点也一样会遇到这个问题。 所以这个时候无哦们要用到分布式环境中一个非常重要的手段：分片，每个节点都只是存储总体数据的一部分，那这个就是我们今天要讲的分库分表。分片以后为了提升可用性，可以对分片再做冗余。 1.2.4 数据库配置如果通过架构层面没有解决问题，或者机器虽然配置很高但是性能没有发挥到极致，还可以优化数据库的配置，比如连接数，缓冲池大小等等 1.2.5 操作系统当然，因为数据库时安装在操作系统上的，所以操作西永的配置也有优化空间。最后才是硬件的优化，在单机的数据库上当然可以做。 我们先对数据库性能优化有了一个全局的认识，这个是非常重要的。我们清楚了分库分表在什么位置，也知道并不是数据库一慢，就要去做分库分表，可以优化的地方多的是。 OK，那么问题来了，这么多的优化方案，到底什么时候才需要分库分表呢? 评判标准是什么？ 如果是数据量的话，一张表存储了多少记录的时候，才需要考虑分库分表？ 如果是数据增长速度的话，每天产生多少数据，才需要考虑分库分表？ 如果是应用访问情况的话，查询超过几秒中，有多少请求无法获取连接，才需要考虑分库分表？ 先来看一下一个消费金融核心系统的架构演进过程。这个也是很多公司项目一般的演进过程。 1.3 架构演进与分库分表消费金融这个名字可能听起来比较陌生，但是跟大 家的生活息息相关。它主要是分成线上和线下两部分。线下的就是跟一些门店合作，提 供贷款服务，所以大家买手机买电脑买摩托车可以分期。线上的就是一些电商的场景， 比如花呗、京东白条，都属于消费金融。 1.3.1 单应用单数据库当时我们是直接采购了一套消费金融核心系统，这是一个典型的单体架构的应用。 单体架构应用的特点就是所有的代码都在一个工程里面，打成一个 war 包部署到 tomcat，最后运行在一个进程中。 有了这个系统以后，客户办理在门店办理贷款，也就是贷前贷中贷后的所有的流程 都可以通过这一套系统完成。这套消费金融的核心系统，用的是 Oracle 的数据库，初始 化以后有几百张表，比如客户信息表、账户表、商户表、产品表、放款表、还款表等等。 公司门店开到了全国几百个城市，基本上一个城市一个分公司。合作的商户有十几万家，门店数量二十几万家，客户数量到达了千万级别。 为了适应业务的发展，这一套核心系统不停地在修改，代码量越来越大，系统变得 越来越臃肿。 节假日做活动，订单暴增，结果系统宕机了几个小 时，导致全国的销售有几个小时都做不了单，干着急。 对于 IT 部来说，该做的事情全都做了，搭集群，负载均衡，加缓存，优化数据库，优化业务代码系统，但是都应对不了系统的访问压力。 所以这个时候系统拆分就势在必行了。也就是我们说的对计算进行分片。 另外一块其实也是管理上的问题，几百个人做一个项目肯定会有很多的冲突。我们把以前这一套采购的核心系统拆分出来很多的子系统，比如提单系统、商户管理系统、 信审系统、合同系统、代扣系统、催收系统，所有的系统都依旧共用一套 Oracle 数据库。 这个时候我们进入了多应用单数据库的阶段。 1.3.2 多应用单数据库 对代码进行了解耦，职责进行了拆分，我们的生产环境出现问题的时候，可以快速 地排查和解决。这是第一次改造，原来我们一个系统使用一个据库，现在多个子系统共 用一个 Oracle 的数据库。 但是这种多个子系统共用一个 DB 的架构，会出现一些问题，什么问题呢? 第一个就是所有的业务系统都共用一个 DB，无论是从性能还是存储的角度来说，都 是满足不了需求的。随着我们的业务继续膨胀，我们又会增加更多的系统来访问核心数 据库，但是一个物理数据库能够支撑的并发量是有限的，所有的业务系统之间还会产生 竞争，最终会导致应用的性能下降，甚至拖垮业务系统。 1.3.3 多应用独立数据库所以这个时候，我们必须要对各个子系统的数据库也做一个拆分。这个时候每个业 务系统都有了自己的数据库，不同的业务系统就可以用不同的存储方案。 当然在一段时间之内核心数据库并没有下线，它依然是所有的 IT 系统交换数据的一 个中心，每个系统都会把自己的数据同步到核心系统，也是从核心系统同步其他系统的数据，后面我们也在逐步脱离这个核心系统。 所以，分库其实是我们在解决系统性能问题的过程中，对系统进行拆分的时候带来 的一个必然的结果。现在的微服务架构也是一样的，只拆应用不拆分数据库，不能解决根本的问题。 所以，对数据库进行分库，它一般是应用的服务拆分，模块的分解，或者子系统的 划分带来一个必然的结果。 1.3.4 什么时候分表?当我们对原来一个数据库的表做了分库以后，其中一些表的数据在快速地膨胀，比 如客户表已经超过 1000 万了，合同表也超过 5000 万了，还款历史表已经上亿了，而且还在以一个非常快的速度在增长，这个时候查询也已经出现了非常明显的效率下降。 所以，在分库之后，还需要进一步进行分表(单应用多数据库)。当然，我们最开 始想到的可能是在一个数据库里面拆分数据，分区或者分表，到后面才是切分到多个数据库中。 所以，分表主要是为了减少单张表的大小，解决单表数据量带来的性能问题。 回到我们开始的问题，大家觉得一张表的存储的数量达到多少的时候，需 要做分表? 那么到底一张表数据量到达多少的时候，我们需要去做分库分表呢?200 万?300 万?500 万? 大家可能在网上看过一些数据库的规范，比如阿里巴巴 Java 开发手册，它推荐的理 论分表界线是 500 万。 【推荐】单表行数超过 500 万行或者单表容量超过 2GB，才推荐进行分库分表。 说明:如果预计三年后的数据量根本达不到这个级别，请不要在创建表时就分库分表。 在阿里编程规约里面，它推荐的是超过 500 万才考虑分表。但是一段时间之内到不了这个数量级，不要先做分库分表。 从这句话里面我们读出来两个信息: 1、第一，如果可以不用分库分表，我们尽量不要分库分表。因为它会大大地提升系统的复杂度，带来很多新的问题。如果对于一个很简单的项目，一上线就分库分表，这个就叫过度设计了，也不符合项目迭代和演进的规律。 2、第二，分库分表是一个长期的规划，要解决的不只是现在的问题。它不需要经常 性地去实施，但是一旦做了，在几年之内是不需要变动的。 到底是不是 500 万呢?这个也不一定，还是要以业务的实际的情况为准。如果我们 创建的表结构合理，字段不是太多，并且索引创建正确的情况下，单张表存储几千万的 数据是完全没有问题的，这个还是以应用的实际情况为准。 如果是真的慢了，而且其他的方案都用过了，性能还是跟不上，这个时候才考虑分 库分表。 那如果要做分库分表，分库分表到底有哪些类型? 2. 分库分表的类型和特点我们把前面的拆分方式归纳了一下，一共就两种，一种叫垂直拆分，一种叫水平拆分。 垂直切分:基于表或字段划分，表结构不同。我们有单库的分表，也有多库的分库。 水平切分:基于数据划分，表结构相同，数据不同，也有同库的水平切分和多库的 切分。 2.1 垂直切分垂直分表有两种，一种单库的，一种多库的。字段太多就要拆表，表太多就要拆库 2.1.1 单库垂直分表单库分表，比如:商户信息表，拆分成基本信息表，联系方式表，结算信息表，附 件表等等。 2.1.2 多库垂直分表多库垂直分表就是把原来存储在一个库的不同的表，拆分到不同的数据库。 比如:消费金融核心系统数据库，有很多客户相关的表，这些客户相关的表，全部 单独存放到客户的数据库里面。合同，放款，风控相关的业务表也是一样的。 当我们对原来的一张表做了分库的处理，如果某些业务系统的数据还是有一个非常 快的增长速度，比如说还款数据库的还款历史表，数据量达到了几个亿，这个时候硬件 限制导致的性能问题还是会出现，所以从这个角度来说垂直切分并没有从根本上解决单 库单表数据量过大的问题。在这个时候，我们还需要对我们的数据做一个水平的切分。 这个时候，一个应用需要多个数据库。 2.2 水平切分水平切分就是按照数据的维度分布不同的表中，可以是单库的，也可以是多库的。 2.2.1 单库水平分表两个案例: 银行的交易流水表，所有进出的交易都需要登记这张表，因为绝大部分时候客户都 是查询当天的交易和一个月以内的交易数据，所以我们根据使用频率把这张表拆分成三 张表: 当天表 channel_transaction:只存储当天的数据。 当月表 channel_transaction_month:我们在夜间运行一个定时任务，前一天 的数据，全部迁移到当月表。用的是 insert into select，然后 delete。 历史表 channel_transaction_history:同样是通过定时任务，把登记时间超过 30 天的数据，迁移到 history 历史表(历史表的数据非常大，我们按照月度，每个 月建立分区)。 费用明细表: 消费金融公司跟线下商户合作，给客户办理了贷款以后，消费金融公司要给商户返 费用，或者叫提成，每天都会产生很多的费用的数据。为了方便管理，我们每个月建立 一张费用表，例如 fee_detail_202501……fee_detail_202512。 但是注意，跟分区一样，在一个数据库分表的方式虽然可以一定程度解决单表查询 性能的问题，但是并不能解决单机存储瓶颈的问题，因为所有的表占用的是相同的磁盘 存储空间。 2.2.2 多库水平分表另一种是多库的水平分表。比如客户表，我们拆分到多个库存储，表结构是完全一 样的。 一般我们说的分库分表都是跨库的分表。 既然分库分表能够帮助我们解决性能的问题，那我们是不是马上动手去做，甚至在 项目设计的时候就先给它分几个库呢?先冷静一下，我们来看一下分库分表会带来哪些 问题，也就是我们前面说的分库分表之后带来的复杂性。 2.3 分库分表带来的问题2.3.1 跨库关联查询比如查询在合同信息的时候要关联客户数据，由于是合同数据和客户数据是在不同的数据库，那么我们肯定不能直接使用join这种方式去做关联查询 我们有几种主要的解决方案： 字段冗余 数据同步 ： 比如商户系统要查询产品系统的产品表，我们干脆在商户系统创建一张产品表，通过 ETL、MQ 或者 canal 定时同步产品数据。 全局表：有一些基础信息表，比如行名行号表、行政区划表，被很多业务系统用到，如果我们放在核心系统，每个系统都要调接口去查询，这个时候我们可 以在所有的数据库都存储相同的基础数据，各个系统自己维护，保持同步。 上面的思路都是通过合理的业务设计避免跨库关联查询，实际上在我们的系统中， 尽量不要用跨库关联查询。如果最后无法避免跨库关联的情况，那我们就只能用最后一 种办法。 系统业务层组装：在不同的数据库节点，各自利用查询条件，把符合条件数据的数据查询出来，然后在内存中重新组装，返回给客户端。 2.3.2 分布式事务比如在一个贷款的流程里面，合同系统登记了数据，放款系统也必须生成放款记录， 如果两个操作不是同时成功或者同时失败，就会出现数据一致性的问题。 如果实在一个数据库里面，我们可以使用本第十五来控制，但是在不同的数据库里面就不行了。这里必须要出现一个协调者的角色，大家统一行动，而且要分成多个阶段。一般是是先确定都能成功才能保证成功，只要有一个不成功，就要全部失败。 核心思想其实是在预先提交能够恒公的情况下，尽量缩短同时提交的时间差，来提升成功的概率。 分布式事务，在微服务篇有文章详细介绍。 2.3.3 排序、翻页、函数计算问题跨节点多苦进行查询时没会出现limit分页，order by排序的问题。比如有两个节点： 节点 1 存的是奇数 id=1,3,5,7,9……;节点 2 存的是偶数 id=2,4,6,8,10…… 如果查询语句是查出第一页的 10 条数据: select * from user_info order by id limit 0,10 需要在两个节点上各取出 10 条(为什么都要查 10 条?假设 10 条都在第 2 个节点上?)，然后合并数据，重新排序，节点多的话就更麻烦了。 max、min、sum、count 之类的函数在进行计算的时候，也需要先在每个分片上执行相应的函数，然后将各个分片的结果集进行汇总和再次计算，最终将结果返回。 2.3.4 全局ID避重MySQL 的数据库里面字段有一个自增的属性，Oracle 也有 Sequence 序列。如果 是一个数据库，那么可以保证 ID 是不重复的，但是水平分表以后，每个表都按照自己的 规律自增，不同的表之间肯定会出现 ID 重复的问题。 全局ID也有单独文章进行介绍。 当然还有一个非常关键的问题。 原来你的应用系统只需要连接到一个数据库，配置一个数据源，现在要配置多个。 配置就配置吧，问题就来了: 我们在执行一条 SQL 语句的时候，比如插入，它应该是在哪个数据节点上面执行呢? 又比如查询，1 条数据只在其中的一个节点上面，我怎么知道在哪个节点?如果是列表查询，数据分布在多个节点，是不是要在所有的数据库节点里面都查询一遍，才能拿到结 果? 这个问题我们把它叫做:多数据源的问题，或者动态数据源的问题。 我们可以从查询的整个流程来分析一下，哪些环节是我们可以下手的。 2.4 多数据源/动态数据源的解决方案在 SSM 的项目里面，查询一般要经过这些流程: DAO——Mapper(ORM)——JDBC——代理——数据库服务 2.4.1 DAO层第一个就是在我们的客户端的代码，比如 DAO 层，在我们连接到某一个数据源之前， 我们先根据配置的分片规则，判断需要连接到哪些节点，再建立连接。 Spring 中提供了一个抽象类 AbstractRoutingDataSource，可以实现数据源的动态切换。 详见代码 在 DAO 层实现的优势:不需要依赖 ORM 框架，即使替换了 ORM 框架也不受影响。实现简单(不需要解析 SQL 和路由规则)，可以灵活地定制。 在 DAO 层实现的缺点:不能复用，不能跨语言。 2.4.2 ORM 框架层第二个是在框架层，比如我们用 MyBatis 连接数据库，也可以指定数据源。我们可以基于 MyBatis 插件的拦截机制(拦截 query 和 update 方法)，实现数据源的选择。 例如: Mybatis 分片:可以插件通过设置 Statement 的 Connection，或者使用不同的 SqlSessionFactory 实现。 2.4.3 驱动层不管是 MyBatis 还是 Hibernate，还是 Spring 的 JdbcTemplate，本质上都是对 JDBC 的封装，所以第三层就是驱动层。比如 Sharding-JDBC，就是对 JDBC 的对象进行了封 装。JDBC 里面有两个核心对象，一个是 Connection，是一个连接的封装，一个是 DataSource，是对一个数据库的封装。 我们可以自己实现一个 DataSource，在项目中配置多个数据源，这样就可以随心所 欲地切换 datasource 了(Sharding-JDBC 就是这样实现的)。 2.4.4 代理层前面三种都是在客户端实现的。也就是说，如果你有 10 个项目，那就要对 10 个项 目进行改造，当然这种情况下我们会把逻辑抽取出来打成 jar 包，直接依赖使用。但如果不是 Java 的项目呢?那就麻烦了，同样的逻辑还是要实现一遍。 所以我们干脆把它做成一个服务，这样不同语言的项目都可以直接连接，使用这个逻辑了。它应该提供跟数据库一样的协议，减少客户端的变动，比如我原来用的 Spring、MyBatis、Druid，都不要让我去改，只要改数据库的 IP 和连接规则就行了。 到了这个时候，因为提供了一个代理服务，帮我们去查数据，再把数据返回，我们就把它叫代理层。Mycat 和 Sharding-Proxy，都是属于这一层。 2.4.5 数据库服务最后一层就是在数据库服务上实现。以非关系型数据库 Redis 为例，Redis Cluster 分片，产品多个连接以后，能够自动路由。MySQL 可以吗?不可以，那我就去改一下 MySQL 的源码，让它变成一个分布式的数据库。在数据库服务前面加一个路由层，后面 支持多个数据源。 腾讯云现在主推的 TDSQL，就是这样一种实现。不过，这样的数据库在部署的时候， 多了很多的节点需要部署。","categories":[{"name":"数据库技术","slug":"数据库技术","permalink":"https://zzkenyon.github.io/categories/数据库技术/"}],"tags":[{"name":"Mycat","slug":"Mycat","permalink":"https://zzkenyon.github.io/tags/Mycat/"}],"keywords":[{"name":"数据库技术","slug":"数据库技术","permalink":"https://zzkenyon.github.io/categories/数据库技术/"}]},{"title":"MyBatis-给源码加中文注释(转)","slug":"数据库技术-MyBatis-源码分析之从源码构建","date":"2020-04-23T16:00:00.000Z","updated":"2020-05-22T11:54:43.915Z","comments":true,"path":"2020/04/24/数据库技术-MyBatis-源码分析之从源码构建/","link":"","permalink":"https://zzkenyon.github.io/2020/04/24/数据库技术-MyBatis-源码分析之从源码构建/","excerpt":"","text":"我们在看框架源码的时候，如果没有注释，看起来会比较吃力。所以如果能够一边看源码一边自己加中文注释，下次阅读的时候就会轻松很多。 问题是：通过maven下载的jar，查看源码，实际上看到的是经过反编译的class文件，是不能够修改的（提示：file is read only）。如果把当前maven下载的jar包强行关联到自己下载的源码，又有可能会出现字节码跟源码文件不一致的情况（提示：Library source does not match the bytecode for class），导致debug的时候无法进入代码。 如果要保证源码和字节码一致，最好的办法当然是在本地把下载的源码编译生成jar包，上传到本地maven仓库，再引用这个jar。 以MyBatis为例，如果我们要给MyBatis源码加上中文注释（以IDEA操作为例） 原文连接 1、配置Maven因为需要用Maven打包编译源代码，所以第一步是检查Maven的配置。 第一个是环境变量，需要在系统变量中添加MAVEN_HOME，配置Maven主路径，例如“E:\\dev\\apache-maven-3.5.4”，确保mvn命令可以使用。 第二个是检查Maven的配置。Maven运行时，默认会使用conf目录下的settings.xml配置，例如：E:\\dev\\apache-maven-3.5.4\\conf\\settings.xml。 为了保证下载速度，建议配置成国内的aliyun中央仓库（此处需要自行搜索）。 并且，settings.xml中的localRepository应该和IDEA中打开的项目设置中的Local repository保持一致（例如：E:\\repository）。否则项目引入依赖时，无法读取到编译后的jar包。 2、下载编译MyBatis源码因为MyBatis源码编译依赖parent项目的源码，所以第一步是编译parent项目。 先从git clone两个工程的项目（截止2020年4月，最新版本是3.5.4）。 以在E盘根目录下载为例。 12git clone https://github.com/mybatis/parentgit clone https://github.com/mybatis/mybatis-3 打开mybatis-3中的pom.xml文件，查看parent的版本号，例如： 123456&lt;parent&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-parent&lt;/artifactId&gt; &lt;version&gt;31&lt;/version&gt; &lt;relativePath /&gt;&lt;/parent&gt; 确定parent版本是31（记住这个数字）。 把mybatis版本号改成自定义的版本号，避免跟官方版本号冲突（加上了-snapshot）： 123&lt;artifactId&gt;mybatis&lt;/artifactId&gt;&lt;version&gt;3.5.4-snapshot&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt; 进入parent目录，切换项目分支（不能在默认的master分支中编译），工程名后面的数字就是前面看到的parent版本号。 开始编译parent项目： 12345cd parentgit checkout mybatis-parent-31mvn install 接下来编译mybatis工程，进入mybatis-3目录，切换到最新3.5.4分支（不能在默认的master分支中编译）。 1234567cd ../mybatis-3git checkout mybatis-3.5.4mvn cleanmvn install -DskipTests=true -Dmaven.test.skip=true -Dlicense.skip=true 编译完毕，本地仓库就会出现一个编译后的jar包，例如：E:\\repository\\org\\mybatis\\mybatis\\3.5.4-snapshot\\mybatis-3.5.4-snapshot.jar 在我们的项目中就可以引入这个jar包了（version是自定义的version） 12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.4-snapshot&lt;/version&gt;&lt;/dependency&gt; 3、关联jar包到源码本地编译的jar包已经有了，接下来是把jar包和源码关联起来。 Project Structure —— Libries —— Maven: org.mybatis:mybatis:3.5.4-snapshot —— 在原来的Sources上面点+（加号） —— 选择到下载的源码路径，例如：E:\\mybatis-3\\src\\main\\java，点击OK 关联好之后，开始打断点debug，就会进入到本地的源码，可以给本地的源码加上注释了。 4、注意1、如果之前打开过类的字节码文件，本地可能有缓存，一样会有“Library source does not match the bytecode for class”的提示。解决办法：File —— Invalidate Caches and Restart（IDEA会重启）。 2、如果添加注释导致了debug的当前行跟实际行不一致，再把mybatis3工程编译一次即可。","categories":[{"name":"ORM框架","slug":"ORM框架","permalink":"https://zzkenyon.github.io/categories/ORM框架/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://zzkenyon.github.io/tags/Mybatis/"}],"keywords":[{"name":"ORM框架","slug":"ORM框架","permalink":"https://zzkenyon.github.io/categories/ORM框架/"}]},{"title":"RPC-手写RPC调用过程","slug":"分布式-手写RPC调用","date":"2020-04-18T16:00:00.000Z","updated":"2020-05-22T11:45:12.708Z","comments":true,"path":"2020/04/19/分布式-手写RPC调用/","link":"","permalink":"https://zzkenyon.github.io/2020/04/19/分布式-手写RPC调用/","excerpt":"","text":"rpc 全称remote procedure call 远程过程调用，是一种分布式服务调用协议。 需求：分布式环境下，服务A想要调用服务B的某方法，就像调用自己本地的方法一样 分析： 首先，服务A需要知道服务B提供了哪些方法，并且知道这些方法的调用方式（参数列表，返回类型） 其次，服务A需要将调用的方法和参数发送给服务B，B接收到之后本地调用获得结果，再将结果发送给服务A 设计： 要提供一套统一的接口让调用方服务A知道有哪些方法可供调用，服务B作为接口的实现方。 服务A要提供接口的代理类工厂，本地调用接口方法时，代理类能将调用请求发送出去。 数据传输方面，暂不考虑性能，使用BIO以及JDK序列化方式 开始编码： 提供一套接口：创建maven项目rpc-api，项目中添加接口文件 123public interface IHelloService &#123; String sayHello(String var1);&#125; 接口中还需要指定一个简要的rpc协议，调用方和服务方都要遵循此协议 12345public class RpcRequest implements Serializable &#123; private String className; private String methodName; private Object[] args;&#125; 将rpc-api install到本地仓库。 调用方服务A：创建maven项目rpc-client，pom中添加依赖rpc-api 先来写main方法： 123456789public class App &#123; public static void main( String[] args ) &#123; RpcProxyFactory rpcProxyFactory = new RpcProxyFactory(); IHelloService helloService = rpcProxyFactory.newProxyInstance(IHelloService.class,\"localhost\",8080); Object o = helloService.sayHello(\"zzk\"); System.out.println((String) o); &#125;&#125; 流程很清晰： 创建代理工厂RpcProxyFactory 使用代理工厂类生成指定接口的代理对象 调用接口方法获取结果 123456public class RpcProxyFactory &#123; public &lt;T&gt; T newProxyInstance(final Class&lt;T&gt; interfaceClass, final String host, final int port)&#123; return (T)Proxy.newProxyInstance(interfaceClass.getClassLoader(),new Class&lt;?&gt;[] &#123;interfaceClass&#125;, new RemoteInvocationHandler(host,port)); &#125;&#125; 代理方式我选用的是jdk的动态代理，创建代理对象需要传进三个参数 类加载器 需要代理的接口 触发管理类 前两个参数都是现成的，编写触发管理类代码，实现InvocationHandler接口，通过代理对象调用接口方法都会进到invoke方法中来。 123456789101112131415161718public class RemoteInvocationHandler implements InvocationHandler &#123; private String host; private int port; public RemoteInvocationHandler(String host, int port) &#123; this.host = host; this.port = port; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; RpcRequest rpcRequest = new RpcRequest(); rpcRequest.setClassName(method.getDeclaringClass().getName()); rpcRequest.setMethodName(method.getName()); rpcRequest.setArgs(args); return new RpcNetTransport(host,port).send(rpcRequest); &#125;&#125; invoke 方法负责将请求参数序列化，并发送出去，这里使用一个类专门负责发送： 123456789101112131415161718192021public class RpcNetTransport &#123; private String host; private int port; public RpcNetTransport(String host, int port) &#123; this.host = host; this.port = port; &#125; public Object send(RpcRequest rpcRequest)&#123; try(Socket socket = new Socket(host,port); ObjectOutputStream out = new ObjectOutputStream(socket.getOutputStream()); ObjectInputStream in = new ObjectInputStream(socket.getInputStream())) &#123; out.writeObject(rpcRequest); return in.readObject(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; return null; &#125;&#125; 至此调用发代码完成 再来看服务方B的代码编写：创建maven项目，引入依赖rpc-api、spring-context来管理对象 首先服务方应该实现接口： 12345678@Servicepublic class HelloServiceImpl implements IHelloService &#123; @Override public String sayHello(String content) &#123; System.out.println(\"request sayHello from : \" + content); return \"Response: hello, \" + content; &#125;&#125; 服务器需要接收请求，代码思想：启动监听指定端口，这里使用了spring的InitializingBean接口，创建RpcServer时，当port设置成功之后会执行afterPropertiesSet()方法启动监听。 此外，我们将对象交给spring管理后，当请求进来我们需要找到正确service去执行，我的做法是让RpcServer实现ApplicationContextAware接口，这样RpcServer可以在setApplicationContext方法中，将所有的service对象取出来缓存，请求进来直接在缓存中找 1234567891011121314151617181920212223242526272829303132333435public class RpcServer implements InitializingBean,ApplicationContextAware &#123; private ExecutorService pool = Executors.newCachedThreadPool(); private int port; private Map&lt;String,Object&gt; serviceObjs = new HashMap&lt;&gt;(); public RpcServer(int port) &#123; this.port = port; &#125; @Override public void afterPropertiesSet() throws Exception &#123; // socket 通信 发布服务 try (ServerSocket serverSocket = new ServerSocket(port))&#123; while (true)&#123; Socket socket = serverSocket.accept(); pool.execute(new ProcessorHandler(socket,serviceObjs)); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; // 获取容器中的服务bean 封装成map Map&lt;String,Object&gt; beans = applicationContext.getBeansWithAnnotation(RpcService.class); for(Object service : beans.values())&#123; Class&lt;?&gt; clazz = service.getClass(); String serviceKey = rpcService.value().getName(); serviceObjs.put(serviceKey,service); &#125; &#125;&#125; 当获取请求之后，丢给线程池进行执行，那我继续编写线程池执行任务代码： 1234567891011121314151617181920212223242526272829303132public class ProcessorHandler implements Runnable &#123; private Socket socket; private Map&lt;String,Object&gt; serviceObj; public ProcessorHandler(Socket socket,Map&lt;String,Object&gt; serviceObj) &#123; this.socket = socket; this.serviceObj = serviceObj; &#125; @Override public void run() &#123; try (ObjectInputStream in = new ObjectInputStream(socket.getInputStream()); ObjectOutputStream out = new ObjectOutputStream(socket.getOutputStream()))&#123; RpcRequest rpcRequest = (RpcRequest) in.readObject(); Object result = invoke(rpcRequest); out.writeObject(result); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; private Object invoke(RpcRequest rpcRequest) throws ClassNotFoundException, NoSuchMethodException, InvocationTargetException, IllegalAccessException &#123; Object[] args = rpcRequest.getArgs(); Class&lt;?&gt;[] types = new Class[args.length]; for(int i = 0; i &lt; args.length; i++)&#123; types[i]= args[i].getClass(); &#125; Class clazz = Class.forName(rpcRequest.getClassName()); Method method = clazz.getMethod(rpcRequest.getMethodName(),types); String serviceKey = rpcRequest.getClassName() + rpcRequest.getVersion(); return method.invoke(serviceObj.get(serviceKey),args); &#125;&#125; 既然是线程池执行的任务，肯定是Runnable对象，run方法的逻辑很清晰：从socket中获取请求对象，丢给invoke返回结果，在通过socket发送出去。 重点在invoke方法：通过反射的方式对方法进行调用 还有spring的最后一步，配置和启动: 12345678@Configuration@ComponentScan(basePackages = \"com.pd\")public class SpringConfig&#123; @Bean public RpcServer rpcServer()&#123; return new RpcServer(8080); &#125;&#125; 1234567public class App &#123; public static void main( String[] args ) &#123; AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(SpringConfig.class); context.start(); &#125;&#125; 运行： 先启动rpc-server 再启动rpc-client 结果：Response: hello, zzk 总结流程图示： 参考代码","categories":[{"name":"分布式架构技术","slug":"分布式架构技术","permalink":"https://zzkenyon.github.io/categories/分布式架构技术/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"https://zzkenyon.github.io/tags/RPC/"}],"keywords":[{"name":"分布式架构技术","slug":"分布式架构技术","permalink":"https://zzkenyon.github.io/categories/分布式架构技术/"}]},{"title":"CSRF攻击与防御（转）","slug":"其他-CSRF攻击与防御","date":"2020-04-13T16:00:00.000Z","updated":"2020-06-12T00:32:49.804Z","comments":true,"path":"2020/04/14/其他-CSRF攻击与防御/","link":"","permalink":"https://zzkenyon.github.io/2020/04/14/其他-CSRF攻击与防御/","excerpt":"","text":"转载地址 CSRF概念：CSRF跨站点请求伪造(Cross—Site Request Forgery)，跟XSS攻击一样，存在巨大的危害性，你可以这样来理解：攻击者盗用了你的身份，以你的名义发送恶意请求，对服务器来说这个请求是完全合法的，但是却完成了攻击者所期望的一个操作，比如以你的名义发送邮件、发消息，盗取你的账号，添加系统管理员，甚至于购买商品、虚拟货币转账等。 如下：其中Web A为存在CSRF漏洞的网站，Web B为攻击者构建的恶意网站，User C为Web A网站的合法用户。 CSRF攻击攻击原理及过程如下： 用户C打开浏览器，访问受信任网站A，输入用户名和密码请求登录网站A； 在用户信息通过验证后，网站A产生Cookie信息并返回给浏览器，此时用户登录网站A成功，可以正常发送请求到网站A； 用户未退出网站A之前，在同一浏览器中，打开一个TAB页访问网站B； 网站B接收到用户请求后，返回一些攻击性代码，并发出一个请求要求访问第三方站点A； 浏览器在接收到这些攻击性代码后，根据网站B的请求，在用户不知情的情况下携带Cookie信息，向网站A发出请求。网站A并不知道该请求其实是由B发起的，所以会根据用户C的Cookie信息以C的权限处理该请求，导致来自网站B的恶意代码被执行。 CSRF攻击实例受害者 Bob 在银行有一笔存款，通过对银行的网站发送请求 http://bank.example/withdraw?account=bob&amp;amount=1000000&amp;for=bob2 可以使 Bob 把 1000000 的存款转到 bob2 的账号下。通常情况下，该请求发送到网站后，服务器会先验证该请求是否来自一个合法的 session，并且该 session 的用户 Bob 已经成功登陆。 黑客 Mallory 自己在该银行也有账户，他知道上文中的 URL 可以把钱进行转帐操作。Mallory 可以自己发送一个请求给银行：http://bank.example/withdraw?account=bob&amp;amount=1000000&amp;for=Mallory。但是这个请求来自 Mallory 而非 Bob，他不能通过安全认证，因此该请求不会起作用。 这时，Mallory 想到使用 CSRF 的攻击方式，他先自己做一个网站，在网站中放入如下代码： src=”http://bank.example/withdraw?account=bob&amp;amount=1000000&amp;for=Mallory ”，并且通过广告等诱使 Bob 来访问他的网站。当 Bob 访问该网站时，上述 url 就会从 Bob 的浏览器发向银行，而这个请求会附带 Bob 浏览器中的 cookie 一起发向银行服务器。大多数情况下，该请求会失败，因为他要求 Bob 的认证信息。但是，如果 Bob 当时恰巧刚访问他的银行后不久，他的浏览器与银行网站之间的 session 尚未过期，浏览器的 cookie 之中含有 Bob 的认证信息。这时，悲剧发生了，这个 url 请求就会得到响应，钱将从 Bob 的账号转移到 Mallory 的账号，而 Bob 当时毫不知情。等以后 Bob 发现账户钱少了，即使他去银行查询日志，他也只能发现确实有一个来自于他本人的合法请求转移了资金，没有任何被攻击的痕迹。而 Mallory 则可以拿到钱后逍遥法外。 CSRF漏洞检测：检测CSRF漏洞是一项比较繁琐的工作，最简单的方法就是抓取一个正常请求的数据包，去掉Referer字段后再重新提交，如果该提交还有效，那么基本上可以确定存在CSRF漏洞。 随着对CSRF漏洞研究的不断深入，不断涌现出一些专门针对CSRF漏洞进行检测的工具，如CSRFTester，CSRF Request Builder等。 以CSRFTester工具为例，CSRF漏洞检测工具的测试原理如下：使用CSRFTester进行测试时，首先需要抓取我们在浏览器中访问过的所有链接以及所有的表单等信息，然后通过在CSRFTester中修改相应的表单等信息，重新提交，这相当于一次伪造客户端请求。如果修改后的测试请求成功被网站服务器接受，则说明存在CSRF漏洞，当然此款工具也可以被用来进行CSRF攻击。 防御CSRF攻击：（1）验证 HTTP Referer 字段根据 HTTP 协议，在 HTTP 头中有一个字段叫 Referer，它记录了该 HTTP 请求的来源地址。在通常情况下，访问一个安全受限页面的请求来自于同一个网站，比如需要访问 http://bank.example/withdraw?account=bob&amp;amount=1000000&amp;for=Mallory，用户必须先登陆 bank.example，然后通过点击页面上的按钮来触发转账事件。这时，该转帐请求的 Referer 值就会是转账按钮所在的页面的 URL，通常是以 bank.example 域名开头的地址。而如果黑客要对银行网站实施 CSRF 攻击，他只能在他自己的网站构造请求，当用户通过黑客的网站发送请求到银行时，该请求的 Referer 是指向黑客自己的网站。因此，要防御 CSRF 攻击，银行网站只需要对于每一个转账请求验证其 Referer 值，如果是以 bank.example 开头的域名，则说明该请求是来自银行网站自己的请求，是合法的。如果 Referer 是其他网站的话，则有可能是黑客的 CSRF 攻击，拒绝该请求。 这种方法的显而易见的好处就是简单易行，网站的普通开发人员不需要操心 CSRF 的漏洞，只需要在最后给所有安全敏感的请求统一增加一个拦截器来检查 Referer 的值就可以。特别是对于当前现有的系统，不需要改变当前系统的任何已有代码和逻辑，没有风险，非常便捷。 然而，这种方法并非万无一失。Referer 的值是由浏览器提供的，虽然 HTTP 协议上有明确的要求，但是每个浏览器对于 Referer 的具体实现可能有差别，并不能保证浏览器自身没有安全漏洞。使用验证 Referer 值的方法，就是把安全性都依赖于第三方（即浏览器）来保障，从理论上来讲，这样并不安全。事实上，对于某些浏览器，比如 IE6 或 FF2，目前已经有一些方法可以篡改 Referer 值。如果 bank.example 网站支持 IE6 浏览器，黑客完全可以把用户浏览器的 Referer 值设为以 bank.example 域名开头的地址，这样就可以通过验证，从而进行 CSRF 攻击。 即便是使用最新的浏览器，黑客无法篡改 Referer 值，这种方法仍然有问题。因为 Referer 值会记录下用户的访问来源，有些用户认为这样会侵犯到他们自己的隐私权，特别是有些组织担心 Referer 值会把组织内网中的某些信息泄露到外网中。因此，用户自己可以设置浏览器使其在发送请求时不再提供 Referer。当他们正常访问银行网站时，网站会因为请求没有 Referer 值而认为是 CSRF 攻击，拒绝合法用户的访问。 （2）在请求地址中添加 token 并验证CSRF 攻击之所以能够成功，是因为黑客可以完全伪造用户的请求，该请求中所有的用户验证信息都是存在于 cookie 中，因此黑客可以在不知道这些验证信息的情况下直接利用用户自己的 cookie 来通过安全验证。要抵御 CSRF，关键在于在请求中放入黑客所不能伪造的信息，并且该信息不存在于 cookie 之中。可以在 HTTP 请求中以参数的形式加入一个随机产生的 token，并在服务器端建立一个拦截器来验证这个 token，如果请求中没有 token 或者 token 内容不正确，则认为可能是 CSRF 攻击而拒绝该请求。 这种方法要比检查 Referer 要安全一些，token 可以在用户登陆后产生并放于 session 之中，然后在每次请求时把 token 从 session 中拿出，与请求中的 token 进行比对，但这种方法的难点在于如何把 token 以参数的形式加入请求。对于 GET 请求，token 将附在请求地址之后，这样 URL 就变成 http://url?csrftoken=tokenvalue。 而对于 POST 请求来说，要在 form 的最后加上 ，这样就把 token 以参数的形式加入请求了。但是，在一个网站中，可以接受请求的地方非常多，要对于每一个请求都加上 token 是很麻烦的，并且很容易漏掉，通常使用的方法就是在每次页面加载时，使用 javascript 遍历整个 dom 树，对于 dom 中所有的 a 和 form 标签后加入 token。这样可以解决大部分的请求，但是对于在页面加载之后动态生成的 html 代码，这种方法就没有作用，还需要程序员在编码时手动添加 token。 该方法还有一个缺点是难以保证 token 本身的安全。特别是在一些论坛之类支持用户自己发表内容的网站，黑客可以在上面发布自己个人网站的地址。由于系统也会在这个地址后面加上 token，黑客可以在自己的网站上得到这个 token，并马上就可以发动 CSRF 攻击。为了避免这一点，系统可以在添加 token 的时候增加一个判断，如果这个链接是链到自己本站的，就在后面添加 token，如果是通向外网则不加。不过，即使这个 csrftoken 不以参数的形式附加在请求之中，黑客的网站也同样可以通过 Referer 来得到这个 token 值以发动 CSRF 攻击。这也是一些用户喜欢手动关闭浏览器 Referer 功能的原因。 （3）在 HTTP 头中自定义属性并验证这种方法也是使用 token 并进行验证，和上一种方法不同的是，这里并不是把 token 以参数的形式置于 HTTP 请求之中，而是把它放到 HTTP 头中自定义的属性里。通过 XMLHttpRequest 这个类，可以一次性给所有该类请求加上 csrftoken 这个 HTTP 头属性，并把 token 值放入其中。这样解决了上种方法在请求中加入 token 的不便，同时，通过 XMLHttpRequest 请求的地址不会被记录到浏览器的地址栏，也不用担心 token 会透过 Referer 泄露到其他网站中去。 然而这种方法的局限性非常大。XMLHttpRequest 请求通常用于 Ajax 方法中对于页面局部的异步刷新，并非所有的请求都适合用这个类来发起，而且通过该类请求得到的页面不能被浏览器所记录下，从而进行前进，后退，刷新，收藏等操作，给用户带来不便。另外，对于没有进行 CSRF 防护的遗留系统来说，要采用这种方法来进行防护，要把所有请求都改为 XMLHttpRequest 请求，这样几乎是要重写整个网站，这代价无疑是不能接受的。","categories":[{"name":"其他","slug":"其他","permalink":"https://zzkenyon.github.io/categories/其他/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://zzkenyon.github.io/tags/网络/"}],"keywords":[{"name":"其他","slug":"其他","permalink":"https://zzkenyon.github.io/categories/其他/"}]},{"title":"分布式-logstash配置文件编写","slug":"分布式-logstash配置文件编写","date":"2020-04-08T16:00:00.000Z","updated":"2020-06-12T00:27:44.000Z","comments":true,"path":"2020/04/09/分布式-logstash配置文件编写/","link":"","permalink":"https://zzkenyon.github.io/2020/04/09/分布式-logstash配置文件编写/","excerpt":"","text":"贴一下配置好的logstash配置文件 12345678910111213141516171819202122input&#123; tcp&#123; port=&gt;4675 codec=&gt;json &#125;&#125;filter&#123; mutate&#123; gsub=&gt;[&quot;message&quot;,&quot;[\\\\]&quot;,&quot;&quot;] &#125; json&#123; source=&gt;&quot;message&quot; &#125;&#125;output&#123; elasticsearch&#123; action=&gt;index host=&gt;localhost:9092 index=&gt;&quot;dmp_audit_logs_%&#123;[+YYYY-MM-dd]&#125;&quot; &#125;&#125; 配置中主要分为三部分input、filter、output，这三部分是logstash pipeline中的三个元素，其中input和output是必须的，filter是可选的。 input配置数据的输入源 控制台输入 文件输入 插件输入（beat） 中间件输入（kafka） 应用日志输入（日志appender） 最简单的输入源配置： 12input&#123; stdin&#123;&#125; &#125;output&#123; stdout&#123;&#125; &#125; //控制台输出 这样就配置了一个控制台输入和输出，启动logstash在控制台输入一条消息：hello logstash 控制台输出如下： 123456&#123; \"@timestamp\" =&gt; 2020-06-10T00:29:46.056Z, \"message\" =&gt; \"hello logstash\", \"@version\" =&gt; \"1\", \"host\" =&gt; \"zzk-redis.novalocal\"&#125; logstash会自动给消息加上时间戳和版本信息，以及消息来源的ip，这里由于是本地发送的消息，所以host显示的是主机名 需求：将系统日志以json格式直接发送到logstash服务器 项目中配置logAppender，将日志直接发送给logshatsh的10514端口， 123456input&#123; tcp&#123; port=&gt;10514 // 配置logstash监听4675端口 codec=&gt;json // 配置数据解析方式为json &#125;&#125; 在生产环境中，当服务器访问量较大，连续执行日志写出动作，出现了tcp拆包的问题，见下图： 可以看到，一条日志被拆成了两份，导致json解析失败。 所以高并发场景下，直接将日志写出到logstash是不可取的。 在中间加一层kafka就能解决上述问题，logAppender直接将日志文件写出到kafka中，logstash配置输入源为kafka，kafka作为消息中间件，一定不存在tcp拆包问题。 output配置数据输出目的地： 标准输出 es输出 中间件输出 需求：将日志数据输出到es存储 1234567output&#123; elasticsearch&#123; action=&gt;index host=&gt;localhost:9092 index=&gt;\"dmp_audit_logs_%&#123;[+YYYY-MM-dd]&#125;\" &#125;&#125; action=&gt;index表示是插入索引操作 host=&gt;localhost:9092 es的host index=&gt;”dmp_audit_logs_%{[+YYYY-MM-dd]}” 表示插入的索引名称 配置完input和output就可以收集数据上传到es啦，那么logstash肯定不是只有这么简单的收集&amp;上传操作，logstash主要解决的问题是将乱七八糟各式各样的日志文件，整理成统一的格式上传到es，方便es进行统计分析。最主要的功能是在可选的filter模块实现的。 filter我在上传审计日志的过程中，遇到一些问题： 审计日志主要是采集了用户的一些请求信息，将这些信息转换成json字符串之后，字串携带了大量的转义反斜杠，将这个字串直接上传到logstash，发现审计信息不能解析出来，还是以json字串形式存放在message字段中，我的需求是将所有的信息都解析成独立的字段。 字串去反斜杠 去反斜杠的操作不能再在java中执行，因为java并不知道反斜杠的存在 因此需要在logshtash中进行配置 12345678filter&#123; mutate&#123; gsub=&gt;[\"message\",\"[\\\\]\",\"\"] // 去掉反斜杠 &#125; json&#123; source=&gt;\"message\" &#125;&#125; gsub 操作：将制定字段中的 某字串 替换成 另一个字符（串） json操作： 对制定字段的信息执行反json操作，获取字段信息 以上就解决了将java审计日志上传至es的配置 filter可以对数据字段进行很多的操作，本业务场景中并没有用到，可以参考一以下链接 一文快速上手Logstash logstash配置文件详解 Logstash输出到Elasticsearch笔记 Logstash替换字符串","categories":[{"name":"分布式架构技术","slug":"分布式架构技术","permalink":"https://zzkenyon.github.io/categories/分布式架构技术/"}],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://zzkenyon.github.io/tags/ElasticSearch/"}],"keywords":[{"name":"分布式架构技术","slug":"分布式架构技术","permalink":"https://zzkenyon.github.io/categories/分布式架构技术/"}]},{"title":"ELK统一日志管理","slug":"分布式-ELK统一日志管理","date":"2020-04-06T16:00:00.000Z","updated":"2020-06-12T00:42:20.960Z","comments":true,"path":"2020/04/07/分布式-ELK统一日志管理/","link":"","permalink":"https://zzkenyon.github.io/2020/04/07/分布式-ELK统一日志管理/","excerpt":"","text":"ElasticSearch部署下载解压改配置文件/config/elasticsearch.yml 12345cluster.name: my-applicationnode.name: node-1network.host: 0.0.0.0http.port: 9200cluster.initial_master_nodes: [\"node-1\"] 启动es命令： 123cd /usr/app/elasticSearch#后台启动./bin/elasticksearch -d Kibana部署下载解压改配置文件/config/kibana.yml： 123port: 5601server.host: 0.0.0.0elasticsearch.hosts: [\"ip:port\",\"ip:port\"] 启动kibana命令： 123cd /usr/app/kibana#后台启动nohup ./bin/kibana &amp; logstash部署启动logstash 1234567cd /usr/app/logstash/bin#测试logstash --path.settings ../config/ -f ../config/logstash.conf --config.test_and_exit#启动logstash -f ../config/logstash-es.conf#查看端口监听状态以及pidnetstat -lntp |grep 10514 logstash-es.conf 文件 12345678910111213141516171819202122input &#123; tcp &#123; port =&gt; 10514 codec =&gt; json &#125;&#125;filter &#123; grok &#123; match=&gt;&#123;\"message\"=&gt; \"%&#123;IP:client&#125; %&#123;WORD:method&#125; %&#123;URIPATHPARAM:request&#125; %&#123;NUMBER:bytes&#125; %&#123;NUMBER:duration&#125;\" &#125; &#125;&#125;output &#123; stdout&#123; codec=&gt;rubydebug #美化输出 &#125; elasticsearch &#123; action =&gt; \"index\" hosts =&gt; [\"10.0.12.72:9200\"] index =&gt; \"dmp_audit_logs_%&#123;[+YYYY-MM-dd]&#125;\" &#125;&#125; logback.xml 1234567891011121314151617181920212223242526272829303132&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration debug=\"false\" scan=\"false\"&gt; &lt;appender name=\"console\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;MM-dd HH:mm:ss.SSS&#125; %-5level [%logger&#123;50&#125;] - %msg%n &lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name=\"logstash\" class=\"net.logstash.logback.appender.LogstashTcpSocketAppender\"&gt; &lt;param name=\"Encoding\" value=\"UTF-8\"/&gt; &lt;destination&gt;10.0.12.72:10514&lt;/destination&gt; &lt;encoder charset=\"UTF-8\" class=\"net.logstash.logback.encoder.LogstashEncoder\"&gt; &lt;!--%&#123;appName&#125;中的appName需要在属性中配置，作为字段写入到doc中--&gt; &lt;customFields&gt;&#123;\"appname\":\"dmp\"&#125;&lt;/customFields&gt; &lt;/encoder&gt; &lt;connectionStrategy&gt; &lt;roundRobin&gt; &lt;connectionTTL&gt;5 minutes&lt;/connectionTTL&gt; &lt;/roundRobin&gt; &lt;/connectionStrategy&gt; &lt;/appender&gt; &lt;root level=\"info\"&gt; &lt;appender-ref ref=\"console\"/&gt; &lt;/root&gt; &lt;logger name=\"com.cetiti.es.controller\" level=\"INFO\" addtivity=\"false\"&gt; &lt;appender-ref ref=\"logstash\"/&gt; &lt;/logger&gt;&lt;/configuration&gt; 参考文档： ELK-概念 logback+ELK日志搭建","categories":[{"name":"分布式架构技术","slug":"分布式架构技术","permalink":"https://zzkenyon.github.io/categories/分布式架构技术/"}],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://zzkenyon.github.io/tags/ElasticSearch/"}],"keywords":[{"name":"分布式架构技术","slug":"分布式架构技术","permalink":"https://zzkenyon.github.io/categories/分布式架构技术/"}]},{"title":"系统审计日志需求分析及方案","slug":"业务-系统审计日志需求分析以及方案","date":"2020-04-05T16:00:00.000Z","updated":"2021-01-25T09:25:29.676Z","comments":true,"path":"2020/04/06/业务-系统审计日志需求分析以及方案/","link":"","permalink":"https://zzkenyon.github.io/2020/04/06/业务-系统审计日志需求分析以及方案/","excerpt":"","text":"在一个完整的信息系统里面，日志系统是一个非常重要的功能组成部分。它可以记录下系统所产生的所有行为，并按照某种规范表达出来。我们可以使用日志系统所记录的信息为系统进行排错，优化系统的性能，或者根据这些信息调整系统的行为。在安全领域，日志可以反应出很多的安全攻击行为，比如登录错误，异常访问等。日志还能告诉你很多关于网络中所发生事件的信息，包括性能信息、故障检测和入侵检测。日志会成为在事故发生后查明“发生了什么”的一个很好的“取证”信息来源。日志可以为审计进行审计跟踪。 需求分析审计日志在哪里执行记录操作？ controller层？service层？dao层？ controller层最先接触到request请求，如果我们要对分析用户的行为，那么日志应该在c层记录 service层是向c层提供服务的，整合了数据访问、数据计算等任务，如果要分析系统服务性能、那么日志应该打在s层 dao层是数据访问层，主要负责数据库的读写任务，如果要对数据访问接口的性能进行分析，那么日志应该在dao层 审计日志内容怎么存储？ 日志文件？关系？es？ 写日志文件是对磁盘顺序写操作，操作效率高，但是有两个缺点：一是不利于检索，一是日志文件存储在本地，分布式环境下不利于日志统一管理，因此日志文件不适合审计日志的存储 关系型数据，中小型系统可以使用，随着日志越来越多，检索效率降低，可以根据日志时间或者日志类型分表存储，缺点是日志分析不是很方便 ES，卓越的检索效率，集群部署方便扩展的特点，是审计日志最好的存储方式，自带分析统计功能，可以实时统计 审计日志要记录哪些内容？ 针对用户分析日志：请求用户、请求ip地址、请求参数、 针对服务分析日志：服务接口执行时间、调用次数、堆栈大小，继而可以分析出服务的调用频率、平均耗时 用户行为分析： 登录日志：记录登录时间、登录ip地址、登录用户、登录结果 业务访问日志：记录操作时间、用户Ip地址、访问接口、请求参数、请求结果 确定方案spring-aop + 自定义注解 + elk aop面向切面的思想可以将记录日志逻辑 从 业务逻辑中解耦出来 自定义注解可以 更灵活的 指定切面 es存储日志，便于扩展，利于检索和分析 方案实现所有的外部请求都会经过网关，网关负责登录，考虑到登录与业务访问需要记录的日志内容不太相同，所以登录模块单独设计一个注解，业务模块可以共用一个注解。 登录模块： 业务模块：","categories":[{"name":"随便写写","slug":"随便写写","permalink":"https://zzkenyon.github.io/categories/随便写写/"}],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://zzkenyon.github.io/tags/ElasticSearch/"}],"keywords":[{"name":"随便写写","slug":"随便写写","permalink":"https://zzkenyon.github.io/categories/随便写写/"}]},{"title":"分布式-全局一致性id","slug":"分布式-全局ID","date":"2020-03-12T16:00:00.000Z","updated":"2020-12-14T08:06:30.213Z","comments":true,"path":"2020/03/13/分布式-全局ID/","link":"","permalink":"https://zzkenyon.github.io/2020/03/13/分布式-全局ID/","excerpt":"","text":"全局ID的要求 全局唯一性 有序的递增性 高可用性 时间上的特性 全局ID的实现方式 UUID，32个字符， 4个横线 18 - 4-4-4- 12 ​ UUID.randomUUID.toString(); ​ 基于时间的UUID(time &amp; MAC) ​ UUID(time&amp;POSIX UID或GID) ​ 随机数的UUID ​ UUID(SHA1) 数据库 1234create table sequence( id int auto_increment, b_id int unique_key) 1234begin replace into sequence(b_id) values(); select LAST_INSERT_ID();commit; redis/mongdb increBy / incr ObjectId 3. 雪花算法3.1 介绍使用64位长整型表示id 1bit，不用，因为二进制中最高位是符号位，1表示负数，0表示正数。生成的id一般都是用整数，所以最高位固定为0。 41bit-时间戳，用来记录时间戳，毫秒级。 41位可以表 2^{41}-1 个数字 如果只用来表示正整数（计算机中正数包含0），可以表示的数值范围是：0 至 2^{41}-1，减1是因为可表示的数值范围是从0开始算的，而不是1。 也就是说41位可以表示个毫秒的值，转化成单位年则是(2^{41}-1) / (1000 60 60 24 365) = 69年 10bit-工作机器id，用来记录工作机器id。 可以部署在 2^{10} = 1024 个节点，包括5位datacenterId和5位workerId 5位（bit）可以表示的最大正整数是2^{5}-1 = 31，即可以用0、1、2、3、….31这32个数字，来表示不同的datecenterId或workerId 12bit-序列号，序列号，用来记录同毫秒内产生的不同id。 12位（bit）可以表示的最大正整数是2^{12}-1 = 4095，即可以用0、1、2、3、….4094这4095个数字，来表示同一机器同一时间截（毫秒)内产生的4095个ID序号。 由于在Java中64bit的整数是long类型，所以在Java中SnowFlake算法生成的id就是long来存储的。 SnowFlake可以保证： 所有生成的id按时间趋势递增 整个分布式系统内不会产生重复id（因为有datacenterId和workerId来做区分） 3.2 实现4. 美团leaf算法4.1 leaf-snowflake snowflake算法：改造时钟回拨的问题 4.2 leaf-segment每次取优化为批量取 为了防止网络抖动，使用双buffer存储号段 5. 百度UIDGeneratorsnowflake算法(改造版本)","categories":[{"name":"分布式架构技术","slug":"分布式架构技术","permalink":"https://zzkenyon.github.io/categories/分布式架构技术/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"https://zzkenyon.github.io/tags/RPC/"}],"keywords":[{"name":"分布式架构技术","slug":"分布式架构技术","permalink":"https://zzkenyon.github.io/categories/分布式架构技术/"}]},{"title":"redis-热key问题","slug":"redis-热点key问题","date":"2020-01-01T16:00:00.000Z","updated":"2020-10-28T02:57:40.773Z","comments":true,"path":"2020/01/02/redis-热点key问题/","link":"","permalink":"https://zzkenyon.github.io/2020/01/02/redis-热点key问题/","excerpt":"","text":"原文链接 所谓热key问题就是，突然有几十万的请求去访问redis上的某个特定key。那么，这样会造成流量过于集中，达到物理网卡上限，从而导致这台redis的服务器宕机。那接下来这个key的请求，就会直接怼到你的数据库上，导致你的服务不可用。 1. 怎么发现热key方法一:凭借业务经验，进行预估哪些是热key其实这个方法还是挺有可行性的。比如某商品在做秒杀，那这个商品的key就可以判断出是热key。 缺点很明显，并非所有业务都能预估出哪些key是热key。 方法二:在客户端进行收集这个方式就是在操作redis之前，加入一行代码进行数据统计。那么这个数据统计的方式有很多种，也可以是给外部的通讯系统发送一个通知信息。缺点就是对客户端代码造成入侵。 方法三:在Proxy层做收集有些集群架构是下面这样的，Proxy可以是Twemproxy，是统一的入口。可以在Proxy层做收集上报，但是缺点很明显，并非所有的redis集群架构都有proxy。 方法四:用redis自带命令 monitor命令，该命令可以实时抓取出redis服务器接收到的命令，然后写代码统计出热key是啥。当然，也有现成的分析工具可以给你使用，比如redis-faina。但是该命令在高并发的条件下，有内存暴增的隐患，还会降低redis的性能。 hotkeys参数，redis 4.0.3提供了redis-cli的热点key发现功能，执行redis-cli时加上–hotkeys选项即可。但是该参数在执行的时候，如果key比较多，执行起来比较慢。 缺点是对redis性能影响较大 方法五:自己抓包评估Redis客户端使用TCP协议与服务端进行交互，通信协议采用的是RESP。自己写程序监听端口，按照RESP协议规则解析数据，进行分析。缺点就是开发成本高，维护困难，有丢包可能性。 以上五种方案，各有优缺点。根据自己业务场景进行抉择即可。那么发现热key后，如何解决呢？ 2. 如何解决目前业内的方案有两种 方案一：利用二级缓存比如利用ehcache，或者一个HashMap都可以。在你发现热key以后，把热key加载到系统的JVM中。针对这种热key请求，会直接从jvm中取，而不会走到redis层。假设此时有十万个针对同一个key的请求过来,如果没有本地缓存，这十万个请求就直接怼到同一台redis上了。现在假设，你的应用层有50台机器，OK，你也有jvm缓存了。这十万个请求平均分散开来，每个机器有2000个请求，会从JVM中取到value值，然后返回数据。避免了十万个请求怼到同一台redis上的情形。 方案二：备份热key这个方案也很简单。不要让key走到同一台redis上不就行了。我们把这个key，在多个redis上都存一份不就好了。接下来，有热key请求进来的时候，我们就在有备份的redis上随机选取一台，进行访问取值，返回数据。假设redis的集群数量为N，步骤如下图所示 注:不一定是2N，你想取3N，4N都可以，看要求。伪代码如下 12345678910const M = N * 2//生成随机数random = GenRandom(0, M)//构造备份新keybakHotKey = hotKey + “_” + randomdata = redis.GET(bakHotKey)if data == NULL &#123; data = GetFromDB() redis.SET(bakHotKey, expireTime + GenRandom(0,5))&#125; 3. 业内方案OK，其实看完上面的内容，大家可能会有一个疑问。 有办法在项目运行过程中，自动发现热key，然后程序自动处理么？ 嗯，好问题，那我们来讲讲业内怎么做的。其实只有两步 监控热key 通知系统做处理 正巧，前几天有赞出了一篇《有赞透明多级缓存解决方案（TMC）》，里头也有提到热点key问题，我们刚好借此说明 监控热key 在监控热key方面，有赞用的是方式二：在客户端进行收集。在《有赞透明多级缓存解决方案（TMC）》中有一句话提到 TMC 对原生jedis包的JedisPool和Jedis类做了改造，在JedisPool初始化过程中集成TMC“热点发现”+“本地缓存”功能Hermes-SDK包的初始化逻辑。 也就说人家改写了jedis原生的jar包，加入了Hermes-SDK包。那Hermes-SDK包用来干嘛？OK，就是做热点发现和本地缓存。 从监控的角度看，该包对于Jedis-Client的每次key值访问请求，Hermes-SDK 都会通过其通信模块将key访问事件异步上报给Hermes服务端集群，以便其根据上报数据进行“热点探测”。 当然，这只是其中一种方式，有的公司在监控方面用的是方式五:自己抓包评估。 具体是这么做的，先利用flink搭建一套流式计算系统。然后自己写一个抓包程序抓redis监听端口的数据，抓到数据后往kafka里丢。接下来，流式计算系统消费kafka里的数据，进行数据统计即可，也能达到监控热key的目的。 通知系统做处理 在这个角度，有赞用的是上面的解决方案一:利用二级缓存进行处理。 有赞在监控到热key后，Hermes服务端集群会通过各种手段通知各业务系统里的Hermes-SDK，告诉他们:”老弟，这个key是热key，记得做本地缓存。” 于是Hermes-SDK就会将该key缓存在本地，对于后面的请求。Hermes-SDK发现这个是一个热key，直接从本地中拿，而不会去访问集群。 除了这种通知方式以外。我们也可以这么做，比如你的流式计算系统监控到热key了，往zookeeper里头的某个节点里写。然后你的业务系统监听该节点，发现节点数据变化了，就代表发现热key。最后往本地缓存里写，也是可以的。 通知方式各种各样，大家可以自由发挥。本文只是提供一个思路。","categories":[{"name":"noSql","slug":"noSql","permalink":"https://zzkenyon.github.io/categories/noSql/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://zzkenyon.github.io/tags/redis/"}],"keywords":[{"name":"noSql","slug":"noSql","permalink":"https://zzkenyon.github.io/categories/noSql/"}]},{"title":"mysql-innoDB架构分析","slug":"数据库技术-mysql-innoDB架构分析","date":"2020-01-01T16:00:00.000Z","updated":"2020-11-03T02:00:27.534Z","comments":true,"path":"2020/01/02/数据库技术-mysql-innoDB架构分析/","link":"","permalink":"https://zzkenyon.github.io/2020/01/02/数据库技术-mysql-innoDB架构分析/","excerpt":"","text":"先上一张官网的架构图，本文将按照架构图中的组件逐一分析。 1. buffer pool按照局部性原理，将预期会使用到的数据缓存到内存中，避免每次读取数据都需要进行磁盘i/o，提升i/o性能，这块存放缓存的内存区域就是buffer pool。 buffer pool 是一种降低磁盘访问的机制。 磁盘访问通常以页为单位。 缓存池常见的实现方式是LRU（链表实现，为了减少数据移动），管理磁盘页。 缓存池管理方式–LRU（链表实现，为了减少数据移动） 普通LRU会有以下问题： 预读取失效，预读取的页不会真正被读取 优化思路：让预读失效页尽快出内存，真正读取页才挪到LRU头部 方案：分代管理，预读取进入老生代，真正读取再进入新生代 缓冲池污染，要批量扫描大量数据，导致缓冲池中的热点页被大量替换出去 方案：在老生代设置停留时间，只有被真正读取并且停留时间达到阈值，才会移步新生代 innoDB 的buffer pool 对应参数 参数：innodb_buffer_pool_size 介绍：配置缓冲池的大小，在内存允许的情况下，DBA往往会建议调大这个参数，越多数据和索引放到内存里，数据库的性能会越好。 参数：innodb_old_blocks_pct 介绍：老生代占整个LRU链长度的比例，默认是37，即整个LRU中新生代与老生代长度比例是63:37。 画外音：如果把这个参数设为100，就退化为普通LRU了。 参数：innodb_old_blocks_time 介绍：老生代停留时间窗口，单位是毫秒，默认是1000，即同时满足“被访问”与“在老生代停留时间超过1秒”两个条件，才会被插入到新生代头部。 Buffer pool 参考链接 对于读请求，buffer pool 能够减少磁盘的io，提高性能，那么对于写请求呢？ 2. Change Buffer而对于写请求的优化，就是使用change buffer 来降低磁盘io的 主要应用于不在缓冲池中的非唯一普通索引页的写操作 如果要写的页写已经在缓冲池中了是怎样一个写流程？ 为什么唯一索引不适用呢？ 唯一索引的话每次插入操作都需要检查索引的唯一性 change buffer 参考 相关参数： 参数：innodb_change_buffer_max_size 介绍：配置写缓冲的大小，占整个缓冲池的比例，默认值是25%，最大值是50%。 画外音：写多读少的业务，才需要调大这个值，读多写少的业务，25%其实也多了。 参数：innodb_change_buffering 介绍：配置哪些写操作启用写缓冲，可以设置成all/none/inserts/deletes等。 3. Log buffer知其然，知其所以然。思路比结论重要 事务提交时，事务日志为什么要先写到log buffer 在写到os cache中呢？ 虽然是内存操作，但是日志写到os cache中需要进行上下文切换切换到内核态，每次事务提交都直接写则每次都要切换到内核态。先写到log buffer中，将每次写优化为批量写，减少上下文切换次数。 这个优化思路很常见，高并发的MQ落盘，高并发的业务数据落盘，都可以使用。 4. AHI–Adaptive Hash Index自适应哈希索引 为什么叫自适应？ 用户不能创建，是mysql优化器自行判断，需要时创建 既然是hash，key是什么，value是什么？ key是索引键值 value是索引记录的页面位置 所以hash索引是索引的索引 为什么要用哈希索引进行优化？ 通过附加索引查询数据时，有时候会进行回表查询，这样会导致查询连路很长降低查询效率 哪些业务适用，哪些业务不适用？ 单行记录查询、索引范围查询、记录数不多能全部放到内存中—-适用 业务中有大量join、like时，AHI的维护会成为负担，建议手动关闭。 5. redo log有单独文章讲解 6. double write buffer知其然，知其所以然。思路比结论重要 解决什么问题？ innoDB数据页大小是16k，文件系统中的数据页（后称系统页）大小是4K，那么写数据库时我们将一页数据页落盘，需要刷写4页系统页，如果在此过程中系统掉电，将造成磁盘数据页损坏（例如，前两页系统页已被刷写，后两页未刷写）。 双写缓存 如何解决？ DWB缓存即将刷写的数据页。 DWB具有两层架构，分为内存和磁盘 当有数据要落盘时： 第一步：将内存中修改后的数据页memcopy到dwb内存中 第二步：将dwb内存中的数据页写入dwb磁盘 第三步：将dwb中的数据页落盘到磁盘数据页 假使第二步掉电，磁盘数据页也还是完整的，可以通过redo log进行恢复，redo无法修复这类“页数据损坏”的异常，修复的前提是“页数据正确”并且redo日志正常。 假如第三笔掉电，dwb中的数据页也是完整的，可以直接落盘 性能影响大吗？ 第一步属于内存操作，速度很快 第二步属于磁盘顺序追加写，1秒几万次没问题 第三步不属于额外操作 另外，dwb 由128页组成，容量2MB，会分两次刷入dwb磁盘，每次1M，速度也很快 有第三方评测，性能损失约为10% 可以通过： show global status like “%dblwr%” 查看dwb使用情况 Innodb_dblwr_pages_written 记录dwb中的写入页数 Innodb_dblwr_writes 记录dwb的写入次数","categories":[{"name":"数据库技术","slug":"数据库技术","permalink":"https://zzkenyon.github.io/categories/数据库技术/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://zzkenyon.github.io/tags/mysql/"}],"keywords":[{"name":"数据库技术","slug":"数据库技术","permalink":"https://zzkenyon.github.io/categories/数据库技术/"}]},{"title":"mysql-redo log写流程分析(转)","slug":"数据库技术-mysql-redo log写流程分析","date":"2020-01-01T16:00:00.000Z","updated":"2020-11-03T01:49:00.220Z","comments":true,"path":"2020/01/02/数据库技术-mysql-redo log写流程分析/","link":"","permalink":"https://zzkenyon.github.io/2020/01/02/数据库技术-mysql-redo log写流程分析/","excerpt":"","text":"原文链接：https://mp.weixin.qq.com/s/-Hx2KKYMEQCcTC-ADEuwVA 为什么我的事务提交了，还会丢失数据呢？ 这要从innoDB的一个参数说起 innodb_flush_log_at_trx_commit 参数的字面意思是innodb在事务提交时更新日志的方式，这个参数有 0，1，2 三种取值，表示有三种方式更新日志 首先我们要弄清楚事务提交时会更新那些日志呢？ 前滚日志redo log 和 回滚日志undo log ，这两者称为innodb的事务日志。 事务提交后，存储引擎要将事务对数据的修改刷写到磁盘上以保证事务的ACID特性 A: atomicity-原子性 C: consistency-一致性 I: isolation-隔离性 D: durability-持久性 这个刷盘，是一个随机写，随机写性能较低，如果每次事务提交都刷盘，会极大影响数据库的性能。 知其然，知其所以然。思路比结论重要 所以为了优化随机写带来的低性能，架构设计中有两个常见的优化方法： （1）先写日志(write log first)，将随机写优化为顺序写； （2）将每次写优化为批量写； 这两个优化，InnoDB都用上了。 先说第一个优化，将对数据的修改先顺序写到日志里，这个日志就是redo log。 假如某一时刻，数据库崩溃，还没来得及将数据页刷盘，数据库重启时，会重做redo log里的内容，以保证已提交事务对数据的影响被刷到磁盘上。因此，redo log 又称为重做日志。 一句话定义，redo log是为了保证已提交事务的ACID特性，同时能够提高数据库性能的技术。 既然redo log能保证事务的ACID特性，那为什么还会出现，水友提问中出现的“数据库奔溃，丢数据”的问题呢？一起看下redo log的实现细节。 redo log的三层架构 画了一个丑图，简单说明下redo log的三层架构： 粉色，是InnoDB的一项很重要的内存结构(In-Memory Structure)，日志缓冲区(Log Buffer)，这一层，是MySQL应用程序用户态 屎黄色，是操作系统的缓冲区(OS cache)，这一层，是OS内核态 蓝色，是落盘的日志文件 redo log最终落盘的步骤如何？ 首先，事务提交的时候，会写入Log Buffer，这里调用的是MySQL自己的函数WriteRedoLog； 接着，只有当MySQL发起系统调用写write时，Log Buffer里的数据，才会写到OS cache。注意，MySQL系统调用完write之后，就认为文件已经写完，至于什么时候落盘，是操作系统决定的； 画外音：有时候打日志，明明printf了，tail -f**却看不到，就是这个原因，这个细节在《明明打印到文件了，为啥tail -f看不到》一文里说过，此处不再展开。 最后，由操作系统（当然，MySQL也可以主动flush）将OS cache里的数据，最终fsync到磁盘上； 操作系统为什么要缓冲数据到OS cache里，而不直接刷盘呢？ 这里就是将“每次写”优化为“批量写”，以提高操作系统性能。 数据库为什么要缓冲数据到Log Buffer里，而不是直接write呢？ 这也是“每次写”优化为“批量写”思路的体现，以提高数据库性能。 画外音：这个优化思路，非常常见，高并发的MQ落盘，高并发的业务数据落盘，都可以使用。 redo log的三层架构，MySQL做了一次批量写优化，OS做了一次批量写优化，确实能极大提升性能，但有什么副作用吗？ 画外音：有优点，必有缺点。 这个副作用，就是可能丢失数据： （1）事务提交时，将redo log写入Log Buffer，就会认为事务提交成功； （2）如果写入Log Buffer的数据，write入OS cache之前，数据库崩溃，就会出现数据丢失； （3）如果写入OS cache的数据，fsync入磁盘之前，操作系统奔溃，也可能出现数据丢失； 画外音：如上文所说，应用程序系统调用完write之后（不可能每次write后都立刻flush，这样写日志很蠢），就认为写成功了，操作系统何时fsync，应用程序并不知道，如果操作系统崩溃，数据可能丢失。 任何脱离业务的技术方案都是耍流氓： （1）有些业务允许低效，但不允许一丁点数据丢失； （2）有些业务必须高性能高吞吐，能够容忍少量数据丢失； MySQL是如何折衷的呢？ MySQL有一个参数： 1innodb_flush_log_at_trx_commit 能够控制事务提交时，刷redo log的策略。 目前有三种策略： 策略一：最佳性能(innodb_flush_log_at_trx_commit=0) 每隔一秒，才将Log Buffer中的数据批量write入OS cache，同时MySQL主动fsync。 这种策略，如果数据库奔溃，有一秒的数据丢失。 策略二：强一致(innodb_flush_log_at_trx_commit=1) 每次事务提交，都将Log Buffer中的数据write入OS cache，同时MySQL主动fsync。 这种策略，是InnoDB的默认配置，为的是保证事务ACID特性。 策略三：折衷(innodb_flush_log_at_trx_commit=2) 每次事务提交，都将Log Buffer中的数据write入OS cache； 每隔一秒，MySQL主动将OS cache中的数据批量fsync。 画外音：磁盘IO次数不确定，因为操作系统的fsync频率并不是MySQL能控制的。 这种策略，如果操作系统奔溃，最多有一秒的数据丢失。 画外音：因为OS也会fsync，MySQL主动fsync的周期是一秒，所以最多丢一秒数据。 讲了这么多，回到水友的提问上来，数据库崩溃，重启后丢失了数据，有很大的可能，是将innodb_flush_log_at_trx_commit参数设置为0了，这位水友最好和DBA一起检查一下InnoDB的配置。 可能有水友要问，高并发的业务，InnoDB运用哪种刷盘策略最合适？ 高并发业务，行业最佳实践，是使用第三种折衷配置（=2），这是因为： 配置为2和配置为0，性能差异并不大，因为将数据从Log Buffer拷贝到OS cache，虽然跨越用户态与内核态，但毕竟只是内存的数据拷贝，速度很快； 配置为2和配置为0，安全性差异巨大，操作系统崩溃的概率相比MySQL应用程序崩溃的概率，小很多，设置为2，只要操作系统不奔溃，也绝对不会丢数据。 总结 一、为了保证事务的ACID特性，理论上每次事务提交都应该刷盘，但此时效率很低，有两种优化方向： 随机写优化为顺序写； 每次写优化为批量写； 二、redo log是一种顺序写，它有三层架构： MySQL应用层：Log Buffer OS内核层：OS cache OS文件：log file 三、为了满足不用业务对于吞吐量与一致性的需求，MySQL事务提交时刷redo log有三种策略： 0：每秒write一次OS cache，同时fsync刷磁盘，性能好； 1：每次都write入OS cache，同时fsync刷磁盘，一致性好； 2：每次都write入OS cache，每秒fsync刷磁盘，折衷； 四、高并发业务，行业内的最佳实践，是： 1innodb_flush_log_at_trx_commit=2","categories":[{"name":"数据库技术","slug":"数据库技术","permalink":"https://zzkenyon.github.io/categories/数据库技术/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://zzkenyon.github.io/tags/mysql/"}],"keywords":[{"name":"数据库技术","slug":"数据库技术","permalink":"https://zzkenyon.github.io/categories/数据库技术/"}]},{"title":"redis-CentOS7安装单实例和集群","slug":"redis-CentOS7安装单实例和集群","date":"2019-12-30T16:00:00.000Z","updated":"2020-11-27T01:23:25.316Z","comments":true,"path":"2019/12/31/redis-CentOS7安装单实例和集群/","link":"","permalink":"https://zzkenyon.github.io/2019/12/31/redis-CentOS7安装单实例和集群/","excerpt":"","text":"1、单实例安装1.1、下载redis下载地址在：redis.io 首页 如果从官网下载慢，可以把链接贴到迅雷下载，再传到虚拟机： 12cd /usr/local/soft/wget https://download.redis.io/releases/redis-6.0.9.tar.gz 1.2、解压压缩包1tar -zxvf redis-6.0.9.tar.gz 1.3、安装gcc依赖Redis是C语言编写的，编译需要GCC。Redis6.x.x版本支持了多线程，需要gcc的版本大于4.9，但是CentOS7的默认版本是4.8.5。查看gcc的版本： 1gcc -v 升级gcc版本： 1234567yum -y install centos-release-sclyum -y install devtoolset-9-gcc devtoolset-9-gcc-c++ devtoolset-9-binutilsscl enable devtoolset-9 bashecho &quot;source /opt/rh/devtoolset-9/enable&quot; &gt;&gt;/etc/profile 确认gcc的版本（在同一个窗口中！）： 1gcc -v 1.4、编译安装12cd redis-6.0.9/srcmake install 安装成功的结果是src目录下面出现服务端和客户端的脚本redis-serverredis-cliredis-sentinel 1.5、修改配置文件默认的配置文件是/usr/local/soft/redis-6.0.9/redis.conf后台启动，不然窗口一关服务就挂了 1daemonize no 改成 1daemonize yes 下面一行必须改成 bind 0.0.0.0 或注释，否则只能在本机访问 1bind 127.0.0.1 如果需要密码访问，取消requirepass的注释，在外网（比如阿里云）这个必须要配置！ 1requirepass yourpassword 1.6、使用指定配置文件启动Redis1/usr/local/soft/redis-6.0.9/src/redis-server /usr/local/soft/redis-6.0.9/redis.conf 查看端口是否启动成功： 1netstat -an|grep 6379 1.7、进入客户端1/usr/local/soft/redis-6.0.9/src/redis-cli 1.8、停止redis（在客户端中）1redis&gt; shutdown 或 12ps -aux | grep rediskill -9 xxxx 1.9、配置别名的步骤1vim ~/.bashrc 添加两行： 12alias redis=&apos;/usr/local/soft/redis-6.0.9/src/redis-server /usr/local/soft/redis-6.0.9/redis.conf&apos;alias rcli=&apos;/usr/local/soft/redis-6.0.9/src/redis-cli&apos; 编译生效： 1source ~/.bashrc 这样就可以用redis启动服务，rcli进入客户端了 2、三主三从伪集群安装为了节省机器，我们直接把6个Redis实例安装在同一台机器上（3主3从），只是使用不同的端口号。机器IP 192.168.44.181可以跟单机的redis安装在同一台机器上，因为数据目录不同，没有影响。 1234cd /usr/local/soft/redis-6.0.9mkdir redis-clustercd redis-clustermkdir 7291 7292 7293 7294 7295 7296 复制redis配置文件到7291目录 1cp /usr/local/soft/redis-6.0.9/redis.conf /usr/local/soft/redis-6.0.9/redis-cluster/7291 修改7291的redis.conf配置文件，内容： 123cd /usr/local/soft/redis-6.0.9/redis-cluster/7291&gt;redis.confvim redis.conf 内容如下： 123456789port 7291daemonize yesprotected-mode nodir /usr/local/soft/redis-6.0.9/redis-cluster/7291/cluster-enabled yescluster-config-file nodes-7291.confcluster-node-timeout 5000appendonly yespidfile /var/run/redis_7291.pid 把7291下的redis.conf复制到其他5个目录。 123456cd /usr/local/soft/redis-6.0.9/redis-cluster/7291cp redis.conf ../7292cp redis.conf ../7293cp redis.conf ../7294cp redis.conf ../7295cp redis.conf ../7296 批量替换内容 123456cd /usr/local/soft/redis-6.0.9/redis-clustersed -i &apos;s/7291/7292/g&apos; 7292/redis.confsed -i &apos;s/7291/7293/g&apos; 7293/redis.confsed -i &apos;s/7291/7294/g&apos; 7294/redis.confsed -i &apos;s/7291/7295/g&apos; 7295/redis.confsed -i &apos;s/7291/7296/g&apos; 7296/redis.conf 启动6个Redis节点 1234567cd /usr/local/soft/redis-6.0.9/./src/redis-server redis-cluster/7291/redis.conf./src/redis-server redis-cluster/7292/redis.conf./src/redis-server redis-cluster/7293/redis.conf./src/redis-server redis-cluster/7294/redis.conf./src/redis-server redis-cluster/7295/redis.conf./src/redis-server redis-cluster/7296/redis.conf 是否启动了6个进程 1ps -ef|grep redis 创建集群 注意用绝对IP，不要用127.0.0.1 12cd /usr/local/soft/redis-6.0.9/src/redis-cli --cluster create 192.168.44.181:7291 192.168.44.181:7292 192.168.44.181:7293 192.168.44.181:7294 192.168.44.181:7295 192.168.44.181:7296 --cluster-replicas 1 Redis会给出一个预计的方案，对6个节点分配3主3从，如果认为没有问题，输入yes确认 12345678910111213141516171819202122&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Master[0] -&gt; Slots 0 - 5460Master[1] -&gt; Slots 5461 - 10922Master[2] -&gt; Slots 10923 - 16383Adding replica 192.168.44.181:7295 to 192.168.44.181:7291Adding replica 192.168.44.181:7296 to 192.168.44.181:7292Adding replica 192.168.44.181:7294 to 192.168.44.181:7293&gt;&gt;&gt; Trying to optimize slaves allocation for anti-affinity[WARNING] Some slaves are in the same host as their masterM: 2058bd8fc0def0abe746816221c5b87f616e78ae 192.168.44.181:7291 slots:[0-5460] (5461 slots) masterM: 4e41266f2fb7944420d66235475318f5f9526cd8 192.168.44.181:7292 slots:[5461-10922] (5462 slots) masterM: 9ff8ac86b5faf3c0eca149f090800efea3b142e0 192.168.44.181:7293 slots:[10923-16383] (5461 slots) masterS: 8383088d3ce75732fc9acb31ca4bce68833028f7 192.168.44.181:7294 replicates 9ff8ac86b5faf3c0eca149f090800efea3b142e0S: d185adbfa62133e30cee291b028eff451502ecca 192.168.44.181:7295 replicates 2058bd8fc0def0abe746816221c5b87f616e78aeS: 634709cf14809976ea40b65615f816e31d424748 192.168.44.181:7296 replicates 4e41266f2fb7944420d66235475318f5f9526cd8Can I set the above configuration? (type &apos;yes&apos; to accept): 注意看slot的分布： 1237291 [0-5460] (5461个槽) 7292 [5461-10922] (5462个槽) 7293 [10923-16383] (5461个槽) 输入yes确认，集群创建完成 1234567891011121314151617181920212223&gt;&gt;&gt; Performing Cluster Check (using node 192.168.44.181:7291)M: 2058bd8fc0def0abe746816221c5b87f616e78ae 192.168.44.181:7291 slots:[0-5460] (5461 slots) master 1 additional replica(s)S: 8383088d3ce75732fc9acb31ca4bce68833028f7 192.168.44.181:7294 slots: (0 slots) slave replicates 9ff8ac86b5faf3c0eca149f090800efea3b142e0S: d185adbfa62133e30cee291b028eff451502ecca 192.168.44.181:7295 slots: (0 slots) slave replicates 2058bd8fc0def0abe746816221c5b87f616e78aeM: 9ff8ac86b5faf3c0eca149f090800efea3b142e0 192.168.44.181:7293 slots:[10923-16383] (5461 slots) master 1 additional replica(s)M: 4e41266f2fb7944420d66235475318f5f9526cd8 192.168.44.181:7292 slots:[5461-10922] (5462 slots) master 1 additional replica(s)S: 634709cf14809976ea40b65615f816e31d424748 192.168.44.181:7296 slots: (0 slots) slave replicates 4e41266f2fb7944420d66235475318f5f9526cd8[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered. 重置集群的方式是在每个节点上个执行cluster reset，然后重新创建集群 批量写入值 12cd /usr/local/soft/redis-6.0.9/redis-cluster/vim setkey.sh 脚本内容 1234567#!/bin/bashfor ((i=0;i&lt;20000;i++))doecho -en &quot;helloworld&quot; | redis-cli -h 192.168.44.181 -p 7291 -c -x set name$i &gt;&gt;redis.logdonechmod +x setkey.sh./setkey.sh 连接到客户端 123redis-cli -p 7291redis-cli -p 7292redis-cli -p 7293 每个节点分布的数据 123456127.0.0.1:7291&gt; dbsize(integer) 6652127.0.0.1:7292&gt; dbsize(integer) 6683127.0.0.1:7293&gt; dbsize(integer) 6665 其他命令，比如添加节点、删除节点，重新分布数据： 1234567891011121314151617181920212223242526272829303132333435363738redis-cli --cluster helpCluster Manager Commands: create host1:port1 ... hostN:portN --cluster-replicas &lt;arg&gt; check host:port --cluster-search-multiple-owners info host:port fix host:port --cluster-search-multiple-owners reshard host:port --cluster-from &lt;arg&gt; --cluster-to &lt;arg&gt; --cluster-slots &lt;arg&gt; --cluster-yes --cluster-timeout &lt;arg&gt; --cluster-pipeline &lt;arg&gt; --cluster-replace rebalance host:port --cluster-weight &lt;node1=w1...nodeN=wN&gt; --cluster-use-empty-masters --cluster-timeout &lt;arg&gt; --cluster-simulate --cluster-pipeline &lt;arg&gt; --cluster-threshold &lt;arg&gt; --cluster-replace add-node new_host:new_port existing_host:existing_port --cluster-slave --cluster-master-id &lt;arg&gt; del-node host:port node_id call host:port command arg arg .. arg set-timeout host:port milliseconds import host:port --cluster-from &lt;arg&gt; --cluster-copy --cluster-replace help For check, fix, reshard, del-node, set-timeout you can specify the host and port of any working node in the cluster. 3、命令3.1 集群命令cluster info ：打印集群的信息cluster nodes ：列出集群当前已知的所有节点（node），以及这些节点的相关信息。cluster meet ：将 ip 和 port 所指定的节点添加到集群当中，让它成为集群的一份子。cluster forget &lt;node_id&gt; ：从集群中移除 node_id 指定的节点(保证空槽道)。cluster replicate &lt;node_id&gt; ：将当前节点设置为 node_id 指定的节点的从节点。cluster saveconfig ：将节点的配置文件保存到硬盘里面。 3.2 槽slot命令cluster addslots [slot …] ：将一个或多个槽（slot）指派（assign）给当前节点。cluster delslots [slot …] ：移除一个或多个槽对当前节点的指派。cluster flushslots ：移除指派给当前节点的所有槽，让当前节点变成一个没有指派任何槽的节点。cluster setslot node &lt;node_id&gt; ：将槽 slot 指派给 node_id 指定的节点，如果槽已经指派给另一个节点，那么先让另一个节点删除该槽&gt;，然后再进行指派。cluster setslot migrating &lt;node_id&gt; ：将本节点的槽 slot 迁移到 node_id 指定的节点中。cluster setslot importing &lt;node_id&gt; ：从 node_id 指定的节点中导入槽 slot 到本节点。cluster setslot stable ：取消对槽 slot 的导入（import）或者迁移（migrate）。 3.3 键命令cluster keyslot ：计算键 key 应该被放置在哪个槽上。cluster countkeysinslot ：返回槽 slot 目前包含的键值对数量。cluster getkeysinslot ：返回 count 个 slot 槽中的键 4、管理工具一个Win7可用的Redis可视化客户端（redis-desktop-manager-0.8.3.3850）最后一个免费版本是0.9.3.817，后面都要付费了，不升级不用付费链接：https://pan.baidu.com/s/1m6QoUaU0AKLfiXGhSNDJww提取码：ewa0","categories":[{"name":"noSql","slug":"noSql","permalink":"https://zzkenyon.github.io/categories/noSql/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://zzkenyon.github.io/tags/redis/"}],"keywords":[{"name":"noSql","slug":"noSql","permalink":"https://zzkenyon.github.io/categories/noSql/"}]},{"title":"reids-5.0版本的高可用集群搭建","slug":"redis-集群搭建","date":"2019-12-30T16:00:00.000Z","updated":"2020-05-22T12:12:57.988Z","comments":true,"path":"2019/12/31/redis-集群搭建/","link":"","permalink":"https://zzkenyon.github.io/2019/12/31/redis-集群搭建/","excerpt":"","text":"Redis系统介绍： Redis的基础介绍与安装使用步骤Redis的基础数据结构与使用Redis核心原理Redis 5 之后版本的高可用集群搭建Redis 5 版本的高可用集群的水平扩展Redis 5 集群选举原理分析Redis 5 通信协议解析以及手写一个Jedis客户端 1. 集群方案比较：1.1 哨兵模式：在redis3.0以前的版本要实现集群一般是借助哨兵sentinel工具来监控master节点的状态，如果master节点异常，则会做主从切换，将某一台slave作为master，哨兵的配置略微复杂，并且性能和高可用性等各方面表现一般，特别是在主从切换的瞬间存在访问瞬断的情况，而且哨兵模式只有一个主节点对外提供服务，没法支持很高的并发，且单个主节点内存也不宜设置得过大，否则会导致持久化文件过大，影响数据恢复或主从同步的效率。 1.2 高可用集群模式：redis集群是一个由多个主从节点群组成的分布式服务器群，它具有复制、高可用和分片特性。Redis集群不需要sentinel哨兵也能完成节点移除和故障转移的功能。需要将每个节点设置成集群模式，这种集群模式没有中心节点，可水平扩展，据官方文档称可以线性扩展到上万个节点(官方推荐不超过1000个节点)。redis集群的性能和高可用性均优于之前版本的哨兵模式，且集群配置非常简单。 2. 开始搭建2.1 安装redis参考之前博客：Redis的基础介绍与安装使用步骤：https://www.jianshu.com/p/2a23257af57b 下载地址：http://redis.io/download 1、安装gcc 1yum install gcc 2、把下载好的redis-5.0.2.tar.gz放在/usr/local文件夹下，并解压 123wget http://download.redis.io/releases/redis-5.0.2.tar.gztar xzf redis-5.0.2.tar.gzcd redis-5.0.2 3、进入到解压好的redis-5.0.2目录下，进行编译与安装 1make &amp; make install 4、启动并指定配置文件 1src/redis-server redis.conf （注意要使用后台启动，所以修改redis.conf里的daemonize改为yes) 5、验证启动是否成功 1ps -ef | grep redis 6、进入redis客户端 12cd /usr/local/redis/redis-5.0.2/src./redis-cli 7、退出客户端 1exit 8、退出redis服务： 123pkill redis-serverkill 进程号src/redis-cli shutdown 2.2 集群搭建redis集群需要至少要三个master节点，我们这里搭建三个master节点，并且给每个master再搭建一个slave节点，总共6个redis节点，这里用一台机器（可以多台机器部署，修改一下ip地址就可以了）部署6个redis实例，三主三从，搭建集群的步骤如下： 第一步：在机器的/usr/local下创建文件夹redis-cluster，然后在其下面创建6个文件夾如下: 123mkdir -p /usr/local/redis-clustermkdir 8001 8002 8003 8004 8005 8006 第二步：把之前的redis.conf配置文件copy到8001下，修改如下内容： 1）daemonize yes 2）port 8001（分别对每个机器的端口号进行设置） 3）dir /usr/local/redis-cluster/8001/（指定数据文件存放位置，必须要指定不同的目录位置，不然会丢失数据） 4）cluster-enabled yes（启动集群模式） 5）cluster-config-file nodes-8001.conf（集群节点信息文件，这里800x最好和port对应上） 6）cluster-node-timeout 5000 7) bind 127.0.0.1（去掉bind绑定访问ip信息） 8) protected-mode no （关闭保护模式） 9）appendonly yes 如果要设置密码需要增加如下配置： 10）requirepass xxx (设置redis访问密码) 11）masterauth xxx (设置集群节点间访问密码，跟上面一致) 第三步：把修改后的配置文件，copy到8002-8006，修改第2、3、5项里的端口号，可以用批量替换： 1%s/源字符串/目的字符串/g 第四步：分别启动6个redis实例，然后检查是否启动成功 1/usr/local/redis-5.0.7/src/redis-server /usr/local/redis-cluster/800*/redis.conf 第五步：用redis-cli创建整个redis集群(redis5以前的版本集群是依靠ruby脚本redis-trib.rb实现) 1/usr/local/redis-5.0.7/src/redis-cli -a xxx --cluster create --cluster-replicas 1 192.168.2.116:8001 192.168.2.116:8002 192.168.2.116:8003 192.168.2.116:8004 192.168.2.116:8005 192.168.2.116:8006 代表为每个创建的主服务器节点创建一个从服务器节点 第六步：验证集群： 1）连接任意一个客户端即可： 1./redis-cli -c -a xxx -h 192.168.2.116 -p 8001 提示：-a访问服务端密码，-c表示集群模式，指定ip地址和端口号 例如： 1/usr/local/redis-5.0.2/src/redis-cli -a xxx -c -h 192.168.2.116 -p 8001 注意这里进入到8002了，redirected。 2）进行验证： cluster info（查看集群信息）、cluster nodes（查看节点列表） 3）进行数据操作验证 4）关闭集群则需要逐个进行关闭，使用命令： 1/usr/local/redis/src/redis-cli -a xxx -c -h 192.168.2.116 -p 8001 shutdown 3. 设置开机自启1vim /etc/init.d/redis 将如下代码粘贴进去： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#!/src/sh# chkconfig: 2345 80 90## Simple Redis init.d script conceived to work on Linux systems# as it does use of the /proc filesystem.​REDISPORT1=8001REDISPORT2=8002REDISPORT3=8003REDISPORT4=8004REDISPORT5=8005REDISPORT6=8006EXEC=/usr/local/redis-5.0.7/src/redis-serverCLIEXEC=/usr/local/redis-5.0.7/src/redis-cli​PIDFILE=/var/run/redis_$&#123;REDISPORT1&#125;.pid​CONF1=\"/usr/local/redis-cluster/$&#123;REDISPORT1&#125;/redis.conf\"CONF2=\"/usr/local/redis-cluster/$&#123;REDISPORT2&#125;/redis.conf\"CONF3=\"/usr/local/redis-cluster/$&#123;REDISPORT3&#125;/redis.conf\"CONF4=\"/usr/local/redis-cluster/$&#123;REDISPORT4&#125;/redis.conf\"CONF5=\"/usr/local/redis-cluster/$&#123;REDISPORT5&#125;/redis.conf\"CONF6=\"/usr/local/redis-cluster/$&#123;REDISPORT6&#125;/redis.conf\"​case \"$1\" in start) if [ -f $PIDFILE ] then echo \"$PIDFILE exists, process is already running or crashed\" else echo \"Starting Redis cluster server...\" $EXEC $CONF1 &amp; $EXEC $CONF2 &amp; $EXEC $CONF3 &amp; $EXEC $CONF4 &amp; $EXEC $CONF5 &amp; $EXEC $CONF6 &amp; echo \"启动成功...\" fi ;; stop) if [ ! -f $PIDFILE ] then echo \"$PIDFILE does not exist, process is not running\" else PID=$(cat $PIDFILE) echo \"Stopping ...\" $CLIEXEC -p $REDISPORT1 shutdown $CLIEXEC -p $REDISPORT2 shutdown $CLIEXEC -p $REDISPORT3 shutdown $CLIEXEC -p $REDISPORT4 shutdown $CLIEXEC -p $REDISPORT5 shutdown $CLIEXEC -p $REDISPORT6 shutdown while [ -x /proc/$&#123;PID&#125; ] do echo \"Waiting for Redis cluster to shutdown ...\" sleep 1 done echo \"Redis cluster stopped\" fi ;; *) echo \"Please use start or stop as first argument\" ;;esac 添加权限 1chmod +x /etc/init.d/redis 加入开机启动服务 1chkconfig --add redis 使用命令进行开启或关闭redis集群 12service redis start service redis stop 原文连接 https://blog.csdn.net/qq_37859539/article/details/83715803","categories":[{"name":"noSql","slug":"noSql","permalink":"https://zzkenyon.github.io/categories/noSql/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://zzkenyon.github.io/tags/redis/"}],"keywords":[{"name":"noSql","slug":"noSql","permalink":"https://zzkenyon.github.io/categories/noSql/"}]},{"title":"彻底理解cookie/session/token","slug":"其他-彻底理解cookie，session，token","date":"2019-11-22T16:00:00.000Z","updated":"2020-11-03T11:49:17.005Z","comments":true,"path":"2019/11/23/其他-彻底理解cookie，session，token/","link":"","permalink":"https://zzkenyon.github.io/2019/11/23/其他-彻底理解cookie，session，token/","excerpt":"","text":"原文链接 发展史 1、 很久很久以前，Web基本上就是文档的浏览而已，既然是浏览，作为服务器，不需要记录谁在某一段时间里都浏览了什么文 档，每次请求都是一个新的HTTP协议，就是请求加响应，尤其是我不用记住是谁刚刚发了 HTTP请求，每个请求对我来说都是 全新的。这段时间很嗨皮 2、 但是随着交互式Web应用的兴起，像在线购物网站，需要登录的网站等等，马上就面临一个问题，那就是要管理会话，必须记住 哪些人登录系统，哪些人往自己的购物车中放商品，也就是说我必须把每个人区分开，这就是一个不小的挑战，因为HTTP请求是 无状态的，所以想出的办法就是给大家发一个会话标识(session id),说白了就是一个随机的字串，每个人收到的都不一样，每次大 家向我发起HTTP请求的时候，把这个字符串给一并捎过来，这样我就能区分开谁是谁了 3、 这样大家很嗨皮了，可是服务器就不嗨皮了，每个人只需要保存自己的session id，而服务器要保存所有人的session id !如果 访问服务器多了，就得由成千上万，甚至几十万个。这对服务器说是一个巨大的开销，严重的限制了服务器扩展能力，比如说我用两个机器组成了一个集群，小F通过机器A登录了系 统，那session id会保存在机器A上，假设小F的下一次请求被转发到机器B怎么办？机器B可没有小F的session id啊。 有时候会采用_点小伎俩：session sticky,就是让小 F的请求一直粘连在机器A上，但是这也不管用，要是机器A挂掉了，还得转 到机器B去。那只好做session的复制了，把session id在两个机器之间搬来搬去，快累死了。 后来有个叫Memcached的支了招：把session id 集中存储到一个地方，所有的机器都来访问这个地方的数据，这样一来，就不用复制了。但是增加了单点失败的可能性，要是那个负责session的机器挂了，所有的人都得重新登录一遍，估计的被人骂死。后来也尝试把这个单点的机器搞成集群，增加可靠性，但是不管如何，这个小小的session对我来说是一个称重的负担。 4 于是就有人一直在思考，我为什么要保存这个可恶的session呢，让每个客户端去保存该多好可是如果不保存这些session id 怎么验证客户端发给我的session id 的确是我生成的呢？如果不去验证，我们都不知道他们是不是合法的登录用户，那些不怀好意的家伙们就能伪造session id 为所欲为了 哦，对了 关键点就是验证 比如说，小F已经登陆了系统，我给他发一个令牌（Token），里面包含了小F的user id ，下一次小F再次通过Http请求访问我的时候，把这个token通过http header带过来不就可以了。不过这和session id 没有本质区别啊 ，任何人都可以伪造，所以我的想点办法让别人伪造不了。 那就对数据做一个签名吧，比如说我用HMAC-SHA256算法，加上一个只我才知道的秘钥，对数据做一个签名，把这个签名和数据一起作为token，由于秘钥被人不知道，就无法伪造了。 这个token我们不保存，当小F把这个token发给我的时候，我在用同样的算法和密钥对数据在计算一次签名，和token中带的签名做个比较：如果相同，我就知道小F已经登陆过了，并且可以直接取到小F的user id；若果不相同，数据部分肯定被人篡改过，我就回复发送者：对不起，没有验证。 Token中的数据是明文保存的（虽然我会用Base64做下编码，但那不是加密），还是可以被别人看到的，所以我不能在其中保存像密码这样的敏感信息当然，如果一个人的token被别人偷走了，那我也没办法，我也会任为小偷就是合法用户，这其实和一个人的session id 被别人偷走是一样的。 这样一来，我就不保存session id 了，我只是生成token，然后验证token。用计算时间换区存储空间解除了session id 这个负担，可以说是一身轻松，我的机器集群现在可以轻松的做水平扩展，用户访问量增大，直接加机器就行。这种无状态的感觉实在太好了！ cookiecookie是一个非常具体的东西，指的就是浏览器里能永久存储的一种数据，仅仅是浏览器实现的一种数据存储功能。cookie有服务器生成，发送给浏览器，浏览器吧cookie一kv的形式保存到某个目录下的文本文件内，下一次请求同一域名时会把该cookie发送给服务器。由于cookie是存在客户端上的没所以浏览器加入了一些限制确保cookie不会给恶意使用，同事不会占据太多磁盘空间。所以每个域的cookie数量是有限的。 集群模式下的会话丢失session sticky IP hash 同一个会话负载到同一个服务器上 hash算法 Hash 算法 MD5、SHA-1、SHA-256","categories":[{"name":"其他","slug":"其他","permalink":"https://zzkenyon.github.io/categories/其他/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://zzkenyon.github.io/tags/网络/"}],"keywords":[{"name":"其他","slug":"其他","permalink":"https://zzkenyon.github.io/categories/其他/"}]},{"title":"mysql-innodb的事务管理与锁","slug":"数据库技术-mysql-innodb的事务管理与锁","date":"2019-11-22T16:00:00.000Z","updated":"2020-11-03T02:53:18.791Z","comments":true,"path":"2019/11/23/数据库技术-mysql-innodb的事务管理与锁/","link":"","permalink":"https://zzkenyon.github.io/2019/11/23/数据库技术-mysql-innodb的事务管理与锁/","excerpt":"","text":"典型的事务场景：下单、转账 事物的定义：事务是DBMS执行过程中的一个逻辑单位，由一个有限的数据库操作序列构成 MYSQL中支持事务的数据引擎：innodb ndb 1、数据库事务的四大特性是什么？原子性 Atomicity 由undo log保证 一致性 Consistent 数据完整性 隔离性 Isolation 不同事务之间处理同一段数据应当是隔离的互不干扰的 持久性 Durable redo log 原子性、隔离性和持久性最终都是为了实现一致性。 2、什么时候会出现事务、结束事务？当我们执行单条语句的时候，会默认开启事务 mysql 参数 autocommit 默认为 on 开启状态，执行单条查询语句不需要显示的声明事务、提交事务 12345show global VARIABLE like 'autocommit' --显示该参数的全局值show session VARIABLE like 'autocommit' --显示当前会话该参数的值set session autocommit=off --关闭autocommit后，需要手动提交 手动开启事务，两种方式 123start TRANSACATION; begin; 事务的结束： 提交结束 commit; 回滚结束 rollback； 连接断开 会话结束 -&gt; 事务结束 3、事务并发带来的问题有哪些？ 脏读（读到未提交的数据）：事务A执行一条查询，在此之前事务B修改了这部分数据但没提交，导致A读取到事务B没有提交的数据，事务B可能回滚导致事务A读取到的数据是脏数据。 不可重复读：事务A执行一条查询后，事务B对这部分数据执行了update/delete并提交了，导致事务A再次查询时与上一次的查询结果不一致，称为不可重复度。 幻读：事务A执行一条范围查询后，事务B在此范围insert了若干条数据，导致事务A再次执行该查询是记录数增多，产生幻读。与不可重复的区别是这里针对的是插入操作。 注意：幻读和不可重复度的区别是事务B对数据进行的操作不同，幻读是insert操作，不可重复读是update和delete操作 以上三个问题称为数据库的读一致性问题，必须由数据库自己提供一定的事务隔离机制来解决 4、SQL92 标准许多数据库专家联合制定了一个标准，建议数据库厂商都按照这个标准提供一定的事务隔离级别，来解决事务并发问题。 看一下SQL92标准的官网：http://www.contrib.andrew.cmu.edu/~shadow/sql/sql1992.txt 在官网搜索_iso，会看到一张表格： Level P1 P2 P3 READ UNCOMMITTED Possible Possible Possible READ COMMITTED Not Possible Possible Possible REPEATABLE READ Not Possible Not Possible Possible SERIALIZABLE Not Possible Not Possible Not Possible 这里定义了四个隔离级别，右边的P1P2P3就是代表事务并发的三个问题，脏读，不可重复度，幻读。Possible表示在这个隔离级别下该问题有可能发生，Not Possible表示解决了该问题。 Read Uncommited 未提交读 顾名思义，事务可以读取到其他事物未提交的数据，使用这种隔离级别其实并未解决以上的任何问题 Read Commited 已提交读 只能读到其他事物已经提交了的数据，解决了脏读问题 Repeatable Read 可重复读 事务重复读取，保证重复读取数据一致，解决了不可重复度的问题 Serializable 串行化 事务串行化运行，没有并发自然没有不一性问题产生，但是严重影响效率，不推荐使用 不同的厂商或者数据库引擎在实现以上标准时会有一些差异。Oracle只实现了两种RC和Serializable，Innodb对以上的四种隔离级别都进行了实现，值得一提的是，innodb 对Repeatable Read 这一级别的实现同时也解决了幻读的问题，因此这一级别是innodb的默认事务隔离级别。 5、innodb是如何实现事务隔离级别的呢?如果要解决读一致性的问题 ，保证一个事务前后两次读取数据一致，实现事务隔离级别，应该怎么做 方案1： MVCC 基于多版本的并发控制 生成一个数据请求时间点的一致性数据，并用这个快照来提供一定级别的一致性读取。 方案2 ： LBCC 基于锁的并发控制 MVCC的实现原理InnoDB为每行记录都实现了三个隐藏字段 DB_ROW_ID 6字节：行标识 DB_TRX_ID 6字节：插入或更新行的最后一个事务ID，自动递增（理解为创建版本号） DB_ROLL_PTR： 7字节：回滚指针（理解为删除版本号）数据被删除或记录为旧数据的时候记录当前的操作事务id。 mvcc核心思想，一个事务根据自己的事务id进行判断，只能查询到创建版本号比自己事务ID小的（在我之前插入或更新的数据） 和 删除版本号比我事务ID大的记录 下面通过一个简单的例子说明： 事务一： 12345--Transaction 1begin;insert into mvcctest values(NULL,\"zzk\");insert into mvcctest values(NULL,\"pjp\");commit; 此时的数据，创建版本是当前的事务id，删除版本号为空； id name 创建版本 删除版本 1 zzk 1 undefined 2 pjp 1 undefined 事务二：执行第一次查询，读取到两条原始数据，这时事务id为2： 123--Transaction 2begin；select * from mvcctest ; -- (1) 第一次查询 注意此处没有提交，事务2没有结束 事务三，插入一条数据 1234-- Transaction 3begin;insert into mvctest values(NULL,\"zpd\");commit; 此时的数据多了一条zpd，它的创建版号是3： id name 创建版本 删除版本 1 zzk 1 undefined 2 pjp 1 undefined 3 zpd 3 undefined 然后事务二再进行第二次查询 1234--Transaction 2begin；select * from mvcctest ; -- (1) 第一次查询 注意此处没有提交，事务2没有结束select * from mvcctest ; -- (2) 第二次查询 注意此处没有提交，事务2没有结束 根据MVCC的原则：只能查询创建版本比自己小的数据，所以第二次查询也只能查询2条数据。 事务四：删除数据，删除了id=1 zzk这条记录 1234--Transaction 4begin；delete from mvcctest where id = 1commit; 这时候的数据，赵政康的删除版本被记录为事务id 4，其他不变： id name 创建版本 删除版本 1 zzk 1 4 2 pjp 1 undefined 3 zpd 3 undefined 然后事务二执行第三次查询： 12345--Transaction 2begin；select * from mvcctest ; -- (1) 第一次查询 注意此处没有提交，事务2没有结束select * from mvcctest ; -- (2) 第二次查询 注意此处没有提交，事务2没有结束select * from mvcctest ; -- (3) 第三次查询 注意此处没有提交，事务2没有结束 根据MVCC的查找原则：只能查询创建版本比自己小，删除版本比自己大、以及未删除的记录 也就是说在事务2开始之后被删除的数据依然可以被查出来，所以查询结果依然是2条数据。 事务五：执行更新操作 1234--Transaction 5begin；update mvcctest set name='潘佳萍' where id = 2；commit; 此时的数据，更新数据的时候，旧数据的删除版本被记录为当前事务id，产生一条新数据，创建版本为当前事务id id name 创建版本 删除版本 1 zzk 1 4 2 pjp 1 5 3 zpd 3 undefined 2 潘佳萍 5 undefined 然后事务二执行第四次查询： 123456--Transaction 2begin；select * from mvcctest ; -- (1) 第一次查询 注意此处没有提交，事务2没有结束select * from mvcctest ; -- (2) 第二次查询 注意此处没有提交，事务2没有结束select * from mvcctest ; -- (3) 第三次查询 注意此处没有提交，事务2没有结束select * from mvcctest ; -- (4) 第四次查询 注意此处没有提交，事务2没有结束 查找规则：只能查询创建版本小于自己，删除版本大于自己，或者未删除的数据，所以依然是2条数据。 通过以上演示我们可以看到，通过版本号的控制，无论其他事物是插入修改删除，事务2查询到的数据都没有变化。 在InnoDB中，MVCC是通过undo log实现的，需要注意的是，MVCC和锁是协同使用来实现隔离性的，这两种方案并不是互斥的。 Oracle、postgres等其他数据口都有MVCC的实现。 6、innodb中的锁官网将锁分成了8类，这里我们将两个行级别的锁，和两个表级别的锁称锁的基本模式；后面三个Record Locks、Gap Locks、Next-Key Locks 称为锁的算法，也就是分别在上面情况下锁定什么范围。 6.1 共享锁第一个行级别的锁就是我们在广网看到的Shard Locks（共享锁），我们获取了一行数据的共享锁之后，可以用他来读取数据，所以叫读锁。而且多个事务可以共享一把读锁。 可以用select... lock in share mode;的方式手工加上一把读锁。 释放读锁有两种方式：提交事务或断开连接 读锁可以重复的获取 6.2 排它锁第二个行级别的锁叫Exclusive Locks（排它锁），它是用来操作数据的，所以又叫写锁。只要一个事务获取了一行数据的排它锁，其他的事务就不能再获取这一行数据额的共享锁和排它锁。 排它锁加锁两种方式：自动（增删改查操作自动加），手动加锁 手动加锁命令 在查询语句后面加上for update，就会给查询的数据加上一个写锁 释放排它锁的方式和共享锁一样。 6.3 意向锁意向锁是数据库自己维护的。 当我们你给一行数据加上共享锁之前，数据库会自动在这张表上面加上一个意向共享锁； 当我们给一行数据加上排它锁之前，数据库会自动在这张表上加上一个意向排它锁。 如果一张表上至少有一个意向共享锁，说明有其他的事务给其中的某些数据加上了共享锁； 如果一张表上面至少有一个意向排他锁，说明有其他的事务给其中的某些数据行加 了排他锁。 那么这两个表级别锁存在的意义是什么？ 第一个，有了表级别锁，在innodb中就可以支持更多粒度的锁； 第二个，如果没有意向锁的话，当我们想要一张表加上表锁的时候，是不是必须先判断有没有其他的事务锁定了其中的一行数据，那么这时候我们要扫描整张表才能确定能不能成功加上一个表锁，如果数据量大，加表锁的效率肯定很低 这是引入意向锁之后，只要判断这张表上面有没有意向锁，如果有加表锁操作直接返回失败。所以innodb中的意向表锁，我们可以把它理解成一个标志。 7、行锁的原理行锁锁住的是什么？ 首先我们准备三张表，一张没有索引的 t1，一张有主键索引的 t2，一张有唯一索引的 t3。 我们先假设 InnoDB 的锁锁住了是一行数据或者一条记录。 我们先来看一下 t1 的表结构，它有两个字段，int 类型的 id 和 varchar 类型的 name。 里面有 4 条数据，1、2、3、4。 Transaction 1 Transaction 2 begin; SELECT * FROM t1 WHERE id =1 FOR UPDATE; select * from t1 where id=3 for update; //blocked INSERT INTO t1 (id, name) VALUES (5, ‘5’); //blocked 现在我们在两个会话里面手工开启两个事务。 在第一个事务里面，我们通过 where id =1 锁住第一行数据。 在第二个事务里面，我们尝试给 id=3 的这一行数据加锁。 这个加锁的操作被阻塞了。为什么第一个事务锁住了 id=1 的这行数据，我不能操作 id=3 的数据呢？ 再来操作一条不存在的数据，插入 id=5。它也被阻塞了。实际上这里整张表都被锁 住了。所以，我们的第一个猜想被推翻了，InnoDB 的锁锁住的应该不是 Record。 为什么在没有索引或者没有用到索引的情况下，会锁住整张表？这个问题我们先留 在这里。 有主键索引的表 我们看一下 t2 的表结构。字段是一样的，不同的地方是 id 上创建了一个主键索引。 里面的数据是 1、4、7、10。 Transaction 1 Transaction 2 begin; select * from t2 where id=1 for update; select * from t2 where id=1 for update; // blocked select * from t2 where id=4 for update; // OK 第一种情况，使用相同的 id 值去加锁，冲突；使用不同的 id 加锁，可以加锁成功。 那么，既然不是锁定一行数据，有没有可能是锁住了 id 的这个字段呢？ 我们继续往下验证。 唯一索引（假设锁住字段） 我们看一下 t3 的表结构。字段还是一样的， id 上创建了一个主键索引，name 上 创建了一个唯一索引。里面的数据是 1、4、7、10。 Transaction 1 Transaction 2 begin; select * from t3 where name= ‘4’ for update; select * from t3 where name = ‘4’ for update; // blocked select * from t3 where id = 4 for update; // blocked 在第一个事务里面，我们通过 name 字段去锁定值是 4 的这行数据。 在第二个事务里面，尝试获取一样的排它锁，肯定是失败的。 在这里我们怀疑 InnoDB 锁住的是字段，所以换一个字段，用 id=4 去给这行数据加锁。又被阻塞了，说明锁住的是字段的这个推测也是错的，否则就不会出现第一个事务 锁住了 name，第二个字段锁住 id 失败的情况。 既然锁住的不是 record，也不是 column，InnoDB 里面锁住的到底是什么呢？在这 三个案例里面，我们要去分析一下他们的差异在哪里，也就是这三张表的结构，是什么 区别导致了加锁的行为的差异？其实答案就是索引。InnoDB 的行锁，就是通过锁住索引实现的。 那么我们还有两个问题没有解决： 1、为什么表里面没有索引的时候，锁住一行数据会导致锁表？ 或者说，如果锁住的是索引，一张表没有索引怎么办？ 所以，一张表有没有可能没有索引？ 1）如果我们定义了主键(PRIMARY KEY)，那么 InnoDB 会选择主键作为聚集索引。 2）如果没有显式定义主键，则 InnoDB 会选择第一个不包含有 NULL 值的唯一索 引作为主键索引。 3）如果也没有这样的唯一索引，则 InnoDB 会选择内置 6 字节长的 ROWID 作 为隐藏的聚集索引，它会随着行记录的写入而主键递增。 所以，为什么锁表，是因为查询没有使用索引，会进行全表扫描，然后把每一个隐藏的聚集索引都锁住了。 2、为什么通过唯一索引给数据行加锁，主键索引也会被锁住？ 大家还记得在 InnoDB 里面，当我们使用辅助索引的时候，它是怎么检索数据的吗？ 辅助索引的叶子节点存储的是什么内容？ 在辅助索引里面，索引存储的是二级索引和主键的值。比如name=4，存储的是name 的索引和主键 id 的值 4。 而主键索引里面除了索引之外，还存储了完整的数据。所以我们通过辅助索引锁定 一行数据的时候，它跟我们检索数据的步骤是一样的，会通过主键值找到主键索引，然 后也锁定。 8、锁的算法t2 这张表有一个主键索引。 我们插入了 4 行数据，主键 id 分别是 1、4、7、10。 因为我们用主键索引加锁，我们这里的划分标准就是主键索引的值。 这些数据库里面存在的主键值，我们把它叫做 Record，记录，那么这里我们就有 4 个 Record。 根据主键，这些存在的 Record 隔开的数据不存在的区间，我们把它叫做 Gap，间 隙，它是一个左开右开的区间。 假设我们有 N 个 Record，那么所有的数据会被划分成多少个 Gap 区间？答案是 N+1，就像我们把一条绳子砍 N 刀，它最后肯定是变成 N+1 段。 最后一个，间隙（Gap）连同它左边的记录（Record），我们把它叫做临键的区间， 它是一个左开右闭的区间。 8.1 记录锁第一种情况，当我们对于唯一性的索引（包括唯一索引和主键索引）使用等值查询， 精准匹配到一条记录的时候，这个时候使用的就是记录锁。 比如 where id = 1 4 7 10 。 我们使用不同的 key 去加锁，不会冲突，它只锁住这个 record。 8.2 间隙锁第二种情况，当我们查询的记录不存在，没有命中任何一个 record，无论是用等值 查询还是范围查询的时候，它使用的都是间隙锁。 举个例子，where id &gt;4 and id &lt;7，where id = 6。 注意，间隙锁主要是阻塞插入 insert。相同的间隙锁之间不冲突。 Gap Lock 只在 RR 中存在，如果要关闭间隙锁，就是把事务隔离级别设置成 RC， 并且把 innodb_locks_unsafe_for_binlog 设置为 ON。 这种情况下除了外键约束和唯一性检查会加间隙锁，其他情况都不会用间隙锁。 8.3 临键锁第三种情况，当我们使用了范围查询，不仅仅命中了 Record 记录，还包含了 Gap 间隙，在这种情况下我们使用的就是临键锁，它是 MySQL 里面默认的行锁算法，相当于 记录锁加上间隙锁。 唯一性索引，等值查询匹配到一条记录的时候，退化成记录锁。 没有匹配到任何记录的时候，退化成间隙锁。 比如我们使用&gt;5 &lt;9， 它包含了记录不存在的区间，也包含了一个 Record 7。 临键锁，锁住最后一个 key 的下一个左开右闭的区间。 123select * from t2 where id &gt;5 and id &lt;=7 for update; -- 锁住(4,7]和(7,10] select * from t2 where id &gt;8 and id &lt;=10 for update; -- 锁住 (7,10]，(10,+∞) 为什么要锁住下一个左开右闭的区间？ 就是为了解决幻读的问题。 9、innodb隔离级别的实现-9.1 Read UncommitedRU 隔离级别：不加锁。 9.2 SerializableSerializable 所有的 select 语句都会被隐式的转化为 select ... in share mode，会 和 update、delete 互斥。 这两个很好理解，主要是 RR 和 RC 的区别？ 9.3 Repeatable ReadRR 隔离级别下，普通的 select 使用基于MVCC的快照读(snapshot read) 加锁的 select(select ... in share mode / select ... for update)以及更新操作 update, delete 等语句使用当前读（current read），底层使用记录锁、或者间隙锁、 临键锁。 9.4 Read CommitedRC 隔离级别下，普通的 select 都是快照读，使用 MVCC 实现。 加锁的 select 都使用记录锁，因为没有 Gap Lock。 除了两种特殊情况——外键约束检查(foreign-key constraint checking)以及重复键检查(duplicate-key checking)时会使用间隙锁封锁区间。 所以 RC 会出现幻读的问题。","categories":[{"name":"数据库技术","slug":"数据库技术","permalink":"https://zzkenyon.github.io/categories/数据库技术/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://zzkenyon.github.io/tags/mysql/"}],"keywords":[{"name":"数据库技术","slug":"数据库技术","permalink":"https://zzkenyon.github.io/categories/数据库技术/"}]},{"title":"netty源码分析之PipeLine","slug":"nio-netty源码分析之PipeLine","date":"2019-11-20T16:00:00.000Z","updated":"2020-09-08T03:28:48.294Z","comments":true,"path":"2019/11/21/nio-netty源码分析之PipeLine/","link":"","permalink":"https://zzkenyon.github.io/2019/11/21/nio-netty源码分析之PipeLine/","excerpt":"","text":"重读总结： 事件传播方法，以fireChannelActive()为例，这个方法是定义在ChannelInboundInvoker接口中的，AbstractChannelHandlerContext和DefaultChannelPipeline两个类中都重载了这个方法，两者实现的区别是： AbstractChannelHandlerContext中的重载是从当前的Pipeline节点开始传播事件，一般用于业务逻辑处理结束后继续传播事件，下一节点需要查找 DefaultChannelPipeline的逻辑是用于事件刚要进入pipeline的时候，下一节点直接指定，In事件指定给head，out事件指定给tail Handler热插拔 Channel创建的时候会创建一个PipeLine，并且PipeLine也持有Channel对象的引用，二者是互相引用的关系。 12345678// AbstractChannel.classprotected AbstractChannel(Channel parent) &#123; ... pipeline = newChannelPipeline();&#125;protected DefaultChannelPipeline newChannelPipeline() &#123; return new DefaultChannelPipeline(this);&#125; AbstractChannel 是Channel接口的第一个抽象实现类，其中就声明了对pipeline的引用，在看pipeLine的初始化，创建了一个DefaultChannelPipeline ，构造函数将正在构造的channel对象传进去，源码： 123456789101112//DefaultChannelPipelineprotected DefaultChannelPipeline(Channel channel) &#123; this.channel = ObjectUtil.checkNotNull(channel, \"channel\"); succeededFuture = new SucceededChannelFuture(channel, null); voidPromise = new VoidChannelPromise(channel, true); tail = new TailContext(this); head = new HeadContext(this); head.next = tail; tail.prev = head;&#125; 第一步就是将传入的channel对象存下来，然后创建头结点head和尾结点tail组成一个初始的双向链表。 ok，至此我们可以了解到PipeLine 数据结构是一个双向链表，头结点是HeadContext对象，尾结点是TailContext对象，而头尾节点都是 AbstractChannelHandlerContext 的子类。 那我们要弄清楚pipeLine的工作方式，肯定要先搞搞明白组成它的节点AbstractChannelHandlerContext 到底是个啥。 PipeLine节点分析AbstractChannelHandlerContext 是实现了ChannelHandlerContext接口的抽象类，我们根据字面意思理解，ChannelHandlerContext 就是执行 ChannelHandler的上下文，上下文应该包含该Handler的执行逻辑，并且负责这段逻辑的调用，以及调用结果的处理。 而ChannelHandler我们应该很熟悉了，用来处理客户端请求或者服务器响应的一些处理器。 服务器对客户端请求的处理，一般来说都是要分步骤执行的，一个常见的例子就是 123接受请求得到byteBuf--&gt;解码得到request对象--&gt;对request鉴权--&gt;处理reques得到response--&gt;对response编码得到byteBuf并发送响应 对于以上流程，服务器程序中需要调用pipeline.addLast(new xxxxHandler())方法加入到pipeline中Handler有：DecodeHandler–&gt;LoginHandler–&gt;BussinessHandler–&gt;EncodeHandler ，跟进addLast方法调用最终会到达 1234567891011121314151617181920//DefaultChannelPipelinepublic final ChannelPipeline addLast(EventExecutorGroup group, String name, ChannelHandler handler) &#123; final AbstractChannelHandlerContext newCtx; synchronized (this) &#123; //1 检查是否重复添加 checkMultiplicity(handler); //2 创建节点 DefaultChannelHandlerContext类型 newCtx = newContext(group, filterName(name, handler), handler); //3 添加节点 双向链表操作 addLast0(newCtx); ... &#125; //4 回调用户方法 callHandlerAdded0(newCtx); return this;&#125;private AbstractChannelHandlerContext newContext(EventExecutorGroup group, String name, ChannelHandler handler) &#123; //group为null，因此childExecutor(group)也返回null return new DefaultChannelHandlerContext(this, childExecutor(group), name, handler);&#125; 1234567//DefaultChannelHandlerContextDefaultChannelHandlerContext( DefaultChannelPipeline pipeline, EventExecutor executor, String name, ChannelHandler handler) &#123; // 将参数回传到父类，保存Handler的引用 super(pipeline, executor, name, handler.getClass()); this.handler = handler;&#125; 123456789//AbstractChannelHandlerContextAbstractChannelHandlerContext(DefaultChannelPipeline pipeline, EventExecutor executor, String name, Class&lt;? extends ChannelHandler&gt; handlerClass) &#123; this.name = ObjectUtil.checkNotNull(name, \"name\"); this.pipeline = pipeline; this.executor = executor; // null this.executionMask = mask(handlerClass); // 生成一个掩码 可以快读判断这个Handler重载了哪些方法 ordered = executor == null || executor instanceof OrderedEventExecutor; // ture&#125; 可以看到，addLast方法将用户写的Handler包装成了一个 DefaultChannelPipeline ，加入到了双向链表的tail节点之前。pipeline节点就拥有了handler执行逻辑。 接下来要弄清楚的是，ChannelHandlerContext 是怎样调用这些逻辑的，ChannelHandlerContext继承了ChannelInboundInvoker, ChannelOutboundInvoker这两个接口，里面定义的方法就是用来调用handler逻辑。 那为什么要继承两个接口呢？ Handler 有 in 和 out 之分，但是HandlerContext没有，所以为了既能调用inhandler逻辑又能调用outhandler逻辑，就继承了两个接口。 老版本的netty，AbstractChannelHandlerContext 有两个bool属性InBound 和outBound，InBound=true表示该节点是inBound，outBound=true表示该节点是outBound，当然也可能同时为true。在我阅读的源代码版本（4.1.50）中已经删除了这两个属性，取而代之的是属性executionMask，通过使用该属性可以在事件传播时，快速的判断出该节点中的Handler在inBound方向和outBound方向有没有重载某事件处理逻辑。此处将另外分析。 最后要弄明白的是，handler的执行结果应该怎么处理？ 我们不要忘了，pipeLine是一个双向链表，在一个上下文节点中，我们可以很方便的获取到前一个或者后一个上下文节点，当前的节点执行完handler逻辑之后，调用ChannelInboundInvoker或者ChannelOutboundInvoker定义的方法（AbstractChannelHandlerContext对这些方法做了实现），就可以将当前的执行结果传递给下一个节点或者上一个节点。这将取决于事件的类型是inBound还是outBound。 事件传播在此分别选取一种事件传播的源码看一下 inBound事件 看一个inBound事件，当unsafe中执行pipeline.fireChannelRead() 123456//DefaultChannelPipelinepublic final ChannelPipeline fireChannelRead(Object msg) &#123; // 最先调用的是head节点的channelRead方法，此处是静态方法调用 AbstractChannelHandlerContext.invokeChannelRead(head, msg); return this;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//AbstractChannelHandlerContext// 最最核心的就是这个静态调用，负责传播的核心方法static void invokeChannelRead(final AbstractChannelHandlerContext next, Object msg) &#123; final Object m = next.pipeline.touch(ObjectUtil.checkNotNull(msg, \"msg\"), next); EventExecutor executor = next.executor(); if (executor.inEventLoop()) &#123; next.invokeChannelRead(m); &#125; else &#123; executor.execute(new Runnable() &#123; @Override public void run() &#123; next.invokeChannelRead(m); &#125; &#125;); &#125;&#125;// 这是实例方法，在某节点中确定下一个执行节点，确定了之后将执行静态调用public ChannelHandlerContext fireChannelRead(final Object msg) &#123; // 又是这个静态调用 invokeChannelRead(findContextInbound(MASK_CHANNEL_READ), msg); return this;&#125;// 寻找下一个节点的逻辑private AbstractChannelHandlerContext findContextInbound(int mask) &#123; AbstractChannelHandlerContext ctx = this; EventExecutor currentExecutor = executor(); do &#123; // 这里可以看出inBound事件是向后传播的 ctx = ctx.next; &#125; while (skipContext(ctx, currentExecutor, mask, MASK_ONLY_INBOUND)); return ctx;&#125;// 具体负责执行handler逻辑的方法private void invokeChannelRead(Object msg) &#123; if (invokeHandler()) &#123; try &#123; ((ChannelInboundHandler) handler()).channelRead(this, msg); &#125; catch (Throwable t) &#123; invokeExceptionCaught(t); &#125; &#125; else &#123; fireChannelRead(msg); &#125;&#125; 在handler channelRead()逻辑最后，都会调用一下ctx.channelRead，将事件传播下去 outBound事件 再看一个outBound事件传播的代，当我们在某handler中执行 ctx.pipeline().writeAndFlush() 1234//DefaultChannelPipelinepublic final ChannelFuture writeAndFlush(Object msg, ChannelPromise promise) &#123; return tail.write(msg, promise); //pipeline直接找tail&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152//AbstractChannelHandlerContextpublic ChannelFuture write(Object msg) &#123; return write(msg, newPromise());&#125;public ChannelFuture write(final Object msg, final ChannelPromise promise) &#123; write(msg, false, promise); return promise;&#125;private void write(Object msg, boolean flush, ChannelPromise promise) &#123; ObjectUtil.checkNotNull(msg, \"msg\"); ... final AbstractChannelHandlerContext next = findContextOutbound(flush ? (MASK_WRITE | MASK_FLUSH) : MASK_WRITE); final Object m = pipeline.touch(msg, next); EventExecutor executor = next.executor(); if (executor.inEventLoop()) &#123; if (flush) &#123; next.invokeWriteAndFlush(m, promise); &#125; else &#123; next.invokeWrite(m, promise); // 执行这里 &#125; &#125; else &#123; final WriteTask task = WriteTask.newInstance(next, m, promise, flush); if (!safeExecute(executor, task, promise, m, !flush)) &#123; task.cancel(); &#125; &#125;&#125;// 寻找下一个节点private AbstractChannelHandlerContext findContextOutbound(int mask) &#123; AbstractChannelHandlerContext ctx = this; EventExecutor currentExecutor = executor(); do &#123; ctx = ctx.prev;// 往前找 &#125; while (skipContext(ctx, currentExecutor, mask, MASK_ONLY_OUTBOUND)); return ctx;&#125;void invokeWrite(Object msg, ChannelPromise promise) &#123; if (invokeHandler()) &#123; invokeWrite0(msg, promise); &#125; else &#123; write(msg, promise); &#125;&#125;// 执行handler逻辑的方法private void invokeWrite0(Object msg, ChannelPromise promise) &#123; try &#123; ((ChannelOutboundHandler) handler()).write(this, msg, promise); &#125; catch (Throwable t) &#123; notifyOutboundHandlerException(t, promise); &#125;&#125; 在handler的write方法中最后，都会调用一下ctx.write()将时间传播上去 inBound事件传播是从head节点开始，到tail节点结束。tail节点，作为InBoundHandler实现了所有的inBound事件处理方法，而实现的逻辑是空的，即不作任何处理，以结束inBound事件的传播。 OutBound事件传播是从tail节点开始，到head节点结束，head节点作为OutBoundHandler，实现了所有的outBound事件处理方法，将所有的outBoud事件委托给unsafe执行相应的底层逻辑。 整理一下思路：对于in 和 out 应该站在pipeLine的角度去理解，比如新连接channel注册成功之后，会调用pipeline().fireChannelActive()，向pipeline中传入事件，这种就是in事件；而writeAndFlush操作，需要跳出pipeline调用unSafe来向channel中写数据，因此是一个out事件。 至此，还有一点需要分析，那就是异常的传播。 异常传播我们通常在业务代码中，会加入一个异常处理器，统一处理pipeline过程中的所有的异常，并且，一般该异常处理器需要加载自定义节点的最末尾 此类ExceptionHandler一般继承自 ChannelDuplexHandler，标识该节点既是一个inBound节点又是一个outBound节点，我们分别分析一下inBound事件和outBound事件过程中，ExceptionHandler是如何才处理这些异常的 inBound异常 我们以数据的读取为例，看下netty是如何传播在这个过程中发生的异常 我们前面已经知道，对于每一个节点的数据读取都会调用AbstractChannelHandlerContext.invokeChannelRead()方法 12345678//AbstractChannelHandlerContextprivate void invokeChannelRead(Object msg) &#123; try &#123; ((ChannelInboundHandler) handler()).channelRead(this, msg); &#125; catch (Throwable t) &#123; notifyHandlerException(t); &#125;&#125; 可以看到该节点最终委托到其内部的ChannelHandler处理channelRead，而在最外层catch整个Throwable，因此，我们在如下用户代码中的异常会被捕获 123456789public class BusinessHandler extends ChannelInboundHandlerAdapter &#123; @Override protected void channelRead(ChannelHandlerContext ctx, Object data) throws Exception &#123; //... throw new BusinessException(...); //... &#125;&#125; 上面这段业务代码中的 BusinessException 会被 BusinessHandler所在的节点捕获，进入到 notifyHandlerException(t);往下传播，我们看下它是如何传播的 123456789//AbstractChannelHandlerContextprivate void notifyHandlerException(Throwable cause) &#123; // 略去了非关键代码，读者可自行分析 invokeExceptionCaught(cause);&#125;private void invokeExceptionCaught(final Throwable cause) &#123; handler().exceptionCaught(this, cause);&#125; 可以看到，此Hander中异常优先由此Handelr中的exceptionCaught方法来处理，默认情况下，如果不覆写此Handler中的exceptionCaught方法，调用 12345//ChannelInboundHandlerAdapterpublic void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; ctx.fireExceptionCaught(cause);&#125; 12345//AbstractChannelHandlerContextpublic ChannelHandlerContext fireExceptionCaught(final Throwable cause) &#123; invokeExceptionCaught(next, cause); return this;&#125; 到了这里，已经很清楚了，如果我们在自定义Handler中没有处理异常，那么默认情况下该异常将一直传递下去，遍历每一个节点，直到最后一个自定义异常处理器ExceptionHandler来终结，收编异常 1234567public Exceptionhandler extends ChannelDuplexHandler &#123; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; // 处理该异常，并终止异常的传播 &#125;&#125; 到了这里，你应该知道为什么异常处理器要加在pipeline的最后了吧？ outBound异常 然而对于outBound事件传播过程中所发生的异常，该Exceptionhandler照样能完美处理，为什么？ 我们以前面提到的writeAndFlush方法为例，来看看outBound事件传播过程中的异常最后是如何落到Exceptionhandler中去的 前面我们知道，channel.writeAndFlush()方法最终也会调用到节点的 invokeFlush0()方法（write机制比较复杂，我们留到后面的文章中将） 123456789101112131415161718//AbstractChannelHandlerContextprivate void invokeWriteAndFlush(Object msg, ChannelPromise promise) &#123; if (invokeHandler()) &#123; invokeWrite0(msg, promise); invokeFlush0(); &#125; else &#123; writeAndFlush(msg, promise); &#125;&#125;private void invokeFlush0() &#123; try &#123; ((ChannelOutboundHandler) handler()).flush(this); &#125; catch (Throwable t) &#123; notifyHandlerException(t); &#125;&#125; 而invokeFlush0()会委托其内部的ChannelHandler的flush方法，我们一般实现的即是ChannelHandler的flush方法 1234567private void invokeFlush0() &#123; try &#123; ((ChannelOutboundHandler) handler()).flush(this); &#125; catch (Throwable t) &#123; notifyHandlerException(t); &#125;&#125; 好，假设在当前节点在flush的过程中发生了异常，都会被 notifyHandlerException(t);捕获，该方法会和inBound事件传播过程中的异常传播方法一样，也是轮流找下一个异常处理器，而如果异常处理器在pipeline最后面的话，一定会被执行到，这就是为什么该异常处理器也能处理outBound异常的原因 关于为啥 ExceptionHandler 既能处理inBound，又能处理outBound类型的异常的原因，总结一点就是，在任何节点中发生的异常都会往下一个节点传递，最后终究会传递到异常处理器 Handler热插拔netty 还有个最大的特性之一就是Handler可插拔，可以做到动态编织pipeline，比如在首次建立连接的时候，需要通过进行权限认证，在认证通过之后，就可以将此context移除，下次pipeline在传播事件的时候就就不会调用到权限认证处理器。 新连接接入时，ServerBootstrapAcceptor 会给新的NioSocketChannel 添加一个InBoundHandler叫ChannelInitialzer，添加成功之后会触发handlerAdded方法，该方法会调用重载的initialChannel方法初始化新连接的pipeline，结束后会调用pipeline.remove 删除此handler，这里也是热插拔的体现。","categories":[{"name":"I/O和网络编程","slug":"I-O和网络编程","permalink":"https://zzkenyon.github.io/categories/I-O和网络编程/"}],"tags":[{"name":"netty","slug":"netty","permalink":"https://zzkenyon.github.io/tags/netty/"}],"keywords":[{"name":"I/O和网络编程","slug":"I-O和网络编程","permalink":"https://zzkenyon.github.io/categories/I-O和网络编程/"}]},{"title":"mysql-innodb的索引","slug":"数据库技术-mysql-innodb的索引","date":"2019-11-19T16:00:00.000Z","updated":"2020-11-02T02:25:14.971Z","comments":true,"path":"2019/11/20/数据库技术-mysql-innodb的索引/","link":"","permalink":"https://zzkenyon.github.io/2019/11/20/数据库技术-mysql-innodb的索引/","excerpt":"","text":"数据库索引是数据库管理系统中一个排序的数据结构，以协助快速查询更新数据库表中数据 索引类型：normal普通索引、unique唯一索引、全文索引 普通索引：也叫非唯一索引，没有任何的限制 唯一索引：要求索引的键值不能重复，另外，主键索引是一种特殊的唯一索引，比唯一索引多了一条限制。即键值不能为null 全文索引：针对较大的数据，比如我么存放的是消息内容没有几KB的数据这种情况。如果要解决like查询效率低的问题，可以创建全文索引。只有文本类型的字段才可以创建全文索引，比如：char、varchar、text 1、索引用什么数据结构？索引是用来加快记录的查找速度，但是在查询记录之前是不是需要先定位到记录索引呢。因此为了加快索引的查找速度，可以考虑将索引按照顺序进行存放，然后使用二分查找法查找。 既然是按照顺序存放，那么可以考虑的数据结构就有以下几种： 1.1 有序列表有序列表查询没有问题，但是插如记录的时候需要同步插入记录的索引，有序列表的插入需要移动大量的数据，所以有序列表排除。 1.2 单链表单链表插入没有问题，查找的时候需要重头开始遍历，不能使用二分查找，因此排除 1.3 二叉树查找树既然单链表不能二分查找，那么就用支持二分查找的二叉树，但是极端情况下（插入顺序有序），二叉链表回退化成单链表，排除 1.4 AVL树-平衡二叉树 平衡二叉树解决了二叉树左右子树高度相差太大的极端问题，但是它也存在其他问题： 二叉树每个节点只能存放一条索引记录，当数据量很大的时候，树会长的很高，查询效率降低 平衡二叉树的平衡操作开销比较大 索引数据是以节点为单位存放到磁盘上，磁盘的最小单位是一页16KB，使用二叉树意味着每页磁盘页只能存放一条索引，浪费巨大显然不合理。 1.5 多路平衡查找树 B Tree跟 AVL 树一样，B 树在枝节点和叶子节点存储键值、数据地址、节点引用。 它有一个特点：分叉数（路数）永远比关键字数多 1。比如我们画的这棵树，每个节点存储两个关键字，那么就会有三个指针指向三个子节点。 B Tree 的查找规则是什么样的呢？ 比如我们要在这张表里面查找 15。 因为 15 小于 17，走左边。 因为 15 大于 12，走右边。 在磁盘块 7 里面就找到了 15，只用了 3 次 IO。 B树的缺点：范围查询时性能捉急：因为需要中序遍历 1.6 B+树（加强版多路平衡查找树）B Tree 的效率已经很高了，为什么 MySQL 还要对 B Tree 进行改良，最终使用了 B+Tree 呢？ 总体上来说，这个 B +树的改良版本解决的问题比 B Tree 更全面。 我们来看一下 InnoDB 里面的 B+树的存储结构： 的 B+Tree 有几个特点： 1、它的关键字的数量是跟路数相等的； 2、B+Tree 的根节点和枝节点中都不会存储数据，只有叶子节点才存储数据。查找到索引键值不会直接返回，会到最后一层的叶子节点。比如我们搜索 id=28，虽然在第一层直接命中了，但是全部的数据在叶子节点上面，所以我还要继续往下搜索，一直到叶子节点。 我们举个例子：假设一条记录是 1K，一个叶子节点（一页）可以存储 16 条记录。 非叶子节点可以存储多少个指针？ 假设主键为自增的bigint类型，占8字节，B+树指针为6字节，中间节点一页能存放的索引数量是16KB/14B=1170， 即至少有1170页即18MB存放行数据。而实际上这个这个值应该比计算出来的要大，原因是理论上一个叶节点中可能存放的记录数应该是1-1170行，但是1170是按照主键大小+指针大小计算出来的值，真正的行数据肯定还会有其他的字段，因此叶节点不能存放1170行数据是肯定的，那么多出来的行数据就会使用新的页进行存储并通过指针进行连接，这部分页并没有直接与B+树的中间节点连接，所以也无法进行精确计算。 如下图所示 树深度为2的时候，有1170^2个叶子节点 ，可以存储的数据为 1170X1170X16=21902400。 在查找数据时一次页的查找代表一次 IO，也就是说，一张 2000 万左右的表，查询数据最多需要访问 3 次磁盘。 所以在 InnoDB 中 B+ 树深度一般为 1-3 层，它就能满足千万级的数据存储。 3、B+Tree 的每个叶子节点增加了一个指向相邻叶子节点的指针，它的最后一个数据会指向下一个叶子节点的第一个数据，形成了一个有序链表的结构。 4、它是根据左闭右开的区间 [ )来检索数据。 B+Tree 的数据搜寻过程： 1）比如我们要查找 28，在根节点就找到了键值，但是因为它不是页子节点，所以 会继续往下搜寻，28 是[28,66)的左闭右开的区间的临界值，所以会走中间的子节点，然后继续搜索，它又是[28,34)的左闭右开的区间的临界值，所以会走左边的子节点，最后在叶子节点上找到了需要的数据。 2）第二个，如果是范围查询，比如要查询从 22 到 60 的数据，当找到 22 之后，只需要顺着节点和指针顺序遍历就可以一次性访问到所有的数据节点，这样就极大地提高了区间查询效率（不需要返回上层父节点重复遍历查找）。 重点 总结一下，InnoDB 中的 B+Tree 的特点： 1)它是 B Tree 的变种，B Tree 能解决的问题，它都能解决。B Tree 解决的两大问题是什么？（每个节点存储更多关键字；路数更多） 2)扫库、扫表能力更强（如果我们要对表进行全表扫描，只需要遍历叶子节点就可以了，不需要遍历整棵 B+Tree 拿到所有的数据） 3) B+Tree 的磁盘读写能力相对于 B Tree 来说更强（根节点和枝节点不保存数据区，所以一个节点可以保存更多的关键字，一次磁盘加载的关键字更多） 4)排序能力更强（因为叶子节点上有下一个数据区的指针，数据形成了链表） 5)效率更加稳定（B+Tree 永远是在叶子节点拿到数据，所以 IO 次数是稳定的） 数据结构可视化网站 2、B+Tree 落地形式不同的存储引擎文件不一样。 1show VARIABLES LIKE 'datadir'; 每 张 InnoDB 的 表 有 两 个 文 件 （ .frm 和 .ibd ） ， MyISAM 的 表 有 三 个 文 件 （.frm、.MYD、.MYI）。 有一个是相同的文件，.frm。 .frm 是 MySQL 里面表结构定义的文件，不管你建表的时候选用任何一个存储引擎都会生成，我们就不看了。 我们主要看一下其他两个文件是怎么实现 MySQL 不同的存储引擎的索引的。 2.1 MyISAM在 MyISAM 里面，另外有两个文件： 一个是.MYD 文件，D 代表 Data，是 MyISAM 的数据文件，存放数据记录，比如我 们的 user_myisam 表的所有的表数据。 一个是.MYI 文件，I 代表 Index，是 MyISAM 的索引文件，存放索引，比如我们在id 字段上面创建了一个主键索引，那么主键索引就是在这个索引文件里面。 也就是说，在 MyISAM 里面，索引和数据是两个独立的文件。 那我们怎么根据索引找到数据呢？ MyISAM 的 B+Tree 里面，叶子节点存储的是数据文件对应的磁盘地址，也就是指针。所以从索引文件.MYI 中找到键值后，会到数据文件.MYD 中获取相应的数据记录。 2.2 InnoDBInnoDB 只有一个文件（.ibd 文件），那索引放在哪里呢？ 在 InnoDB 里面，它是以主键为索引来组织数据的存储的，所以索引文件和数据文 件是同一个文件，都在.ibd 文件里面。 在 InnoDB 的主键索引的叶子节点上，它直接存储了我们的数据。 什么叫做聚集索引（聚簇索引）？ 就是索引键值的逻辑顺序跟表数据行的物理存储顺序是一致的。（比如字典的目录 是按拼音排序的，内容也是按拼音排序的，按拼音排序的这种目录就叫聚集索引）。 在 InnoDB 里面，它组织数据的方式叫做叫做（聚集）索引组织表（clustered index organize table），所以主键索引是聚集索引，非主键都是非聚集索引。 主键之外的索引，比如我们在 name 字段上面建的普通索引，又是怎么存储和检索 数据的呢？ InnoDB 中，主键索引和辅助索引是有一个主次之分的。 辅助索引存储的是辅助索引和主键值。如果使用辅助索引查询，会根据主键值在主键索引中查询，最终取得数据。 比如我们用 name 索引查询 name= ‘青山’，它会在叶子节点找到主键值，也就是 id=1，然后再到主键索引的叶子节点拿到数据。 3、主键索引的三种情形有primaryKey –使用主键组织数据存储 没有主键，存在unique字段– 使用该unique字段组织数据存储 没有主键，没有unique字段–使用隐藏字段_rowid组织数据 4、使用索引的注意点回表查询：命中辅助索引后，根据辅助索引查询到的主键，再去主键索引中查询数据，称为回表 覆盖索引：组成联合索引的字段包含了所需查询的字段，查询到辅助索引页即可得到结果，无需回表查询 为什么不建议使用Select * ？ 阻止了覆盖索引生效，导致回表查询，使用指定列的sql能节省数据库内存占用，提高数据传输效率 索引的最左匹配原则是什么意思？ 有联合索引 index(A,B,C) 查询时，使用A、A&amp;B 、A&amp;B&amp;C 查询都能命中该索引，且与字段顺序无关，即B&amp;A也能命中 A&amp;C B&amp;C B C 都不符合最左匹配原则，不能命中 模糊匹配可以用到索引吗？ like %abc 不能命中索引，like abc%可以命中 因此我们得出结论：前导模糊匹配不能命中索引 负向查询 != not in &lt;&gt; 能不能用到索引？ 能不能用到索引是优化器决定的，优化器基于开销判断，一般不推荐使用负向查询 为什么推荐递增字段做主键索引？ InnoDB的索引底层是B+树，且通过主键索引来组织数据存储。如果使用自增主键，那么每次插入新的记录，就会顺序添加到当前索引节点的后续位置（右边），当写满一页就会开辟新页，这样就会形成一个近似顺序填满的紧凑结构，插入过程无需移动已有数据。 而如果使用uuid或者身份证号这种不规则的数据作为主键索引，那么插入数据时，相当于随机插入，导致已有数据频繁移动，磁盘io开销变大，且可能产生大量的叶碎片 总结使用索引应注意以下几点： 负向查询不能命中索引 前导模糊查询不能命中索引（like条件前面带%） 字符串不加引号，出现隐式转换 ，不能命中索引 数据区分度不大不宜建立索引（性别） 在索引属性上进行计算（函数或表达式）不能命中索引 并非周知的sql实践： 业务存在大量单条查询，实用hash索引效率高 允许为null的字段有大坑，单列索引不存null值，复合索引不存全为null的值，设置为not null 或者设置默认值 固定范围取值的字段使用枚举类型而不是字符串 小众实用的规则： 明确返回结果数量，实用limit能提升查询效率 把计算放到业务层而不是数据库层 强制类型转换会扫描全表 参考： 数据库索引，到底是什么做的？","categories":[{"name":"数据库技术","slug":"数据库技术","permalink":"https://zzkenyon.github.io/categories/数据库技术/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://zzkenyon.github.io/tags/mysql/"}],"keywords":[{"name":"数据库技术","slug":"数据库技术","permalink":"https://zzkenyon.github.io/categories/数据库技术/"}]},{"title":"netty源码分析之新连接接入","slug":"nio-netty源码分析之新连接接入","date":"2019-11-17T16:00:00.000Z","updated":"2020-09-07T07:44:08.026Z","comments":true,"path":"2019/11/18/nio-netty源码分析之新连接接入/","link":"","permalink":"https://zzkenyon.github.io/2019/11/18/nio-netty源码分析之新连接接入/","excerpt":"","text":"重读总结： 客户端的通道是由服务器创建的，当主线程监听到Accept事件，会进入事件处理流程，创建客户端通道 子通道的生命周期 创建——初始化——注册 创建，主线程执行处理流程时创建子通道NioSocketChannel对象 初始化，在主通道PipeLine中有一个ServerBootstrapAcceptor处理器，专门对新的子通道执行初始化和注册操作 注册，注册完成之后子通道就处于激活状态了，会调用channelActive方法，向下调用doBeginRead完成监听事件的更改 所有的通道创建后都默认为autoRead，在通道激活之后，就会进入doBeginRead()流程，该流程就是更改通道的监听事件 我们知道服务端启动后，会有一条boss线程在运行着，负责接受客户端的新连接。boss线程具体运行的逻辑在NioEventLoop的run()方法中，这里不做具体体分析，只截取本文关心的代码片段： 123456789//NioEventLoopprotected void run() &#123; ... strategy = select(curDeadlineNanos); ... if (strategy &gt; 0) &#123; processSelectedKeys(); &#125; &#125; 典型的jdk nio 的代码逻辑，先select，再处理selectedKey，跟进处理代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243//NioEventLoopprivate void processSelectedKeys() &#123; if (selectedKeys != null) &#123; // 优化过的处理 一般会进这里 processSelectedKeysOptimized(); &#125; else &#123; // 正常处理 processSelectedKeysPlain(selector.selectedKeys()); &#125;&#125;private void processSelectedKeysOptimized() &#123; for (int i = 0; i &lt; selectedKeys.size; ++i) &#123; final SelectionKey k = selectedKeys.keys[i]; selectedKeys.keys[i] = null; final Object a = k.attachment(); // 由于主线程上只注册了一条主通道，所以 // 从selectedKey中取出附件只能是NioServerSocketChannel对象 if (a instanceof AbstractNioChannel) &#123; // 继续跟进 processSelectedKey(k, (AbstractNioChannel) a); &#125; else &#123; @SuppressWarnings(\"unchecked\") NioTask&lt;SelectableChannel&gt; task = (NioTask&lt;SelectableChannel&gt;) a; processSelectedKey(k, task); &#125; if (needsToSelectAgain) &#123; selectedKeys.reset(i + 1); selectAgain(); i = -1; &#125; &#125;&#125;private void processSelectedKey(SelectionKey k, AbstractNioChannel ch) &#123; ... try&#123; ... //注意：所有通道注册的时候都没有第一时间指定监听事件，而ops==0 时，这里默认是监听读就绪事件 if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) &#123; unsafe.read(); &#125; &#125; catch (CancelledKeyException ignored) &#123;&#125;&#125; 看到最终调用了unsafe.read()方法，注意这里处理的是 NioServerSocketChannel 上的读。 这里我们要清楚，netty能读到的数据分为两种类型，对于NioServerSocketChannel来说，它只负责接收新连接，所以读到的是建立连接的请求，netty将这类数据称为 message 。对于已经接入的客户端连接，读到的是业务请求，netty将这类数据成为 byte。 由于这里处理的是新连接接入，read()方法将进入 AbstractNioMessageChannel.NioMessageUnsafe 类： 1234567891011121314151617181920212223242526272829303132333435//NioMessageUnsafepublic void read() &#123; assert eventLoop().inEventLoop(); final ChannelConfig config = config(); final ChannelPipeline pipeline = pipeline(); final RecvByteBufAllocator.Handle allocHandle = unsafe().recvBufAllocHandle(); allocHandle.reset(config); boolean closed = false; Throwable exception = null; try &#123; try &#123; do &#123; // 不断的读取消息，可以猜到读取的是一个个NioSocketChannel对象 int localRead = doReadMessages(readBuf); ... &#125; while (allocHandle.continueReading()); &#125; int size = readBuf.size(); for (int i = 0; i &lt; size; i ++) &#123; readPending = false; // 这里向NioServerSocketChannel 的pipeline中传进ChannelRead事件,参数是读取到的NioSocketChannel pipeline.fireChannelRead(readBuf.get(i)); &#125; readBuf.clear(); allocHandle.readComplete(); pipeline.fireChannelReadComplete(); ... &#125; finally &#123; if (!readPending &amp;&amp; !config.isAutoRead()) &#123; removeReadOp(); &#125; &#125; &#125;&#125; 重点在doReadMessages() 方法，该方法将调用到底层的jdk的accept()得到的 SocketChannel ，并将其包装成netty的 NioSocketChannel 并add 到 buf 中，而上层的read()方法可以直接访问 buf。 12345678910111213141516//NioServerSocketChannelprotected int doReadMessages(List&lt;Object&gt; buf) throws Exception &#123; // accept得到SocketChannel对象 SocketChannel ch = SocketUtils.accept(javaChannel()); try &#123; if (ch != null) &#123; // 根据SocketChannel对象 创建NioSocketChannel buf.add(new NioSocketChannel(this, ch)); return 1; &#125; &#125; catch (Throwable t) &#123; ... &#125; return 0;&#125; doReadMessages() 调用完之后，我们再回到read()方法，可以看到将读取到每个 NioSocketChannel 作为参数调用了 NioServerSocketChannel 的 pipeline.channalRead(buf.get(i)) 方法，这个调用会产生什么反应呢？ 服务端启动分析时提到，初始化 NioServerSocketChannel 阶段向 主通道的PipeLine 中添加了一个 ServerBootstrapAcceptor ，后文称接收器，源码如下： 123456789101112131415161718//ServerBootstrapvoid init(Channel channel) &#123; ... ChannelPipeline p = channel.pipeline(); // 这里是NioServerSocketChannel的pipeline p.addLast(new ChannelInitializer&lt;Channel&gt;() &#123; @Override public void initChannel(final Channel ch) &#123; ... ch.eventLoop().execute(new Runnable() &#123; @Override public void run() &#123; pipeline.addLast(new ServerBootstrapAcceptor( ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); &#125; &#125;); &#125; &#125;);&#125; 初始化结束后， NioServerSocketChannel 的 pipeline 有以下几个节点： 1head--&gt;ServerBootstrapAcceptor--&gt;tail 再看这个接收器ServerBootstrapAcceptor，它是 NioServerSocketChannel 的一个 InBound 事件处理器，read()方法调用pipeline.channalRead(buf.get(i))时，会首先进入head执行channelRead 方法，head只是简单的向下传播此事件，然后进入 ServerBootstrapAcceptor 的 channelRead 方法，我们来看具体做了什么： 12345678910111213141516171819202122//ServerBootstrapAcceptorpublic void channelRead(ChannelHandlerContext ctx, Object msg) &#123; final Channel child = (Channel) msg; //1、向NioSocketChannel的PipeLine中 add ChannelInitializer child.pipeline().addLast(childHandler); //2. 设置options和attrs setChannelOptions(child, childOptions, logger); setAttributes(child, childAttrs); try &#123; //3. 异步执行通道注册，监听事件尚未指定，未指定默认监听读就绪 childGroup.register(child).addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; if (!future.isSuccess()) &#123; forceClose(child, future.cause()); &#125; &#125; &#125;); &#125; catch (Throwable t) &#123; forceClose(child, t); &#125; &#125; 首先对读取到的 NioSocketChannel 执行了初始化，该方法主要对 NioSocketChannel 做了三件事： 添加用户代码中指定的 InBound 事件处理器 ChannelInitializer 用于初始化NioSocketChannel，该handle向NioSocketChannel 中 add 一系列事件处理器 ，ChannelInitializer执行完成之后将会被remove掉。 设置用户代码中指定的 NioSocketChannel 的 options 和 attrs 使用 childGroup 线程池执行 NioSocketChannel 注册任务 childGroup 会使用 chooser 选择分配一条线程（EventLoop）给 NioSocketChannel，之后所有该channel的任务都将由这条线程执行。 注册过程与NioServerSocketChannel的注册流程一致，最终会调用到 AbstractChannel.AbstractUnsafe 类的 register0 ()方法进行注册。 12345678910111213141516171819202122232425private void register0(ChannelPromise promise) &#123; try &#123; ... boolean firstRegistration = neverRegistered; //1. 执行注册 doRegister(); neverRegistered = false; registered = true; //2.传入事件handlerAdded pipeline.invokeHandlerAddedIfNeeded(); safeSetSuccess(promise); //3.传入事件channelRegistered pipeline.fireChannelRegistered(); //4.注册成功则传入事件channelActice if (isActive()) &#123; if (firstRegistration) &#123; pipeline.fireChannelActive(); &#125; else if (config().isAutoRead()) &#123; beginRead(); &#125; &#125; &#125; catch (Throwable t) &#123; ... &#125;&#125; 调用jdk底层注册channel 12345protected void doRegister() throws Exception &#123; ... selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this); ...&#125; 再提一次，注册时并没有设置感兴趣的事件，第二个参数为0，第三个参数则是将netty封装后的NioSocketChannel 当做附件，放到了selectionKey中，之后select出的selectionKey中都将带有netty的channel对象，这种设计实现了netty channel 与 jdk channel 的映射。 继续往下看，注册完之后，会调用一系列的pipeline方法，handlerAdded、channelRegistered、channelActive，此时应该已经很清楚，从 unsafe 中调用 pipeline 的方法，调用进入 pipeline传入的事件我们称之为 inbound 事件。 其中 channelActive 为流程中的重要一环，pipeLine调用后首先会调用head节点的channelActive方法，我们看一下head的channelActive源码： 12345678910111213// HeadCotextpublic void channelActive(ChannelHandlerContext ctx) &#123; // 向下传递事件 ctx.fireChannelActive(); // 如果设置为自动读，autoRead 默认为true，则调用channel的read方法 readIfIsAutoRead();&#125;private void readIfIsAutoRead() &#123; if (channel.config().isAutoRead()) &#123; channel.read(); &#125;&#125; 往下看调用链 12345// AbstractChannelpublic Channel read() &#123; pipeline.read(); return this;&#125; 再跟进 12345// DefaultChannelPipelinepublic final ChannelPipeline read() &#123; tail.read(); return this;&#125; 最终调用到了tail的read方法, tail 的 read 方法是继承自父类 AbstractChannelHandlerContext： 12345678910111213141516//AbstractChannelHandlerContextpublic ChannelHandlerContext read() &#123; // read方法 将从tail开始往前检索，找到实现了read方法的OutBoundHandler，将找到head节点 final AbstractChannelHandlerContext next = findContextOutbound(MASK_READ); EventExecutor executor = next.executor(); if (executor.inEventLoop()) &#123; next.invokeRead(); &#125; else &#123; Tasks tasks = next.invokeTasks; if (tasks == null) &#123; next.invokeTasks = tasks = new Tasks(next); &#125; executor.execute(tasks.invokeReadTask); &#125; return this;&#125; 逻辑也很清晰，从 tail 开始，向前调用重载了read方法的OutboundHandler，直到head节点，看一下head节点的 read() 方法： 123public void read(ChannelHandlerContext ctx) &#123; unsafe.beginRead();&#125; 调用到了 unsafe 的 beginRead方法，这里我们需要明白从 pipeline 中不断调用最终到达unsafe 的调用链，称为OutBound 事件传播，调用出pipeline，所以 read 是一个outbound事件。 继续跟源码： 123456@Overridepublic final void beginRead() &#123; ... doBeginRead(); ...&#125; 跟进: 12345678910111213// AbstractNioChannelprotected void doBeginRead() throws Exception &#123; final SelectionKey selectionKey = this.selectionKey; if (!selectionKey.isValid()) &#123; return; &#125; readPending = true; final int interestOps = selectionKey.interestOps(); // interestOps &amp; OP_READ 若果没有监听读就绪事件 do it if ((interestOps &amp; readInterestOp) == 0) &#123; selectionKey.interestOps(interestOps | readInterestOp); &#125; &#125; 重点是最后一行，设置监听事件为读就绪。 一个连接从接入，到注册，到设置监听读就绪，之后，客户端与服务器便能正常的通信了。","categories":[{"name":"I/O和网络编程","slug":"I-O和网络编程","permalink":"https://zzkenyon.github.io/categories/I-O和网络编程/"}],"tags":[{"name":"netty","slug":"netty","permalink":"https://zzkenyon.github.io/tags/netty/"}],"keywords":[{"name":"I/O和网络编程","slug":"I-O和网络编程","permalink":"https://zzkenyon.github.io/categories/I-O和网络编程/"}]},{"title":"netty源码分析之服务端启动","slug":"nio-netty源码分析之服务端启动","date":"2019-11-14T16:00:00.000Z","updated":"2020-09-07T07:09:29.238Z","comments":true,"path":"2019/11/15/nio-netty源码分析之服务端启动/","link":"","permalink":"https://zzkenyon.github.io/2019/11/15/nio-netty源码分析之服务端启动/","excerpt":"","text":"重读总结： 想要更好的理解服务启动流程，就要明白netty的线程模型——reactor模型，主线程负责接受新连接，只监听主线程selector上注册的ACCEPT事件 主通的生命周期为 创建——初始化——注册——绑定 创建，就是通过反射调用 默认的构造函数，创建一个NioServerSocketChannel对象 初始化，将启动程序中对主通道的设置配置到该对象中，最主要的是在主通道PipeLine中添加ServerBootstrapAcceptor处理器，用于处理新子通道的注册 注册，将主通道注册到主线程的Selector上，此时未设置监听事件，且注册完成之后，主通道还是处于未激活状态 绑定，将主通道绑定到一个端口上，绑定成功将激活通道，触发主通道PipeLine的channelActice事件，这是InBound事件，首先调用HeadContext的channelActice方法，在该方法中开始执行read流程。由于read是一个个OutBound流程，最终还是会调用到HeadContext.read()方法。HeadContext.read又会调用unsafe层的read方法，在该方法中对主通道的监听事件进行了初始化。 需要注意的是，主线程上只注册了主通道一条通道。 首先贴一段简单的服务器启动代码 123456789101112131415public static void main(String[] args)&#123; NioEventLoopGroup parent = new NioEventLoopGroup(1); NioEventLoopGroup children = new NioEventLoopGroup(); ServerBootstrap bs = new ServerBootstrap(); bs.group(parent,children) .channel(NioServerSocketChannel.class) .handler(new ServerHandler()) .childHandler(new ChannelInitializer&lt;Channel&gt;()&#123; @Override protected void initChannel(NioSocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new Spliter()); &#125; &#125;); bs.bind(8080);&#125; 代码逻辑： 1、创建了一个线程池 parent，其中只有一个线程，主要负责接受新连接 2、创建另一个线程池 children，线程个数为默认值，核心数的2倍，主要负责处理客户端channel上的各种事件 3、创建服务器启动引导对象，将两个线程池通过 group 方法设置进去 4、使用 channel 方法指定服务器使用的i/o模型为nio 5、使用 handler 方法给服务器的 NioServerSocketChannel 的pipeline添加节点。 6、使用childHandler 方法指定新连接接入过程中客户端 NioSocketChannel 初始化方法，主要给这些channe l的 PipeLine 添加节点 7、通过 bind(8080) 方法启动服务绑定到8080端口 对于Reactor线程模型一直有一点疑惑，worker线程池的工作方式是一条channel分配一条线程执行所有的业务逻辑，但是boss线程池面对是仅有一条的NioServerSocketChannel，为什么还需要线程池来处理呢？ 实际上bossGroup中有多个NioEventLoop线程，每个NioEventLoop绑定一个端口，也就是说，如果程序只需要监听1个端口的话，bossGroup里面只需要有一个NioEventLoop线程就行了。 本文的主要讲述的是服务端的启动流程，所以以bind方法为入口，源码节选关键代码块。 bind方法定义在 ServerBootstrap 类的父类 AbstractBootstrap中： 12345//AbstractBootstrappublic ChannelFuture bind() &#123; ... return doBind(localAddress);&#125; 12345678910111213141516private ChannelFuture doBind(final SocketAddress localAddress) &#123; // 核心 初始化通道 注册通道 final ChannelFuture regFuture = initAndRegister(); final Channel channel = regFuture.channel(); ... if (regFuture.isDone()) &#123; ChannelPromise promise = channel.newPromise(); // 核心 绑定监听端口 doBind0(regFuture, channel, localAddress, promise); return promise; &#125; else &#123; ... &#125; return promise;&#125; doBind方法中主要有两个核心方法 initAndRegister()和doBind0()，前者主要负责创建、初始化、注册NioServerSocketChannel，后者负责将创建的通绑定到指定端口并启动服务。 下面我们逐一来分析，首先是initAndRegister()，看源码： 12345678910111213141516final ChannelFuture initAndRegister() &#123; Channel channel = null; try &#123; // 创建 channel = channelFactory.newChannel(); // 初始化 init(channel); &#125; catch (Throwable t) &#123; ... &#125; // 注册 ChannelFuture regFuture = config().group().register(channel); if (regFuture.cause() != null) &#123; ... &#125;&#125; 逻辑清晰，先创建，再初始化，再注册。 创建：见文章开头服务器启动代码，调用ServerBootstrap的channel()方法设置io模式的时候： 1234567891011//AbstractBootstrappublic B channel(Class&lt;? extends C&gt; channelClass) &#123; return channelFactory(new ReflectiveChannelFactory&lt;C&gt;( ObjectUtil.checkNotNull(channelClass, \"channelClass\") ));&#125;public B channelFactory(ChannelFactory&lt;? extends C&gt; channelFactory) &#123; ... this.channelFactory = channelFactory; return self();&#125; 已经指定了 channelFactory 为 ReflectiveChannelFactory , 所以创建语句channelFactory.newChannel()会调用到ReflectiveChannelFactory的newChannel()方法，源码就不贴了，就是反射调用指定类型的默认构造函数创建一个Channel对象，io模型为NIO时，创建的是NioServerSocketChannel对象。 初始化： init(channel)调用到ServerBootstrap的init()方法 123456789101112131415161718192021222324252627282930313233343536//ServerBootstrapvoid init(Channel channel) &#123; // 设置options setChannelOptions(channel, newOptionsArray(), logger); // 设置 attrs setAttributes(channel, attrs0().entrySet().toArray(EMPTY_ATTRIBUTE_ARRAY)); ChannelPipeline p = channel.pipeline(); // 设置新接入channel的options和attrs final EventLoopGroup currentChildGroup = childGroup; final ChannelHandler currentChildHandler = childHandler; final Entry&lt;ChannelOption&lt;?&gt;, Object&gt;[] currentChildOptions; synchronized (childOptions) &#123; currentChildOptions = childOptions.entrySet().toArray(EMPTY_OPTION_ARRAY); &#125; final Entry&lt;AttributeKey&lt;?&gt;, Object&gt;[] currentChildAttrs = childAttrs.entrySet().toArray(EMPTY_ATTRIBUTE_ARRAY); // 向NioServerSocketChannel中添加用户自定义Handler，最后添加用于处理新连接的ServerBootstrapAcceptor p.addLast(new ChannelInitializer&lt;Channel&gt;() &#123; @Override public void initChannel(final Channel ch) &#123; final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); if (handler != null) &#123; pipeline.addLast(handler); // 添加ServerHandler &#125; // 向serverChannel的流水线处理器中加入了一个 ServerBootstrapAcceptor， // 从名字上就可以看出来，这是一个接入器，专门接受新请求 ch.eventLoop().execute(new Runnable() &#123; @Override public void run() &#123; pipeline.addLast(new ServerBootstrapAcceptor( ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); &#125; &#125;); &#125; &#125;);&#125; ServerBootstrapAcceptor是一个重点类，这是一个InBoundHandler，当客户端连接请求到来，服务器channel会将新的客户端channel丢给这个handler进行处理，而他主要的执行逻辑就是，将这个新的客户端channel注册到childGroup中的一个线程中，看代码： 1234567891011121314151617181920212223public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; // 这里拿到的服务端为新接入的客户端创建的 NioSocketChannel对象 final Channel child = (Channel) msg; //向NioSocketChannel的PipeLine中 add ChannelInitializer，初始化客户端channel的执行流程pipleLine child.pipeline().addLast(childHandler); setChannelOptions(child, childOptions, logger); setAttributes(child, childAttrs); try &#123; // 异步执行客户端通道注册，监听事件尚未指定，未指定默认监听读就绪 childGroup.register(child).addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; if (!future.isSuccess()) &#123; // 强制关闭 forceClose(child, future.cause()); &#125; &#125; &#125;); &#125; catch (Throwable t) &#123; forceClose(child, t); &#125;&#125; 注册：config().group().register(channel)经过一系列调用，最终会调用到 AbstractChannel.AbstractUnsafe 类的 register0 ()方法进行注册。 1234567891011121314151617181920212223242526//AbstractChannel.AbstractUnsafeprivate void register0(ChannelPromise promise) &#123; try &#123; ... boolean firstRegistration = neverRegistered; //1. 执行注册 doRegister(); neverRegistered = false; registered = true; //2.传入事件handlerAdded pipeline.invokeHandlerAddedIfNeeded(); safeSetSuccess(promise); //3.传入事件channelRegistered pipeline.fireChannelRegistered(); //4.注册成功判断是否激活，是则传入事件channelActice if (isActive()) &#123; if (firstRegistration) &#123; pipeline.fireChannelActive(); &#125; else if (config().isAutoRead()) &#123; beginRead(); &#125; &#125; &#125; catch (Throwable t) &#123; ... &#125;&#125; 调用jdk底层注册channel 123456//AbstractChannel.AbstractUnsafeprotected void doRegister() throws Exception &#123; ... selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this); ...&#125; 可以看到，注册时并没有设置感兴趣的事件，第二个参数为0，第三个参数则是将netty封装后的NioSocketChannel 当做附件，放到了selectionKey中，之后select出的selectionKey中都将带有netty的channel对象，这种设计实现了netty channel 与 jdk channel 的映射。 注册完成之后会会进行一次判断isActive()，对于NioServerSocketChannel来说，到这里并没有激活，因为NioServerSocketChannel 的激活条件是isOpen() &amp;&amp; javaChannel().socket().isBound()，channel需要open且已绑定端口，目前只完成了注册还未进行绑定，所以这里不能触发channelActive事件。 而对于NioSocketChannel来说，判断条件是ch.isOpen() &amp;&amp; ch.isConnected()，open并已连接，所以NioSocketChannel 一般是在此处触发channelActive事件。 initAndRegister()执行完，来到了dBind0()方法： 1234567891011121314151617//AbstractBootstrapprivate static void doBind0( final ChannelFuture regFuture, final Channel channel, final SocketAddress localAddress, final ChannelPromise promise) &#123; channel.eventLoop().execute(new Runnable() &#123; @Override public void run() &#123; if (regFuture.isSuccess()) &#123; channel.bind(localAddress, promise) .addListener(ChannelFutureListener.CLOSE_ON_FAILURE); &#125; else &#123; promise.setFailure(regFuture.cause()); &#125; &#125; &#125;);&#125; 唯一的逻辑就是提交了一个异步任务，调用channel.bind()方法。 对于channel来说bind是一个outBound事件，channel.bind()会继续调用pipeline.bind()，继续往下掉用tail.bind()，然后就是一个节点一个节点往前传，最终调用到head节点的bind方法： 1234public void bind( ChannelHandlerContext ctx, SocketAddress localAddress, ChannelPromise promise) &#123; unsafe.bind(localAddress, promise);&#125; 看到unsafe我就开心，因为马上要干活了， 123456789101112131415161718192021//AbstractChannel.AbstractUnsafepublic final void bind(final SocketAddress localAddress, final ChannelPromise promise) &#123; ...//略过一大堆判断 // 连接是否激活 绑定之前时false boolean wasActive = isActive(); try &#123; // 关键点 doBind(localAddress); &#125; catch (Throwable t) &#123;&#125; // 之前未激活 现在已激活 if (!wasActive &amp;&amp; isActive()) &#123; //触发连接激活事件 invokeLater(new Runnable() &#123; @Override public void run() &#123; pipeline.fireChannelActive(); &#125; &#125;); &#125; safeSetSuccess(promise);&#125; 最终unsafe.doBind()调用到了NioServerSocketChannel中的doBind()，兜了一个大圈还是回到了原点。 123456789//NioServerSocketChannelprotected void doBind(SocketAddress localAddress) throws Exception &#123; if (PlatformDependent.javaVersion() &gt;= 7) &#123; // 这里调用jdk nio的api 进行绑定 javaChannel().bind(localAddress, config.getBacklog()); &#125; else &#123; javaChannel().socket().bind(localAddress, config.getBacklog()); &#125;&#125; 这里就是底层jdk的逻辑了，这里执行完成，serverSocket就算是真正的启动了起来。 再回到unsafe.doBind()，成功后触发pipeline.fireChannelActive()，我们现在都有经验了，这种inBound事件，调用一大圈最终都是从head节点开始执行，来看head的channelActive()方法： 12345678910111213// HeadCotextpublic void channelActive(ChannelHandlerContext ctx) &#123; // 向下传递事件 ctx.fireChannelActive(); // 如果设置为自动读，autoRead 默认为true，则调用channel的read方法 readIfIsAutoRead();&#125;private void readIfIsAutoRead() &#123; if (channel.config().isAutoRead()) &#123; channel.read(); &#125;&#125; 往下看调用链： 12345// AbstractChannelpublic Channel read() &#123; pipeline.read(); return this;&#125; 再跟进 12345// DefaultChannelPipelinepublic final ChannelPipeline read() &#123; tail.read(); return this;&#125; 最终调用到了tail的read方法, tail 的 read 方法是继承自父类 AbstractChannelHandlerContext： 123456789101112//AbstractChannelHandlerContextpublic ChannelHandlerContext read() &#123; // read方法 将从tail开始往前检索，找到实现了read方法的OutBoundHandler，将找到head节点 final AbstractChannelHandlerContext next = findContextOutbound(MASK_READ); EventExecutor executor = next.executor(); if (executor.inEventLoop()) &#123; next.invokeRead(); &#125; else &#123; ... &#125; return this;&#125; 逻辑也很清晰，从 tail 开始，向前调用重载了read方法的OutboundHandler，直到head节点，看一下head节点的 read() 方法： 123public void read(ChannelHandlerContext ctx) &#123; unsafe.beginRead();&#125; 调用到了 unsafe 的 beginRead方法，这里我们需要明白从 pipeline 中不断调用最终到达unsafe 的调用链，称为OutBound 事件传播，调用出pipeline，所以 read 是一个outbound事件。 继续跟源码： 123456//AbstractChannel.AbstractUnsafepublic final void beginRead() &#123; ... doBeginRead(); ...&#125; 跟进: 12345678910111213// AbstractNioChannelprotected void doBeginRead() throws Exception &#123; final SelectionKey selectionKey = this.selectionKey; if (!selectionKey.isValid()) &#123; return; &#125; readPending = true; final int interestOps = selectionKey.interestOps(); // 若果没有监听指定的事件 do it 这里readInterestOp = OP_ACCEPT if ((interestOps &amp; readInterestOp) == 0) &#123; selectionKey.interestOps(interestOps | readInterestOp); &#125; &#125; 重点是最后一行，设置监听事件为OP_ACCEPT。至此 NioServerSocketChannel 注册成功并监听OP_ACCEPT事件。 readInterestOp是AbstractNioChannel的成员变量，在其子类NioServerSocketChannel初始化的时候进行了指定，指定为SelectionKey.OP_ACCEPT，看代码： 1234public NioServerSocketChannel(ServerSocketChannel channel) &#123; super(null, channel, SelectionKey.OP_ACCEPT); config = new NioServerSocketChannelConfig(this, javaChannel().socket());&#125; 下一篇分析客户端新连接入流程。","categories":[{"name":"I/O和网络编程","slug":"I-O和网络编程","permalink":"https://zzkenyon.github.io/categories/I-O和网络编程/"}],"tags":[{"name":"netty","slug":"netty","permalink":"https://zzkenyon.github.io/tags/netty/"}],"keywords":[{"name":"I/O和网络编程","slug":"I-O和网络编程","permalink":"https://zzkenyon.github.io/categories/I-O和网络编程/"}]},{"title":"netty源码分析之异步编程","slug":"nio-netty源码分析之异步编程","date":"2019-11-07T16:00:00.000Z","updated":"2020-06-29T10:44:55.022Z","comments":true,"path":"2019/11/08/nio-netty源码分析之异步编程/","link":"","permalink":"https://zzkenyon.github.io/2019/11/08/nio-netty源码分析之异步编程/","excerpt":"","text":"netty的异步编程模型异步编程的目标是：提交一个任务给线程池，在任务执行期间，提交者可以执行其他的逻辑，当提交的任务执行完成，通知提交者来获取执行结果 netty 异步任务的实现Future/Promise异步模型， 模型定义了几个接口： 12345678910111213141516171819public interface Future&lt;V&gt; extends java.util.concurrent.Future&lt;V&gt; &#123; boolean isSuccess(); boolean isCancellable(); Throwable cause(); Future&lt;V&gt; addListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); Future&lt;V&gt; addListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); Future&lt;V&gt; removeListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); Future&lt;V&gt; removeListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); Future&lt;V&gt; sync() throws InterruptedException; Future&lt;V&gt; syncUninterruptibly(); Future&lt;V&gt; await() throws InterruptedException; Future&lt;V&gt; awaitUninterruptibly(); boolean await(long timeout, TimeUnit unit) throws InterruptedException; boolean await(long timeoutMillis) throws InterruptedException; boolean awaitUninterruptibly(long timeout, TimeUnit unit); boolean awaitUninterruptibly(long timeoutMillis); V getNow(); boolean cancel(boolean mayInterruptIfRunning);&#125; 123456789101112public interface ChannelFuture extends Future&lt;Void&gt; &#123; Channel channel(); // 实现类需要持有channel引用 boolean isVoid(); // 如果该实现类是一个Future&lt;Void&gt; ChannelFuture addListener(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt; listener); ChannelFuture addListeners(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt;... listeners); ChannelFuture removeListener(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt; listener); ChannelFuture removeListeners(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt;... listeners); boolean isSuccess(); // 当且仅当io操作成功返回true boolean isCancellable(); // 当且仅当io操作被cancel方法取消，返回true ChannelFuture sync() throws InterruptedException; // 等待这个future直到它完成为止，如果future失败，则重新抛出失败的原因。 ChannelFuture await() throws InterruptedException;// 等待这个future的完成&#125; 12345678910111213public interface Promise&lt;V&gt; extends Future&lt;V&gt; &#123; Promise&lt;V&gt; setSuccess(V result);// 标记此futrue成功，并通知所有的监听器 boolean trySuccess(V result);//标记此futrue成功，并通知所有的监听器，当且仅当成功返回true Promise&lt;V&gt; setFailure(Throwable cause); boolean tryFailure(Throwable cause); boolean setUncancellable(); // 标记此futrue不可取消，如果这该futrue已取消，返回false Promise&lt;V&gt; addListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); Promise&lt;V&gt; addListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); Promise&lt;V&gt; removeListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); Promise&lt;V&gt; removeListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); Promise&lt;V&gt; sync() throws InterruptedException; Promise&lt;V&gt; await() throws InterruptedException;&#125; 123456789101112131415161718192021222324252627282930public interface ChannelPromise extends ChannelFuture, Promise&lt;Void&gt; &#123; @Override Channel channel(); @Override ChannelPromise setSuccess(Void result); ChannelPromise setSuccess(); boolean trySuccess(); @Override ChannelPromise setFailure(Throwable cause); @Override ChannelPromise addListener(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt; listener); @Override ChannelPromise addListeners(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt;... listeners); @Override ChannelPromise removeListener(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt; listener); @Override ChannelPromise removeListeners(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt;... listeners); @Override ChannelPromise sync() throws InterruptedException; @Override ChannelPromise syncUninterruptibly(); @Override ChannelPromise await() throws InterruptedException; @Override ChannelPromise awaitUninterruptibly(); /** * Returns a new &#123;@link ChannelPromise&#125; if &#123;@link #isVoid()&#125; returns &#123;@code true&#125; otherwise itself. */ ChannelPromise unvoid();&#125; 12345678910111213141516171819202122232425262728293031//ChannelFutureListenerpublic interface ChannelFutureListener extends GenericFutureListener&lt;ChannelFuture&gt; &#123; ChannelFutureListener CLOSE = new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) &#123; future.channel().close(); &#125; &#125;; ChannelFutureListener CLOSE_ON_FAILURE = new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) &#123; if (!future.isSuccess()) &#123; future.channel().close(); &#125; &#125; &#125;; ChannelFutureListener FIRE_EXCEPTION_ON_FAILURE = new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) &#123; if (!future.isSuccess()) &#123; future.channel().pipeline().fireExceptionCaught(future.cause()); &#125; &#125; &#125;;&#125;public interface GenericFutureListener&lt;F extends Future&lt;?&gt;&gt; extends EventListener &#123; void operationComplete(F future) throws Exception;&#125; 要创建一个ChannelPromise，需要提供一个channel和处理该channel上事件的Executor，例如注册一个channel时，创建一个DefaultChannelPromise，里面包装了即将注册的channel和即将执行注册操作的Executor： 123public ChannelFuture register(Channel channel) &#123; return register(new DefaultChannelPromise(channel, this));&#125; 12345public ChannelFuture register(final ChannelPromise promise) &#123; ObjectUtil.checkNotNull(promise, \"promise\"); promise.channel().unsafe().register(this, promise); return promise;&#125; 完成注册操作之后返回这个promise，注意返回值类型是ChannelFuture，DefaultChannelPromise向上转型成 ChannelFuture 1234567891011121314151617181920212223242526private void register0(ChannelPromise promise) &#123; try &#123; if (!promise.setUncancellable() || !ensureOpen(promise)) &#123; return; &#125; boolean firstRegistration = neverRegistered; doRegister(); neverRegistered = false; registered = true; pipeline.invokeHandlerAddedIfNeeded(); safeSetSuccess(promise); // &gt;&gt; pipeline.fireChannelRegistered(); if (isActive()) &#123; if (firstRegistration) &#123; pipeline.fireChannelActive(); &#125; else if (config().isAutoRead()) &#123; beginRead(); &#125; &#125; &#125; catch (Throwable t) &#123; closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); // &gt;&gt; &#125;&#125; 主要看这两个方法：safeSetSuccess和safeSetFailure 1234567891011protected final void safeSetSuccess(ChannelPromise promise) &#123; if (!(promise instanceof VoidChannelPromise) &amp;&amp; !promise.trySuccess()) &#123; logger.warn(\"Failed to mark a promise as success because it is done already: &#123;&#125;\", promise); &#125;&#125;protected final void safeSetFailure(ChannelPromise promise, Throwable cause) &#123; if (!(promise instanceof VoidChannelPromise) &amp;&amp; !promise.tryFailure(cause)) &#123; logger.warn(\"Failed to mark a promise as failure because it's done already: &#123;&#125;\", promise, cause); &#125;&#125; trySuccess会通知所有的监听器，跟一下调用链： 123456789101112131415161718192021222324public boolean trySuccess(V result) &#123; return setSuccess0(result);&#125;private boolean setSuccess0(V result) &#123; return setValue0(result == null ? SUCCESS : result);&#125;private boolean setValue0(Object objResult) &#123; ... notifyListeners(); ...&#125;private void notifyListeners() &#123; ... notifyListenersNow(); ... safeExecute(executor, new Runnable() &#123; @Override public void run() &#123; notifyListenersNow(); &#125; &#125;); &#125;&#125; 在往下就是调用具体的监听器方法operationComplete(future) 此处需要注意的是，DefaultPromise中保存监听器的字段是private Object listeners，它是一个object引用，当我们之添加了一个监听器的时候，该引用是GenericFutureListener类型的，当大于一个监听器被添加到这个promise中，该引用就是DefaultFutureListeners类型了，此类型维护了一个监听器数组。这样处理的原因是为了性能考虑，因为大多数时候我们只会添加一个监听器。看一下add函数更一目了然· 123456789private void addListener0(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener) &#123; if (listeners == null) &#123; listeners = listener; &#125; else if (listeners instanceof DefaultFutureListeners) &#123; ((DefaultFutureListeners) listeners).add(listener); &#125; else &#123; listeners = new DefaultFutureListeners((GenericFutureListener&lt;?&gt;) listeners, listener); &#125;&#125; netty的异步响应处理的是多线程之间的任务，最终也没有超出虚拟机的层面，还有一种异步编程，节点与节点之间的异步响应，比如向消息中间件服务器发送异步消息 rocketMq的异步消息发送rocket mq 底层使用netty实现客户端与服务器之间的通信，使用rocketmq原生的api异步发送一条消息：消息msg发送出去之后立即返回，当服务器响应到达时，mq客户端会通过异步编程处理最终调用到SendCallback中的方法，消息发送成功调用onSuccess()，否则调用onException()。 12345678910producer.send(msg, new SendCallback() &#123; @Override public void onSuccess(SendResult sendResult) &#123; System.out.printf(\"%s%n\" ,sendResult); &#125; @Override public void onException(Throwable throwable) &#123; throwable.printStackTrace(); &#125; &#125;); 接下来我将跟一下源码，分析一下这里是怎么实现客户端与服务器之间的异步通信的； 123456//DefaultMQProducerpublic void send(Message msg, SendCallback sendCallback) throws MQClientException, RemotingException, InterruptedException &#123; msg.setTopic(withNamespace(msg.getTopic())); this.defaultMQProducerImpl.send(msg, sendCallback);&#125; 12345//DefaultMQProducerImplpublic void send(Message msg, SendCallback sendCallback) throws MQClientException, RemotingException, InterruptedException &#123; send(msg, sendCallback, this.defaultMQProducer.getSendMsgTimeout());&#125; 123456789101112131415161718192021222324252627282930313233343536373839//DefaultMQProducerImplpublic void send(final Message msg, final MessageQueue mq, final SendCallback sendCallback, final long timeout) throws MQClientException, RemotingException, InterruptedException &#123; final long beginStartTime = System.currentTimeMillis(); ExecutorService executor = this.getAsyncSenderExecutor(); try &#123; executor.submit(new Runnable() &#123; @Override public void run() &#123; try &#123; makeSureStateOK(); Validators.checkMessage(msg, defaultMQProducer); if (!msg.getTopic().equals(mq.getTopic())) &#123; throw new MQClientException(\"message's topic not equal mq's topic\", null); &#125; long costTime = System.currentTimeMillis() - beginStartTime; if (timeout &gt; costTime) &#123; try &#123; sendKernelImpl(msg, mq, CommunicationMode.ASYNC, sendCallback, null, timeout - costTime); &#125; catch (MQBrokerException e) &#123; throw new MQClientException(\"unknown exception\", e); &#125; &#125; else &#123; sendCallback.onException(new RemotingTooMuchRequestException(\"call timeout\")); &#125; &#125; catch (Exception e) &#123; sendCallback.onException(e); &#125; &#125; &#125;); &#125; catch (RejectedExecutionException e) &#123; throw new MQClientException(\"executor rejected \", e); &#125;&#125;","categories":[{"name":"I/O和网络编程","slug":"I-O和网络编程","permalink":"https://zzkenyon.github.io/categories/I-O和网络编程/"}],"tags":[{"name":"netty","slug":"netty","permalink":"https://zzkenyon.github.io/tags/netty/"}],"keywords":[{"name":"I/O和网络编程","slug":"I-O和网络编程","permalink":"https://zzkenyon.github.io/categories/I-O和网络编程/"}]},{"title":"netty源码分析之定时任务的的优化","slug":"nio-netty源码分析之定时任务的优化","date":"2019-10-31T16:00:00.000Z","updated":"2020-09-14T02:07:02.150Z","comments":true,"path":"2019/11/01/nio-netty源码分析之定时任务的优化/","link":"","permalink":"https://zzkenyon.github.io/2019/11/01/nio-netty源码分析之定时任务的优化/","excerpt":"","text":"1、时间计算上的优化ScheduledFutureTask使用一个成员变量deadlineNanos记录定时任务延迟执行的时间，所以延时时间是从创建任务开始计算的。 考虑以下两种情况： 第一次创建ScheduledFutureTask时，需要先将ScheduledFutureTask类加载到虚拟机中 所有定时任务执行完成之后，JVM内存中不再有ScheduledFutureTask对象引用，下一次full gc时，ScheduledFutureTask类的元信息也会被释放掉，只有再创建定时任务需要执行类加载流程 以上情况，导致在创建定时任务之前，会执行类加载，类加载阶段的耗时，会延长定时任务的期望执行等待时间。 为了解决以上问题，netty是这样做的，当ScheduledFutureTask类加载时，会用一个静态常量记录加载完成的时间，称为T0： 1private static final long START_TIME = System.nanoTime(); 提供一个静态方法 1234// 获取当前时间 和 ScheduledFutureTask 加载时间的 差值static long nanoTime() &#123; return System.nanoTime() - START_TIME;&#125; 所以，以nanoTime()返回的时间戳作为定时任务计时起点，能够有效的排除不确定的类加载导致的定时延长问题。 2、外部提交定时任务方式优化在分析定时任务源码的时候，发现一个有意思的地方，外部线程向reactor线程提交一个定时任务。 虽然这类场景很少见，但是netty作为一个无比健壮的高性能io框架，必须要考虑到这种情况。 对此，新老版本的netty的处理方式是不同的： 在Netty-4.1.6.Final中，如果是在外部线程调用schedule，netty将添加定时任务的逻辑封装成一个普通的task，这个task的任务是添加[添加定时任务]的任务，而不是添加定时任务，其实也就是第二种场景，这样，对 PriorityQueue的访问就变成单线程，即只有reactor线程 1234567891011121314&lt;V&gt; ScheduledFuture&lt;V&gt; schedule(final ScheduledFutureTask&lt;V&gt; task) &#123; if (inEventLoop()) &#123; scheduledTaskQueue().add(task); &#125; else &#123; // 进入到场景二，进一步封装任务 execute(new Runnable() &#123; @Override public void run() &#123; scheduledTaskQueue().add(task); &#125; &#125;); &#125; return task;&#125; 而在4.1.50.Final版本中，并没有将外部线程提交的定时任务添加到定时任务队列中，而是直接添加到了普通队列中，并添加了一些线程控制 12345678910111213141516171819private &lt;V&gt; ScheduledFuture&lt;V&gt; schedule(final ScheduledFutureTask&lt;V&gt; task) &#123; if (inEventLoop()) &#123; scheduleFromEventLoop(task); // 如果在线程内，添加到定时队列 &#125; else &#123; // 否则 final long deadlineNanos = task.deadlineNanos(); // 在提交之前进行一次判断 deadlineNanos &lt; nextWakeUpNanos if (beforeScheduledTaskSubmitted(deadlineNanos)) &#123; execute(task); &#125; else &#123; lazyExecute(task); // 提交完成之后再一次进行判断， deadlineNanos &lt; nextWakeUpNanos if (beforeScheduledTaskSubmitted(deadlineNanos)) &#123; if (afterScheduledTaskSubmitted(deadlineNanos)) &#123; execute(WAKEUP_TASK); // 执行唤醒线程的任务 &#125; &#125; &#125; return task;&#125; 两者的不同之处在对else分支的处理上 第一种方式，提交一个 提交定时任务任务，这种方式貌似很有设计感，却经不起推敲。 因为提交定时任务的任务并不是立即执行的，这段代码可能本身就在任务队列中一个任务的执行流程中。 并且，netty每次执行任务 默认的最小数量是64个，见之前的分析文章。 所以，通过这种方式提交的定时任务，定时时间多多少少会被延长，也就是说所有通过这种方式提交的定时任务都不会在期望的时间内执行，而是会比期望的执行点延后执行。 所以在新版本中，为了修复以上的bug，在提交任务的时候会先比较 定时任务的剩余时间 和 下一次唤醒select()剩余时间： 对于定时时间很短的任务，在提交前 deadlineNanos &lt; nextWakeUpNanos 那么直接将任务添加到任务队列中，并立即唤醒select，使reactor线程执行队列任务 123456@Overrideprotected void wakeup(boolean inEventLoop) &#123; if (!inEventLoop &amp;&amp; nextWakeupNanos.getAndSet(AWAKE) != AWAKE) &#123; selector.wakeup(); &#125;&#125; 对于提交前 deadlineNanos &gt; nextWakeUpNanos 的任务，依然会提交到任务队列，但不会执行唤醒select操作。 对于第二种情况，提交完成之后，会再一次判断，因为此时nextWakeUpNanos可能会发生改变（nextWakeUpNanos是reactor线程的变量，并且此代码是在外部线程运行，此时reactor线程可能正要开始新一轮的轮询，nextWakeUpNanos会重新设置，因此需要再次判断），如果此时deadlineNanos &lt; nextWakeUpNanos成立，则提交一个空任务WAKEUP_TASK给任务队列，该任务的存在会让reactor线程在下一轮轮询无法正常开始，因为轮询之前需要判断 123if (!hasTasks()) &#123; // 没有待执行的任务，才能开始轮询 strategy = select(curDeadlineNanos);&#125; 之前的困惑：为什么提交到taskQueue还是能够定时执行？ 因为提交的是一个ScheduledFutrueTask，这种task执行时，会根据deadLineNanos进行判断，如果没到时间直接不做运行直接返回。 12345678910111213141516171819202122232425262728293031323334353637public void run() &#123; assert executor().inEventLoop(); try &#123; if (delayNanos() &gt; 0L) &#123; //delayNanos() 返回当前任务剩余等待时间 // 大于0表示还没到期 if (isCancelled()) &#123; scheduledExecutor().scheduledTaskQueue().removeTyped(this); &#125; else &#123; scheduledExecutor().scheduleFromEventLoop(this); &#125; return; // 不做运行直接返回 &#125; if (periodNanos == 0) &#123; //periodNanos=0 表示只执行一次 if (setUncancellableInternal()) &#123; V result = runTask(); setSuccessInternal(result); &#125; &#125; else &#123; // check if is done as it may was cancelled if (!isCancelled()) &#123; runTask(); if (!executor().isShutdown()) &#123; if (periodNanos &gt; 0) &#123; deadlineNanos += periodNanos; &#125; else &#123; deadlineNanos = nanoTime() - periodNanos; &#125; if (!isCancelled()) &#123; // 添加回定时队列 scheduledExecutor().scheduledTaskQueue().add(this); &#125; &#125; &#125; &#125; &#125; catch (Throwable cause) &#123; setFailureInternal(cause); &#125;&#125; periodNanos： 0 表示不重复执行 正数 表示每隔 periodNanos 执行1一次 负数 表示执行完之后间隔 periodNanos 再执行","categories":[{"name":"I/O和网络编程","slug":"I-O和网络编程","permalink":"https://zzkenyon.github.io/categories/I-O和网络编程/"}],"tags":[{"name":"netty","slug":"netty","permalink":"https://zzkenyon.github.io/tags/netty/"}],"keywords":[{"name":"I/O和网络编程","slug":"I-O和网络编程","permalink":"https://zzkenyon.github.io/categories/I-O和网络编程/"}]},{"title":"netty源码分析之线程模型","slug":"nio-netty源码分析之线程模型","date":"2019-10-31T16:00:00.000Z","updated":"2020-09-14T02:07:07.926Z","comments":true,"path":"2019/11/01/nio-netty源码分析之线程模型/","link":"","permalink":"https://zzkenyon.github.io/2019/11/01/nio-netty源码分析之线程模型/","excerpt":"","text":"一个NioEventLoop对应于Reactor模型中的一个从Reactor线程，它持有一个Thread引用，可以简单将NioEventLoop理解为一个用于处理channel事件的线程。 一个channel上的事件只能被同一个线程处理，NioEventLoop线程对channel事件的处理是一个串行化无锁执行过程，netty在初始化channel的时候在pipeline中添加了一系列用户指定的Handler（通过childHanler()方法），这些Handler的处理需要遵循一个固定的顺序，netty底层使用同一个线程按照这个顺序串行执行，避免了多线程处理同一个channel需要使用锁同步产生的开销，这叫串行化无锁编程 一个NioEventLoop可以处理多个channel的就绪事件，即同一个nio线程可以处理多条连接的请求，这叫多路复用 1、Channel指定evenloopChannel的EventLoop是在注册的时候指定的，netty服务器启动时，首先会注册一个ServerChannel，该注册工作由Boss线程池完成，通常Boss线程池中只有一个线程。 123456// AbstractBootstrapfinal ChannelFuture initAndRegister() &#123; ... ChannelFuture regFuture = config().group().register(channel); ...&#125; group().register(channel)在boss线程池中注册Channel，boss线程池调用next()方法获取一个EventLoop对象来注册channel，看下面代码： 1234// MultithreadEventLoopGrouppublic ChannelFuture register(Channel channel) &#123; return next().register(channel);&#125; next方法获取到一个EventLoop对象之后，再调用SingleThreadEventLoop类的注册方法： 123456// SingleThreadEventLooppublic ChannelFuture register(final ChannelPromise promise) &#123; ObjectUtil.checkNotNull(promise, \"promise\"); promise.channel().unsafe().register(this, promise); return promise;&#125; 最终会调用channel的unsafe对象完成注册，并在此时将this EventLoop 作为参数传进去 123456// AbstractChannel.AbstractUnsafepublic final void register(EventLoop eventLoop, final ChannelPromise promise) &#123; ... AbstractChannel.this.eventLoop = eventLoop; ...&#125; 注册的时候完成了eventLoop的指定。 总结一下： 以上分析的是ServerChannel注册时指定EventLoop的过程，这个过程只会在服务启动的时候进行，而在服务运行期间，会不断的有新连接接入，每个新连接都需要注册到一个selector上，这是nio编程的规则。 所以服务启动程序创建的childGroup中的每个线程都持有一个selector的，新连接的注册过程，就是从childGroup中选取一个EventLoop对象，然后将新连接channel注册到该线程对象的selector上，再指定新连接channel的EventLoop为当前选取的的实例。 2、reactor线程启动https://www.jianshu.com/p/0d0eece6d467 netty对于线程的创建采取的懒加载模式，第一次提交任务的时候才会创建线程。 NioServerSocketChannel 第一次提交任务，就是在注册的时候 1234567891011121314151617//AbstractChannel.AbstractUnsafepublic final void register(EventLoop eventLoop, final ChannelPromise promise) &#123; ... AbstractChannel.this.eventLoop = eventLoop; // 刚指定了channel的eventLoop if (eventLoop.inEventLoop()) &#123; // 还是主线程在执行，返回false register0(promise); &#125; else &#123; try &#123;//来到这里提交注册任务 eventLoop.execute(new Runnable() &#123; @Override public void run() &#123; register0(promise); &#125; &#125;); &#125; catch (Throwable t) &#123;&#125; &#125;&#125; eventLoop.execute()可以向NioEventLoop中提交一个任务，这个方法继承自父类SingleThreadEventExecutor 1234567891011121314// SingleThreadEventExecutor private void execute(Runnable task, boolean immediate) &#123; // 判断当前线程是不是this对象的线程 // 还是主线程在执行，返回false boolean inEventLoop = inEventLoop(); //将task加入EventLoop持有的任务队列 addTask(task); if (!inEventLoop) &#123; //如果执行此代码的线程不是eventloop线程，创建新线程并启动 startThread(); ... &#125; ...&#125; 跟进startThread()方法 123456789101112131415161718192021222324// SingleThreadEventExecutor private void startThread() &#123; if (state == ST_NOT_STARTED) &#123; if (STATE_UPDATER.compareAndSet(this, ST_NOT_STARTED, ST_STARTED)) &#123; boolean success = false; try &#123; doStartThread(); // &gt;&gt; ...&#125;private void doStartThread() &#123; ... // 创建新线程 executor.execute(new Runnable() &#123; @Override public void run() &#123; // 设置eventLoop持有线程为执行这段代码的线程 thread = Thread.currentThread(); ... SingleThreadEventExecutor.this.run(); ... &#125; &#125;&#125; 再调用了doStartThread方法，这个方法是启动线程的核心逻辑了，在执行doStartThread的时候，会调用eventLoop内部的一个用于新建线程的执行器execute()方法，注意与上面的区别，此执行器默认为ThreadPerTaskExecutor类型，创建新线程后将NioEventLoop的主体逻辑run()提交进去，并启动。 ThreadPerTaskExecutor 在每次执行execute() 方法的时候都会通过DefaultThreadFactory创建一个FastThreadLocalThread线程，而这个线程就是netty中的reactor线程实体，创建线程源码如下： 12345678910public final class ThreadPerTaskExecutor implements Executor &#123; private final ThreadFactory threadFactory; public ThreadPerTaskExecutor(ThreadFactory threadFactory) &#123; this.threadFactory = ObjectUtil.checkNotNull(threadFactory, \"threadFactory\"); &#125; @Override public void execute(Runnable command) &#123; threadFactory.newThread(command).start(); &#125;&#125; 总结一下： 我们在new一个NioEventLoopGroup的时候，它会持有一个NioEventLoop数组，数组中每个NioEventLoop元素对象会持有一个Thread引用，就是reactor线程本体了。 netty对于线程的初始化采取的懒加载模式，当我们没有用到某个NioEventLoop时，它的线程是不会被创建出来的。 当我们通过group().next()获取到一个NioEventLoop，并向其提交任务，这时就会触发线程的创建-任务提交-启动。创建是通过 ThreadPerTaskExecutor 和 DefaultThreadFactory 两个类执行的，新线程执行的任务是 NioEventLoop 的主体逻辑run方法。 3、reactor线程执行https://www.jianshu.com/p/467a9b41833e 回到主线逻辑中，创建的线程中执行了SingleThreadEventExecutor.this.run();即reactor线程的主体逻辑，贴一下主要代码片段 1234567891011protected void run() &#123; for (;;) &#123; ... strategy = select(curDeadlineNanos); ... processSelectedKeys(); ... ranTasks = runAllTasks(0); ... &#125;&#125; 此方法内部是一个无限循环，一旦启动将一直运行。 从以上代码中可以看出，线程一直在循环做三件事情 执行select 处理就绪的channel 执行任务队列中的任务 此处的源代码很长，下面我将分三个步骤分析run函数的主要流程 3.1 select阶段12345678910111213141516171819202122232425262728293031323334353637383940414243// protected void run() &#123; int selectCnt = 0; for (;;) &#123; try &#123; int strategy; try &#123; strategy = selectStrategy.calculateStrategy(selectNowSupplier, hasTasks()); switch (strategy) &#123; // hasTask 时continue case SelectStrategy.CONTINUE: continue; // 由于NIO不支持忙碌等待，因此要选择跳过 case SelectStrategy.BUSY_WAIT: // 当没有可调度任务时 strategy = SelectStrategy.SELECT case SelectStrategy.SELECT: // 获取现在到下一个计划任务调度执行之间的时间，没有定时任务返回-1 long curDeadlineNanos = nextScheduledTaskDeadlineNanos(); if (curDeadlineNanos == -1L) &#123; //NONE 是Integer.maxValue curDeadlineNanos = NONE; &#125; // 设定原子量 nextWakeupNanos.set(curDeadlineNanos); try &#123; if (!hasTasks()) &#123; strategy = select(curDeadlineNanos); &#125; &#125; finally &#123; ... &#125; // fall through default: &#125; &#125; catch (IOException e) &#123; ... &#125; // select计数器+1 selectCnt++; ... &#125;catch(Exception e)&#123; &#125; &#125;&#125; 首先看strategy = selectStrategy.calculateStrategy(selectNowSupplier, hasTasks());这句，netty会根据任务队列的情况执行相应的select操作： 1234// DefaultSelectStrategypublic int calculateStrategy(IntSupplier selectSupplier, boolean hasTasks) throws Exception &#123; return hasTasks ? selectSupplier.get() : SelectStrategy.SELECT;&#125; 当hasTasks()返回true表明当前的任务队列中有需要执行的任务，会执行selectSupplier.get()，那么selectSupplier是什么呢？定位到该成员变量的初始化代码： 12345678910// NioEventLoopprivate final IntSupplier selectNowSupplier = new IntSupplier() &#123; @Override public int get() throws Exception &#123; return selectNow(); &#125;&#125;;int selectNow() throws IOException &#123; return selector.selectNow();&#125; 看到这里我就可以得出结论了，strategy的初始化逻辑是：当任务队列hasTasks时selectNow，返回就绪数量，否则返回SelectStrategy.SELECT。 当strategy=SelectStrategy.SELECT时，获取现在到下一个计划任务调度执行之间的时间curDeadlineNanos，在这段时间内执行strategy=select(curDeadlineNanos) 当strategy为正数，说明select到了就绪事件，此时将继续往下执行，进入处理阶段。 思考：SelectStrategy.CONTINUE是哪种情况时设置的? 3.2 处理阶段ioRatio 时间控制netty通过一个int型参数ioRatio来控制io与cpu的耗时比例，ioRatio默认的初始值为50，即io和cpu计算各占50% 12345678910111213141516171819202122232425262728cancelledKeys = 0; //needsToSelectAgain = false;// io时间所占比例，初始值为50final int ioRatio = this.ioRatio;boolean ranTasks; // 记录runAllTasks返回值，表示runAllTasks执行时间有没有超出参数指定的时间，是返回trueif (ioRatio == 100) &#123; try &#123; if (strategy &gt; 0) &#123; // 就绪数量大于0，处理selectedKeys，这里的处理属于io处理 processSelectedKeys(); &#125; &#125; finally &#123; // io时间占比达到100% 将一直执行runAllTasks 这里的处理属于cpu处理 // runAllTasks没有指定时间参数，当且仅当最后一个任务被执行之后 返回 true ranTasks = runAllTasks(); &#125;&#125; else if (strategy &gt; 0) &#123; // 说明有通道就绪 final long ioStartTime = System.nanoTime(); try &#123; processSelectedKeys(); &#125; finally &#123; final long ioTime = System.nanoTime() - ioStartTime; // 由于ioRatio = 50 所以运行runAllTasks时间与上面处理io时间一致 ranTasks = runAllTasks(ioTime * (100 - ioRatio) / ioRatio); &#125;&#125; else &#123; ranTasks = runAllTasks(0); // This will run the minimum number of tasks&#125; 如果ioRatio等于100，那么优先处理io事件，处理完就绪通道，再执行队列任务，一次全部执行完。 如果ioRatio不等于100， 若有就绪通道，那么在处理通道io事件时，会记录用时，完了之后再使用同样的时间去执行队列任务 若没有就绪通道，则执行最小数量（不一定是1个，后面分析）的队列任务 就绪通道处理不仅仅是对执行时间进行了细粒度的优化，在处理过程中也是尽可能的考虑到了执行效率，继续往下分析处理，也就是processSelectedKeys()方法，贴上代码： 12345678910111213//NioEventLoopprivate void processSelectedKeys() &#123; //这里做的优化，主要是使用netty 自定义的selectedKeys对象 通过反射的方式替换掉jdk原生selector中的 selectedKeySet字段属性 // 自定义的keyset 使用数组存放selectedKeys，原生的使用HashSet，主要优化的是检索性能 // 替换过程 见本类的openSelector方法 if (selectedKeys != null) &#123; // 优化过的处理 一般会进这里 processSelectedKeysOptimized(); &#125; else &#123; // 正常处理 processSelectedKeysPlain(selector.selectedKeys()); &#125;&#125; selectedKeys优化我们对优化过的selectedKeys的处理稍微展开一下，看看netty是如何优化的，我们查看 selectedKeys 被引用过的地方，有如下代码 123456789101112131415161718192021222324252627282930private SelectorTuple openSelector() &#123; ... final SelectedSelectionKeySet selectedKeySet = new SelectedSelectionKeySet(); Object maybeException = AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; @Override public Object run() &#123; try &#123; Field selectedKeysField = selectorImplClass.getDeclaredField(\"selectedKeys\"); Field publicSelectedKeysField = selectorImplClass.getDeclaredField(\"publicSelectedKeys\"); ... Throwable cause = ReflectionUtil.trySetAccessible(selectedKeysField, true); if (cause != null) &#123; return cause; &#125; cause = ReflectionUtil.trySetAccessible(publicSelectedKeysField, true); if (cause != null) &#123; return cause; &#125; selectedKeysField.set(unwrappedSelector, selectedKeySet); publicSelectedKeysField.set(unwrappedSelector, selectedKeySet); return null; &#125; ... &#125; &#125;); ... selectedKeys = selectedKeySet; ...&#125; 首先，selectedKeys是一个 SelectedSelectionKeySet 类对象，在NioEventLoop 的 openSelector 方法中创建，之后就通过反射将selectedKeys与 sun.nio.ch.SelectorImpl 中的两个field绑定 sun.nio.ch.SelectorImpl 中我们可以看到，这两个field其实是两个HashSet 12345678910111213abstract class SelectorImpl extends AbstractSelector&#123; // Public views of the key sets private final Set&lt;SelectionKey&gt; publicKeys; // Immutable private final Set&lt;SelectionKey&gt; publicSelectedKeys; // Removal allowed, but not addition protected SelectorImpl(SelectorProvider sp) &#123; super(sp); keys = ConcurrentHashMap.newKeySet(); selectedKeys = new HashSet&lt;&gt;(); publicKeys = Collections.unmodifiableSet(keys); publicSelectedKeys = Util.ungrowableSet(selectedKeys); &#125;&#125; selector在调用select()族方法的时候，如果有IO事件发生，就会往里面的两个field中塞相应的selectionKey(具体怎么塞有待研究)，即相当于往一个hashSet中add元素，既然netty通过反射将jdk中的两个field替换掉，那我们就应该意识到是不是netty自定义的SelectedSelectionKeySet在add方法做了某些优化呢？ 带着这个疑问，我们进入到 SelectedSelectionKeySet 类中探个究竟 12345678910111213141516171819final class SelectedSelectionKeySet extends AbstractSet&lt;SelectionKey&gt; &#123; SelectionKey[] keys; int size; SelectedSelectionKeySet() &#123; keys = new SelectionKey[1024]; &#125; @Override public boolean add(SelectionKey o) &#123; if (o == null) &#123; return false; &#125; keys[size++] = o; if (size == keys.length) &#123; increaseCapacity(); &#125; return true; &#125; ...&#125; 该类其实很简单，继承了 AbstractSet，说明该类可以当作一个set来用，但是底层使用一个数据来存放selectedKey，在add方法中经历下面三个步骤 将SelectionKey塞到该数组的逻辑尾部 更新该数组的逻辑长度+1 如果该数组的逻辑长度等于数组的物理长度，就将该数组扩容 我们可以看到，待程序跑过一段时间，等数组的长度足够长，每次在轮询到nio事件的时候，netty只需要O(1)的时间复杂度就能将 SelectionKey 塞到 set中去，而jdk底层使用的hashSet需要O(lgn)的时间复杂度 执行就绪事件关于netty对SelectionKeySet的优化我们暂时就跟这么多，下面我们继续跟netty对IO事件的处理，转到processSelectedKeysOptimized方法： 12345678910111213141516171819202122232425private void processSelectedKeysOptimized() &#123; for (int i = 0; i &lt; selectedKeys.size; ++i) &#123; final SelectionKey k = selectedKeys.keys[i]; // 手动置空 gc selectedKeys.keys[i] = null; // SelectionKey中附件了channel的引用 final Object a = k.attachment(); if (a instanceof AbstractNioChannel) &#123; processSelectedKey(k, (AbstractNioChannel) a); &#125; else &#123; @SuppressWarnings(\"unchecked\") NioTask&lt;SelectableChannel&gt; task = (NioTask&lt;SelectableChannel&gt;) a; processSelectedKey(k, task); // &gt;&gt; &#125; // needsToSelectAgain 默认为false 在本类的cancel方法中，当连接取消次数达到256 被设置为true // cancel方法 最终是在 AbstractNioChannel 类的 doDeregister 方法中被调用，调用一次取消连接数+1 if (needsToSelectAgain) &#123; // reset将selectedKeys中未处理的所有key手动置空 selectedKeys.reset(i + 1); //重新select selectAgain(); i = -1; &#125; &#125;&#125; 该方法有两个关键内容 processSelectedKey() 方法，就绪事件处理的核心逻辑 needsToSelectAgain 参数，判断是否该再来次轮询 processSelectedKey：逻辑很简单，获取就绪通道的监听事件，根据不同的事件分别进行处理 123456789101112131415161718192021222324252627282930private void processSelectedKey(SelectionKey k, AbstractNioChannel ch) &#123; final AbstractNioChannel.NioUnsafe unsafe = ch.unsafe(); if (!k.isValid()) &#123; ... return; &#125; try &#123; int readyOps = k.readyOps(); if ((readyOps &amp; SelectionKey.OP_CONNECT) != 0) &#123; // 表示监听了连接事件 int ops = k.interestOps(); // 连接就绪是所有就绪选择中最简单的，对它的处理也很简单。 // 当客户端调用connect()并注册OP_CONNECT事件后，连接操作就会就绪。 // 因此该事件只可能出现在客户端程序 ops &amp;= ~SelectionKey.OP_CONNECT; k.interestOps(ops); unsafe.finishConnect(); &#125; if ((readyOps &amp; SelectionKey.OP_WRITE) != 0) ch.unsafe().forceFlush(); &#125; if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) &#123; // 注意：所有通道注册的时候都没有第一时间指定监听事件，而ops==0 时，这里默认是监听读就绪事件 // NioServerSocketChannel 中创建的是NioMessageUnSafe实例 ，处理OP_ACCEPT // NioSocketChannel 中创建的是NioByteUnSafe实例 ， 处理 OP_READ unsafe.read(); &#125; &#125; catch (CancelledKeyException ignored) &#123; unsafe.close(unsafe.voidPromise()); &#125;&#125; needsToSelectAgain及重轮询123456789// needsToSelectAgain 默认为false 在本类的cancel方法中，当连接取消次数达到256 被设置为true// cancel方法 最终是在 AbstractNioChannel 类的 doDeregister 方法中被调用，调用一次取消连接数+1if (needsToSelectAgain) &#123; // reset将selectedKeys中未处理的所有key手动置空 selectedKeys.reset(i + 1); //重新select selectAgain(); i = -1;&#125; 回忆上面run函数的代码，这个参数在每一次轮询结束后都会被置为false，那么上面时候会置为true，从而执行在一次轮询呢？ 通过检索，找到这样一个方法： 123456789// NioEventLoopvoid cancel(SelectionKey key) &#123; key.cancel(); cancelledKeys ++; if (cancelledKeys &gt;= CLEANUP_INTERVAL) &#123; cancelledKeys = 0; needsToSelectAgain = true; &#125;&#125; 还需要继续找出调用cancel函数的地方，使用IDEA的find usages 1234//AbstractNioChannelprotected void doDeregister() throws Exception &#123; eventLoop().cancel(selectionKey());&#125; 不难看出，在channel从selector上移除的时候，调用cancel函数将key取消，并且当被去掉的key到达 CLEANUP_INTERVAL 的时候，设置needsToSelectAgain为true,CLEANUP_INTERVAL默认值为256 也就是说，对于每个NioEventLoop而言，每隔256个channel从selector上移除的时候，就标记 needsToSelectAgain 为true，我们还是跳回到上面这段代码 每满256次，就会进入到if的代码块，首先，将selectedKeys的内部数组全部清空，方便被jvm垃圾回收，然后重新调用selectAgain重新填装一下 selectionKey 12345678private void selectAgain() &#123; needsToSelectAgain = false; try &#123; selector.selectNow(); &#125; catch (Throwable t) &#123; logger.warn(\"Failed to update SelectionKeys.\", t); &#125;&#125; netty这么做的目的应该是每隔256次channel断线，重新清理一下selectionKey，保证现存的SelectionKey及时有效 4 执行队列任务https://www.jianshu.com/p/58fad8e42379 4.1 netty任务netty中的task的常见使用场景： 非当前reactor线程调用channel的各种方法 已经分析过的服务启动过程中，主通道的注册、新连接接入时子通道的注册就是提交任务完成的，因为彼时运行的线程是main线程和主线程。 此外，这种情况在push系统中比较常见，一般在业务线程里面，根据用户的标识，找到对应的channel引用，然后调用write类方法向该用户推送消息，就会进入到这种场景 12// non reactor threadchannel.write(...) 关于channel.write()类方法的调用链，后面会单独拉出一篇文章来深入剖析，这里，我们只需要知道，最终write方法串至以下方法 12345678910111213141516171819private void write(Object msg, boolean flush, ChannelPromise promise) &#123; // ... EventExecutor executor = next.executor(); if (executor.inEventLoop()) &#123; if (flush) &#123; next.invokeWriteAndFlush(m, promise); &#125; else &#123; next.invokeWrite(m, promise); &#125; &#125; else &#123; AbstractWriteTask task; if (flush) &#123; task = WriteAndFlushTask.newInstance(next, m, promise); &#125; else &#123; task = WriteTask.newInstance(next, m, promise); &#125; safeExecute(executor, task, promise, m); &#125;&#125; 外部线程在调用write的时候，executor.inEventLoop()会返回false，直接进入到else分支，将write封装成一个WriteTask（这里仅仅是write而没有flush，因此flush参数为false）, 然后调用 safeExecute方法 12345private static void safeExecute(EventExecutor executor, Runnable runnable, ChannelPromise promise, Object msg) &#123; // ... executor.execute(runnable); // ...&#125; 接下来的调用链就进入到第一种场景了，但是和第一种场景有个明显的区别就是，第一种场景的调用链的发起线程是reactor线程，第二种场景的调用链的发起线程是用户线程，用户线程可能会有很多个，显然多个线程并发写taskQueue可能出现线程同步问题，此时阻塞队列的作用展现出来了。 用户自定义普通任务 推荐使用的方法。 123456ctx.channel().eventLoop().execute(new Runnable() &#123; @Override public void run() &#123; //... &#125;&#125;); 如果在业务处理的代码中，即业务处理Handler中，没有使用这种提交任务的方式，那么业务处理逻辑就会被当成IO阶段的一部分直接执行，占用IO时间。如果连接数大，会影响系统的吞吐量，推荐使用任务提交的方式处理业务请求。 我们跟进execute方法，看重点 123456@Override// NioEventLooppublic void execute(Runnable task) &#123; //... addTask(task); //...&#125; execute方法调用 addTask方法 1234567// NioEventLoopprotected void addTask(Runnable task) &#123; // ... if (!offerTask(task)) &#123; reject(task); &#125;&#125; 然后调用offerTask方法，如果offer失败，那就调用reject方法，通过默认的 RejectedExecutionHandler 直接抛出异常 12345// NioEventLoopfinal boolean offerTask(Runnable task) &#123; // ... return taskQueue.offer(task);&#125; 跟到offerTask方法，基本上task就落地了，netty内部使用一个taskQueue将task保存起来，那么这个taskQueue又是何方神圣？ 我们查看 taskQueue 定义的地方和被初始化的地方 123456789// NioEventLoopprivate final Queue&lt;Runnable&gt; taskQueue;taskQueue = newTaskQueue(this.maxPendingTasks);@Overrideprotected Queue&lt;Runnable&gt; newTaskQueue(int maxPendingTasks) &#123; return new LinkedBlockingQueue&lt;Runnable&gt;(maxPendingTasks);&#125; 我们发现 taskQueue在NioEventLoop中默认是阻塞队列，老版本（4.1.6）中使用mpsc队列，即多生产者单消费者队列，netty使用mpsc，方便的将外部线程的task聚集，在reactor线程内部用单线程来串行执行，此处为什么要做此改变？ 在本节讨论的任务场景中，所有代码的执行都是在reactor线程中的，所以，所有调用 inEventLoop() 的地方都返回true，既然都是在reactor线程中执行，那么其实这里的阻塞队列其实没有发挥真正的作用。 用户自定义定时任务 123456ctx.channel().eventLoop().schedule(new Runnable() &#123; @Override public void run() &#123; &#125;&#125;, 60, TimeUnit.SECONDS); 第三种场景就是定时任务逻辑了，用的最多的便是如上方法：在一定时间之后执行任务 我们跟进schedule方法 12345public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit) &#123;//... return schedule(new ScheduledFutureTask&lt;Void&gt;( this, command, null, ScheduledFutureTask.deadlineNanos(unit.toNanos(delay))));&#125; 通过 ScheduledFutureTask, 将用户自定义任务再次包装成一个netty内部的任务 123456&lt;V&gt; ScheduledFuture&lt;V&gt; schedule(final ScheduledFutureTask&lt;V&gt; task) &#123; // ... scheduledTaskQueue().add(task); // ... return task;&#125; 到了这里，我们有点似曾相识，在非定时任务的处理中，netty通过一个阻塞队列将任务落地，这里，是否也有一个类似的队列来承载这类定时任务呢？带着这个疑问，我们继续向前 12345678910//Queue&lt;ScheduledFutureTask&lt;?&gt;&gt; scheduledTaskQueue() &#123; if (scheduledTaskQueue == null) &#123; scheduledTaskQueue = new DefaultPriorityQueue&lt;ScheduledFutureTask&lt;?&gt;&gt;( SCHEDULED_FUTURE_TASK_COMPARATOR, // Use same initial capacity as java.util.PriorityQueue 11); &#125; return scheduledTaskQueue;&#125; 果不其然，scheduledTaskQueue() 方法，会返回一个优先级队列，然后调用 add 方法将定时任务加入到队列中去，但是，这里为什么要使用优先级队列，而不需要考虑多线程的并发？ 因为我们现在讨论的场景，调用链的发起方是reactor线程，不会存在多线程并发这些问题 但是，万一有的用户在reactor之外执行定时任务呢？虽然这类场景很少见，但是netty作为一个无比健壮的高性能io框架，必须要考虑到这种情况。 对此，新老版本的netty的处理方式是不同的： 在Netty-4.1.6.Final中，如果是在外部线程调用schedule，netty将添加定时任务的逻辑封装成一个普通的task，这个task的任务是添加[添加定时任务]的任务，而不是添加定时任务，其实也就是第二种场景，这样，对 PriorityQueue的访问就变成单线程，即只有reactor线程 1234567891011121314&lt;V&gt; ScheduledFuture&lt;V&gt; schedule(final ScheduledFutureTask&lt;V&gt; task) &#123; if (inEventLoop()) &#123; scheduledTaskQueue().add(task); &#125; else &#123; // 进入到场景二，进一步封装任务 execute(new Runnable() &#123; @Override public void run() &#123; scheduledTaskQueue().add(task); &#125; &#125;); &#125; return task;&#125; 而在4.1.50.Final版本中，并没有将外部线程提交的定时任务添加到定时任务队列中，而是直接添加到了普通队列中，并添加了一些线程控制 12345678910111213141516171819private &lt;V&gt; ScheduledFuture&lt;V&gt; schedule(final ScheduledFutureTask&lt;V&gt; task) &#123; if (inEventLoop()) &#123; scheduleFromEventLoop(task); // 如果在线程内，添加到定时队列 &#125; else &#123; // 否则 final long deadlineNanos = task.deadlineNanos(); // 在提交之前进行一次判断 deadlineNanos 是否 小于 当前距离线程下一次被唤醒的nanos if (beforeScheduledTaskSubmitted(deadlineNanos)) &#123; execute(task); // &gt;&gt; 这里需要跟进去 &#125; else &#123; lazyExecute(task); // 提交完成之后再一次进行判断， deadlineNanos是否 小于 当前距离线程下一次被唤醒的nanos if (afterScheduledTaskSubmitted(deadlineNanos)) &#123; execute(WAKEUP_TASK); // 执行唤醒线程的任务 &#125; &#125; &#125; return task;&#125; 跟进execute(task)方法 1234public void execute(Runnable task) &#123; ObjectUtil.checkNotNull(task, \"task\"); execute(task, !(task instanceof LazyRunnable) &amp;&amp; wakesUpForTask(task));&#125; task是ScheduledFutureTask类型，task instanceof LazyRunnable为false，wakesUpForTask(task)返回true，所以这里会调用execute(task,true) 12345678910private void execute(Runnable task, boolean immediate) &#123; boolean inEventLoop = inEventLoop(); //将task加入任务队列 taskQueue 中 addTask(task); ... // addTaskWakesUp 一般默认为false if (!addTaskWakesUp &amp;&amp; immediate) &#123; wakeup(inEventLoop); &#125;&#125; 传入的参数immediate表示是否立即唤醒select()来执行任务，所以此时会执行wakeup(inEventLoop)方法， 123456// NioEventLoopprotected void wakeup(boolean inEventLoop) &#123; if (!inEventLoop &amp;&amp; nextWakeupNanos.getAndSet(AWAKE) != AWAKE) &#123; selector.wakeup(); &#125;&#125; 那么再看lazyExecute(task) 123public void lazyExecute(Runnable task) &#123; execute(ObjectUtil.checkNotNull(task, \"task\"), false);&#125; 指定参数immediate为false，表示任务添加之后不会立即唤醒线程。所以在任务提交完成之后，会再一次进行判断 deadlineNanos是否 小于 当前距离线程下一次被唤醒的nanos，如果是则执行唤醒线程的任务（那个空任务） 总结： 下面继续分析： 为什么定时任务要保存在优先级队列中，我们可以先不看源码，来思考一下优先级对列的特性 优先级队列按一定的顺序来排列内部元素，内部元素必须是可以比较的，联系到这里每个元素都是定时任务，那就说明定时任务是可以比较的，那么到底有哪些地方可以比较？ 每个任务都有一个下一次执行的截止时间，截止时间是可以比较的，截止时间相同的情况下，任务添加的顺序也是可以比较的，就像这样，阅读源码的过程中，一定要多和自己对话，多问几个为什么 带着猜想，我们研究与一下ScheduledFutureTask，抽取出关键部分 123456789101112131415161718192021final class ScheduledFutureTask&lt;V&gt; extends PromiseTask&lt;V&gt; implements ScheduledFuture&lt;V&gt; &#123; private static final AtomicLong nextTaskId = new AtomicLong(); private static final long START_TIME = System.nanoTime(); static long nanoTime() &#123; return System.nanoTime() - START_TIME; &#125; private final long id = nextTaskId.getAndIncrement(); /* 0 - no repeat, &gt;0 - repeat at fixed rate, &lt;0 - repeat with fixed delay */ private final long periodNanos; @Override public int compareTo(Delayed o) &#123; //... &#125; // 精简过的代码 @Override public void run() &#123; &#125; 这里，我们一眼就找到了compareTo 方法，cmd+u跳转到实现的接口，发现就是Comparable接口 12345678910111213141516171819public int compareTo(Delayed o) &#123; if (this == o) &#123; return 0; &#125; ScheduledFutureTask&lt;?&gt; that = (ScheduledFutureTask&lt;?&gt;) o; long d = deadlineNanos() - that.deadlineNanos(); if (d &lt; 0) &#123; return -1; &#125; else if (d &gt; 0) &#123; return 1; &#125; else if (id &lt; that.id) &#123; return -1; &#125; else if (id == that.id) &#123; throw new Error(); &#125; else &#123; return 1; &#125;&#125; 进入到方法体内部，我们发现，两个定时任务的比较，确实是先比较任务的截止时间，截止时间相同的情况下，再比较id，即任务添加的顺序，如果id再相同的话，就抛Error 这样，在执行定时任务的时候，就能保证最近截止时间的任务先执行 下面，我们再来看下netty是如何来保证各种定时任务的执行的，netty里面的定时任务分以下三种 1.若干时间后执行一次 2.每隔一段时间执行一次 3.每次执行结束，隔一定时间再执行一次 netty使用一个 periodNanos 来区分这三种情况，正如netty的注释那样 12/* 0 - no repeat, &gt;0 - repeat at fixed rate, &lt;0 - repeat with fixed delay */private final long periodNanos; 了解这些背景之后，我们来看下netty是如何来处理这三种不同类型的定时任务的 12345678910111213141516public void run() &#123; if (periodNanos == 0) &#123; V result = task.call(); setSuccessInternal(result); &#125; else &#123; task.call(); long p = periodNanos; if (p &gt; 0) &#123; deadlineNanos += p; &#125; else &#123; deadlineNanos = nanoTime() - p; &#125; scheduledTaskQueue.add(this); &#125; &#125;&#125; if (periodNanos == 0) 对应 若干时间后执行一次 的定时任务类型，执行完了该任务就结束了。 否则，进入到else代码块，先执行任务，然后再区分是哪种类型的任务，periodNanos大于0，表示是以固定频率执行某个任务，和任务的持续时间无关，然后，设置该任务的下一次截止时间为本次的截止时间加上间隔时间periodNanos，否则，就是每次任务执行完毕之后，间隔多长时间之后再次执行，截止时间为当前时间加上间隔时间，-p就表示加上一个正的间隔时间，最后，将当前任务对象再次加入到队列，实现任务的定时执行 netty内部的任务添加机制了解地差不多之后，我们就可以查看reactor第三部曲是如何来调度这些任务的 4.2 reactor线程task的调度首先，我们将目光转向最外层的外观代码 1runAllTasks(long timeoutNanos); 顾名思义，这行代码表示了尽量在一定的时间内，将所有的任务都取出来run一遍。timeoutNanos 表示该方法最多执行这么长时间，netty为什么要这么做？我们可以想一想，reactor线程如果在此停留的时间过长，那么将积攒许多的IO事件无法处理(见reactor线程的前面两个步骤)，最终导致大量客户端请求阻塞，因此，默认情况下，netty将控制内部队列的执行时间 好，我们继续跟进 1234567891011121314151617181920212223242526272829303132333435363738protected boolean runAllTasks(long timeoutNanos) &#123; //从scheduledTaskQueue转移定时任务到taskQueue fetchFromScheduledTaskQueue(); Runnable task = pollTask(); if (task == null) &#123; afterRunningAllTasks(); return false; &#125; //计算本次任务循环的截止时间 final long deadline = timeoutNanos &gt; 0 ? ScheduledFutureTask.nanoTime() + timeoutNanos : 0; long runTasks = 0; long lastExecutionTime; //执行任务 for (;;) &#123; safeExecute(task); runTasks ++; // 每隔0x3F任务，即每执行完64次任务之后，判断当前时间是否超过本次reactor任务循环的截止时间了， // 如果超过，那就break掉，如果没有超过，那就继续执行。 // 可以看到，netty对性能的优化考虑地相当的周到，假设netty任务队列里面如果有海量小任务， // 如果每次都要执行完任务都要判断一下是否到截止时间，那么效率是比较低下的 if ((runTasks &amp; 0x3F) == 0) &#123; lastExecutionTime = ScheduledFutureTask.nanoTime(); if (lastExecutionTime &gt;= deadline) &#123; break; &#125; &#125; task = pollTask(); if (task == null) &#123; lastExecutionTime = ScheduledFutureTask.nanoTime(); break; &#125; &#125; // 收尾 afterRunningAllTasks(); this.lastExecutionTime = lastExecutionTime; return true;&#125; 这段代码便是reactor执行task的所有逻辑，可以拆解成下面几个步骤 从scheduledTaskQueue转移定时任务到taskQueue(mpsc queue) 计算本次任务循环的截止时间 执行任务 收尾 从scheduledTaskQueue转移定时任务到taskQueue(mpsc queue) 首先调用 fetchFromScheduledTaskQueue()方法，将到期的定时任务转移到mpsc queue里面 12345678910111213141516171819private boolean fetchFromScheduledTaskQueue() &#123; if (scheduledTaskQueue == null || scheduledTaskQueue.isEmpty()) &#123; return true; &#125; //为当前纳秒减去ScheduledFutureTask类被加载的纳秒个数 long nanoTime = AbstractScheduledEventExecutor.nanoTime(); for (;;) &#123; Runnable scheduledTask = pollScheduledTask(nanoTime); if (scheduledTask == null) &#123; return true; &#125; // 转移失败重新放回定时队列 if (!taskQueue.offer(scheduledTask)) &#123; // No space left in the task queue add it back to the scheduledTaskQueue so we pick it up again. scheduledTaskQueue.add((ScheduledFutureTask&lt;?&gt;) scheduledTask); return false; &#125; &#125;&#125; 可以看到，netty在把任务从scheduledTaskQueue转移到taskQueue的时候还是非常小心的，当taskQueue无法offer的时候，需要把从scheduledTaskQueue里面取出来的任务重新添加回去 从scheduledTaskQueue从拉取一个定时任务的逻辑如下，传入的参数nanoTime为当前时间(其实是当前纳秒减去ScheduledFutureTask类被加载的纳秒个数)，这里是一处优化，为了解决第一次添加定时任务时，ScheduledFutureTask加载耗时导致定时任务定时缩短的问题。 123456789101112protected final Runnable pollScheduledTask(long nanoTime) &#123; assert inEventLoop(); ScheduledFutureTask&lt;?&gt; scheduledTask = peekScheduledTask(); //只有在当前任务的截止时间已经到了才会取出来 if (scheduledTask == null || scheduledTask.deadlineNanos() - nanoTime &gt; 0) &#123; return null; &#125; scheduledTaskQueue.remove(); scheduledTask.setConsumed(); return scheduledTask;&#125; 可以看到，每次 pollScheduledTask 的时候，只有在当前任务的截止时间已经到了，才会取出来 计算本次任务循环的截止时间 123456789Runnable task = pollTask();if (task == null) &#123; afterRunningAllTasks(); return false;&#125;//计算本次任务循环的截止时间final long deadline = timeoutNanos &gt; 0 ? ScheduledFutureTask.nanoTime() + timeoutNanos : 0;long runTasks = 0;long lastExecutionTime; 这一步将取出第一个任务，用reactor线程传入的超时时间 timeoutNanos 来计算出当前任务循环的deadline，并且使用了runTasks，lastExecutionTime来时刻记录任务的状态 循环执行任务 12345678910111213141516171819//执行任务for (;;) &#123; safeExecute(task); runTasks ++; // 每隔0x3F任务，即每执行完64次任务之后，判断当前时间是否超过本次reactor任务循环的截止时间了， // 如果超过，那就break掉，如果没有超过，那就继续执行。 if ((runTasks &amp; 0x3F) == 0) &#123; lastExecutionTime = ScheduledFutureTask.nanoTime(); if (lastExecutionTime &gt;= deadline) &#123; break; &#125; &#125; task = pollTask(); if (task == null) &#123; lastExecutionTime = ScheduledFutureTask.nanoTime(); break; &#125;&#125; 这一步便是netty里面执行所有任务的核心代码了。首先调用safeExecute来确保任务安全执行，忽略任何异常 然后将已运行任务 runTasks 加一，每隔0x3F任务，即每执行完64个任务之后，判断当前时间是否超过本次reactor任务循环的截止时间了，如果超过，那就break掉，如果没有超过，那就继续执行。可以看到，netty对性能的优化考虑地相当的周到，假设netty任务队列里面如果有海量小任务，如果每次都要执行完任务都要判断一下是否到截止时间，那么效率是比较低下的 收尾 12afterRunningAllTasks();this.lastExecutionTime = lastExecutionTime; 收尾工作很简单，调用一下 afterRunningAllTasks 方法 1234@Override //SingleThreadEventLoopprotected void afterRunningAllTasks() &#123; runAllTasksFrom(tailTasks);&#125; NioEventLoop可以通过父类SingleTheadEventLoop的executeAfterEventLoopIteration方法向tailTasks中添加收尾任务，比如，你想统计一下一次执行一次任务循环花了多长时间就可以调用此方法 1234567public final void executeAfterEventLoopIteration(Runnable task) &#123; // ... if (!tailTasks.offer(task)) &#123; reject(task); &#125; //...&#125; 5 解决JDK空轮询bughttps://www.jianshu.com/p/3ec120ca46b2 空轮询bug： 正常情况下，selector.select()操作是阻塞的，只有被监听的fd有读写操作时，才被唤醒 但是，在这个bug中，没有任何fd有读写请求，但是select()操作依旧被唤醒 很显然，这种情况下，selectedKeys()返回的是个空数组 然后按照逻辑执行到while(true)处，循环执行，导致死循环。 netty 会在每次进行 selector.select(timeoutMillis) 之前记录一下开始时间currentTimeNanos，在select之后记录一下结束时间，判断select操作是否至少持续了timeoutMillis秒 这里将time - TimeUnit.MILLISECONDS.toNanos(timeoutMillis) &gt;= currentTimeNanos改成 time - currentTimeNanos &gt;= TimeUnit.MILLISECONDS.toNanos(timeoutMillis)或许更好理解一些 如果持续的时间大于等于timeoutMillis，说明就是一次有效的轮询，重置selectCnt标志，否则，表明该阻塞方法并没有阻塞这么长时间，可能触发了jdk的空轮询bug，当空轮询的次数超过一个阀值的时候，默认是512，就开始重建selector","categories":[{"name":"I/O和网络编程","slug":"I-O和网络编程","permalink":"https://zzkenyon.github.io/categories/I-O和网络编程/"}],"tags":[{"name":"netty","slug":"netty","permalink":"https://zzkenyon.github.io/tags/netty/"}],"keywords":[{"name":"I/O和网络编程","slug":"I-O和网络编程","permalink":"https://zzkenyon.github.io/categories/I-O和网络编程/"}]},{"title":"epoll高效运行的原理","slug":"nio-epoll高效运行原理","date":"2019-10-25T16:00:00.000Z","updated":"2020-09-07T01:53:19.111Z","comments":true,"path":"2019/10/26/nio-epoll高效运行原理/","link":"","permalink":"https://zzkenyon.github.io/2019/10/26/nio-epoll高效运行原理/","excerpt":"","text":"nio非阻塞牛逼在哪里？ 要解答这个问题首先要清楚bio的痛点在哪里。 假如我们的服务使用bio模型，服务器启动之后需要一条线程一直监听端口上是否有连接请求发过来，如果没有请求，这条线程就一直等着； 等了好久好久终于来了一个请求连接，连接建立成功后，又要开始等业务请求，由于网络慢或者其他原因又等了一千年； 终于拿到了请求，电光火石间处理完拿到响应数据，准备响应出去，这时候发现由于不明原因，一千五百年之前的一条响应还没有发送出去，占据了内核缓冲区，这时候害得等，等前一条响应发出去才能将本次的响应写入缓冲区。。。沧海桑田 当然这里可以使用多线程优化，但是没有解决根本问题，那就是线程等太久的问题。 这时候nio模式横空出世，牛逼在不用等。nio在linux平台基于epoll实现的 接下来的疑问 1、epoll是基于事件的，那么有哪些事件，事件由谁来触发？ 2、jdk nio是怎么和epoll实现对接的？ 带着这两个疑问，查阅了网上一些文章，大概能解答以上两点疑惑 链接：彻底搞懂epoll高效运行的原理 epoll是一种I/O事件通知机制，是linux 内核实现IO多路复用的一个实现。 IO多路复用是指，在一个操作里同时监听多个输入输出源，在其中一个或多个输入输出源可用的时候返回，然后对其的进行读写操作。 事件 可读事件，当文件描述符关联的内核读缓冲区可读，则触发可读事件。(可读：内核缓冲区非空，有数据可以读取) 可写事件，当文件描述符关联的内核写缓冲区可写，则触发可写事件。(可写：内核缓冲区不满，有空闲空间可以写入） epoll的通俗解释是：一种当文件描述符的内核缓冲区非空时发出可读信号通知、当写缓冲区不满时发出可写信号通知的机制 epoll的APIepoll的核心是3个API，核心数据结构是：1个红黑树和1个链表 1. int epoll_create(int size);创建一个epoll对象，返回对象的句柄，后面两个操作都以句柄为核心。 参数size用来表示要监听的fd数量的最大值，之后版本的Linux已弃用该参数。 1Selector selector = Selector.open(); java nio中，执行以上代码，就会在底层调用epoll_create方法创建一个epoll对象 2.int epoll_ctl(int epfd, int op, int fd, struct epoll_event* event); epoll的事件注册接口，负责将被监听的描述符添加到红黑树或从红黑树中删除或者对监听事件进行修改。参数 epfd 表示epoll对象句柄；参数 op 表示动作，用三个宏来表示： 123EPOLL_CTL_ADD //注册新的fd到epfd中；EPOLL_CTL_MOD //修改已经注册的fd的监听事件；EPOLL_CTL_DEL //从epfd中删除一个fd； 参数 fd 是需要监听的fd 参数 event 表示此次注册的事件，struct epoll_event结构如下： data域是唯一能给出描述符信息的字段，所以在调用epoll_ctl加入一个需要监测的描述符时，一定要在此域写入描述符相关信息； events域是bit mask，描述一组epoll事件，在epoll_ctl调用中解释为：描述符所期望的epoll事件，可多选。 1234567891011121314/**表示某个fd上某事件被触发了**/struct epoll_event &#123; __uint32_t events; // 在被监测的文件描述符上实际发生的事件。 epoll_data_t data; &#125;;typedef union epoll_data &#123; void *ptr; // 指向用户自定义数据 int fd; //注册的文件描述符 __uint32_t u32; //32-bit integer __uint64_t u64; //64-bit integer&#125; epoll_data_t; 常用的epoll事件 12345678EPOLLIN //表示对应的文件描述符可以读（包括对端SOCKET正常关闭）EPOLLOUT //表示对应的文件描述符可以写EPOLLET //将 EPOLL设为边缘触发EPOLLONESHOT //第一次进行通知，之后不再监测EPOLLPRI //由带外数据触发EPOLLERR //描述符产生错误时触发，默认检测事件EPOLLHUP //本端描述符产生一个挂断事件，默认监测事件EPOLLRDHUP //对端描述符产生一个挂断事件 在java nio中执行事件注册的代码如下： 1SelectionKey key = channel.register(selector,Selectionkey.OP_READ); channel就是fd在jdk中的包装对象，selector可以认为是epoll对象，这一句的含义是将一个fd注册到epoll对象上，且监听的事件是OP_READ 3、int epoll_wait(int epfd， struct epoll_event *events， int maxevents， int timeout); 功能：阻塞等待事件的发生，返回事件数目，并将触发的事件写入参数events数组中 参数：events: 用来记录被触发的events，其大小应该和maxevents一致 ​ maxevents: 返回的events的最大个数 处于ready状态的那些FD会被复制进ready list中，epoll_wait 用于向用户进程返回这个list，events和maxevents两个参数描述一个由用户分配的struct epoll event数组，调用返回时，内核将ready list复制到这个数组中，并将实际复制的个数作为返回值。注意，如果ready list比maxevents长，则只能复制前maxevents个成员；反之，则能够完全复制ready list。 参数timeout描述在函数调用中阻塞时间上限，单位是ms： timeout = -1表示调用将一直阻塞，直到有文件描述符进入ready状态或者捕获到信号才返回； timeout = 0用于非阻塞检测是否有描述符处于ready状态，不管结果怎么样，调用都立即返回； timeout &gt; 0表示调用将最多持续timeout时间，如果期间有检测对象变为ready状态或者捕获到信号则返回，否则直到超时。 java nio 中，Selector类有以下方法 123int select() //阻塞方法，阻塞到至少有一个通道在注册的事件上就绪。 timeout = -1int select(long timeout) //超时返回的阻塞方法 timeout &gt; 0int selectNow() //非阻塞方法，不管是否有通道就绪，立即返回。 timeout = 0 这句就是查找就绪fd，底层将调用epoll_wait方法。 epoll的两种触发方式epoll监控多个文件描述符的I/O事件。epoll支持边缘触发(edge trigger，ET)或水平触发（level trigger，LT)，通过epoll_wait等待I/O事件，如果当前没有可用的事件则阻塞调用线程。 select和poll只支持LT工作模式，epoll的默认的工作模式是LT模式。 1.水平触发的时机 对于读操作，只要缓冲不为空，LT模式返回读就绪。对于写操作，只要缓冲区还不满，LT模式会返回写就绪。 当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。如果这次没有把数据一次性全部读写完(如读写缓冲区太小)，那么下次调用 epoll_wait()时，它还会通知你在上没读写完的文件描述符上继续读写，当然如果你一直不去读写，它会一直通知你。如果系统中有大量你不需要读写的就绪文件描述符，而它们每次都会返回，这样会大大降低处理程序检索自己关心的就绪文件描述符的效率。 2.边缘触发的时机 对于读操作，以下三种情况会触发读就绪事件： 当缓冲区由不可读变为可读的时候，即缓冲区由空变为不空的时候； 当有新数据到达时，即缓冲区中的待读数据变多的时候； 当缓冲区有数据可读，且应用进程对相应的描述符进行EPOLL_CTL_MOD 修改EPOLLIN事件时（设置监听读就绪时）； 响应的对于写操作，以下情况会触发写就绪事件： 当缓冲区由不可写变为可写时。 当有旧数据被发送走，即缓冲区中的内容变少的时候。 当缓冲区有空间可写，且应用进程对相应的描述符进行EPOLL_CTL_MOD 修改EPOLLOUT事件时。 当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。如果这次没有把数据全部读写完(如读写缓冲区太小)，那么下次调用epoll_wait()时，它不会通知你，就是说只会通知一次，直到该文件描述符上触发第二次可读写事件时才会再次通知。这种模式比水平触发效率高，系统不会充斥大量你不关心的就绪文件描述符。 举例1： 读缓冲区刚开始是空的读缓冲区写入2KB数据，水平触发和边缘触发模式此时都会发出可读信号收到信号通知后，读取了1KB的数据，读缓冲区还剩余1KB数据，水平触发会再次进行通知，而边缘触发不会再进行通知 举例2：（以脉冲的高低电平为例） 水平触发：0为无数据，1为有数据。缓冲区有数据则一直为1，则一直触发。边缘触发发：0为无数据，1为有数据，只要在0变到1的上升沿才触发。 JDK在Linux已经默认使用epoll方式，但是JDK的epoll采用的是水平触发，而Netty重新实现了epoll机制，采用边缘触发方式，netty epoll transport 暴露了更多的nio没有的配置参数，如 TCP_CORK, SO_REUSEADDR等等；另外像Nginx也采用边缘触发。 epoll与select、poll的对比1. 用户态将文件描述符传入内核的方式 select：创建3个文件描述符集并拷贝到内核中，分别监听读、写、异常动作。这里受到单个进程可以打开的fd数量限制，默认是1024。 poll：将传入的struct pollfd结构体数组拷贝到内核中进行监听。 epoll：执行epoll_create会在内核的高速cache区中建立一颗红黑树以及就绪链表(该链表存储已经就绪的文件描述符)。接着用户执行的epoll_ctl函数添加文件描述符会在红黑树上增加相应的结点。 2. 内核态检测文件描述符读写状态的方式 select：采用轮询方式，遍历所有fd，最后返回一个描述符读写操作是否就绪的mask掩码，根据这个掩码给fd_set赋值。 poll：同样采用轮询方式，查询每个fd的状态，如果就绪则在等待队列中加入一项并继续遍历。 epoll：采用回调机制。在执行epoll_ctl的add操作时，不仅将文件描述符放到红黑树上，而且也注册了回调函数，内核在检测到某文件描述符可读/可写时会调用回调函数，该回调函数将文件描述符放在就绪链表中。 3. 找到就绪的文件描述符并传递给用户态的方式 select：将之前传入的fd_set拷贝传出到用户态并返回就绪的文件描述符总数。用户态并不知道是哪些文件描述符处于就绪态，需要遍历来判断。 poll：将之前传入的fd数组拷贝传出用户态并返回就绪的文件描述符总数。用户态并不知道是哪些文件描述符处于就绪态，需要遍历来判断。 epoll：epoll_wait只用观察就绪链表中有无数据即可，最后将链表的数据返回给数组并返回就绪的数量。内核将就绪的文件描述符放在传入的数组中，所以只用遍历依次处理即可。这里返回的文件描述符是通过mmap让内核和用户空间共享同一块内存实现传递的，减少了不必要的拷贝。 4. 重复监听的处理方式 select：将新的监听文件描述符集合拷贝传入内核中，继续以上步骤。 poll：将新的struct pollfd结构体数组拷贝传入内核中，继续以上步骤。 epoll：无需重新构建红黑树，直接沿用已存在的即可。 epoll更高效的原因select和poll的动作基本一致，只是poll采用链表来进行文件描述符的存储，而select采用fd标注位来存放，所以select会受到最大连接数的限制，而poll不会。 select、poll、epoll虽然都会返回就绪的文件描述符数量。但是select和poll并不会明确指出是哪些文件描述符就绪，而epoll会。造成的区别就是，系统调用返回后，调用select和poll的程序需要遍历监听的整个文件描述符找到是谁处于就绪，而epoll则直接处理即可。 select、poll都需要将有关文件描述符的数据结构拷贝进内核，最后再拷贝出来。而epoll创建的有关文件描述符的数据结构本身就存于内核态中，系统调用返回时利用mmap()文件映射内存加速与内核空间的消息传递：即epoll使用mmap减少复制开销。 select、poll采用轮询的方式来检查文件描述符是否处于就绪态，而epoll采用回调机制。造成的结果就是，随着fd的增加，select和poll的效率会线性降低，而epoll不会受到太大影响，除非活跃的socket很多。 epoll的边缘触发模式效率高，系统不会充斥大量不关心的就绪文件描述符虽然epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。","categories":[{"name":"I/O和网络编程","slug":"I-O和网络编程","permalink":"https://zzkenyon.github.io/categories/I-O和网络编程/"}],"tags":[{"name":"nio","slug":"nio","permalink":"https://zzkenyon.github.io/tags/nio/"}],"keywords":[{"name":"I/O和网络编程","slug":"I-O和网络编程","permalink":"https://zzkenyon.github.io/categories/I-O和网络编程/"}]},{"title":"git规范的commit message（转）","slug":"其他-git规范的Commit Message","date":"2019-10-22T16:00:00.000Z","updated":"2020-06-12T00:32:37.078Z","comments":true,"path":"2019/10/23/其他-git规范的Commit Message/","link":"","permalink":"https://zzkenyon.github.io/2019/10/23/其他-git规范的Commit Message/","excerpt":"","text":"git上每次提交，Commit message 都包括三个部分：Header，Body 和 Footer。 12345&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;// 空一行&lt;body&gt;// 空一行&lt;footer&gt; 其中，Header 是必需的，Body 和 Footer 可以省略。 不管是哪一个部分，任何一行都不得超过72个字符（或100个字符）。这是为了避免自动换行影响美观。 Header(必需) type(必需) 用于说明 commit 的类别 feat：新功能（feature） fix：修补bug docs：文档（documentation） style： 格式（不影响代码运行的变动） refactor：重构（即不是新增功能，也不是修改bug的代码变动） test：增加测试 chore：构建过程或辅助工具的变动 revert：用于以前的 commit，则必须以revert:开头，后面跟着被撤销 Commit 的 Header。 123revert: feat(pencil): add &apos;graphiteWidth&apos; optionThis reverts commit 667ecc1654a317a13331b17617d973392f415f02. Body部分的格式是固定的，必须写成This reverts commit &amp;lt;hash&gt;.，其中的hash是被撤销 commit 的 SHA 标识符。 如果当前 commit 与被撤销的 commit，在同一个发布（release）里面，那么它们都不会出现在 Change log 里面。如果两者在不同的发布，那么当前 commit，会出现在 Change log 的Reverts小标题下面。 如果type为feat和fix，则该 commit 将肯定出现在 Change log 之中。其他情况（docs、chore、style、refactor、test）由你决定，要不要放入 Change log，建议是不要。 scope 用于说明 commit 影响的范围，比如数据层、控制层、视图层等等，视项目不同而不同。 subject(必需) 是 commit 目的的简短描述，不超过50个字符。 以动词开头，使用第一人称现在时，比如change，而不是changed或changes 第一个字母小写 结尾不加句号（.） BodyBody 部分是对本次 commit 的详细描述，可以分成多行。 有两个注意点: 使用第一人称现在时，比如使用change而不是changed或changes。 应该说明代码变动的动机，以及与以前行为的对比。 FooterFooter 部分只用于两种情况。 不兼容变动 如果当前代码与上一个版本不兼容，则 Footer 部分以BREAKING CHANGE开头，后面是对变动的描述、以及变动理由和迁移方法。 关闭 Issue 如果当前 commit 针对某个issue，那么可以在 Footer 部分关闭这个 issue 。 Closes #234 也可以一次关闭多个 issue 。 Closes #123, #245, #992 原文链接","categories":[{"name":"其他","slug":"其他","permalink":"https://zzkenyon.github.io/categories/其他/"}],"tags":[{"name":"git","slug":"git","permalink":"https://zzkenyon.github.io/tags/git/"}],"keywords":[{"name":"其他","slug":"其他","permalink":"https://zzkenyon.github.io/categories/其他/"}]},{"title":"说说零拷贝","slug":"nio-说说零拷贝","date":"2019-10-18T16:00:00.000Z","updated":"2020-06-08T02:40:21.755Z","comments":true,"path":"2019/10/19/nio-说说零拷贝/","link":"","permalink":"https://zzkenyon.github.io/2019/10/19/nio-说说零拷贝/","excerpt":"","text":"从一个业务场景开始：从本地磁盘读取一个文件通过socket发送出去。（kafka消费场景） 传统的I/O接口处理流程如下：读文件到应用-&gt;应用打包文件到socket-&gt;发送 应用发起系统调用sys_read()（或等价的方法）请求读磁盘文件 系统切换到内核态，读磁盘数据到内核读缓冲区（DMA方式） 系统将内核读缓冲区数据拷贝到应用缓冲区（CPU拷贝），read方法返回，系统切换到用户态。 应用包装好数据后发起send() 系统调用 系统切换到内核态，将数据写入到socket缓冲区（CPU拷贝） 将socket缓冲区的数据发送给网络接口卡（DMA方式），网卡发出 send() 返回，系统切换到用户态回到应用。 整个过程将经历4次上下文切换，2次CPU拷贝。 1. NIO的零拷贝java.nio包中有一个TransferTo接口，专门用来发送数据，我们来看看它是怎么做的。 TransferTo接口调用了本地TransferTo方法，在Linux平台上将发起sendfile系统调用，执行过程如下： 应用发起sendfile系统调用请求发送文件 系统切换到内核态，读磁盘数据到内核读缓冲区（DMA方式） 将内核读缓冲区的数据直接拷贝到socket缓冲区（CPU拷贝） 将socket缓冲区的数据发送给网络接口卡（DMA方式），网卡发出 系统切换到用户态回到应用 整个过程经历2次上下文切换和1次CPU拷贝。 如果底层NIC（网络接口卡）支持gather操作，可以进一步减少内核中的数据拷贝。在Linux 2.4以及更高版本的内核中，socket缓冲区描述符已被修改用来适应这个需求。这种方式不但减少上下文切换，同时消除了需要CPU参与的重复的数据拷贝。 用户这边的使用方式不变，依旧通过transferTo方法，但是方法的内部实现发生了变化： transferTo方法调用触发DMA引擎将文件上下文信息拷贝到内核缓冲区 数据不会被拷贝到套接字缓冲区，只有数据的描述符（包括数据位置和长度）被拷贝到套接字缓冲区。DMA 引擎直接将数据从内核缓冲区拷贝到协议引擎，这样减少了最后一次需要消耗CPU的拷贝操作。 将一个文件拷贝到另一个目录，使用nio方式性能提升100%，对比代码 2. 直接内存在不需要进行数据文件操作时，可以使用NIO的零拷贝。但如果既需要IO速度，又需要进行数据操作，则需要使用NIO的直接内存映射。 Linux提供的mmap系统调用, 它可以将一段用户空间内存映射到内核空间, 当映射成功后, 用户对这段内存区域的修改可以直接反映到内核空间；同样地， 内核空间对这段区域的修改也直接反映用户空间。正因为有这样的映射关系, 就不需要在用户态(User-space)与内核态(Kernel-space) 之间拷贝数据， 提高了数据传输的效率，这就是以内存直接映射为基础的零拷贝技术。 NIO的直接内存映射 NIO中一个重要的类：MappedByteBuffer——java nio引入的文件内存映射方案，读写性能极高。MappedByteBuffer将文件直接映射到内存。可以映射整个文件，如果文件比较大的话可以考虑分段进行映射，只要指定文件的感兴趣部分就可以。 由于MappedByteBuffer申请的是直接内存，因此不受Minor GC控制，只能在发生Full GC时才能被回收，因此Java提供了DirectByteBuffer类来改善这一情况。它是MappedByteBuffer类的子类，同时它实现了DirectBuffer接口，维护一个Cleaner对象来完成内存回收。因此它既可以通过Full GC来回收内存，也可以调用clean()方法来进行回收 2.1 直接内存的创建在ByteBuffer有两个子类，HeapByteBuffer和DirectByteBuffer。前者是存在于JVM堆中的，后者是存在于Native堆中的。 申请堆内存 12345public static ByteBuffer allocate(int capacity) &#123; if (capacity &lt; 0) throw new IllegalArgumentException(); return new HeapByteBuffer(capacity, capacity);&#125; 申请直接内存 123public static ByteBuffer allocateDirect(int capacity) &#123; return new DirectByteBuffer(capacity);&#125; 为什么使用直接内存（好处） 对垃圾回收停顿的改善。因为full gc时，垃圾收集器会对所有分配的堆内内存进行扫描，垃圾收集对Java应用造成的影响，跟堆的大小是成正比的。过大的堆会影响Java应用的性能。如果使用堆外内存的话，堆外内存是直接受操作系统管理。这样做的结果就是能保持一个较小的JVM堆内存，以减少垃圾收集对应用的影响。full gc会回收空闲的直接内存。） 减少了数据从JVM拷贝到native内存的次数，在某些场景下可以提升程序I/O的性能。 可以突破JVM内存限制，操作更多的物理内存。 使用直接内存注意事项 与堆内存相比直接内存读数据快、申请慢，所以适合申请次数少，访问频繁的场合。 堆外内存只能通过序列化和反序列化来存储，保存对象速度比堆内存慢，不适合存储很复杂的对象。一般简单的对象或者扁平化的比较适合。 当直接内存不足时会触发full gc，排查full gc的时候，一定要考虑。 堆外内存难以控制，如果内存泄漏，那么很难排查 NIO的直接内存映射的函数调用FileChannel提供了map方法来把文件映射为内存对象： MappedByteBuffer map(int mode,long position,long size);可以把文件的从position开始的size大小的区域映射为内存对象，mode指出了 可访问该内存映像文件的方式 READ_ONLY,（只读）： 试图修改得到的缓冲区将导致抛出 ReadOnlyBufferException.(MapMode.READ_ONLY) READ_WRITE（读/写）： 对得到的缓冲区的更改最终将传播到文件；该更改对映射到同一文件的其他程序不一定是可见的。 (MapMode.READ_WRITE) PRIVATE（专用）： 对得到的缓冲区的更改不会传播到文件，并且该更改对映射到同一文件的其他程序也不是可见的；相反，会创建缓冲区已修改部分的专用副本。 (MapMode.PRIVATE) 使用参数-XX:MaxDirectMemorySize=10M，可以指定DirectByteBuffer的大小最多是10M。 对比代码 将一个文件读入内存不做处理，与nio处理方式进行对比，直接内存处理性能提升500%","categories":[{"name":"I/O和网络编程","slug":"I-O和网络编程","permalink":"https://zzkenyon.github.io/categories/I-O和网络编程/"}],"tags":[{"name":"nio","slug":"nio","permalink":"https://zzkenyon.github.io/tags/nio/"}],"keywords":[{"name":"I/O和网络编程","slug":"I-O和网络编程","permalink":"https://zzkenyon.github.io/categories/I-O和网络编程/"}]},{"title":"分布式-序列化之protobuf","slug":"分布式-序列化之protobuf","date":"2019-10-18T16:00:00.000Z","updated":"2020-12-14T08:03:09.799Z","comments":true,"path":"2019/10/19/分布式-序列化之protobuf/","link":"","permalink":"https://zzkenyon.github.io/2019/10/19/分布式-序列化之protobuf/","excerpt":"","text":"1.MAC安装步骤 从github上下载protobuf3 protobuf3下载地址 有很多语言版本的，mac下选择第一个。 下载下来后解压压缩包，并进入目录 1cd protobuf-3.7.0/ 3.设置编译目录 1./configure --prefix=/usr/local/protobuf 4.切换到root用户 1sudo -i 5.安装 12makemake install 6.配置环境变量 找到用户目录/Users/pauljiang 的 .bash_profile文件并编辑 1vim .bash_profile 底部添加 12export PROTOBUF=/usr/local/protobuf export PATH=$PROTOBUF/bin:$PATH source一下使文件生效 1source .bash_profile 7.测试安装结果 1protoc --version 2. java使用使用 protobuf 开发的一般步骤是 配置开发环境，安装 protocol compiler 代码编译器 编写.proto 文件，定义序列化对象的数据结构 基于编写的.proto 文件，使用 protocol compiler 编译器生成对应的序列化/反序列化工具 类 基于自动生成的代码，编写自己的序列化应用 2.1 编写proto文件数据类型string / bytes / bool / int32(4 个字节) /int64/float/double enum 枚举类 message 自定义类 修饰符 required 表示必填字段 optional 表示可选字段 repeated 可重复，表示集合 1，2，3，4 需要在当前范围内是唯一的，表示顺序 demo: 12345678910syntax=&quot;proto2&quot;;package com.pd.serial;option java_package = &quot;com.gupaoedu.serial&quot;;option java_outer_classname=&quot;UserProtos&quot;;message User &#123; required string name=1; required int32 age=2;&#125; 使用命令生成实体类： 1.\\protoc.exe --java_out=./ ./user.proto 在项目中可以使用插件： gradle构建，引入以下插件和依赖 123456plugins &#123; id \"com.google.protobuf\" version \"0.8.14\"&#125;dependencies &#123; implementation 'com.google.protobuf:protobuf-java:3.9.2'&#125; 2.2 调用序列化： 12345UserProtos.User user = UserProtos.User.newBuilder() .setAge(300) .setName(\"Mic\") .build();byte[] bytes = user.toByteArray(); 反序列化： 1UserProtos.User = UserProtos.User.parseFrom(bytes); 3. protobuf原理protobuf优势是空间开销小，性能也相对较好。它里面用到的一些算法还是值得我们去学习的 12345678910public static void main(String[] args) &#123; UserProtos.User user=UserProtos.User.newBuilder() .setAge(300) .setName(\"Mic\") .build(); byte[] bytes=user.toByteArray(); for(byte bt:bytes)&#123; System.out.print(bt+\" \"); &#125;&#125; 打印出的序列为：10 3 77 105 99 16 -84 2 序列化出来的数字基本看不懂，但是序列化以后的数据确实很小，那我们接下来带大家去了解一下底层的原理 正常来说，要达到最小的序列化结果，一定会用到压缩的技术，而 protobuf 里面用到了两种压缩算法，一种是 varint，另一种是 zigzag varint 先说第一种，我们先来看 age=300 这个数字是如何被压缩的 这两个字节字节分别的结果是:-84 、2 -84 怎么计算来的呢? 我们知道在二进制中表示负数的方法，高位设置为 1， 并且是对应数字的二进制取反以后再计算补码表示(补码是反码+1) 所以如果要反过来计算 【补码】10101100 -1 得到 10101011 【反码】01010100 得到的结果为 84. 由于高位是 1，表示负数所以结果为-84 字符如何转化为编码 “Mic”这个字符，需要根据 ASCII 对照表转化为数字。 M =77、i=105、c=99 所以结果为 77 105 99 这里的结果为什么直接就是 ASCII 编码的值呢？怎么没有做压缩呢 原因是，varint 是对字节码做压缩，但是如果这个数字的二进制只需要一个字节表示的时候， 其实最终编码出来的结果是不会变化的 还有两个数字，3 和 16 代表什么呢?那就要了解 protobuf 的存储格式了 存储格式 protobuf 采用 T-L-V 作为存储方式 tag 的计算方式是 field_number(当前字段的编号) &lt;&lt; 3 | wire_type 比如Mic的字段编号是1 ，类型wire_type的值为 2 所以 : 1&lt;&lt;3|2=10 age=300 的字段编号是 2，类型 wire_type 的值是 0， 所以 : 2&lt;&lt;3|0 =16 第一个数字 10，代表的是 key，剩下的都是 value。 负数的存储 在计算机中，负数会被表示为很大的整数，因为计算机定义负数符号位为数字的最高位，所 以如果采用 varint 编码表示一个负数，那么一定需要 5 个比特位。所以在 protobuf 中通过 sint32/sint64 类型来表示负数，负数的处理形式是先采用 zigzag 编码(把符号数转化为无符号数)，在采用 varint 编码。 sint32:(n &lt;&lt; 1) ^ (n &gt;&gt; 31) sint64:(n &lt;&lt; 1) ^ (n &gt;&gt; 63) 比如存储一个(-300)的值 123456789101112-300原码:0001 0010 1100取反:1110 1101 0011加 1 :1110 1101 0100n&lt;&lt;1: 整体左移一位，右边补 0 -&gt; 1101 1010 1000 n&gt;&gt;31: 整体右移 31 位，左边补 1 -&gt; 1111 1111 1111 (n&lt;&lt;1) ^ (n &gt;&gt;31)1101 1010 1000 ^ 1111 1111 1111 = 0010 0101 0111十进制: 0010 0101 0111 = 599varint 算法: 从右往做，选取 7 位，高位补 1/0(取决于字节数) 得到两个字节1101 0111 0000 0100-41 、 4 总结 Protocol Buffer 的性能好，主要体现在序列化后的数据体积小 &amp; 序列化速度快，最终使得 传输效率高，其原因如下: 序列化速度快的原因: a. 编码 / 解码 方式简单(只需要简单的数学运算 = 位移等等) b. 采用 Protocol Buffer 自身的框架代码 和 编译器 共同完成 序列化后的数据量体积小(即数据压缩效果好)的原因: a. 采用了独特的编码方式，如 Varint、Zigzag 编码方式等等 b. 采用 T - L - V 的数据存储方式：减少了分隔符的使用 &amp; 数据存储得紧凑 4. 序列化技术的选型技术层面 序列化空间开销，也就是序列化产生的结果大小，这个影响到传输的性能 序列化过程中消耗的时长，序列化消耗时间过长影响到业务的响应时间 序列化协议是否支持跨平台，跨语言。因为现在的架构更加灵活，如果存在异构系统通信 需求，那么这个是必须要考虑的 可扩展性/兼容性，在实际业务开发中，系统往往需要随着需求的快速迭代来实现快速更新， 这就要求我们采用的序列化协议基于良好的可扩展性/兼容性，比如在现有的序列化数据结 构中新增一个业务字段，不会影响到现有的服务 技术的流行程度，越流行的技术意味着使用的公司多，那么很多坑都已经淌过并且得到了解决，技术解决方案也相对成熟 学习难度和易用性 选型建议 对性能要求不高的场景，可以采用基于 XML 的 SOAP 协议 对性能和间接性有比较高要求的场景，那么 Hessian、Protobuf、Thrift、Avro 都可以。 基于前后端分离，或者独立的对外的 api 服务，选用 JSON 是比较好的，对于调试、可读 性都很不错 Avro 设计理念偏于动态类型语言，那么这类的场景使用 Avro 是可以的 各个序列化技术的性能比较 这 个 地 址 有 针 对 不 同 序 列 化 技 术 进 行 性 能 比 较 : https://github.com/eishay/jvm- serializers/wiki 其他序列化方式介绍 XML 序列化框架介绍 XML 序列化的好处在于可读性好，方便阅读和调试。但是序列化以后的字节码文件比较大， 而且效率不高，适用于对性能不高，而且 QPS 较低的企业级内部系统之间的数据交换的场景， 同时 XML 又具有语言无关性，所以还可以用于异构系统之间的数据交换和协议。比如我们熟 知的 Webservice，就是采用 XML 格式对数据进行序列化的。XML 序列化/反序列化的实现方 式有很多，熟知的方式有 XStream 和 Java 自带的 XML 序列化和反序列化两种 JSON 序列化框架 JSON(JavaScript Object Notation)是一种轻量级的数据交换格式，相对于 XML 来说，JSON 的字节流更小，而且可读性也非常好。现在 JSON 数据格式在企业运用是最普遍的 JSON 序列化常用的开源工具有很多 Jackson (https://github.com/FasterXML/jackson) 阿里开源的 FastJson (https://github.com/alibaba/fastjon) Google 的 GSON (https://github.com/google/gson) 这几种 json 序列化工具中，Jackson 与 fastjson 要比 GSON 的性能要好，但是 Jackson、 GSON 的稳定性要比 Fastjson 好。而 fastjson 的优势在于提供的 api 非常容易使用 Hessian 序列化框架 Hessian 是一个支持跨语言传输的二进制序列化协议，相对于 Java 默认的序列化机制来说， Hessian 具有更好的性能和易用性，而且支持多种不同的语言 实际上 Dubbo 采用的就是 Hessian 序列化来实现，只不过 Dubbo 对 Hessian 进行了重构， 性能更高 Avro 序列化 Avro 是一个数据序列化系统，设计用于支持大批量数据交换的应用。它的主要特点有:支持 二进制序列化方式，可以便捷，快速地处理大量数据;动态语言友好，Avro 提供的机制使动 态语言可以方便地处理 Avro 数据。 kyro 序列化框架 Kryo 是一种非常成熟的序列化实现，已经在 Hive、Storm)中使用得比较广泛，不过它不能 跨语言. 目前 dubbo 已经在 2.6 版本支持 kyro 的序列化机制。它的性能要优于之前的 hessian2","categories":[{"name":"分布式架构技术","slug":"分布式架构技术","permalink":"https://zzkenyon.github.io/categories/分布式架构技术/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"https://zzkenyon.github.io/tags/RPC/"}],"keywords":[{"name":"分布式架构技术","slug":"分布式架构技术","permalink":"https://zzkenyon.github.io/categories/分布式架构技术/"}]},{"title":"redis-类型底层实现原理","slug":"redis-类型底层实现原理","date":"2019-10-01T16:00:00.000Z","updated":"2021-01-26T15:00:01.666Z","comments":true,"path":"2019/10/02/redis-类型底层实现原理/","link":"","permalink":"https://zzkenyon.github.io/2019/10/02/redis-类型底层实现原理/","excerpt":"","text":"1、String存储类型： 可以用来存储int、float、string 存储实现原理： redis是KV数据库，最外层是通过Hashtable实现的，我们称为外层的哈希 外层hash的实现：dick.h 47line 12345678910typedef struct dictEntry &#123; void *key; // key 关键字定义 union &#123; void *val; // value 定义 uint64_t u64; int64_t s64; double d; &#125; v; struct dictEntry *next; //指向下一个键值对节点&#125; dictEntry; 实际上最外层是redisDb，里面放了dict：server.h 661line 1234567891011typedef struct redisDb &#123; dict *dict; /* 所有的键值对 */ dict *expires; /* 设置了过期时间的键值对*/ dict *blocking_keys; /* Keys with clients waiting for data (BLPOP)*/ dict *ready_keys; /* Blocked keys that received a PUSH */ dict *watched_keys; /* WATCHED keys for MULTI/EXEC CAS */ int id; /* Database ID */ long long avg_ttl; /* Average TTL, just for stats */ unsigned long expires_cursor; /* Cursor of the active expire cycle. */ list *defrag_later; /* List of key names to attempt to defrag one by one, gradually. */&#125; redisDb; 所以以set hello world 为例，因为key是字符串，redis自己实现了一个字符串类型，叫做SDS，所以hello指向一个SDS value 是world，同样是一个字符串，但是当value存储一个字符串的时候并没有直接使用SDS存储，而是存在了redisObject中。 实际上五中常用的数据类型都是一样的，value通过redisObject存储，最终RedisObject通过一个指针指向实际的数据结构 redisObject定义：server.h 622 1234567typedef struct redisObject &#123; unsigned type:4;/*对象类型*/ unsigned encoding:4; /*具体的数据结构*/ unsigned lru:LRU_BITS; /*24位，对象最后一次被命令访问的事件，与内存回收有关*/ int refcount;/*引用计数，为0表示可以回收了*/ void *ptr; /*指向对象实际的数据*/&#125; robj; 用type key命令看到的就是type的内容 一个对象有对外展示的类型type，也有对内的编码encoding标明数据的存储结构 内部编码使用命令 object encoding key 就可查看 同样都是string类型，对内有三种编码方式： int 存储8字节长整型（2^63-1） embstr 代表embstr格式的SDS，用于存储小于44字节的字符串 raw，存储大于44字节的字符串 问题1、SDS是什么？ Redis中字符串的实现，全称Simple Dynamic String简单动态字符串 源码：sds.h 47 123456struct __attribute__ ((__packed__)) sdshdr8 &#123; uint8_t len; /* 长度 */ uint8_t alloc; /* 总共分配的内存大小 */ unsigned char flags; /* 当前字符数组的属性，标志是sdshdr8还是sdshdr16等 */ char buf[];/* 字符串真正的值 */&#125;; 本质上还是数组 sds有多种结构：sdshdr5、sdshdr8、sdshdr16、sdshdr32、sdshdr64，用于存储不同长度的字符串。分表表示2^5=32byte，2^8=256byte …… 问题2、为什么redis要使用SDS实现字符串 因为C语言本生没有字符串类型，只能用字符数组char[]实现 使用字符数组要提前分配足够空间，否则可能溢出 如果要获取字符串长度，要遍历数组，事件为O(n) C字串长度变化需要重新内存分配，不能动态扩容 通过从字串开始到结尾碰到第一个‘\\0’来标记字串结束，因此不能保证图片、音频等二进制文件保存的内容，二进制不安全 SDS解决了以上的问题，它具有以下特点： 不担心溢出，能动态扩容 获取长度时间为O(1) 通过“空间预分配”和“惰性空间释放”防止多次重分配内存 判断是否结束的标志是len属性，可以包含‘\\0’，（可以继续使用c语言库函数） 问题3、embstr和raw编码的区别？为什么要为不同长度设计不同的编码 embstr的使用只分配一次内存空间（因为RedisObject和SDS是连续的内存） raw需要两次分配内存，分为RedisObject空间和SDS空间 所以与raw相比，embstr好处在创建时少分配一次空间，删除时少释放一次空间，以及对象所有数据是在连续空间的 而embstr的缺点也很明显，如果字串长度增加需要重新分配内存时，整个redisObject和SDS都需要重新分配空间，因此Redis中的embstr实现为只读（这里的只读是对内存对象而言，对用户来说还是可以写的） 问题4、int和embstr什么时候转化为raw？ 1、int 数据不再是整数—raw 2、int大小超出了long的范围—embstr 3、embstr长度超出了44字节—raw 问题5、没有超过44，怎么变成raw了 我们前面说过，对于embstr，由于它的实现是只读的，因此在对embstr对象进行修改时，都会先转化为raw在进行修改 因此，只要是修改过的string类型数据，都是raw编码的 问题6、当长度改变小于44时会还原吗 编码的升级是不可逆的，编码转化只能由小到大 问题7、为什么要对对曾的数据结构使用RedisObject进行一层包装 总结一下：其实无论是设计RedisObject，还是对存储字串设计这么多的SDS，都是为了根据存储不同选择不同的方式进行存储，这样可以尽量节省内存空间和提升查询速度的目的 应用场景： 1、缓存 2、分布式数据共享—session 3、分布式锁 4、全局id—利用INCRBY，利用原子性 5、计数器 – 秒杀场景 2、Hash2.1 存储类型用于存储多个无序的键值对，最大存储数量2^32-1(40亿左右) hash的value只能是字符串，不能嵌套其他类型，比如hash或者list 同样是存储字符串，Hash与String的区别在哪？ 把所有相关的值聚集到一个key中，减少内存空间 减少Key冲突 当需要批量获取值的时候，只需要使用一个命令，减少内存/IO/CPU的消耗 Hash不适合的场景 Field 不能单独设置过期时间 需要考虑数量分布的问题（field非常多的时候，无法分布到多个节点） 2.2 存储实现原理Redis的Hash本身也是一个KV结构，是不是跟外层的哈希一样使用dicEntry实现呢？ 内层hash底层可以使用两种数据结构实现： ziplist：OBJ_ENCODING_ZIPLIST 压缩列表 hashtable：OBJ_ENCODING_HT 哈希表 同样使用命令 object encoding key 查看 2.2.1 ziplist压缩列表它是一个经过特殊编码的，有连续内存块组成的双向链表。 它不存储指向上一个链表节点和指向下一个链表节点的指针，而是存储上一个节点的长度和当前节点的长度。这样读写访问可能会慢一些，因为要去计算长度，但是可以节省内存，是时间换空间的思想。 源码ziplist.c 16行的注释 … zlbytes：压缩列表的字节长度，占4字节，因此压缩列表最长是2^32-1 zltail：压缩列表尾元素相对于压缩列表起始地址的偏移量，占4字节 zllen：压缩列表的元素数目，占2字节，当元素数量超出2字节表示时，通过zllen无法获得压缩列表的元素数量，必须遍历整个压缩列表 entry：压缩列表存储的若干个元素，可以为字节数组或者整数 zlend：压缩列表的结尾符，恒为0XFF ziplist元素的编码结构 编码有哪些？ 12345678#define ZIP_STR_06B (0 &lt;&lt; 6) // 长度小于等于63字节#define ZIP_STR_14B (1 &lt;&lt; 6) //长度小于等于16383字节#define ZIP_STR_32B (2 &lt;&lt; 6) //长度小于等于429496295字节#define ZIP_INT_16B (0xc0 | 0&lt;&lt;4) #define ZIP_INT_32B (0xc0 | 1&lt;&lt;4)#define ZIP_INT_64B (0xc0 | 2&lt;&lt;4)#define ZIP_INT_24B (0xc0 | 3&lt;&lt;4)#define ZIP_INT_8B 0xfe ziplist详情请见 https://blog.csdn.net/zgaoq/article/details/89710600 https://segmentfault.com/a/1190000017328042 我们最关心的Entry内容 : ziplist.c 271 zlentry是根据一个ziplist元素解析计算出来的结构体，记录了该节点的一些重要信息 123456789typedef struct zlentry &#123; unsigned int prevrawlensize; /* 存储上一个链表节点的长度数值需要的字节数*/ unsigned int prevrawlen; /* 上一个链表节点占用的长度 */ unsigned int lensize; /* 存储当前链表节点长度数值所需要的字节数*/ unsigned int len; /* 当前链表节点实际数据占用字节长度 */ unsigned int headersize; /* 当前链表节点的头部大小 prevrawlensize + lensize. */ unsigned char encoding; /* 编码方式 */ unsigned char *p; /*压缩链表以字符串的形式保存，该指针指向当前节点起始位置 */&#125; zlentry; 根据以上的结构体信息，我们能够得到，节点数据的起始位置为 p + headersize，长度是len p-prevrawlen 为上一个节点元素的起始位置 基于这种结构，ziplist从后向前遍历会比较合适 hash类型如何使用ziplist 那么，hash类型的数据是怎么使用ziplist存储的呢， 12将同一键值对的两个节点紧挨着保存，保存键的节点在前，保存值的节点在后，新加入的键值对，放在压缩列表表尾 展开看： 问题：什么时候用ziplist存储 当hash对象同时满足以下两个条件时： hash对象保存的键值对数量小于512个 所有键值对的键和值的字符串长度都小于64字节（一个字母一个字节） 通过查看redis配置文件：redis.conf 12hash-max-ziplist-value 64hash-max-ziplist-entries 521 超过这两个阈值的任何一个，存储结构就会转换成hashtable 2.2.2 hashtable（dict）在Redis中，hashtabe被称为字典 前面我们了解到redis的kv结构是通过一个dictEntry实现的 在hashtable中，又对dictEntry进行了多层的封装 源码位置：dict.h 47 首先有一个dictEntry： 12345678910typedef struct dictEntry &#123; void *key; // key 关键字定义 union &#123; void *val; // value 定义 uint64_t u64; int64_t s64; double d; &#125; v; struct dictEntry *next; //指向下一个键值对节点&#125; dictEntry; dictEntry放到了dictht里面，ht再放在dict里面 1234567891011121314typedef struct dictht &#123; dictEntry **table; unsigned long size; unsigned long sizemask; unsigned long used;&#125; dictht;typedef struct dict &#123; dictType *type; void *privdata; dictht ht[2]; long rehashidx; /* rehashing not in progress if rehashidx == -1 */ unsigned long iterators; /* number of iterators currently running */&#125; dict; 从最底层到最高层：dictEentry –&gt; dictht–&gt;dict 这是一个数组+链表的结构 展开一下，hash表的整体存储结构如下： 问题：为什么要定义两个hash表，其中一个不用呢 redis的hash默认使用的是ht[0]，ht[1]不会初始化和分配空间 哈希表dictht使用链地址法来解决碰撞问题的。在这种情况下，哈希表的性能取决于它的大小和它所保存的节点的数量之间的比率 比率在1:1时，哈希表的性能最好 如果节点数量比哈希表的大小要大大很多，那么哈希表回退化成很多个链表，哈希表本省的性能优势就不存在 如果单个哈希表的节点数量过多，哈希表需要扩容，rehash时就需要用到ht[1] 问题：什么时候触发扩容 根据负载因子决定 源码dict.c 12static int dict_can_resize = 1;static unsigned int dict_force_resize_ratio = 5; 扩容判断和扩容的操作大家可以自己看一下，跟hashMap一样，也有缩容 应用场景 string可以做的，hash也都可以做 存储对象类型的数据 key-id field-field value-value 购物车 key-uid field-商品id value-商品数量 3、List存储类型 存储有序的字符串，元素可以重复。最大存储数量2^32-1（40亿左右）。 存储实现原理 在早期版本中，数据量较小时用ziplist存储，达到临界值时转换为linkedlist进行存储，分别对应OBJ_ENCODING_ZIPLIST 和 OBJ_ENCODING_LINKEDLIST 3.2版本之后统一用quicklist来存储。quicklist存储了一个双向链表，每个节点都是一个ziplist，所以它是ziplist和linkedlist的结合体。 使用 object encoding key 来查看 quicklist 先看总体结构 源码位置：quicklist.h 105行 12345678910typedef struct quicklist &#123; quicklistNode *head; quicklistNode *tail; unsigned long count; /* 所有的ziplist一共存了多少元素 */ unsigned long len; /* 双向链表的长度 */ int fill : QL_FILL_BITS; /* ziplist最大大小 */ unsigned int compress : QL_COMP_BITS; /* 压缩深度 */ unsigned int bookmark_count: QL_BM_BITS;/* 4位，bookmark数组大小 */ quicklistBookmark bookmarks[];/* bookmark是一个可选字段，quicklist重新分配内存空间时使用，不使用不占空间 */&#125; quicklist; redis.config相关参数： list-max-ziplist-size：整数表示单个ziplist最多包含的entry个数，负数代表单个ziplist的大小，默认8k，-1 4K,-2 8k,-3 16k … list-compress-depth：默认是0，1表示首位的ziplist不压缩；2表示收尾第一第二个ziplist不压缩，以此类推。 节点quicklistNode源码在quicklist.h 46行 123456789101112typedef struct quicklistNode &#123; struct quicklistNode *prev; struct quicklistNode *next; unsigned char *zl; unsigned int sz; /* ziplist size in bytes */ unsigned int count : 16; /* count of items in ziplist */ unsigned int encoding : 2; /* RAW==1 or LZF==2 */ unsigned int container : 2; /* NONE==1 or ZIPLIST==2 */ unsigned int recompress : 1; /* was this node previous compressed? */ unsigned int attempted_compress : 1; /* node can't compress; too small */ unsigned int extra : 10; /* more bits to steal for future usage */&#125; quicklistNode; 总结一下：quicklist就是一个数组+链表的结构 应用场景：主要用于存储有序内容的场景 用户的消息列表 网站的公告列表 活动列表 博客的文章列表 评论列表等 还可以当做分布式环境的队列或者栈使用 4、Set存储类型：无序集合 存储原理 redis 用intset或hashtable存储set。如果元素都是整型，就用inset inset.h 35line 12345typedef struct intset &#123; uint32_t encoding; uint32_t length; int8_t contents[];&#125; intset; 如果不是整数类型，就用hashtable（数组+链表） 如果元素个数超过了512个，也会用hashtable，这与一个配置有关 1set-max-intset-entries 512 问题：set的key没有value，怎么用hashtable存储？ value存null 应用场景： 抽奖 点赞、签到、打卡 商品标签 商品筛选 用户关注（共同好友），推荐 5、Zset存储类型 Sorted set存储有序的元素，每个元素有个score，按照score从小到大排名 score相同，按照key的ACSII码排序 存储原理 默认使用ziplist编码 在ziplist内部，按照Score排序递增来存储，插入的时候要移动之后的数据。 如果元素数量大于等于128个，或者任一member长度大于64字节，使用skiplist+dict存储 12zset-max-ziplist-entries 128zset-max-ziplist-value 64 什么是skiplist 先来看一下有序链表： 这样的链表中要查询数据需要从前往后遍历比较，时间复杂度为O(n)，插入亦然。 加入我们没相邻两个节点增加一个执政，让指针指向下一个节点（或者理解为有三个元素进入了第二层） 这样所有新增的指针连成了一个新链表 问：哪些元素会进入到第二层？ 见源码t_zset.c 122行 现在查数据时，可以先沿着新链表查找，碰到比待查数大的节点，进入下一层 在这个查找过程中，由于新增的指针，我们不需要逐个节点去比较，需要比较的节点数大概只有原来的一半。 为什么不用AVL树或者红黑树？因为skiplist更加简洁 且level是随机的，得到的skiplist可能是这样的： 应用场景 顺序会动态变化的列表 排行榜 6、Hyperloglogs提供了一种不太精确的基数统计方法，用来统计一个集中不重复的元素个数，比如统计网站的UV，或者应用的日活，越活，存在一定误差 在redis实现的HyperLogLog，只需要12k内存就能统计2^64个数据。 7、GEO8、Streams5.0版本推出的数据类型，支持多波的可持久化的消息队列，用于实现发布订阅功能，借鉴了kafka的设计。 tips这里介绍一下在网上看到的源码阅读方法（摘自redis源码解析）。 自底向上：从耦合关系最小的模块开始读，然后逐渐过度到关系紧密的模块。就好像写程序的测试一样，先从单元测试开始，然后才到功能测试。 从功能入手：通过文件名（模块名）和函数名，快速定位到一个功能的具体实现，然后追踪整个实现的运作流程，从而了解该功能的实现方式。 自顶向下：从程序的 main() 函数，或者某个特别大的调用者函数为入口，以深度优先或者广度优先的方式阅读它的源码。 另外，按照黄健宏老师《如何阅读 Redis 源码？》一文中介绍的redis阅读方法，基本上可以将上述文件进行合理的拆分，以便于对其进行一一攻破。 按照上图对Redis源码的模块划分，初步确定一下源码的学习路线如下： 第一阶段 阅读Redis的数据结构部分，基本位于如下文件中：内存分配 zmalloc.c和zmalloc.h 动态字符串 sds.h和sds.c 双端链表 adlist.c和adlist.h 字典 dict.h和dict.c 跳跃表 server.h文件里面关于zskiplist结构和zskiplistNode结构，以及t_zset.c中所有zsl开头的函数，比如 zslCreate、zslInsert、zslDeleteNode等等。 基数统计 hyperloglog.c 中的 hllhdr 结构， 以及所有以 hll 开头的函数 第二阶段 熟悉Redis的内存编码结构 整数集合数据结构 intset.h和intset.c 压缩列表数据结构 ziplist.h和ziplist.c 第三阶段 熟悉Redis数据类型的实现 对象系统 object.c 字符串键 t_string.c 列表建 t_list.c 散列键 t_hash.c 集合键 t_set.c 有序集合键 t_zset.c中除 zsl 开头的函数之外的所有函数 HyperLogLog键 hyperloglog.c中所有以pf开头的函数 第四阶段 熟悉Redis数据库的实现 数据库实现 redis.h文件中的redisDb结构，以及db.c文件 通知功能 notify.c RDB持久化 rdb.c AOF持久化 aof.c 以及一些独立功能模块的实现 发布和订阅 redis.h文件的pubsubPattern结构，以及pubsub.c文件 事务 redis.h文件的multiState结构以及multiCmd结构，multi.c文件 第五阶段 熟悉客户端和服务器端的代码实现 事件处理模块 ae.c/ae_epoll.c/ae_evport.c/ae_kqueue.c/ae_select.c 网路链接库 anet.c和networking.c 服务器端 redis.c 客户端 redis-cli.c 这个时候可以阅读下面的独立功能模块的代码实现 lua脚本 scripting.c 慢查询 slowlog.c 监视 monitor.c 第六阶段 这一阶段主要是熟悉Redis多机部分的代码实现 复制功能 replication.c Redis Sentinel sentinel.c 集群 cluster.c 其他代码文件介绍 关于测试方面的文件有： memtest.c 内存检测 redis_benchmark.c 用于redis性能测试的实现。 redis_check_aof.c 用于更新日志检查的实现。 redis_check_dump.c 用于本地数据库检查的实现。 testhelp.c 一个C风格的小型测试框架。 一些工具类的文件如下： bitops.c GETBIT、SETBIT 等二进制位操作命令的实现 debug.c 用于调试时使用 endianconv.c 高低位转换，不同系统，高低位顺序不同 help.h 辅助于命令的提示信息 lzf_c.c 压缩算法系列 lzf_d.c 压缩算法系列 rand.c 用于产生随机数 release.c 用于发布时使用 sha1.c sha加密算法的实现 util.c 通用工具方法 crc64.c 循环冗余校验 sort.c SORT命令的实现 一些封装类的代码实现： bio.c background I/O的意思，开启后台线程用的 latency.c 延迟类 migrate.c 命令迁移类，包括命令的还原迁移等 pqsort.c 排序算法类 rio.c redis定义的一个I/O类 syncio.c 用于同步Socket和文件I/O操作 整个Redis的源码分类大体上如上所述了，接下来就按照既定的几个阶段一一去分析Redis这款如此优秀的源代码吧！","categories":[{"name":"noSql","slug":"noSql","permalink":"https://zzkenyon.github.io/categories/noSql/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://zzkenyon.github.io/tags/redis/"}],"keywords":[{"name":"noSql","slug":"noSql","permalink":"https://zzkenyon.github.io/categories/noSql/"}]},{"title":"redis-缓存数据库双写一致性方案解析","slug":"redis-缓存数据库双写一致性","date":"2019-09-01T16:00:00.000Z","updated":"2020-12-10T02:38:22.884Z","comments":true,"path":"2019/09/02/redis-缓存数据库双写一致性/","link":"","permalink":"https://zzkenyon.github.io/2019/09/02/redis-缓存数据库双写一致性/","excerpt":"","text":"从理论上来说，设置过期时间是保证缓存数据库最终一致性的解决方案。在这种方案下，我们可以对存入缓存的数据设置过期时间，所有写操作以数据库为准，对缓存操作知识尽最大努力即可。也就是说如果数据库写成功，缓存更新失败，那么只要到达过期时间，后面的请求自然会从数据库中读取新值然后填回缓存。因此，接下来讨论的思路不依赖于给缓存设置过期时间这个方案。 本文讨论三种更新策略： 先更新数据库，再更新缓存 先删除缓存，再更新数据库 先更新数据库，再删除缓存 没有先更新缓存再更新数据库的方案，因为所有的写操作要以数据库为准，这种情况下若更新数据库失败，缓存失效后再次读数据库将取得旧值。 1、先更新数据库，再更新缓存该方案从线程安全角度看 假设同时有请求A和请求B进行更新操作，如下图所示的情况下最终数据库中的数据是B请求的数据，缓存中的数据数A请求的数据，最终出现了不一致的情况。这种情况因为网络情况等原因是可能出现的 该方案从业务场景角度看 如果是一个写多读少的场景，使用这种方案会导致数据压根没读到，缓存就被频繁的更新，浪费性能 如果写入db的值需要经过一系列复杂的计算再写入缓存，那么每次写入缓存前都需要计算缓存值，无疑是在浪费性能 所以，更新缓存不可取，删除缓存更合适。 2、先删除缓存，再更新数据库首先看该方案会导致不一致的情况： A 删除缓存，还没及时更新db B 读db，并将旧值写入缓存 A 更新新值到db 这种情况就会导致缓存与db数据不一致的情形出现，而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。 那么，如何解决呢？ 延时双删策略 123456public void write(String key,Object data)&#123; redis.delKey(key); db.updateData(data); Thread.sleep(1000); redis.delKey(key); &#125; 说明：（1）先淘汰缓存（2）再写数据库（3）休眠1秒，再次淘汰缓存这么做，可以将1秒内所造成的缓存脏数据，再次删除。那么，这个1秒怎么确定的，具体该休眠多久呢？针对上面的情形，应该自行评估自己的项目的读数据业务逻辑的耗时。然后写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百ms即可。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。 3、先更新数据库，再删除缓存首先，先说一下。老外提出了一个缓存更新套路，名为《Cache-Aside pattern》。其中就指出 失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。 命中：应用程序从cache中取数据，取到后返回。 更新：先把数据存到数据库中，成功后，再让缓存失效。 另外，知名社交网站facebook也在论文《Scaling Memcache at Facebook》中提出，他们用的也是先更新数据库，再删缓存的策略。 这种情况不存在并发问题么？不是的。假设这会有两个请求，一个请求A做更新操作，一个请求B做查询操作，那么会有如下情形产生如果发生上述情况，确实是会发生脏数据。 然而，发生这种情况的必要条件是1、B读db时A还没有完成写db，这样B才能读到旧数据 2、A写db比B读db先完成，这样A才会在B更新缓存之前删缓存 因此只有在B请求读db成功但还没有更新缓存之前，A请求更新db结束并执行了删缓存操作，才有可能发生以上的情况。","categories":[{"name":"noSql","slug":"noSql","permalink":"https://zzkenyon.github.io/categories/noSql/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://zzkenyon.github.io/tags/redis/"}],"keywords":[{"name":"noSql","slug":"noSql","permalink":"https://zzkenyon.github.io/categories/noSql/"}]},{"title":"redis-总结精讲","slug":"reids-总结精讲","date":"2019-09-01T16:00:00.000Z","updated":"2020-05-22T12:08:35.432Z","comments":true,"path":"2019/09/02/reids-总结精讲/","link":"","permalink":"https://zzkenyon.github.io/2019/09/02/reids-总结精讲/","excerpt":"","text":"本文围绕以下几个主题： 1、为什么使用redis2、使用redis有什么缺点3、单线程的redis为什么这么快4、redis的数据类型，以及每种数据类型的使用场景5、redis的过期策略以及内存淘汰机制6、redis和数据库双写一致性问题7、如何应对缓存穿透和缓存雪崩问题8、如何解决redis的并发竞争问题 1、为什么使用redis在项目中使用redis，主要是从两个角度去考虑:性能和并发。当然redis还具备可以做分布式锁等其他功能，但是如果只是为了分布式锁这些其他功能，完全还有其他中间件(如zookpeer等)代替，并不是非要使用redis。因此，这个问题主要从性能和并发两个角度去答。 1.1 性能如下图所示，我们在碰到需要执行耗时特别久，且结果不频繁变动的SQL，就特别适合将运行结果放入缓存。这样，后面的请求就去缓存中读取，使得请求能够迅速响应。 题外话：忽然想聊一下这个迅速响应的标准。其实根据交互效果的不同，这个响应时间没有固定标准。不过曾经有人这么告诉我:”在理想状态下，我们的页面跳转需要在瞬间解决，对于页内操作则需要在刹那间解决。另外，超过一弹指的耗时操作要有进度提示，并且可以随时中止或取消，这样才能给用户最好的体验。”那么瞬间、刹那、一弹指具体是多少时间呢？根据《摩诃僧祗律》记载 1一刹那者为一念，二十念为一瞬，二十瞬为一弹指，二十弹指为一罗预，二十罗预为一须臾，一日一夜有三十须臾。 那么，经过周密的计算，一瞬间为0.36 秒,一刹那有 0.018 秒.一弹指长达 7.2 秒。 1.2 并发在大并发的情况下，所有的请求直接访问数据库，数据库会出现连接异常。这个时候，就需要使用redis做一个缓冲操作，让请求先访问到redis，而不是直接访问数据库。 2、使用redis有什么缺点基本上使用redis都会碰到一些问题，常见的也就几个。 缓存和数据库双写一致性问题 缓存雪崩问题 缓存击穿问题 缓存的并发竞争问题 这四个问题项目中比较常遇见，具体解决方案，后文给出。 3、单线程的redis为什么这么快这个问题其实是对redis内部机制的一个考察，主要是以下三点 纯内存操作 单线程操作，避免了频繁的上下文切换 采用了非阻塞I/O多路复用 4、redis的数据类型，以及每种数据类型的使用场景 String这个其实没啥好说的，最常规的set/get操作，value可以是String也可以是数字。一般做一些复杂的计数功能的缓存。 hash这里value存放的是结构化的对象，比较方便的就是操作其中的某个字段。在做单点登录的时候，就是用这种数据结构存储用户信息，以cookieId作为key，设置30分钟为缓存过期时间，能很好的模拟出类似session的效果。 list使用List的数据结构，可以做简单的消息队列的功能。另外还有一个就是，可以利用lrange命令，做基于redis的分页功能，性能极佳，用户体验好。 set因为set堆放的是一堆不重复值的集合。所以可以做全局去重的功能。为什么不用JVM自带的Set进行去重？因为我们的系统一般都是集群部署，使用JVM自带的Set，比较麻烦，难道为了一个做一个全局去重，再起一个公共服务，太麻烦了。另外，就是利用交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。 sorted set多了一个权重参数score,集合中的元素能够按score进行排列。可以做排行榜应用，取TOP N操作、延时任务、范围查找等。 5、redis的过期策略以及内存淘汰机制redis采用的是定期删除+惰性删除策略。 5.1 为什么不用定时删除策略定时删除,用一个定时器来负责监视key,过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key,因此没有采用这一策略. 5.2 定期删除+惰性删除是如何工作的定期删除，redis默认每个100ms检查，是否有过期的key,有过期key则删除。需要说明的是，redis不是每个100ms将所有的key检查一次，而是随机抽取进行检查(如果每隔100ms,全部key进行检查，redis岂不是卡死)。因此，如果只采用定期删除策略，会导致很多key到时间没有删除。于是，惰性删除派上用场。也就是说在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除。 5.2 定期删除+惰性删除的问题如果定期删除没删除key。然后你也没即时去请求key，也就是说惰性删除也没生效。这样，redis的内存会越来越高。 解决方法：采用内存淘汰机制。在redis.conf中有一行配置 1maxmemory-policy volatile-lru 该配置就是配内存淘汰策略的(什么，你没配过？好好反省一下自己) noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。不推荐 allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。推荐使用 allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。不推荐 volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。这种情况一般是把redis既当缓存，又做持久化存储的时候才用。 volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。不推荐 volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。不推荐 6、redis和数据库双写一致性问题 一致性问题是分布式常见问题，还可以再分为最终一致性和强一致性。数据库和缓存双写，就必然会存在不一致的问题。答这个问题，先明白一个前提。就是如果对数据有强一致性要求，不能放缓存。我们所做的一切，只能保证最终一致性。另外，我们所做的方案其实从根本上来说，只能说降低不一致发生的概率，无法完全避免。因此，有强一致性要求的数据，不能放缓存。 首先，采取正确更新策略，先更新数据库，再删缓存。其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用消息队列。 7、如何应对缓存穿透、缓存击穿和缓存雪崩问题7.1 缓存穿透缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求，如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大 解决方案： 接口层增加校验，如用户鉴权校验，id做基础校验，id&lt;=0的直接拦截； 从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击 7.2 缓存击穿缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力 解决方案： 设置热点数据永远不过期。 加互斥锁 7.3 缓存雪崩缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是， 缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。 解决方案： 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。 如果缓存数据库是分布式部署，将热点数据均匀分布在不同的缓存数据库中。 设置热点数据永远不过期。 8、如何解决redis的并发竞争问题这个问题大致就是，同时有多个子系统去set一个key。这个时候要注意什么呢？大家思考过么。需要说明一下，博主提前百度了一下，发现答案基本都是推荐用redis事务机制。博主不推荐使用redis的事务机制。因为我们的生产环境，基本都是redis集群环境，做了数据分片操作。你一个事务中有涉及到多个key操作的时候，这多个key不一定都存储在同一个redis-server上。因此，redis的事务机制，十分鸡肋。 如果对这个key操作，不要求顺序这种情况下，准备一个分布式锁，大家去抢锁，抢到锁就做set操作即可，比较简单。 如果对这个key操作，要求顺序假设有一个key1,系统A需要将key1设置为valueA,系统B需要将key1设置为valueB,系统C需要将key1设置为valueC.期望按照key1的value值按照 valueA–&gt;valueB–&gt;valueC的顺序变化。这种时候我们在数据写入数据库的时候，需要保存一个时间戳。假设时间戳如下 123系统A key 1 &#123;valueA 3:00&#125;系统B key 1 &#123;valueB 3:05&#125;系统C key 1 &#123;valueC 3:10&#125; 那么，假设系统B先抢到锁，将key1设置为{valueB 3:05}。接下来系统A抢到锁，发现自己的valueA的时间戳早于缓存中的时间戳，那就不做set操作了。以此类推。 其他方法，比如利用队列，将set方法变成串行访问也可以。总之，灵活变通。","categories":[{"name":"noSql","slug":"noSql","permalink":"https://zzkenyon.github.io/categories/noSql/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://zzkenyon.github.io/tags/redis/"}],"keywords":[{"name":"noSql","slug":"noSql","permalink":"https://zzkenyon.github.io/categories/noSql/"}]},{"title":"并发编程-常见问题","slug":"并发编程-常见问题","date":"2019-08-20T16:00:00.000Z","updated":"2020-05-22T11:40:51.687Z","comments":true,"path":"2019/08/21/并发编程-常见问题/","link":"","permalink":"https://zzkenyon.github.io/2019/08/21/并发编程-常见问题/","excerpt":"","text":"多个线程同时读写，读线程的数量远远⼤于写线程，你认为应该如何解决并发的问题？你会选择加什么样的锁？ JAVA的AQS是否了解，它是⼲嘛的？ 除了synchronized关键字之外，你是怎么来保障线程安全的？ 什么时候需要加volatile关键字？它能保证线程安全吗？ 线程池内的线程如果全部忙，提交⼀个新的任务，会发⽣什么？队列全部塞满了之后，还是忙，再提交会发⽣什么？ Tomcat本身的参数你⼀般会怎么调整？ synchronized关键字锁住的是什么东⻄？在字节码中是怎么表示的？在内存中的对象上表现为什么？ wait/notify/notifyAll⽅法需不需要被包含在synchronized块中？这是为什么？ ExecutorService你⼀般是怎么⽤的？是每个service放⼀个还是⼀个项⽬⾥⾯放⼀个？有什么好处？","categories":[{"name":"并发编程的艺术","slug":"并发编程的艺术","permalink":"https://zzkenyon.github.io/categories/并发编程的艺术/"}],"tags":[{"name":"JDK","slug":"JDK","permalink":"https://zzkenyon.github.io/tags/JDK/"}],"keywords":[{"name":"并发编程的艺术","slug":"并发编程的艺术","permalink":"https://zzkenyon.github.io/categories/并发编程的艺术/"}]},{"title":"rocketmq-分布式事务解决方案","slug":"MQ-rocketmq分布式事务解决方案","date":"2019-08-13T16:00:00.000Z","updated":"2020-11-16T02:03:02.230Z","comments":true,"path":"2019/08/14/MQ-rocketmq分布式事务解决方案/","link":"","permalink":"https://zzkenyon.github.io/2019/08/14/MQ-rocketmq分布式事务解决方案/","excerpt":"","text":"1. 分布式事务简介X/Open Distributed Transaction Processing Reference Model 是X/Open这个组织定义的一套分布式事务的标准，也就是定义了规范和API接口，由各个厂商进行具体的实现。这个标准提出了使用二阶段提交2PC (Two-Phase-Commit)来保证分布式事务的完整性。后来J2EE也遵循了X/OpenDTP规范，设计并实现了java里的分布式事务编程接口规范JTA（Java Transaction API） 分布式事务包括事务管理器（Transaction Manager）和一个或多个支持 XA 协议的资源管理器 ( Resource Manager )。 1.1 分布式事务中的角色在X/OpenDTP事务模型中，定义了三个角色： AP：application，应用程序，也就是业务层。哪些操作属于一个事务，就是AP定义的 RM： Resource Manager，资源管理器。一般是数据库，也可以是其他资源管理器，比如消息队列， 文件系统 TM： Transaction Manager ，事务管理器、事务协调者，负责接收来自AP发起的XA事务指令，并调度和协调参与事务的所有RM，确保事务正确完成 为什么需要TM这个角色？ 在分布式系统中，每一个机器节点虽然都能够明确知道自己在进行事务操作过程中的结果是成功还是失败，但却无法直接获取到其他分布式节点的操作结果。因此当一个事务操作需要跨越多个分布式节点的 时候，为了保持事务处理的ACID特性，就需要引入一个”协调者”来统一调度所有分布式节点的执行逻辑。TM负责调度AP的行为，并最终决定这些AP是否要把各自的事务真正进行提交到RM 1.2 XA协议XA协议由Tuxedo首先提出的，并交给X/Open组织，作为资源管理器（数据库）与事务管理器的接口标准。目前，Oracle、Informix、DB2和Sybase等各大数据库厂家都提供对XA的支持。XA协议采用两阶段提交方式来管理分布式事务。XA接口提供资源管理器与事务管理器之间进行通信的标准接口。XA接口是双向的系统接口，在事务管理器TM以及多个RM之间形成同心桥梁，XA不能自动提交 XA协议包括两套函数，以xa_开头的及以ax_开头的，这些函数使事务管理器可以对资源管理器进行的操作： 1）xa_open，xa_close：建立和关闭与资源管理器的连接。 2）xa_start，xa_end：开始和结束一个本地事务。 3）xa_prepare，xa_commit，xa_rollback：预提交、提交和回滚一个本地事务。 4）xa_recover：回滚一个已进行预提交的事务。 5）ax_开头的函数使资源管理器可以动态地在事务管理器中进行注册，并可以对XID(TRANSACTION IDS)进行操作。 6）ax_reg，ax_unreg；允许一个资源管理器在一个TMS(TRANSACTION MANAGER SERVER)中动态注册或撤消注册。 看到这里我们应该清楚一些概念： X/Open 是一个组织，他提出了分布式事务的标准DTP，该标准采用2PC来保证分布式事务的一致性，标准定义了分布式事务中的各种角色（AP,RM,TM），以及他们之间的通信协议XA，该协议是基于2PC的。J2EE遵循DTP标准实现了java里的分布式事务编程接口规范JTA。 1.3 XA/2PC执行过程XA协议使用了2PC，因此XA需要两阶段提交： prepare 和 commit. 第一阶段为 准备（prepare）阶段。即所有的RM准备执行事务并锁住需要的资源。参与者ready时，向TM报告已准备就绪。 例如数据库在此阶段会做两件事 记录事务日志redo、undo 返回给TM信息ok、error 第二阶段为提交阶段（commit）。当TM确认所有参与者都ready后，向所有RM发送commit命令。 若某个RM返回no，则TM向所有RM发送rollback命令。 存在问题 如果第一阶段完成后TM宕机或网络出现故障，导致TM无法发送commit/Rollback指令，此时RM会一直阻塞发生死锁。 或者某一个RM在第一阶段一直没有回复TM，TM会一直阻塞等待。 这都是因为2PC没有timeout机制导致的问题 XA性能局限性 效率低下，准备阶段的成本持久，全局事务状态的成本持久，性能与本地事务相差10倍左右； 提交前，出现故障难以恢复和隔离问题。 2. 理论支持2.1 CAP理论CAP的含义： C：Consistency 一致性 同一数据的多个副本是否实时相同。 A：Availability 可用性：一定时间内 &amp; 系统返回一个明确的结果 则称为该系统可用。 P：Partition tolerance 分区容错性 将同一服务分布在多个系统中，从而保证某一个系统宕机， 仍然有其他系统提供相同的服务。 在分布式系统中，由于网络的不确定性，分区容错性是一个健壮的系统必须要保证的性能。一致性和可用性则需要根据具体的业务进行选择。CAP理论告诉我们，在分布式系统中，C、A、P三个条件中我们最多只能选择两个，P必选的前提下，要么选择AP，要么选择CP。 对于一个业务系统来说，可用性和分区容错性是必须要满足的两个条件，并且这两者是相辅相成的。业务系统之所以使用分布式系统，主要原因有两个： 提升整体性能 当业务量猛增，单个服务器已经无法满足我们的业务需求的时候，就需要使用分布式系统，使用多个节点提供相同的功能，从而整体上提升系统的性能，这就是使用分布式系统的第一个原因。 实现分区容错性 单一节点 或 多个节点处于相同的网络环境下，那么会存在一定的风险，万一该 机房断电、该地区发生自然灾害，那么业务系统就全面瘫痪了。为了防止这一问题，采用分布式系 统，将多个子系统分布在不同的地域、不同的机房中，从而保证系统高可用性。 这说明分区容错性是分布式系统的根本，如果分区容错性不能满足，那使用分布式系统将失去意义。 此外，可用性对业务系统也尤为重要。在大谈用户体验的今天，如果业务系统时常出现“系统异常”、响 应时间过长等情况，这使得用户对系统的好感度大打折扣，在互联网行业竞争激烈的今天，相同领域的 竞争者不甚枚举，系统的间歇性不可用会立马导致用户流向竞争对手。因此，我们只能通过牺牲一致性 来换取系统的可用性和分区容错 2.2 BASE理论CAP理论告诉我们一个悲惨但不得不接受的事实——我们只能在C、A、P中选择两个条件。而对于业务 系统而言，我们往往选择牺牲一致性来换取系统的可用性和分区容错性。不过这里要指出的是，所谓 的“牺牲一致性”并不是完全放弃数据一致性，而是牺牲强一致性换取弱一致性 BA：Basic Available 基本可用 整个系统在某些不可抗力的情况下，仍然能够保证“可用性”，即一定时间内仍然能够返回一个明确的结果。只不过“基本可用”和“高可用”的区别是： “一定时间”可以适当延长 当举行大促时，响应时间可以适当延长 给部分用户返回一个降级页面，从而缓解服务器压 力。但要注意，返回降级页面仍然是返回明确结果。 S：Soft State：柔性状态 同一数据的不同副本的状态，可以不需要实时一致。 E：Eventual Consisstency：最终一致性 同一数据的不同副本的状态，可以不需要实时一致，但 一定要保证经过一定时间后仍然是一致的。 3. 分布式事务常见解决方案3.1 TCC两阶段补偿方案TCC，Try-Confirm-Cancel是一种在业务层实现分布式事务的方案，能够提供强一致性的保证。微服务间的同步调用， 比如转账场景，扣款与收款需要同时成功，这种有强一致性要求的场景可以使用TCC来完成。 TCC 是服务化的二阶段编程模型，采用的补偿机制，而XA事务采用的是回滚机制。 下面以下单流程为例介绍一下TCC的工作流程，订单服务需要生成订单记录，修改订单支付状态–&gt;调用库存服务扣减库存–&gt;调用积分服务增加会员积分–&gt;调用仓储服务生成销售出库单。 Try阶段 完成所有业务检查(一致性)，预留业务资源(准隔离性) 首先，上面订单服务先把自己的状态修改为：OrderStatus.UPDATING。 这是啥意思呢？也就是说，在 pay() 那个方法里，你别直接把订单状态修改为已支付啊！你先把订单状态修改为 UPDATING，也就是修改中的意思。 这个状态是个没有任何含义的这么一个状态，代表有人正在修改这个状态罢了。 然后呢，库存服务直接提供的那个 reduceStock() 接口里，也别直接扣减库存啊，你可以是冻结掉库存。 举个例子，本来你的库存数量是 100，你别直接 100 - 2 = 98，扣减这个库存！ 你可以把可销售的库存：100 - 2 = 98，设置为 98 没问题，然后在一个单独的冻结库存的字段里，设置一个 2。也就是说，有 2 个库存是给冻结了。 积分服务的 addCredit() 接口也是同理，别直接给用户增加会员积分。你可以先在积分表里的一个预增加积分字段加入积分。 比如：用户积分原本是 1190，现在要增加 10 个积分，别直接 1190 + 10 = 1200 个积分啊！ 你可以保持积分为 1190 不变，在一个预增加字段里，比如说 prepare_add_credit 字段，设置一个 10，表示有 10 个积分准备增加。 仓储服务的 saleDelivery() 接口也是同理啊，你可以先创建一个销售出库单，但是这个销售出库单的状态是“UNKNOWN”。 也就是说，刚刚创建这个销售出库单，此时还不确定它的状态是什么呢！ 上面这套改造接口的过程，其实就是所谓的 TCC 分布式事务中的第一个 T 字母代表的阶段，也就是 Try 阶段。 Confirm阶段 确认执行业务操作，不做任何业务检查，只使用Try阶段预留的业务资源。 然后就分成两种情况了，第一种情况是比较理想的，那就是各个服务执行自己的那个 Try 操作，都执行成功。 这个时候，就需要依靠 TCC 分布式事务框架来推动后续的执行了。这里简单提一句，如果你要玩儿 TCC 分布式事务，必须引入一款 TCC 分布式事务框架，比如国内开源的 ByteTCC、Himly、TCC-transaction。 否则的话，感知各个阶段的执行情况以及推进执行下一个阶段的这些事情，不太可能自己手写实现，太复杂了。 如果你在各个服务里引入了一个 TCC 分布式事务的框架，订单服务里内嵌的那个 TCC 分布式事务框架可以感知到，各个服务的 Try 操作都成功了。 此时，TCC 分布式事务框架会控制进入 TCC 下一个阶段，第一个 C 阶段，也就是 Confirm 阶段。 为了实现这个阶段，你需要在各个服务里再加入一些代码。比如说，订单服务里，你可以加入一个 Confirm 的逻辑，就是正式把订单的状态设置为“已支付”了，大概是类似下面这样子： 12345public class OrderServiceConfirm &#123; public void pay()&#123; orderDao.updateStatus(OrderStatus.PAYED); &#125;&#125; 库存服务也是类似的，你可以有一个 InventoryServiceConfirm 类，里面提供一个 reduceStock() 接口的 Confirm 逻辑，这里就是将之前冻结库存字段的 2 个库存扣掉变为 0。 这样的话，可销售库存之前就已经变为 98 了，现在冻结的 2 个库存也没了，那就正式完成了库存的扣减。 积分服务也是类似的，可以在积分服务里提供一个 CreditServiceConfirm 类，里面有一个 addCredit() 接口的 Confirm 逻辑，就是将预增加字段的 10 个积分扣掉，然后加入实际的会员积分字段中，从 1190 变为 1120。 仓储服务也是类似，可以在仓储服务中提供一个 WmsServiceConfirm 类，提供一个 saleDelivery() 接口的 Confirm 逻辑，将销售出库单的状态正式修改为“已创建”，可以供仓储管理人员查看和使用，而不是停留在之前的中间状态“UNKNOWN”了。 好了，上面各种服务的 Confirm 的逻辑都实现好了，一旦订单服务里面的 TCC 分布式事务框架感知到各个服务的 Try 阶段都成功了以后，就会执行各个服务的 Confirm 逻辑。 订单服务内的 TCC 事务框架会负责跟其他各个服务内的 TCC 事务框架进行通信，依次调用各个服务的 Confirm 逻辑。然后，正式完成各个服务的所有业务逻辑的执行。 Cancel阶段 取消Try阶段预留的业务资源。Try阶段出现异常时，取消所有业务资源预留请求 那如果是异常的一种情况呢？ 举个例子：在 Try 阶段，比如积分服务吧，它执行出错了，此时会怎么样？ 那订单服务内的 TCC 事务框架是可以感知到的，然后它会决定对整个 TCC 分布式事务进行回滚。 也就是说，会执行各个服务的第二个 C 阶段，Cancel 阶段。同样，为了实现这个 Cancel 阶段，各个服务还得加一些代码。 首先订单服务，它得提供一个 OrderServiceCancel 的类，在里面有一个 pay() 接口的 Cancel 逻辑，就是可以将订单的状态设置为“CANCELED”，也就是这个订单的状态是已取消。 库存服务也是同理，可以提供 reduceStock() 的 Cancel 逻辑，就是将冻结库存扣减掉 2，加回到可销售库存里去，98 + 2 = 100。 积分服务也需要提供 addCredit() 接口的 Cancel 逻辑，将预增加积分字段的 10 个积分扣减掉。 仓储服务也需要提供一个 saleDelivery() 接口的 Cancel 逻辑，将销售出库单的状态修改为“CANCELED”设置为已取消。 然后这个时候，订单服务的 TCC 分布式事务框架只要感知到了任何一个服务的 Try 逻辑失败了，就会跟各个服务内的 TCC 分布式事务框架进行通信，然后调用各个服务的 Cancel 逻辑。 总结 总结一下，你要玩儿 TCC 分布式事务的话：首先需要选择某种 TCC 分布式事务框架，各个服务里就会有这个 TCC 分布式事务框架在运行。 然后你原本的一个接口，要改造为 3 个逻辑，Try-Confirm-Cancel： 先是服务调用链路依次执行 Try 逻辑。 如果都正常的话，TCC 分布式事务框架推进执行 Confirm 逻辑，完成整个事务。 如果某个服务的 Try 逻辑有问题，TCC 分布式事务框架感知到之后就会推进执行各个服务的 Cancel 逻辑，撤销之前执行的各种操作。 这就是所谓的 TCC 分布式事务。TCC 分布式事务的核心思想，说白了，就是当遇到下面这些情况时： 某个服务的数据库宕机了。 某个服务自己挂了。 那个服务的 Redis、Elasticsearch、MQ 等基础设施故障了。 某些资源不足了，比如说库存不够这些。 先来 Try 一下，不要把业务逻辑完成，先试试看，看各个服务能不能基本正常运转，能不能先冻结我需要的资源。 如果 Try 都 OK，也就是说，底层的数据库、Redis、Elasticsearch、MQ 都是可以写入数据的，并且你保留好了需要使用的一些资源（比如冻结了一部分库存）。 接着，再执行各个服务的 Confirm 逻辑，基本上 Confirm 就可以很大概率保证一个分布式事务的完成了。 那如果 Try 阶段某个服务就失败了，比如说底层的数据库挂了，或者 Redis 挂了，等等。 此时就自动执行各个服务的 Cancel 逻辑，把之前的 Try 逻辑都回滚，所有服务都不要执行任何设计的业务逻辑。保证大家要么一起成功，要么一起失败。 如果有一些意外的情况发生了，比如说订单服务突然挂了，然后再次重启，TCC 分布式事务框架是如何保证之前没执行完的分布式事务继续执行的呢？ 所以，TCC 事务框架都是要记录一些分布式事务的活动日志的，可以在磁盘上的日志文件里记录，也可以在数据库里记录。保存下来分布式事务运行的各个阶段和状态。 万一某个服务的 Cancel 或者 Confirm 逻辑执行一直失败怎么办呢？ TCC 事务框架会通过活动日志记录各个服务的状态。举个例子，比如发现某个服务的 Cancel 或者 Confirm 一直没成功，会不停的重试调用它的 Cancel 或者 Confirm 逻辑，务必要它成功！ 3.2 最大努力通知方案最大努力通知方案主要也是借助MQ消息系统来进行事务控制，这一点与可靠消息最终一致方案一样。它是比较简单的分布式事务方案，它本质上就是通过定期校对，实现数据一致性。 一、最大努力通知方案的实现 业务活动的主动方，在完成业务处理之后，向业务活动的被动方发送消息，允许消息丢失。 主动方可以设置时间阶梯型通知规则，在通知失败后按规则重复通知，直到通知N次后不再通知。 主动方提供校对查询接口给被动方按需校对查询，用于恢复丢失的业务消息。 业务活动的被动方如果正常接收了数据，就正常返回响应，并结束事务。 如果被动方没有正常接收，根据定时策略，向业务活动主动方查询，恢复丢失的业务消息。 二、最大努力通知方案的特点 用到的服务模式：可查询操作、幂等操作。 被动方的处理结果不影响主动方的处理结果； 适用于对业务最终一致性的时间敏感度低的系统； 适合跨企业的系统间的操作，或者企业内部比较独立的系统间的操作，比如银行通知、商户通知等 举例说明：短信服务场景 在登录、注册、验证场景，业务节点需要通过短信供应商发送验证短信给用户，用户通过短信验证码进行登录。 在这个场景中，短信服务供应商是业务主动方，服务端业务是被动方，需要等待主动方的通知 事务体现：服务端的登录和请求短信服务这两个操应该是一组 再一个例子就是：支付服务场景 支付宝、微信为支付服务的主动方 接入支付服务的应用为被动方 3.3 基于事务消息的最终一致方案RocketMQ的TransactionProducer(事务消息) RocketMQ和其他消息中间件最大的一个区别是支持了事务消息，这也是分布式事务里面的基于消息的最终一致性方案 3.3.1 RocketMQ消息的事务架构设计 生产者执行本地事务，修改订单支付状态，并且提交事务 生产者发送事务消息到broker上，消息发送到broker上在没有确认之前，消息对于consumer是不可见状态 生产者确认事务消息，使得发送到broker上的事务消息对于消费者可见 消费者获取到消息进行消费，消费完之后执行ack进行确认 这里可能会存在一个问题，生产者本地事务成功后，发送事务确认消息到broker上失败了怎么办？这个时候意味着消费者无法正常消费到这个消息。所以RocketMQ提供了消息回查机制，如果事务消息一直处于中间状态，broker会发起重试去查询broker上这个事务的处理状态。一旦发现 事务处理成功，则把当前这条消息设置为可见 注意：本地事务提交之后就不能再回滚了，保证最终一致性的分布式事务中，当下游业务出现异常，要做的不是去回滚上游的业务，而是重试出现异常的业务，直到成功为止，保证业务的最终一致性。 3.3.2 事务消息的实践通过一个下单以后扣减库存的数据一致性场景来演示RocketMQ的分布式事务特性 12345678910111213141516171819public class TransactionProducer &#123; public static void main(String[] args) throws MQClientException, UnsupportedEncodingException, InterruptedException &#123; TransactionMQProducer transactionProducer = new TransactionMQProducer(\"tx_producer_group\"); transactionProducer.setNamesrvAddr(\"10.0.12.76:9876\"); ExecutorService executorService = Executors.newFixedThreadPool(8); transactionProducer.setExecutorService(executorService); transactionProducer.setTransactionListener(new TransactionListenerLocal()); transactionProducer.start(); for(int i=0;i&lt;20;i++) &#123; String orderId= UUID.randomUUID().toString(); String body=\"&#123;'operation':'doOrder','orderId':'\"+orderId+\"'&#125;\"; Message message = new Message(\"pay_tx_topic\", \"TagA\",orderId, body.getBytes(RemotingHelper.DEFAULT_CHARSET)); transactionProducer.sendMessageInTransaction(message, orderId+\"&amp;\"+i); Thread.sleep(1000); &#125; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334public class TransactionListenerLocal implements TransactionListener &#123; private static final Map&lt;String,Boolean&gt; results=new ConcurrentHashMap&lt;&gt;(); /** * 执行本地事务 */ @Override public LocalTransactionState executeLocalTransaction(Message msg, Object arg) &#123; System.out.println(\":执行本地事务:\"+arg.toString()); String orderId=arg.toString(); boolean rs = saveOrder(orderId);//模拟数据入库操作 return rs ? LocalTransactionState.COMMIT_MESSAGE:LocalTransactionState.UNKNOW; // 这个返回状态表示告诉broker这个事务消息是否被确认，允许给到consumer进行消费 // LocalTransactionState.ROLLBACK_MESSAGE 回滚 // LocalTransactionState.UNKNOW 未知 &#125; private boolean saveOrder(String orderId) &#123; //如果订单取模等于0，表示成功,否则表示失败 boolean success=Math.abs(Objects.hash(orderId))%2==0; results.put(orderId,success); return success; &#125; /** * 提供事务执行状态的回查方法，提供给broker回调 */ @Override public LocalTransactionState checkLocalTransaction(MessageExt msg) &#123; String orderId=msg.getKeys(); System.out.println(\"执行事务执行状态的回查，orderId:\"+orderId); boolean rs=Boolean.TRUE.equals(results.get(orderId)); System.out.println(\"回调:\"+rs); return rs?LocalTransactionState.COMMIT_MESSAGE: LocalTransactionState.ROLLBACK_MESSAGE; &#125;&#125; 1234567891011121314151617181920212223public class TransactionConsumer &#123; public static void main(String[] args) throws MQClientException, IOException &#123; DefaultMQPushConsumer defaultMQPushConsumer = new DefaultMQPushConsumer(\"tx_consumer_group\"); defaultMQPushConsumer.setNamesrvAddr(\"10.0.12.76:9876\"); defaultMQPushConsumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); defaultMQPushConsumer.subscribe(\"pay_tx_topic\",\"*\"); defaultMQPushConsumer.registerMessageListener((MessageListenerConcurrently) (msgs, context) -&gt; &#123; msgs.stream().forEach(messageExt -&gt; &#123; try &#123; String orderId=messageExt.getKeys(); String body=new String(messageExt.getBody(), RemotingHelper.DEFAULT_CHARSET); System.out.println(\"收到消息:\"+body+\"，开始扣减库存:\"+orderId); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; &#125;); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;); defaultMQPushConsumer.start(); System.in.read(); &#125;&#125; 3.3.3 RocketMQ事务消息的三种状态 ROLLBACK_MESSAGE：回滚事务 COMMIT_MESSAGE：提交事务 UNKNOW： broker会定时的回查Producer消息状态，直到彻底成功或失败。 当executeLocalTransaction方法返回ROLLBACK_MESSAGE时，表示直接回滚事务 当返回 COMMIT_MESSAGE提交事务 当返回UNKNOW时，Broker会在一段时间之后回查checkLocalTransaction，根据 checkLocalTransaction返回状态执行事务的操作(回滚或提交)。 如示例中，当返回ROLLBACK_MESSAGE时消费者不会收到消息，且不会调用回查函数，当返回 COMMIT_MESSAGE时事务提交，消费者收到消息，当返回UNKNOW时，在一段时间之后调用回查函 数，并根据status判断返回提交或回滚状态，返回提交状态的消息将会被消费者消费，所以此时消费者 可以消费部分消息","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://zzkenyon.github.io/categories/消息中间件/"}],"tags":[{"name":"rocketmq","slug":"rocketmq","permalink":"https://zzkenyon.github.io/tags/rocketmq/"}],"keywords":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://zzkenyon.github.io/categories/消息中间件/"}]},{"title":"rocketmq-消息的存储和发送","slug":"MQ-rocketmq消息的存储和发送","date":"2019-08-11T16:00:00.000Z","updated":"2020-07-06T05:32:33.749Z","comments":true,"path":"2019/08/12/MQ-rocketmq消息的存储和发送/","link":"","permalink":"https://zzkenyon.github.io/2019/08/12/MQ-rocketmq消息的存储和发送/","excerpt":"","text":"由于分布式消息队列对于可靠性的要求比较高，所以需要保证生产者将消息发送到broker之后，保证消 息是不出现丢失的，因此消息队列就少不了对于可靠性存储的要求。 MQ消息存储选择 从主流的几种MQ消息队列采用的存储方式来看，主要会有三种 分布式KV存储，比如ActiveMQ中采用的levelDB、Redis， 这种存储方式对于消息读写能力要求不 高的情况下可以使用 文件系统存储，常见的比如kafka、RocketMQ、RabbitMQ都是采用消息刷盘到所部署的机器上的 文件系统来做持久化，这种方案适合对于有高吞吐量要求的消息中间件，因为消息刷盘是一种高效 率，高可靠、高性能的持久化方式，除非磁盘出现故障，否则一般是不会出现无法持久化的问题 关系型数据库，比如ActiveMQ可以采用mysql作为消息存储，关系型数据库在单表数据量达到千 万级的情况下IO性能会出现瓶颈，所以ActiveMQ并不适合于高吞吐量的消息队列场景。 总的来说，对于存储效率，文件系统要优于分布式KV存储，分布式KV存储要优于关系型数据库 RocketMQ就是采用文件系统的方式来存储消息，消息的存储是由ConsumeQueue和CommitLog配合 完成的。CommitLog是消息真正的物理存储文件。ConsumeQueue是消息的逻辑队列，有点类似于数据库的索引文件，里面存储的是指向CommitLog文件中消息存储的地址。 每个Topic下的每个Message Queue都会对应一个ConsumeQueue文件，文件的地址是: {store_home}/consumequeue/{topicNmae}/{queueId}/​{filename}，默认路径: /root/store 在rocketMQ的文件存储目录下，可以看到这样一个结构的的而文件。 我们只需要关心Commitlog、Consumequeue、Index。 CommitLog CommitLog是用来存放消息的物理文件，每个broker上的commitLog被当前机器上的所有 consumerQueue共享，不做任何的区分。 CommitLog中的文件默认大小为1G，可以动态配置；当一个文件写满以后，会生成一个新的 commitlog文件。所有的Topic数据是顺序写入在CommitLog文件中的。 文件名的长度为20位，左边补0，剩余未起始偏移量，比如 00000000000000000000 表示第一个文件， 文件大小为1024X1024X1024，当第一个文件写满之后，生 成第二个文件 000000000001073741824 表示第二个文件，起始偏移量为1073741824 ConsumeQueue consumeQueue表示消息消费的逻辑队列，这里面包含MessageQueue在commitlog中的其实物理位 置偏移量offset，消息实体内容的大小和Message Tag的hash值。对于实际物理存储来说， consumeQueue对应每个topic和queueid下的文件，每个consumeQueue类型的文件也是有大小，每 个文件默认大小约为600W个字节，如果文件满了后会也会生成一个新的文件 IndexFile 索引文件，如果一个消息包含Key值的话，会使用IndexFile存储消息索引。Index索引文件提供了对 CommitLog进行数据检索，提供了一种通过key或者时间区间来查找CommitLog中的消息的方法。在物 理存储中，文件名是以创建的时间戳命名，固定的单个IndexFile大小大概为400M，一个IndexFile可以 保存2000W个索引 abort broker在启动的时候会创建一个空的名为abort的文件，并在shutdown时将其删除，用于标识进程是否正常退出，如果不正常退出，会在启动时做故障恢复 消息存储的整体结构 RocketMQ的消息存储采用的是混合型的存储结构，也就是Broker单个实例下的所有队列公用一个日志 数据文件CommitLog。这个是和Kafka又一个不同之处。 为什么不采用kafka的设计，针对不同的partition存储一个独立的物理文件呢?这是因为在kafka的设计 中，一旦kafka中Topic的Partition数量过多，队列文件会过多，那么会给磁盘的IO读写造成比较大的压 力，也就造成了性能瓶颈。所以RocketMQ进行了优化，消息主题统一存储在CommitLog中。 当然，这种设计并不是银弹，它也有它的优缺点： 优点在于:由于消息主题都是通过CommitLog来进行读写，ConsumerQueue中只存储很少的数据， 所以队列更加轻量化。对于磁盘的访问是串行化从而避免了磁盘的竞争 缺点在于:消息写入磁盘虽然是基于顺序写，但是读的过程确是随机的。读取一条消息会先读取 ConsumeQueue，再读CommitLog，会降低消息读的效率。 消息发送到消息接收的整体流程 Producer将消息发送到Broker后，Broker会采用同步或者异步的方式把消息写入到CommitLog。 RocketMQ所有的消息都会存放在CommitLog中，为了保证消息存储不发生混乱，对CommitLog 写之前会加锁，同时也可以使得消息能够被顺序写入到CommitLog，只要消息被持久化到磁盘文 件CommitLog，那么就可以保证Producer发送的消息不会丢失。 commitLog持久化后，会把里面的消息Dispatch到对应的Consume Queue上，Consume Queue 相当于kafka中的partition，是一个逻辑队列，queue中的消息存储了这个实际的消息在CommiLog中的起始offset， log大小和MessageTag的hashCode。 当消费者进行消息消费时，会先读取consumerQueue , 逻辑消费队列ConsumeQueue保存了指 定Topic下的队列消息在CommitLog中的起始物理偏移量Offset，消息大小、和消息Tag的 HashCode值 直接从consumequeue中读取消息是没有数据的，真正的消息主体在commitlog中，所以还需要 从commitlog中读取消息 什么时候清理物理消息文件?消息存储在CommitLog之后，的确是会被清理的，但是这个清理只会在以下任一条件成立才会批量删除消息文件(CommitLog): 消息文件过期(默认72小时)，且到达清理时点(默认是凌晨4点)，删除过期文件。 消息文件过期(默认72小时)，且磁盘空间达到了水位线(默认75%)，删除过期文件。 磁盘已经达到必须释放的上限(85%水位线)的时候，则开始批量清理文件(无论是否过期)，直到空间充足。 注:若磁盘空间达到危险水位线(默认90%)，出于保护自身的目的，broker会拒绝写入服务。","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://zzkenyon.github.io/categories/消息中间件/"}],"tags":[{"name":"rocketmq","slug":"rocketmq","permalink":"https://zzkenyon.github.io/tags/rocketmq/"}],"keywords":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://zzkenyon.github.io/categories/消息中间件/"}]},{"title":"rocketmq-基本原理分析","slug":"MQ-rocketmq基本原理分析","date":"2019-08-09T16:00:00.000Z","updated":"2020-11-19T01:11:05.137Z","comments":true,"path":"2019/08/10/MQ-rocketmq基本原理分析/","link":"","permalink":"https://zzkenyon.github.io/2019/08/10/MQ-rocketmq基本原理分析/","excerpt":"","text":"阿里巴巴在2012年开源，2017年成为apache顶级项目 核心设计几件了kafka，所以我们在了解rockeetMq时会发现很多和kafka相同的特性。同时，它在某些功能上氪kafka又有较大的差异。 rocketMQ 特性： 支持集群模型，负载均衡、水平扩展 亿级别消息堆积能力 采用零拷贝原理。顺序写磁盘。随机读 底层通信使用netty 使用nameservice代替zookeeper 实现服务寻址和服务协调 消息失败重试机制，消息可查询 强调集群无单点。可扩展，任意一点高可用， 经过多次双十一的考验 1. 架构介绍集群本身没有什么特殊之处，和kafka整体架构类似，使用NameService代理Zookeeper。在rocketmq的早版本(2.x)的时候，是没有namesrv组件的，用的是zookeeper做分布式协调 和服务发现，但是后期阿里数据根据实际业务需求进行改进和优化，自组研发了轻量级的 namesrv，用于注册Client服务与Broker的请求路由工作，namesrv上不做任何消息的位置存储， 频繁操作zookeeper的位置存储数据会影响整体集群性能。 Rocket由四部分组成： Name Server 可集群部署，节点之间无任何信息同步。提供轻量级的服务发现和路由 Broker(消息中转角色，负责存储消息，转发消息) 部署相对复杂，Broker 分为Master 与Slave，一 个Master 可以对应多个Slave，但是一个Slave 只能对应一个Master，Master 与Slave 的对应关系通过 指定相同的BrokerName，不同的BrokerId来定 义，BrokerId为0 表示Master，非0 表示Slave。 Master 也可以部署多个。 Producer，生产者，拥有相同 Producer Group 的 Producer 组成一个集群， 与Name Server 集群 中的其中一个节点(随机选择)建立长连接，定期从Name Server 取Topic 路由信息，并向提供Topic 服务的Master 建立长连接，且定时向Master 发送心跳。Producer 完全无状态，可集群部署。 Consumer，消费者，接收消息进行消费的实例，拥有相同 Consumer Group 的 Consumer 组成 一个集群，与Name Server 集群中的其中一个节点(随机选择)建立长连接，定期从Name Server 取 Topic 路由信息，并向提供Topic 服务的Master、Slave 建立长连接，且定时向Master、Slave 发送心 跳。Consumer既可以从Master 订阅消息，也可以从Slave 订阅消息，订阅规则由Broker 配置决定。 要使用rocketmq，至少需要启动两个进程，nameserver、broker，前者是各种topic注册中心，后者 是真正的broker。 2. 单机部署 下载压缩包并解压： 1unzip rocketmq-all-4.7.0-bin-release.zip 启动namesrv 进入bin目录 1nohup sh mqnamesrv &amp; 默认情况下，nameserver监听的是9876端口。 使用下面命令查看启动日志： 1tail -f ~/logs/rocketmqlogs/namesrv.log 启动broker 修改conf/broker.conf文件，插入配置：brokerIP1=10.0.12.76（公网ip） ，如此设置才能实现跨域请求 使用以下命令启动broker： 12nohup sh bin/mqbroker -n $&#123;namesrvIp&#125;:9876 -c /conf/broker.conf &amp;# namesrvIp 为当前节点的公网ip 内存不足问题 这是因为bin 目录下启动 nameserv 与 broker 的 runbroker.sh 和 runserver.sh 文件中默认分配的内 存太大，rocketmq比较耗内存，所以默认分配的内存比较大，而系统实际内存却太小导致启动失败， 通常像虚拟机上安装的 CentOS 服务器内存可能是没有高的，只能调小。实际中应该根据服务器内存情 况，配置一个合适的值 修改runbroker.sh和runbroker.sh 停止服务 停止服务的时候需要注意，要先停止broker，其次停止nameserver。 12sh bin/mqshutdown brokersh bin/mqshutdown namesrv broker.conf文件 默认情况下，启动broker会加载conf/broker.conf文件，这个文件里面就是一些常规的配置信息 12345namesrvAddr //nameserver地址brokerCl usterName //Cluster名称，如果集群机器数比较多，可以分成多个cluster，每个cluster提供 给不同的业务场景使用brokerName //broker名称，如果配置主从模式，master和slave需要配置相同的名称来表名关系 brokerId=0 //在主从模式中，一个master broker可以有多个slave，0表示master，大于0表示不同slave的idbrokerRole=SYNC_MASTER/ASYNC_MASTER/SLAVE //同步表示slave和master消息同步完成后再返回信息给客户端autoCreateTopicEnable = true // topic不存在的情况下自动创建 3. 二主二从异步集群部署第一台机器 10.0.12.74端口规划：9876 NameServer110910 BrokerA-master10921 BrokerB-slave 第二台机器 10.0.12.76端口规划：9876 NameServer210920 BrokerB-master10911 BrokerA-slave 3.1 下载从官网首页最新发布版本进入下载地址http://rocketmq.apache.org/ 比如： 12cd /usr/local/appwget https://mirror.bit.edu.cn/apache/rocketmq/4.7.1/rocketmq-all-4.7.1-bin-release.zip 3.2 解压解压后，把文件夹改个名字 12unzip rocketmq-all-4.7.1-bin-release.zipmv rocketmq-all-4.7.1-bin-release rocketmq 在两台机器上都下载、解压好。在rocketmq/conf目录下，有三种建议配置模式：2m-2s-async(2主2从异步) —— 本文采用这种2m-2s-sync (2主2从同步)2m-noslave (2主) 现在需要修改两台机器上2m-2s-async这个目录中的文件。配置文件修改之前先备份。 3.3 配置第一台机器10.0.12.74的两个配置文件 （1）broker-a.properties 12cd /usr/local/app/rocketmq/conf/2m-2s-asyncvim broker-a.properties 修改的内容（名字自定义，保持一致，否则不能组成集群） 1brokerClusterName=qingshan-cluster 增加的内容 1234567891011121314151617181920#Broker 对外服务的监听端口listenPort=10910#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#nameServer地址，分号分割namesrvAddr=10.0.12.74:9876;10.0.12.76:9876#存储路径storePathRootDir=/usr/local/app/rocketmq/store/broker-a#commitLog 存储路径storePathCommitLog=/usr/local/app/rocketmq/store/broker-a/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/usr/local/app/rocketmq/store/broker-a/consumequeue#消息索引存储路径storePathIndex=/usr/local/app/rocketmq/store/broker-a/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/app/rocketmq/store/checkpoint#abort 文件存储路径abortFile=/usr/local/app/rocketmq/store/abort （2）broker-b-s.properties 1vim broker-b-s.properties 修改的内容（名字自定义，保持一致，否则不能组成集群） 1brokerClusterName=qingshan-cluster 增加的内容： 1234567891011121314151617181920#Broker 对外服务的监听端口listenPort=10921#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#nameServer地址，分号分割namesrvAddr=10.0.12.74:9876;10.0.12.76:9876#存储路径storePathRootDir=/usr/local/app/rocketmq/store/broker-b-s#commitLog 存储路径storePathCommitLog=/usr/local/app/rocketmq/store/broker-b-s/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/usr/local/app/rocketmq/store/broker-b-s/consumequeue#消息索引存储路径storePathIndex=/usr/local/app/rocketmq/store/broker-b-s/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/app/rocketmq/store/checkpoint#abort 文件存储路径abortFile=/usr/local/app/rocketmq/store/abort 3.4 配置第二台机器10.0.12.76的两个配置文件修改的内容基本一致，主要是注意一下端口号、路径名。 （1）broker-b.properties 12cd /usr/local/app/rocketmq/conf/2m-2s-asyncvim broker-b.properties 修改的内容（名字自定义，保持一致，否则不能组成集群） 1brokerClusterName=qingshan-cluster 增加的内容 1234567891011121314151617181920#Broker 对外服务的监听端口listenPort=10920#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#nameServer地址，分号分割namesrvAddr=10.0.12.74:9876;10.0.12.76:9876#存储路径storePathRootDir=/usr/local/app/rocketmq/store/broker-b#commitLog 存储路径storePathCommitLog=/usr/local/app/rocketmq/store/broker-b/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/usr/local/app/rocketmq/store/broker-b/consumequeue#消息索引存储路径storePathIndex=/usr/local/app/rocketmq/store/broker-b/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/app/rocketmq/store/checkpoint#abort 文件存储路径abortFile=/usr/local/app/rocketmq/store/abort （2）broker-a-s.properties 12cd /usr/local/app/rocketmq/conf/2m-2s-asyncvim broker-a-s.properties 修改的内容（名字自定义，保持一致，否则不能组成集群） 1brokerClusterName=qingshan-cluster 增加的内容： 1234567891011121314151617181920#Broker 对外服务的监听端口listenPort=10911#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#nameServer地址，分号分割namesrvAddr=10.0.12.74:9876;10.0.12.76:9876#存储路径storePathRootDir=/usr/local/app/rocketmq/store/broker-a-s#commitLog 存储路径storePathCommitLog=/usr/local/app/rocketmq/store/broker-a-s/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/usr/local/app/rocketmq/store/broker-a-s/consumequeue#消息索引存储路径storePathIndex=/usr/local/app/rocketmq/store/broker-a-s/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/app/rocketmq/store/checkpoint#abort 文件存储路径abortFile=/usr/local/app/rocketmq/store/abort 3.5 创建数据目录第一台机器163执行（只需要执行一次） 1mkdir -p /usr/local/app/rocketmq/store/broker-a /usr/local/app/rocketmq/store/broker-a/consumequeue /usr/local/app/rocketmq/store/broker-a/commitlog /usr/local/app/rocketmq/store/broker-a/index /usr/local/app/rocketmq/logs /usr/local/app/rocketmq/store/broker-b-s /usr/local/app/rocketmq/store/broker-b-s/consumequeue /usr/local/app/rocketmq/store/broker-b-s/commitlog /usr/local/app/rocketmq/store/broker-b-s/index 第二台机器164执行（只需要执行一次） 1mkdir -p /usr/local/app/rocketmq/store/broker-a-s /usr/local/app/rocketmq/store/broker-a-s/consumequeue /usr/local/app/rocketmq/store/broker-a-s/commitlog /usr/local/app/rocketmq/store/broker-a-s/index /usr/local/app/rocketmq/logs /usr/local/app/rocketmq/store/broker-b /usr/local/app/rocketmq/store/broker-b/consumequeue /usr/local/app/rocketmq/store/broker-b/commitlog /usr/local/app/rocketmq/store/broker-b/index 3.6 启动两个NameServer启动第一台机器163的NameServer 1nohup sh /usr/local/app/rocketmq/bin/mqnamesrv &gt;/usr/local/app/rocketmq/logs/mqnamesrv.log 2&gt;&amp;1 &amp; 启动第二台机器164的NameServer 1nohup sh /usr/local/app/rocketmq/bin/mqnamesrv &gt;/usr/local/app/rocketmq/logs/mqnamesrv.log 2&gt;&amp;1 &amp; 3.7 启动Broker1、启动节点1 163的 broker-a-master在163上面执行 1nohup sh /usr/local/app/rocketmq/bin/mqbroker -c /usr/local/app/rocketmq/conf/2m-2s-async/broker-a.properties &gt; /usr/local/app/rocketmq/logs/broker-a.log 2&gt;&amp;1 &amp; 在虚拟机中可能由于内存不够导致无法启动，日志文件中出现如下错误： 123nohup: ignoring inputJava HotSpot(TM) 64-Bit Server VM warning: INFO: os::commit_memory(0x00000005c0000000, 8589934592, 0) failed; error=&apos;Cannot allocate memory&apos; (errno=12)vim /usr/local/app/rocketmq/bin/runbroker.sh 把8g和4g改成512m和256m 1JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms512m -Xmx512m -Xmn256m&quot; 再次启动。 2、启动节点2 164的broker-a-s在164上面执行 1nohup sh /usr/local/app/rocketmq/bin/mqbroker -c /usr/local/app/rocketmq/conf/2m-2s-async/broker-a-s.properties &gt; /usr/local/app/rocketmq/logs/broker-a-s.log 2&gt;&amp;1 &amp; 3、启动节点2 164的 broker-b-master在164上面执行 1nohup sh /usr/local/app/rocketmq/bin/mqbroker -c /usr/local/app/rocketmq/conf/2m-2s-async/broker-b.properties &gt; /usr/local/app/rocketmq/logs/broker-b.log 2&gt;&amp;1 &amp; 4、启动节点1 163的broker-b-s在163上面执行 1nohup sh /usr/local/app/rocketmq/bin/mqbroker -c /usr/local/app/rocketmq/conf/2m-2s-async/broker-b-s.properties &gt; /usr/local/app/rocketmq/logs/broker-b-s.log 2&gt;&amp;1 &amp; 查看端口启动状态：netstat -an|grep 109 4. 部署web-console一、下载项目源代码 12cd /usr/local/appwget https://github.com/apache/rocketmq-externals/archive/master.zip 下载慢可以用复制链接到迅雷里面。或者从百度网盘下载：链接：https://pan.baidu.com/s/1O4QnrltZvXgtSGwoqcjcMw提取码：2673 解压： 1unzip master.zip 解压出来的文件夹名字：rocketmq-externals-master 二、修改配置文件 12cd /usr/local/app/rocketmq-externals-master/rocketmq-console/src/main/resources/vim application.properties 修改端口号： 1server.port=7298 修改name server地址（多个地址用英文分号隔开） 1rocketmq.config.namesrvAddr=10.0.12.76:9876 注意后面改了配置文件要重新打包 三、解压编译 12cd /usr/local/app/rocketmq-externals-master/rocketmq-console/mvn clean package -Dmaven.test.skip=true 四、启动jar包 12cd targetjava -jar rocketmq-console-ng-2.0.0.jar 五、访问http://10.0.12.76:7298 六、日志日志配置： 1rocketmq-externals-master/rocketmq-console/src/main/resources/application.properties 指定了logback.xml 为日志配置文件 1&lt;file&gt;$&#123;user.home&#125;/logs/consolelogs/rocketmq-console.log&lt;/file&gt; 实际路径 1cd ~/logs/consolelogs/rocketmq-console.log 5. 原生API调用添加 jar包依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-client&lt;/artifactId&gt; &lt;version&gt;4.7.0&lt;/version&gt;&lt;/dependency&gt; 1234567891011121314151617181920public class RocketMqProducer &#123; public static void main(String[] args) throws MQClientException, InterruptedException &#123; DefaultMQProducer producer = new DefaultMQProducer(\"pd_producer_group\"); producer.setNamesrvAddr(\"10.0.12.76:9876\"); producer.setSendMsgTimeout(60000); producer.start(); for(int i = 0; i &lt; 20; i++)&#123; try &#123; Message message = new Message(\"test-topic\",\"panda\",(\"Hello Rocketmq \" + i) .getBytes(RemotingHelper.DEFAULT_CHARSET)); System.out.println(producer.send(message)); &#125; catch (UnsupportedEncodingException | RemotingException | InterruptedException | MQBrokerException e) &#123; e.printStackTrace(); Thread.sleep(1000); &#125; &#125; producer.shutdown(); &#125;&#125; 12345678910111213141516171819202122public class RocketMqConsumer &#123; public static void main(String[] args) throws MQClientException &#123; DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"pd_consumer_group\"); consumer.setNamesrvAddr(\"10.0.12.076:9876\"); consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); consumer.subscribe(\"test-topic\",\"*\"); consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; for(MessageExt messageExt : msgs) &#123; if(messageExt.getReconsumeTimes() == 5)&#123; // TODO 可以将对应的数据保存到数据库，以便人工干预 &#125; System.out.println(messageExt.getMsgId()+\",\"+messageExt.getBody()); &#125; return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); consumer.start(); System.out.println(\"Consumer Started.%n\"); &#125;&#125; 5.1 RocketMQ消息支持的模式NormalProducer 消息同步发送 消息发送出去之后。procuder会等到broker回应后才能继续发送下一个消息 消息异步发送 异步发送是指发送方在发出数据之后，不等接收方响应，接着发送下一个数据包的通信方式。MQ的异步发送需要用户实现异步调用接口（SendCallback）。消息发送方在发送了一条消息后，不需要等待服务器响应即可返回，发送发通过毁掉接口接收服务器响应，并对相应结果进行处理 OneWay 单向发送特点为发送方只负责发送消息，不等待服务器回应且没有回调函数触发。只发送不管响应，效率最高 OrderProducer 前面我们学习kafka的时候有说到，消息可以通过自定义分区策略来实现消息的顺序发送，实现原理就是把同一类消息都发送到相同的分区上。 在RocketMQ中，是基于多个Message Queue来实现类似于kafka的分区效果。如果一个Topic 要发送 和接收的数据量非常大， 需要能支持增加并行处理的机器来提高处理速度，这时候一个Topic 可以根据 需求设置一个或多个Message Queue。Topic 有了多个Message Queue 后，消息可以并行地向各个 Message Queue 发送，消费者也可以并行地从多个Message Queue 读取消息并消费。 要了解RocketMQ消息的顺序消费，还得对RocketMQ的整体架构有一定的了解 5.2 RocketMQ消息发送及消费的基本原理这是一个比较宏观的部署架构图，rocketmq天然支持高可用，它可以支持多主多从的部署架构，这也 是和kafka最大的区别之一 RocketMQ中并没有master选举功能，所以通过配置多个master节点来保证rocketMQ的高可 用。和所有的集群角色定位一样，master节点负责接受事务请求、slave节点只负责接收读请求，并且接收master同步过来的数据和slave保持一致。当master挂了以后，如果当前rocketmq是一主多从， 就意味着无法接受发送端的消息，但是消费者仍然能够继续消费。所以配置多个主节点后，可以保证当其中一个master节点挂了，另外一个master节点仍然能够对外提 供消息发送服务。 当存在多个主节点时，一条消息只会发送到其中一个主节点，rocketmq对于多个master节点的消息发 送，会做负载均衡，使得消息可以平衡的发送到多个master节点上。一个消费者可以同时消费多个master节点上的消息，在下面这个架构图中，两个master节点恰好可以 平均分发到两个消费者上，如果此时只有一个消费者，那么这个消费者会消费两个master节点的数据。 由于每个master可以配置多个slave，所以如果其中一个master挂了，消息仍然可以被消费者从slave节 点消费到。可以完美的实现rocketmq消息的高可用 接下来，站在topic的角度来看看消息是如何分发和处理的，假设有两个master节点的集群，创建了一 个TestTopic，并且对这个topic创建了两个队列，也就是分区。 消费者定义了两个分组，分组的概念也是和kafka一样，通过分组可以实现消息的广播。 5.3 集群支持RocketMQ天生对集群的支持非常友好 单Master 优点:除了配置简单没什么优点 缺点:不可靠，该机器重启或宕机，将导致整个服务不可用 多Master 优点:配置简单，性能最高 缺点:可能会有少量消息丢失(配置相关)，单台机器重启或宕机期间，该机器下未被消费的消息在机器恢复前不可订阅，影响消息实时性 多Master多Slave，每个Master配一个Slave，有多对Master-Slave 集群采用异步复制方式，主备 有短暂消息延迟，毫秒级 优点:性能同多Master几乎一样，实时性高，主备间切换对应用透明，不需人工干预 缺点:Master宕机或磁盘损坏时会有少量消息丢失 多Master多Slave，每个Master配一个Slave，有多对Master-Slave 集群采用同步双写方式，主备 都写成功，向应用返回成功 优点:服务可用性与数据可用性非常高 缺点:性能比异步集群略低，当前版本主宕备不能自动切换为主 需要注意的是，在RocketMQ里面，1台机器只能要么是Master，要么是Slave。这个在初始的机器配置 里面，就定死了。不会像kafka那样存在master动态选举的功能。其中Master的broker id = 0，Slave 的broker id &gt; 0。 有点类似于mysql的主从概念，master挂了以后，slave仍然可以提供读服务，但是由于有多主的存 在，当一个master挂了以后，可以写到其他的master上。 5.4 消息的顺序消费首先，需要保证顺序的消息要发送到同一个messagequeue中;其次，一个messagequeue只能被一个 消费者消费，这点是由消息队列的分配机制来保证的;最后，一个消费者内部对一个mq的消费要保证 是有序的。 我们要做到生产者 - messagequeue - 消费者之间是一对一对一的关系。 通过自定义发送策略来实现消息只发送到同一个队列，保证消息的顺序存储 因为一个Topic 会有多个Message Queue ，如果使用Producer 的默认配置，这个Producer 会轮流向 各个Message Queue 发送消息。Consumer 在消费消息的时候，会根据负载均衡策略，消费被分配到 的Message Queue，如果不经过特定的设置，某条消息被发往哪个Message Queue ，被哪个Consumer 消费是未知的 如果业务需要我们把消息发送到指定的Message Queue 里，比如把同一类型的消息都发往相同的Message Queue。那是不是可以实现顺序消息的功能呢? 和kafka一样，rocketMQ也提供了消息路由的功能，我们可以自定义消息分发策略，可以实现 MessageQueueSelector，来实现自己的消息分发策略 12345678Message message = new Message(\"test-topic\",\"panda\",(\"Hello Rocketmq \" + i) .getBytes(RemotingHelper.DEFAULT_CHARSET));System.out.println(producer.send(message, new MessageQueueSelector() &#123; @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; return mqs.get(0); //选择第1个队列 &#125;&#125;,\"panda\")); // \"panda\" 可以作为选择队列的参数，上面select方法的形参arg将接受这个值 如何保证消息消费顺序呢? 通过分区规则可以实现同类消息在rocketmq上的顺序存储。但是对于消费端来说，如何保证消费的顺序? 我们前面写的消息消费代码使用的是MessageListenerConcurrently并发监听，也就是基于多个线程并 行来消费消息。这个无法保证消息消费的顺序。 RocketMQ中提供了MessageListenerOrderly 类来实现顺序消费 1234567consumer.registerMessageListener(new MessageListenerOrderly() &#123; @Override public ConsumeOrderlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeOrderlyContext context) &#123; msgs.stream().forEach(messageExt -&gt; System.out.println(new String(messageExt.getBody()))); return ConsumeOrderlyStatus.SUCCESS; &#125;&#125;); 顺序消费会带来一些问题: 遇到消息失败的消息，无法跳过，当前队列消费暂停 降低了消息处理的性能 6. 消费端的负载均衡和kafka一样，消费端也会针对Message Queue做负载均衡，使得每个消费者能够合理的消费多个分区 的消息。 消费端会通过RebalanceService线程，10秒钟做一次基于topic下的所有队列负载 消费端遍历自己的所有topic，依次调rebalanceByTopic 根据topic获取此topic下的所有queue 选择一台broker获取基于group的所有消费端(有心跳向所有broker注册客户端信息) 选择队列分配策略实例AllocateMessageQueueStrategy执行分配算法 什么时候触发负载均衡 消费者启动之后 消费者数量发生变更 每10秒会触发检查一次rebalance 分配算法 RocketMQ提供了6中分区的分配算法： (AllocateMessageQueueAveragely)平均分配算法(默认) (AllocateMessageQueueAveragelyByCircle)环状分配消息队列 (AllocateMessageQueueByConfig)按照配置来分配队列: 根据用户指定的配置来进行负载 (AllocateMessageQueueByMachineRoom)按照指定机房来配置队列 (AllocateMachineRoomNearby)按照就近机房来配置队列: (AllocateMessageQueueConsistentHash)一致性hash，根据消费者的cid进行 7. 消息的的可靠性原则在实际使用RocketMQ的时候我们并不能保证每次发送的消息都刚好能被消费者一次性正常消费成功， 可能会存在需要多次消费才能成功或者一直消费失败的情况，那作为发送者该做如何处理呢? 7.1 消息消费端的确认机制RocketMQ提供了ack机制，以保证消息能够被正常消费。发送者为了保证消息肯定消费成功，只有使 用方明确表示消费成功，RocketMQ才会认为消息消费成功。中途断电，抛出异常等都不会认为成功 1234567consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(\"%s Receive New Messages: %s %n\", Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;&#125;); 所有消费者在设置监听的时候会提供一个回调，业务实现消费回调的时候，当回调方法中返回 ConsumeConcurrentlyStatus.CONSUME_SUCCESS，RocketMQ才会认为这批消息(默认是1条)是 消费完成的。如果这时候消息消费失败，例如数据库异常，余额不足扣款失败等一切业务认为消息需要重试的场景，只要返回ConsumeConcurrentlyStatus.RECONSUME_LATER，RocketMQ就会认为这批 消息消费失败了 7.2 消息的衰减重试为了保证消息肯定至少被消费一次，RocketMQ会把这批消息重新发回到broker，在延迟的某个时间点 (默认是10秒，业务可设置)后，再次投递到这个ConsumerGroup。而如果一直这样重复消费都持续 失败到一定次数(默认16次)，就会投递到DLQ死信队列。应用可以监控死信队列来做人工干预 可以修改broker-a.conf文件 1messageDelayLevel = 1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h 7.3 重试消息的处理机制一般情况下我们在实际生产中是不需要重试16次，这样既浪费时间又浪费性能，理论上当尝试重复次数 达到我们想要的结果时如果还是消费失败，那么我们需要将对应的消息进行记录，并且结束重复尝试 123456789101112consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; for(MessageExt messageExt : msgs) &#123; if(messageExt.getReconsumeTimes() == 5)&#123; // TODO 可以将对应的数据保存到数据库，以便人工干预 &#125; System.out.println(messageExt.getMsgId()+\",\"+messageExt.getBody()); &#125; return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;&#125;);","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://zzkenyon.github.io/categories/消息中间件/"}],"tags":[{"name":"rocketmq","slug":"rocketmq","permalink":"https://zzkenyon.github.io/tags/rocketmq/"}],"keywords":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://zzkenyon.github.io/categories/消息中间件/"}]},{"title":"docker-引擎安装与基本使用","slug":"docker-引擎安装与基本使用","date":"2019-08-07T16:00:00.000Z","updated":"2020-08-10T07:30:41.942Z","comments":true,"path":"2019/08/08/docker-引擎安装与基本使用/","link":"","permalink":"https://zzkenyon.github.io/2019/08/08/docker-引擎安装与基本使用/","excerpt":"","text":"1、安装docker第一步：卸载之前的docker 12345678sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 第二步：安装必要的依赖 123yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 第三步：设置docker仓库 1234#官方地址，龟速不推荐yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo#阿里云地址yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 第四步：安装docker 1yum install -y docker-ce docker-ce-cli containerd.io 第五步：配置阿里云镜像加速器 访问阿里云：https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors并用自己账号登录。 阿里云为每个账号都会生成一个加速url，这里配置不正确会导致docker启动失败。 123456mkdir -p /etc/dockervim /etc/docker/daemon.json &#123; \"registry-mirrors\": [\"https://XXXXX.mirror.aliyuncs.com\"]&#125;systemctl daemon-reload 第六步：启动docker 1systemctl start docker 第七步： 测试docker安装是否成功 1docker -v 2、 docker基本体验拉取镜像并运行 12docker pull tomcatdocker run -d --name my-tomcat -p 9090:8080 tomcat -d 表示以守护进程方式运行 –name 指定容器名称 -p 宿主机到容器的端口映射 9090是宿主机端口 进入到容器里面： 1docker exec -it containerid /bin/bash","categories":[{"name":"容器化技术","slug":"容器化技术","permalink":"https://zzkenyon.github.io/categories/容器化技术/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://zzkenyon.github.io/tags/docker/"}],"keywords":[{"name":"容器化技术","slug":"容器化技术","permalink":"https://zzkenyon.github.io/categories/容器化技术/"}]},{"title":"redis-键空间通知","slug":"redis-键空间通知","date":"2019-08-01T16:00:00.000Z","updated":"2020-12-30T06:43:37.057Z","comments":true,"path":"2019/08/02/redis-键空间通知/","link":"","permalink":"https://zzkenyon.github.io/2019/08/02/redis-键空间通知/","excerpt":"","text":"需求：redis中缓存了一些状态量，业务需要时刻关注状态量变化 方案一：轮询检查（各方面性能太差） 方案二：redis提供的键空间通知机制（redis主动推送，优选） 1、发布与订阅SUBSCRIBE /UNSUBSCRIBE/PUBLISH 三个命令实现了发布与订阅信息泛型（Publish/Subscribe messaging paradigm)，在这个实现中，发送者（发送信息的客户端）不是将信息直接发送给特定的接收者（接收信息的客户端），而是将信息发送给频道（channel），然后由频道将信息转发给所有对这个频道感兴趣的订阅者。 发送者无须知道任何关于订阅者的信息，而订阅者也无须知道是那个客户端给它发送信息，它只要关注自己感兴趣的频道即可。 对发布者和订阅者进行解构，可以极大地提高系统的扩展性，并得到一个更动态的网络拓扑。 比如说，要订阅频道foo和bar，客户端可以使用频道名字作为参数来调用 SUBSCRIBE 命令： 1SUBSCRIBE foo bar 当有客户端发送信息到这些频道时，Redis 会将传入的信息推送到所有订阅这些频道的客户端里面。 正在订阅频道的客户端不应该发送除 SUBSCRIBE 和 UNSUBSCRIBE 之外的其他命令。 其中，SUBSCRIBE 可以用于订阅更多频道，而 UNSUBSCRIBE 则可以用于退订已订阅的一个或多个频道。 SUBSCRIBE 和 UNSUBSCRIBE的执行结果会以信息的形式返回，客户端可以通过分析所接收信息的第一个元素，从而判断所收到的内容是一条真正的信息，还是 SUBSCRIBE 或 UNSUBSCRIBE 命令的操作结果。 1.1 信息格式频道转发的每条信息都是一条带有三个元素的多条批量回复。 第一个元素标识了信息的类型，有以下三种类型： subscribe： 表示当前客户端成功地订阅了信息第二个元素所指示的频道，而此时信息的第三个元素则记录了目前客户端已订阅频道的总数。 unsubscribe： 表示当前客户端成功地退订了信息第二个元素所指示的频道，而此时信息的第三个元素记录了客户端目前仍在订阅的频道数量。 当客户端订阅的频道数量降为0时，客户端不再订阅任何频道，它可以像往常一样，执行任何 Redis 命令。 message： 表示这条信息是由某个客户端执行 PUBLISH 命令所发送的，真正的信息。 第二个元素是信息来源的频道。 第三个元素则是信息的内容。 1.2 订阅模式Redis 的发布与订阅实现支持模式匹配： 客户端可以订阅一个带*号的模式，如果某些频道的名字和这个模式匹配，那么当有信息发送给这个/这些频道的时候，客户端也会收到这个/这些频道的信息。 比如说，执行命令 1PSUBSCRIBE news.* 的客户端将收到来自news.art.figurative、news.music.jazz等频道的信息。 客户端订阅的模式里面可以包含多个 glob 风格的通配符，比如*、?和[...]，等等。 执行命令 1PUNSUBSCRIBE news.* 将退订news.*模式，其他已订阅的模式不会被影响。 通过订阅模式接收到的信息，和通过订阅频道接收到的信息，两者的格式不太一样： 通过订阅模式而接收到的信息的类型为pmessage： 这代表有某个客户端通过 PUBLISH 向某个频道发送了信息，而这个频道刚好匹配了当前客户端所订阅的某个模式。 信息的第二个元素记录了被匹配的模式，第三个元素记录了被匹配的频道的名字，最后一个元素则记录了信息的实际内容。 客户端处理 PSUBSCRIBE 和 PUNSUBSCRIBE 返回值的方式，和客户端处理 SUBSCRIBE 和 UNSUBSCRIBE 的方式类似： 通过对信息的第一个元素进行分析，客户端可以判断接收到的信息是一个真正的信息，还是 PSUBSCRIBE 或 PUNSUBSCRIBE 命令的返回值。 2、发布什么键空间通知使得客户端可以通过订阅频道或模式，来接收那些以某种方式改动了 Redis 数据集的事件。 以下是一些键空间通知发送的事件的例子： 所有修改键的命令。 所有接收到 LPUSH 命令的键。 0号数据库中所有已过期的键。 事件通过 Redis 的订阅与发布功能（pub/sub）来进行分发，因此所有支持订阅与发布功能的客户端都可以在无须做任何修改的情况下，直接使用键空间通知功能。 因为 Redis 目前的订阅与发布功能采取的是发送即忘策略，所以如果你的程序需要可靠事件通知，那么目前的键空间通知可能并不适合你： 当订阅事件的客户端断线时，它会丢失所有在断线期间分发给它的事件。 未来将会支持更可靠的事件分发，这种支持可能会通过让订阅与发布功能本身变得更可靠来实现，也可能会在 Lua 脚本中对消息的订阅与发布进行监听，从而实现类似将事件推入到列表这样的操作。 2.1 通知类型对于每个修改数据库的操作，键空间通知都会发送两种不同类型的事件。 比如说，对0号数据库的键mykey执行 DEL 命令时，系统将分发两条消息，相当于执行以下两个 PUBLISH 命令： 12PUBLISH __keyspace@0__:mykey delPUBLISH __keyevent@0__:del mykey 订阅第一个频道__keyspace@0__:mykey可以接收0号数据库中所有修改键mykey的事件，而订阅第二个频道__keyevent@0__:del则可以接收0号数据库中所有执行del命令的键。 以keyspace为前缀的频道被称为键空间通知，而以keyevent为前缀的频道则被称为键事件通知。 当del mykey命令执行时： 键空间频道的订阅者将接收到被执行的事件的名字，在这个例子中，就是del。 键事件频道的订阅者将接收到被执行事件的键的名字，在这个例子中，就是mykey。 2.2 配置因为开启键空间通知功能需要消耗一些 CPU ，所以在默认配置下，该功能处于关闭状态。 可以通过修改redis.conf文件（重启生效且一直有效），或者直接使用CONFIG SET命令（立即生效且重启失效）来开启或关闭键空间通知功能： 当notify-keyspace-events选项的参数为空字符串时，功能关闭。 另一方面，当参数不是空字符串时，功能 。 notify-keyspace-events的参数可以是以下字符的任意组合，它指定了服务器该发送哪些类型的通知： 字符 发送的通知 K 键空间通知，所有通知以__keyspace@&lt;db&gt;__为前缀 E 键事件通知，所有通知以__keyevent@&lt;db&gt;__为前缀 g DEL、EXPIRE、RENAME等类型无关的通用命令的通知 $ 字符串命令的通知 l 列表命令的通知 s 集合命令的通知 h 哈希命令的通知 z 有序集合命令的通知 x 过期事件：每当有过期键被删除时发送 e 驱逐(evict)事件：每当有键因为maxmemory政策而被删除时发送 A 参数g$lshzxe的别名 输入的参数中至少要有一个K或者E，否则的话，不管其余的参数是什么，都不会有任何通知被分发。 举个例子，如果只想订阅键空间中和列表相关的通知，那么参数就应该设为Kl，诸如此类。 将参数设为字符串&quot;AKE&quot;表示发送所有类型的通知。 2.3 过期通知的发送时间我们已经了解了redis的键过期机制为 定期删除 + 惰性删除： 当一个键被访问时，程序会对这个键进行检查，如果键已经过期，那么该键将被删除。 底层系统会在后台渐进地查找并删除那些过期的键，从而处理那些已经过期、但是不会被访问到的键。 当过期键被以上两个程序的任意一个发现、 并且将键从数据库中删除时，Redis 会产生一个expired通知。 Redis 并不保证生存时间（TTL）变为0的键会立即被删除： 如果程序没有访问这个过期键，或者带有生存时间的键非常多的话，那么在键的生存时间变为0，直到键真正被删除这中间，可能会有一段比较显著的时间间隔。 因此，Redis 产生expired通知的时间为过期键被删除的时候，而不是键的生存时间变为0的时候。命令产生的通知 附录：以下列表记录了不同命令所产生的不同通知： DEL 命令为每个被删除的键产生一个del通知。 RENAME 产生两个通知：为来源键（source key）产生一个rename_from通知，并为目标键（destination key）产生一个rename_to通知。 EXPIRE 和 EXPIREAT 在键被正确设置过期时间时产生一个expire通知。当 EXPIREAT 设置的时间已经过期，或者 EXPIRE 传入的时间为负数值时，键被删除，并产生一个del通知。 每当一个键因为过期而被删除时，产生一个expired通知。 SORT 在命令带有STORE参数时产生一个sortstore事件。如果STORE指示的用于保存排序结果的键已经存在，那么程序还会发送一个del事件。 SET 以及它的所有变种（SETEX 、 SETNX 和 GETSET）都产生set通知。其中 SETEX 还会产生expire通知。 MSET 为每个键产生一个set通知。 SETRANGE 产生一个setrange通知。 INCR 、 DECR 、 INCRBY 和 DECRBY 都产生incrby通知。 INCRBYFLOAT 产生incrbyfloat通知。 APPEND 产生append通知。 LPUSH 和 LPUSHX 都产生单个lpush通知，即使有多个输入元素时，也是如此。 RPUSH 和 RPUSHX 都产生单个rpush通知，即使有多个输入元素时，也是如此。 RPOP 产生rpop通知。如果被弹出的元素是列表的最后一个元素，那么还会产生一个del通知。 LPOP 产生lpop通知。如果被弹出的元素是列表的最后一个元素，那么还会产生一个del通知。 LINSERT 产生一个linsert通知。 LSET 产生一个lset通知。 LTRIM 产生一个ltrim通知。如果 LTRIM 执行之后，列表键被清空，那么还会产生一个del通知。 RPOPLPUSH 和 BRPOPLPUSH 产生一个rpop通知，以及一个lpush通知。两个命令都会保证rpop的通知在lpush的通知之前分发。如果从键弹出元素之后，被弹出的列表键被清空，那么还会产生一个del通知。 HSET 、 HSETNX 和 HMSET 都只产生一个hset通知。 HINCRBY 产生一个hincrby通知。 HINCRBYFLOAT 产生一个hincrbyfloat通知。 HDEL 产生一个hdel通知。如果执行 HDEL 之后，哈希键被清空，那么还会产生一个del通知。 SADD 产生一个sadd通知，即使有多个输入元素时，也是如此。 SREM 产生一个srem通知，如果执行 SREM 之后，集合键被清空，那么还会产生一个del通知。 SMOVE 为来源键（source key）产生一个srem通知，并为目标键（destination key）产生一个sadd事件。 SPOP 产生一个spop事件。如果执行 SPOP 之后，集合键被清空，那么还会产生一个del通知。 SINTERSTORE 、 SUNIONSTORE 和 SDIFFSTORE 分别产生sinterstore、sunionostore和sdiffstore三种通知。如果用于保存结果的键已经存在，那么还会产生一个del通知。 ZINCRBY 产生一个zincr通知。（译注：非对称，请注意。） ZADD 产生一个zadd通知，即使有多个输入元素时，也是如此。 ZREM 产生一个zrem通知，即使有多个输入元素时，也是如此。如果执行 ZREM 之后，有序集合键被清空，那么还会产生一个del通知。 ZREMRANGEBYSCORE 产生一个zrembyscore通知。（译注：非对称，请注意。）如果用于保存结果的键已经存在，那么还会产生一个del通知。 ZREMRANGEBYRANK 产生一个zrembyrank通知。（译注：非对称，请注意。）如果用于保存结果的键已经存在，那么还会产生一个del通知。 ZINTERSTORE 和 ZUNIONSTORE 分别产生zinterstore和zunionstore两种通知。如果用于保存结果的键已经存在，那么还会产生一个del通知。 每当一个键因为maxmemory政策而被删除以回收内存时，产生一个evicted通知。 所有命令都只在键真的被改动了之后，才会产生通知。 比如说，当 SREM 试图删除不存在于集合的元素时，删除操作会执行失败，因为没有真正的改动键，所以这一操作不会发送通知。 如果对命令所产生的通知有疑问，最好还是使用以下命令，自己来验证一下： 1234$ redis-cli config set notify-keyspace-events KEA$ redis-cli --csv psubscribe &apos;__key*__:*&apos;Reading messages... (press Ctrl-C to quit)&quot;psubscribe&quot;,&quot;__key*__:*&quot;,1 然后，只要在其他终端里用 Redis 客户端发送命令，就可以看到产生的通知了： 123&quot;pmessage&quot;,&quot;__key*__:*&quot;,&quot;__keyspace@0__:foo&quot;,&quot;set&quot;&quot;pmessage&quot;,&quot;__key*__:*&quot;,&quot;__keyevent@0__:set&quot;,&quot;foo&quot;...","categories":[{"name":"noSql","slug":"noSql","permalink":"https://zzkenyon.github.io/categories/noSql/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://zzkenyon.github.io/tags/redis/"}],"keywords":[{"name":"noSql","slug":"noSql","permalink":"https://zzkenyon.github.io/categories/noSql/"}]},{"title":"redis-数据持久化配置","slug":"redis-数据持久化配置","date":"2019-07-31T16:00:00.000Z","updated":"2020-10-28T02:46:40.306Z","comments":true,"path":"2019/08/01/redis-数据持久化配置/","link":"","permalink":"https://zzkenyon.github.io/2019/08/01/redis-数据持久化配置/","excerpt":"","text":"redis的数据持久化功能默认是没有开启的，当我们kill掉redis-server进程并重启后，此前所有的缓存数据都会丢失，所以为了防止redis服务器宕机而造成数据丢失，我们应该打开redis的数据持久化功能。 redis持久化方式有两种：RDB 和 AOF，本文将围绕这两种持久化方式展开。 1、持久化原理 RDB的原理是生成当前数据集的快照文件dump.rdb，当服务器宕机重启后，服务器会根据该备份文件恢复数据，备份的是数据。 AOF的原理是维护一个数据写入日志（aof文件），在服务器执行写入命令的时候，在aof文件尾部添加命令。服务器宕机重启后，自动执行aof文件中的数据写入命令恢复数据。 2、运行过程2.1 RDB方式当 Redis 需要保存 dump.rdb 文件时， 服务器执行以下操作： Redis 调用 fork() ，同时拥有父进程和子进程。 子进程将数据集写入到一个临时 RDB 文件中。 当子进程完成对新 RDB 文件的写入时，Redis 用新 RDB 文件替换原来的 RDB 文件，并删除旧的 RDB 文件。 2.2 AOF方式每当 Redis 执行一个改变数据集的命令时（比如 SET、INCR）， 这个命令就会被追加到 AOF 文件的末尾， 当 Redis 重新启时， 程序就可以通过重新执行 AOF 文件中的命令来达到重建数据集的目的。 AOF重写举个例子， 如果你对一个计数器调用了 100 次INCR ， 那么仅仅是为了保存这个计数器的当前值， AOF 文件就需要使用 100 条记录。 然而在实际上， 只使用一条 SET 命令已经足以保存计数器的当前值了， 其余 99 条记录实际上都是多余的。 为了处理这种情况， Redis 支持一种有趣的特性： 可以在不打断服务客户端的情况下， 对 AOF 文件进行重建（rebuild）。 执行 BGREWRITEAOF 命令， Redis 将生成一个新的 AOF 文件， 这个文件包含重建当前数据集所需的最少命令。 重写过程AOF 重写和 RDB 创建快照一样，都巧妙地利用了copy-on-write机制。 Redis 执行 fork() ，现在同时拥有父进程和子进程。 子进程开始将新 AOF 文件的内容写入到临时文件。 对于所有新执行的写入命令，父进程一边将它们累积到一个内存缓存中，一边将这些改动追加到现有 AOF 文件的末尾： 这样即使在重写的中途发生停机，现有的 AOF 文件也还是安全的。 当子进程完成重写工作时，它给父进程发送一个信号，父进程在接收到信号之后，将内存缓存中的所有数据追加到新 AOF 文件的末尾。 现在 Redis 原子地用新文件替换旧文件，之后所有命令都会直接追加到新 AOF 文件的末尾。 3、配置方式4.1 RDB配置手动触发RDB通过手动执行命令SAVE或者BGSAVE生成快照文件，SAVE会阻塞服务器进程直到成功生成备份，不推荐使用；使用BGSAVE，服务器进程会fork一个子进程，异步执行备份，此过程服务器只有在fork()的时候阻塞。 自动触发(配置文件)123456789101112131415161718192021# 停用rdb#save \"\"save 900 1 #表示900 秒内如果至少有 1 个 key 的值变化，则保存save 300 10 #表示300 秒内如果至少有 10 个 key 的值变化，则保存save 60 10000 #表示60 秒内如果至少有 10000 个 key 的值变化，则保存#当启用了RDB且最后一次后台保存数据失败，Redis是否停止接收数据，默认yesstop-writes-on-bgsave-error yes#对于存储到磁盘中的快照，可以设置是否采用LZF进行压缩存储，默认yesrdbcompression yes#在存储快照后，我们还可以让redis使用CRC64算法来进行数据校验#但是这样做会增加大约10%的性能消耗，默认yesrdbchecksum yes#设置快照的文件名，默认是 dump.rdbdbfilename dump.rdb#设置快照文件的存放路径，这个配置项一定是个目录，而不能是文件名dir /var/redis/6379 3.2 AOF配置12345678910111213141516171819202122232425# 开启aofappendonly yes# aof文件名称appendfilename \"appendonly.aof\"# 三种持久化策略# appendfsync always # 每次修改数据集都会追加一次appendfsync everysec # 每1秒追加一次 # appendfsync no # 交给系统控制，linux 系统是30秒# If you have latency problems turn this to \"yes\". Otherwise leave it as# \"no\" that is the safest pick from the point of view of durability.no-appendfsync-on-rewrite no# 当aof文件增长量达到100%，自动重写（设为0则永不重写）auto-aof-rewrite-percentage 100# 当aof文件小于这个值，不会自动重写auto-aof-rewrite-min-size 64mb# aof-load-truncated yes# aof-use-rdb-preamble no 4、优劣势对比 RDB AOF 备份策略灵活多样可配置 只有三种持久化策略 rdb文件内容紧凑，适合灾难恢复 - 备份过程不影响redis性能 持久化策略决定是否影响redis性能 大数据集恢复速度快 大数据量恢复速度较慢 可靠性地，丢失数据概率高 持久化可靠性高，丢失数据概率低 rdb文件不可读 aof文件可读性高，易于分析 每次生成快照都需要操作整个数据集 aof文件只需要进行追加操作 总结来说： RDB方式备份时费劲，恢复时很给力，持久化可靠性低；AOF方式备份简单，恢复时稍费力，持久化可靠性高。具体使用哪种方式，需要根据具体业务场景进行选择。","categories":[{"name":"noSql","slug":"noSql","permalink":"https://zzkenyon.github.io/categories/noSql/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://zzkenyon.github.io/tags/redis/"}],"keywords":[{"name":"noSql","slug":"noSql","permalink":"https://zzkenyon.github.io/categories/noSql/"}]},{"title":"mysql-centos安装配置MySql8.0","slug":"数据库技术-mysql-centos安装配置MySql8.0","date":"2019-07-31T00:36:00.173Z","updated":"2020-11-09T07:26:12.495Z","comments":true,"path":"2019/07/31/数据库技术-mysql-centos安装配置MySql8.0/","link":"","permalink":"https://zzkenyon.github.io/2019/07/31/数据库技术-mysql-centos安装配置MySql8.0/","excerpt":"","text":"MySQL8.0和MySQL5.7具有众多不同之处，此处不述。这里，只简单讲讲在安装过程中遇到的问题之一和解决办法： MySQL8.0安装完成之后的默认密码是多少？如何修改初始密码？ 1. 安装MySQL8.0 yum仓库下载MySQL： 1shell&gt; yum localinstall https://repo.mysql.com//mysql80-community-release-el7-1.noarch.rpm yum安装MySQL： 1shell&gt; yum install mysql-community-server 2. 启动MySQL服务 启动MySQL服务的命令： 123shell&gt; service mysqld startStarting mysqld:[ OK ] 检查MySQL服务器的运行状态： 123456789101112131415shell&gt; sudo service mysqld status● mysqld.service - MySQL Server Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled) Active: active (running) since Sun 2018-06-03 18:31:51 CST; 6min ago Docs: man:mysqld(8) http://dev.mysql.com/doc/refman/en/using-systemd.html Process: 5281 ExecStartPre=/usr/bin/mysqld_pre_systemd (code=exited, status=0/SUCCESS) Main PID: 5299 (mysqld) Status: \"SERVER_OPERATING\" CGroup: /system.slice/mysqld.service └─5299 /usr/sbin/mysqldJun 03 18:31:50 &#123;your-server-name&#125; systemd[1]: Starting MySQL Server...Jun 03 18:31:51 &#123;your-server-name&#125; systemd[1]: Started MySQL Server. 以上信息表示MySQL服务启动成功。 出现Job for mysqld.service failed because the control process exited with error code问题 删除/var/lib/mysql /后重启MySQL服务就可以了！ 12rm -rf /var/lib/mysqlservice mysqld start 3. MySQL默认密码和修改密码在启动MySQL服务的时候，主要会发生以下4件事 MySQL Server初始化并启动起来； MySQL的data文件夹中生成SSL证书和key文件； 密码验证组件被安装并且生效； 创建一个超级管用户‘root‘@’localhost‘。超级用户设置的密码被保存在错误日志文件中，可以通过以下命令查看： 123shell&gt; sudo grep 'temporary password' /var/log/mysqld.log2018-06-03T10:15:57.448920Z 5 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: 0xxXxxXx?xXX 通过默认密码登录MySQL服务器，并马上修改密码(强烈建议)！！！。 有些时候使用上面的筛选命令检索不到文件或内容，可以手动查看/var/log/mysqld.log文件获取初始密码。 用默认密码(0xxXxxXx?xXX)登录： 1shell&gt; mysql -uroot -p 修改密码： 1mysql&gt; ALTER USER 'root'@'localhost' IDENTIFIED BY 'your-password'; mysql8.0 设置简单密码报错ERROR 1819 (HY000): Your password does not satisfy the current policy requirements【起因】有时候只是因为内网访问使用测试服务器，不想设置复杂的密码，比如root：123456但是新版 mysql 加入密码安全度检测机制，导致报错解决方法如下1.查看当前安全变量值 1mysql&gt; SHOW VARIABLES LIKE &apos;validate_password%&apos;; 2.修改变量 注意到8.0 比5.7多了带“.”的变量导致只设置一半是不够的， 12set global validate_password.policy=0; set global validate_password.length=4; 然后退出后再执行(我没有执行这句话，直接重置了) 1mysql_secure_installation 继续重置root密码就可以设置为123456了重置语句 1ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;123456&apos;; 4. 设置允许远程连接在终端登录mysql之后查看是否允许远程访问： 1mysql -u root -p 12345mysql&gt; use mysqlReading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changed 12345678910mysql&gt; select host,user,plugin from user;+-----------+------------------+-----------------------+| host | user | plugin |+-----------+------------------+-----------------------+| localhost | mysql.infoschema | caching_sha2_password || localhost | mysql.session | caching_sha2_password || localhost | mysql.sys | caching_sha2_password || localhost | root | caching_sha2_password |+-----------+------------------+-----------------------+4 rows in set (0.00 sec) 可以看到最后一行root 用户的host为localhost，要远程访问，需要将它改成% 1234567891011121314mysql&gt; update user set host=&apos;%&apos; where user =&apos;root&apos;;Query OK, 1 row affected (0.07 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; select host,user,plugin from user;+-----------+------------------+-----------------------+| host | user | plugin |+-----------+------------------+-----------------------+| % | root | caching_sha2_password || localhost | mysql.infoschema | caching_sha2_password || localhost | mysql.session | caching_sha2_password || localhost | mysql.sys | caching_sha2_password |+-----------+------------------+-----------------------+4 rows in set (0.00 sec) 最后刷新权限 12mysql&gt; FLUSH PRIVILEGES;Query OK, 0 rows affected (0.10 sec)","categories":[{"name":"数据库技术","slug":"数据库技术","permalink":"https://zzkenyon.github.io/categories/数据库技术/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://zzkenyon.github.io/tags/mysql/"}],"keywords":[{"name":"数据库技术","slug":"数据库技术","permalink":"https://zzkenyon.github.io/categories/数据库技术/"}]},{"title":"SpringCloud-sleuth&zipkin实现链路监控","slug":"SpringCloud-sleuth&zipkin实现链路监控","date":"2019-07-30T16:00:00.000Z","updated":"2020-08-10T07:26:22.030Z","comments":true,"path":"2019/07/31/SpringCloud-sleuth&zipkin实现链路监控/","link":"","permalink":"https://zzkenyon.github.io/2019/07/31/SpringCloud-sleuth&zipkin实现链路监控/","excerpt":"","text":"在微服务系统中，随着业务的发展，系统会变得越来越大，那么各个服务之间的调用关系也就变得越来越复杂。一个 HTTP 请求会调用多个不同的微服务来处理返回最后的结果，在这个调用过程中，可能会因为某个服务出现网络延迟过高或发送错误导致请求失败，这个时候，对请求调用的监控就显得尤为重要了。Spring Cloud Sleuth 提供了分布式服务链路监控的解决方案。下面介绍 Spring Cloud Sleuth 整合 Zipkin 的解决方案。 Zipkin 是 Twitter 的一个开源项目，它基于 Google Dapper 实现的。我们可以使用它来收集各个服务器上请求链路的跟踪数据，并通过它提供的 REST API 接口来辅助查询跟踪数据以实现对分布式系统的监控程序，从而及时发现系统中出现的延迟过高问题。除了面向开发的 API 接口之外，它还提供了方便的 UI 组件来帮助我们直观地搜索跟踪信息和分析请求链路明细，比如可以查询某段时间内各用户请求的处理时间等。 Zipkin 和 Config 结构类似，分为服务端 Server，客户端 Client，客户端就是各个微服务应用。 Spring Cloud提供ZipKin组件 SpringCloud Zipkin 与SleuthZipkin 是一个开放源代码分布式的跟踪系统，由Twitter公司开源，它致力于收集服务的定时数据，以解决微服务架构中的延迟问题，包括数据的收集、存储、查找和展现。每个服务向zipkin报告计时数据，例如用户每次请求服务的处理时间等，可方便的监测系统中存在的瓶颈。zipkin会根据调用关系通过Zipkin UI生成依赖关系图。 Spring Cloud Sleuth为服务之间调用提供链路追踪。通过Sleuth可以很清楚的了解到一个服务请求经过了哪些服务，每个服务处理花费了多长。从而让我们可以很方便的理清各微服务间的调用关系。此外Sleuth可以帮助我们：耗时分析: 通过Sleuth可以很方便的了解到每个采样请求的耗时，从而分析出哪些服务调用比较耗时;可视化错误: 对于程序未捕捉的异常，可以通过集成Zipkin服务界面上看到;链路优化: 对于调用比较频繁的服务，可以针对这些服务实施一些优化措施。Spring Cloud Sleuth可以结合Zipkin，将信息发送到Zipkin，利用Zipkin的存储来存储信息，利用Zipkin Ui来展示数据。 部署zipkin serverzipkin jar包下载： 链接:https://pan.baidu.com/s/1jc5XM0coc5qvLwSXuO8FFQ 密码:82ta 运行： 1java -jar zipkinXXXX.jar 基本使用对于调用链路上的每一个服务添加以下依赖 123456789&lt;!--sleuth + zipkin 链路监控--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt;&lt;/dependency&gt; 并进行如下配置 12345678910logging: level: org.springframework.cloud.sleuth: debug spring: sleuth: sampler: probability: 1.0 #请求全部上报 zipkin: base-url: http://zipkin-ip:9411/ #zipkin 服务端地址","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/tags/SpringCloud/"}],"keywords":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}]},{"title":"SpringCloud-Gateway过滤器源码分析","slug":"SpringCloud-Gateway过滤器源码分析","date":"2019-07-29T16:00:00.000Z","updated":"2020-12-22T02:40:31.975Z","comments":true,"path":"2019/07/30/SpringCloud-Gateway过滤器源码分析/","link":"","permalink":"https://zzkenyon.github.io/2019/07/30/SpringCloud-Gateway过滤器源码分析/","excerpt":"","text":"Spring-Cloud-Gateway的过滤器接口分为两种： GlobalFilter : 全局过滤器，不需要在配置文件中配置，作用在所有的路由上，最终通过GatewayFilterAdapter包装成GatewayFilterChain可识别的过滤器 GatewayFilter : 需要通过spring.cloud.routes.filters 配置在具体路由下，只作用在当前路由上或通过spring.cloud.default-filters配置在全局，作用在所有路由上 在Spring-Cloud-Gateway之请求处理流程文中我们了解最终网关是将请求交给过滤器链表进行处理，接下来我们阅读Spring-Cloud-Gateway的整个过滤器类结构以及主要功能 通过源码可以看到Spring-Cloud-Gateway的filter包中接口有如下三个，GatewayFilter，GlobalFilter，GatewayFilterChain，下来我依次阅读接口的主要实现功能。 1. GatewayFilterChain123456/** * 网关过滤链表接口 * 用于过滤器的链式调用 */public interface GatewayFilterChain &#123; Mono&lt;Void&gt; filter(ServerWebExchange exchange); 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * 网关过滤的链表，用于过滤器的链式调用 * 过滤器链表接口的默认实现， * 包含2个构建函数： * 1.集合参数构建用于初始化吧构建链表 * 2. index，parent参数用于构建当前执行过滤对应的下次执行的链表 */ private static class DefaultGatewayFilterChain implements GatewayFilterChain &#123; /** * 当前过滤执行过滤器在集合中索引 */ private final int index; /** * 过滤器集合 */ private final List&lt;GatewayFilter&gt; filters; public DefaultGatewayFilterChain(List&lt;GatewayFilter&gt; filters) &#123; this.filters = filters; this.index = 0; &#125; /** * 构建 * @param parent 上一个执行过滤器对应的FilterChain * @param index 当前要执行过滤器的索引 */ private DefaultGatewayFilterChain(DefaultGatewayFilterChain parent, int index) &#123; this.filters = parent.getFilters(); this.index = index; &#125; public List&lt;GatewayFilter&gt; getFilters() &#123; return filters; &#125; /** * @param exchange the current server exchange * @return */ @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange) &#123; return Mono.defer(() -&gt; &#123; if (this.index &lt; filters.size()) &#123; //获取当前索引的过滤器 GatewayFilter filter = filters.get(this.index); //构建当前索引的下一个过滤器的FilterChain DefaultGatewayFilterChain chain = new DefaultGatewayFilterChain(this, this.index + 1); //调用过滤器的filter方法执行过滤器 return filter.filter(exchange, chain); &#125; else &#123; //当前索引大于等于过滤集合大小，标识所有链表都已执行完毕，返回空 return Mono.empty(); // complete &#125; &#125;); &#125; &#125; 过滤器的GatewayFilterChain 执行顺序 通过GatewayFilter集合构建顶层的GatewayFilterChain 调用顶层GatewayFilterChain，获取第一个Filter，并创建下一个Filter索引对应的GatewayFilterChain 调用filter的filter方法执行当前filter，并将下次要执行的filter对应GatewayFilterChain传入。 2. GatewayFilter12345678//网关路由过滤器public interface GatewayFilter extends ShortcutConfigurable &#123; String NAME_KEY = \"name\"; String VALUE_KEY = \"value\"; Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain);&#125; 网关过滤器接口，有且只有一个方法filter，执行当前过滤器，并在此方法中决定过滤器链表是否继续往下执行，接下来我们看下几个主要的功能实现类 2.1 OrderedGatewayFilter123456789101112131415161718/** * 排序的网关路由过滤器，用于包装真实的网关过滤器，已达到过滤器可排序 */public class OrderedGatewayFilter implements GatewayFilter, Ordered &#123; //目标过滤器 private final GatewayFilter delegate; //排序字段 private final int order; public OrderedGatewayFilter(GatewayFilter delegate, int order) &#123; this.delegate = delegate; this.order = order; &#125; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; return this.delegate.filter(exchange, chain); &#125;&#125; OrderedGatewayFilter实现类主要目的是为了将目标过滤器包装成可排序的对象类型。是目标过滤器的包装类 2.2 GatewayFilterAdapter123456789101112//全局过滤器的包装类，将全局路由包装成统一的网关过滤器private static class GatewayFilterAdapter implements GatewayFilter &#123; //全局过滤器 private final GlobalFilter delegate; public GatewayFilterAdapter(GlobalFilter delegate) &#123; this.delegate = delegate; &#125; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; return this.delegate.filter(exchange, chain); &#125;&#125; GatewayFilterAdapter实现类主要目的是为了将GlobalFilter过滤器包装成GatewayFilter类型的对应。是GlobalFilter过滤器的包装类 3. GlobalFilterGlobalFilter 为请求业务以及路由的URI转换为真实业务服务的请求地址的核心过滤器，不需要配置，模式系统初始化时加载，并作用在每个路由上。 1234567891011121314151617181920//GatewayAutoConfiguration 类 // 全局过滤器，用户通过HttpClient转发请求 @Bean public NettyRoutingFilter routingFilter(HttpClient httpClient, ObjectProvider&lt;List&lt;HttpHeadersFilter&gt;&gt; headersFilters) &#123; return new NettyRoutingFilter(httpClient, headersFilters); &#125; // 全局的过滤器，用户将HttpClient客户端转发请求的响应写入到原始的请求响应中 @Bean public NettyWriteResponseFilter nettyWriteResponseFilter(GatewayProperties properties) &#123; return new NettyWriteResponseFilter(properties.getStreamingMediaTypes()); &#125; //GatewayLoadBalancerClientAutoConfiguration 类 // 全局过滤器，用于在通过负载均衡客户端选择服务实例信息 @Bean @ConditionalOnBean(LoadBalancerClient.class) public LoadBalancerClientFilter loadBalancerClientFilter(LoadBalancerClient client) &#123; return new LoadBalancerClientFilter(client); &#125; GlobalFilter转换成GatewayFilter，并作用于每个路由上，在FilteringWebHandler实现 123456789101112131415161718192021222324252627282930313233343536373839404142//FilteringWebHandler类public class FilteringWebHandler implements WebHandler &#123; //存放适配后的全局过滤器 private final List&lt;GatewayFilter&gt; globalFilters; public FilteringWebHandler(List&lt;GlobalFilter&gt; globalFilters) &#123; this.globalFilters = loadFilters(globalFilters); &#125; //包装加载全局的过滤器，将全局过滤器包装成GatewayFilter private static List&lt;GatewayFilter&gt; loadFilters(List&lt;GlobalFilter&gt; filters) &#123; return filters.stream() .map(filter -&gt; &#123; //将所有的全局过滤器包装成网关过滤器 GatewayFilterAdapter gatewayFilter = new GatewayFilterAdapter(filter); //判断全局过滤器是否实现了可排序接口 if (filter instanceof Ordered) &#123; int order = ((Ordered) filter).getOrder(); //包装成可排序的网关过滤器 return new OrderedGatewayFilter(gatewayFilter, order); &#125; return gatewayFilter; &#125;).collect(Collectors.toList()); &#125; @Override public Mono&lt;Void&gt; handle(ServerWebExchange exchange) &#123; //获取请求上下文设置的路由实例 Route route = exchange.getRequiredAttribute(GATEWAY_ROUTE_ATTR); //获取路由定义下的网关过滤器集合 List&lt;GatewayFilter&gt; gatewayFilters = route.g1etFilters(); //组合全局的过滤器与路由配置的过滤器 List&lt;GatewayFilter&gt; combined = new ArrayList&lt;&gt;(this.globalFilters); //添加路由配置过滤器到集合尾部 combined.addAll(gatewayFilters); //对过滤器进行排序 //TODO: needed or cached? AnnotationAwareOrderComparator.sort(combined); logger.debug(\"Sorted gatewayFilterFactories: \"+ combined); //创建过滤器链表对其进行链式调用 return new DefaultGatewayFilterChain(combined).filter(exchange); &#125;&#125; loadFilters方法是将全局路由使用GatewayFilterAdapter包装成GatewayFilter handle方法 获取当前请求使用的路由Route 获取路由配置的过滤器集合route.getFilters() 合并全过滤器与路由配置过滤器combined 对过滤器排序AnnotationAwareOrderComparator.sort 通过过滤器集合构建顶级链表DefaultGatewayFilterChain，并对其当前请求调用链表的filter方法。 4. 过滤器是怎么调用的FilteringWebHandler在自动配置类中注入容器： 12345//GatewayAutoConfiguration@Beanpublic FilteringWebHandler filteringWebHandler(List&lt;GlobalFilter&gt; globalFilters) &#123; return new FilteringWebHandler(globalFilters);&#125; 带参数的注入方法：默认情况下spring会在容器中找到所有的GlobalFilter，构建成list作为参数 FilteringWebHandler是实现了WebHandler，说明这是一个处理请求的处理器 FilteringWebHandler是怎么被调用到用来处理请求的呢？ 那就要从RoutePredicateHandlerMapping开始分析，我们知道spring mvc中的HandlerMapping的作用主要就是通过请求的路径map到处理该请求的controller方法（也就是handler），而在spring gateway中，RoutePredicateHandlerMapping的作用就是使用请求的各种属性，通过pridicate，map到一个路由配置上去。 RoutePredicateHandlerMapping持有FilteringWebHandler类，也就持有了所有的请求过滤器（全局+路由配置下的GatewayFilter）， 12345678910111213141516171819202122232425262728293031323334353637public class RoutePredicateHandlerMapping extends AbstractHandlerMapping &#123; private final FilteringWebHandler webHandler; private final RouteLocator routeLocator; private final Integer managementPort; private final ManagementPortType managementPortType; @Override protected Mono&lt;?&gt; getHandlerInternal(ServerWebExchange exchange) &#123; // don't handle requests on management port if set and different than server port if (this.managementPortType == DIFFERENT &amp;&amp; this.managementPort != null &amp;&amp; exchange.getRequest().getURI().getPort() == this.managementPort) &#123; return Mono.empty(); &#125; exchange.getAttributes().put(GATEWAY_HANDLER_MAPPER_ATTR, getSimpleName()); return lookupRoute(exchange) // .log(\"route-predicate-handler-mapping\", Level.FINER) //name this .flatMap((Function&lt;Route, Mono&lt;?&gt;&gt;) r -&gt; &#123; exchange.getAttributes().remove(GATEWAY_PREDICATE_ROUTE_ATTR); if (logger.isDebugEnabled()) &#123; logger.debug( \"Mapping [\" + getExchangeDesc(exchange) + \"] to \" + r); &#125; exchange.getAttributes().put(GATEWAY_ROUTE_ATTR, r); return Mono.just(webHandler); &#125;).switchIfEmpty(Mono.empty().then(Mono.fromRunnable(() -&gt; &#123; exchange.getAttributes().remove(GATEWAY_PREDICATE_ROUTE_ATTR); if (logger.isTraceEnabled()) &#123; logger.trace(\"No RouteDefinition found for [\" + getExchangeDesc(exchange) + \"]\"); &#125; &#125;))); &#125;&#125; 看上面源码，RouteLocator从名字就能大概猜到这是一个路由定位器，负责寻找正确的路由配置。 方法getHandlerInternal，顾名思义在内部获取handler处理器","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/tags/SpringCloud/"}],"keywords":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}]},{"title":"SpringCloud-配置中心源码分析","slug":"SpringCloud-config配置中心源码分析","date":"2019-07-26T16:00:00.000Z","updated":"2021-01-21T09:16:55.403Z","comments":true,"path":"2019/07/27/SpringCloud-config配置中心源码分析/","link":"","permalink":"https://zzkenyon.github.io/2019/07/27/SpringCloud-config配置中心源码分析/","excerpt":"","text":"为什么需要配置中心？ 分布式微服务架构，当一个服务存在多个实例分布在不同的服务器上，需要对该服务进行配置变更时，需要逐个服务器进行配置，并需要重启服务。配置中心就是为了解决这个问题，让配置一处变更，处处生效。 开源的配置中心： Diamond(super) Apoll 携程 spring cloud config nacos(alibaba) (服务注册、 配置中心) zookeeper 差异化对比： 权限管理 高可用特性 通信协议 数据更新的方式(pull/push) 是否支持多语言 是否支持灰度 spring-cloud-config 配置中心源码分析要解决的问题： 我在持久化层存储的配置，config server可以通过一系列的接口直接访问，那么server拿到配置后是通过什么方式给到client？ client拿到server 给的配置后，又是怎样塞给Environment对象的，为什么不用重启服务配置就能生效？ 1. bootstrap.yml的加载在对springboot的启动过程有过一定了解之后，我已经了解到对项目进行的配置最终都会加载到Environment对象中，该对象中包含了很对配置来源： 系统属性 系统环境变量 Servlet配置能 命令行配置属性源 配置文件属性源 而springboot应用在启动过程中Environment对象创建完成之后，已经确定了5个属性源，其中没有配置文件以及配置中心 Environment创建完会广播一个事件ApplicationEnvironmentPreparedEvent，这时候监听事件的监听器如下图： BootstrapApplicationListener12public class BootstrapApplicationListener implements ApplicationListener&lt;ApplicationEnvironmentPreparedEvent&gt;, Ordered &#123;...&#125; 从类声明就能看出该监听器将响应ApplicationEnvironmentPreparedEvent事件，找到事件处理逻辑： 1234567891011121314151617181920212223242526272829303132@Overridepublic void onApplicationEvent(ApplicationEnvironmentPreparedEvent event) &#123; ConfigurableEnvironment environment = event.getEnvironment(); if (!environment.getProperty(\"spring.cloud.bootstrap.enabled\", Boolean.class, true)) &#123; //spring.cloud.bootstrap.enabled是Bootstrap配置开关，为false表示不允许使用Bootstrap配置文件进行配置 return; &#125; // don't listen to events in a bootstrap context if (environment.getPropertySources().contains(BOOTSTRAP_PROPERTY_SOURCE_NAME)) &#123; return; // &#125; ConfigurableApplicationContext context = null; String configName = environment //spring.cloud.bootstrap.name:bootstrap 冒号后面是默认值 .resolvePlaceholders(\"$&#123;spring.cloud.bootstrap.name:bootstrap&#125;\"); for (ApplicationContextInitializer&lt;?&gt; initializer : event.getSpringApplication() .getInitializers()) &#123; if (initializer instanceof ParentContextApplicationContextInitializer) &#123; context = findBootstrapContext( (ParentContextApplicationContextInitializer) initializer, configName); &#125; &#125; if (context == null) &#123; //启动会到这里，父context为null 这里会先创建一个父context context = bootstrapServiceContext(environment, event.getSpringApplication(), configName); event.getSpringApplication() .addListeners(new CloseContextOnFailureApplicationListener(context)); &#125; apply(context, event.getSpringApplication(), environment);&#125; 重点是创建父context。bootstrapServiceContext方法源码较长但不复杂，简单分析一下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566private ConfigurableApplicationContext bootstrapServiceContext( ConfigurableEnvironment environment, final SpringApplication application, String configName) &#123; // 创建一个Environment对象 StandardEnvironment bootstrapEnvironment = new StandardEnvironment(); // 拿到Environment对象中的初始属性源集合 MutablePropertySources bootstrapProperties = bootstrapEnvironment .getPropertySources(); //清空操作，完成之后bootstrapProperties没有元素 for (PropertySource&lt;?&gt; source : bootstrapProperties) &#123; bootstrapProperties.remove(source.getName()); &#125; String configLocation = environment //默认为null .resolvePlaceholders(\"$&#123;spring.cloud.bootstrap.location:&#125;\"); String configAdditionalLocation = environment //默认为null .resolvePlaceholders(\"$&#123;spring.cloud.bootstrap.additional-location:&#125;\"); Map&lt;String, Object&gt; bootstrapMap = new HashMap&lt;&gt;(); bootstrapMap.put(\"spring.config.name\", configName); // configName = bootstrap // 如果spring.main.web-application-type=reactive, bootstrap会失败 bootstrapMap.put(\"spring.main.web-application-type\", \"none\"); if (StringUtils.hasText(configLocation)) &#123; bootstrapMap.put(\"spring.config.location\", configLocation); &#125; if (StringUtils.hasText(configAdditionalLocation)) &#123; bootstrapMap.put(\"spring.config.additional-location\", configAdditionalLocation); &#125; bootstrapProperties.addFirst( new MapPropertySource(BOOTSTRAP_PROPERTY_SOURCE_NAME, bootstrapMap)); for (PropertySource&lt;?&gt; source : environment.getPropertySources()) &#123; if (source instanceof StubPropertySource) &#123; continue; &#125; bootstrapProperties.addLast(source); &#125; // 配置SpringApplicationBuilder，将通过这个对象创建SpringApplication SpringApplicationBuilder builder = new SpringApplicationBuilder() .profiles(environment.getActiveProfiles()).bannerMode(Mode.OFF) .environment(bootstrapEnvironment) // Don't use the default properties in this builder .registerShutdownHook(false).logStartupInfo(false) .web(WebApplicationType.NONE); // 拿到创建好的SpringApplication对象 final SpringApplication builderApplication = builder.application(); if (builderApplication.getMainApplicationClass() == null) &#123; builder.main(application.getMainApplicationClass()); &#125; if (environment.getPropertySources().contains(\"refreshArgs\")) &#123; builderApplication .setListeners(filterListeners(builderApplication.getListeners())); &#125; builder.sources(BootstrapImportSelectorConfiguration.class); final ConfigurableApplicationContext context = builder.run(); // gh-214 using spring.application.name=bootstrap to set the context id via // `ContextIdApplicationContextInitializer` prevents apps from getting the actual // spring.application.name // during the bootstrap phase. context.setId(\"bootstrap\"); // Make the bootstrap context a parent of the app context addAncestorInitializer(application, context); // It only has properties in it now that we don't want in the parent so remove // it (and it will be added back later) bootstrapProperties.remove(BOOTSTRAP_PROPERTY_SOURCE_NAME); mergeDefaultProperties(environment.getPropertySources(), bootstrapProperties); return context;&#125; 所以，我们启动应用的时候，run函数创建完第一的Environment对象之后，广播ApplitionEnvironmentPreparedEvent事件，BootstrapApplicationListener响应该事件时会创建一个父context对象，父级别context创建方式也是使用SpringApplication.run()的方式，只是SpringApplication对象的配置创建完全由程序控制，创建出父context之后，会将其引用交给一个叫AncestorInitializer的初始化类，该类在之后的逻辑中会将应用级别的context的父亲引用设置为当前创建的context。 因此第一次创建context的过程只会读取bootstrap.yml配置文件，并且因为父context中并没有加载相关的bean，配置中心中配置的加载也没有执行。 2. Config处理流程在Spring Cloud Config中，我们通过@Value注解注入了一个属性，但是这个属性不存在于本地配置 中，那么Config是如何将远程配置信息加载到Environment中的呢?这里我们需要思考几个问题 如何将配置加载到 Environment 配置变更时，如何控制 Bean 是否需要 create,重新触发一次 Bean 的初始化，才能将 @Value 注 解指定的字段从 Environment 中重新注入。 配置变更时，如何控制新的配置会更新到 Environment 中，才能保证配置变更时可注入最新的 值。 为了解决这三个问题，Spring Cloud Config规范中定义了三个核心的接口 PropertySourceLocator:抽象出这个接口，就是让用户可定制化的将一些配置加载到 Environment。这部分的配置获取遵循了 Spring Cloud Config 的理念，即希望能从外部储存介质 中来 loacte。 RefreshScope: Spring Cloud 定义这个注解，是扩展了 Spring 原有的 Scope 类型。用来标识当前 这个 Bean 是一个refresh 类型的 Scope。其主要作用就是可以控制 Bean 的整个生命周期。 ContextRefresher:抽象出这个 Class，是让用户自己按需来刷新上下文(比如当有配置刷新时， 希望可以刷新上下文，将最新的配置更新到 Environment，重新创建 Bean 时，就可以从 Environment 中注入最新的配置)。 2.1 服务启动时Environment是如何在启动过程中从远程服务器上加载配置的呢? 从前面的代码分析过程中我们知道，Environment中所有外部化配置，针对不同类型的配置都会有与之 对应的PropertySource，比如(SystemEnvironmentPropertySource、 CommandLinePropertySource)。以及PropertySourcesPropertyResolver来进行解析。 那Config Client在启动的时候，必然也会需要从远程服务器上获取配置加载到Environment中，这样才 能使得应用程序通过@value进行属性的注入，而且我们一定可以猜测到的是，这块的工作一定又和 spring中某个机制有关系。 PropertySourceBootstrapConfiguration这个类已经处于spring-config包中，该类是用于在启动过程中加载一些外部配置，配置中心的配置加载就是在此处调用完成的。 它实现了 ApplicationContextInitializer 接口，其目的就是在应 用程序上下文初始化的时候做一些额外的操作. 根据默认的 AnnotationAwareOrderComparator 排序规则对propertySourceLocators数组进行排序 获取运行的环境上下文ConfigurableEnvironment 遍历propertySourceLocators时 调用 locate 方法，传入获取的上下文environment 将source添加到PropertySource的链表中 设置source是否为空的标识标量empty source不为空的情况，才会设置到environment中 返回Environment的可变形式，可进行的操作如addFirst、addLast 移除propertySources中的bootstrapProperties 根据config server覆写的规则，设置propertySources 处理多个active profiles的配置信息 1234567891011121314151617181920212223242526272829303132@Overridepublic void initialize(ConfigurableApplicationContext applicationContext) &#123; List&lt;PropertySource&lt;?&gt;&gt; composite = new ArrayList&lt;&gt;(); //排序 this.propertySourceLocators是自动注入的所有Locator AnnotationAwareOrderComparator.sort(this.propertySourceLocators); boolean empty = true; ConfigurableEnvironment environment = applicationContext.getEnvironment(); for (PropertySourceLocator locator : this.propertySourceLocators) &#123; // 逐一调用locator的locateCollection方法，获取属性源集合 Collection&lt;PropertySource&lt;?&gt;&gt; source = locator.locateCollection(environment); ... List&lt;PropertySource&lt;?&gt;&gt; sourceList = new ArrayList&lt;&gt;(); for (PropertySource&lt;?&gt; p : source) &#123; // 将属性源包装成BootstrapPropertySource sourceList.add(new BootstrapPropertySource&lt;&gt;(p)); &#125; composite.addAll(sourceList); // 添加到composite中 empty = false; &#125; if (!empty) &#123; MutablePropertySources propertySources = environment.getPropertySources(); for (PropertySource&lt;?&gt; p : environment.getPropertySources()) &#123; // BOOTSTRAP_PROPERTY_SOURCE_NAME = \"bootstrapProperties\" if (p.getName().startsWith(BOOTSTRAP_PROPERTY_SOURCE_NAME)) &#123; // 环境对象中若存在属性源bootstrapProperties，移除，一般不会有 propertySources.remove(p.getName()); &#125; &#125; // 插入属性源bootstrapProperties &gt;&gt; insertPropertySources(propertySources, composite); ... &#125;&#125; insertPropertySources(propertySources, composite)方法 该方法将远程配置添加到Environment对象中，其中涉及到重载属性的优先级控制，跟进去一看： 123456789101112131415161718192021222324252627282930313233343536373839404142private void insertPropertySources(MutablePropertySources propertySources, List&lt;PropertySource&lt;?&gt;&gt; composite) &#123; MutablePropertySources incoming = new MutablePropertySources(); List&lt;PropertySource&lt;?&gt;&gt; reversedComposite = new ArrayList&lt;&gt;(composite); //逆序compsite Collections.reverse(reversedComposite); for (PropertySource&lt;?&gt; p : reversedComposite) &#123; incoming.addFirst(p); &#125; PropertySourceBootstrapProperties remoteProperties = new PropertySourceBootstrapProperties(); Binder.get(environment(inming)).bind(\"spring.cloud.config\", Bindable.ofInstance(remoteProperties)); if (!remoteProperties.isAllowOverride() || (!remoteProperties.isOverrideNone() &amp;&amp; remoteProperties.isOverrideSystemProperties())) &#123; for (PropertySource&lt;?&gt; p : reversedComposite) &#123; propertySources.addFirst(p); &#125; return; &#125; if (remoteProperties.isOverrideNone()) &#123; for (PropertySource&lt;?&gt; p : composite) &#123; propertySources.addLast(p); &#125; return; &#125; if (propertySources.contains(SYSTEM_ENVIRONMENT_PROPERTY_SOURCE_NAME)) &#123; if (!remoteProperties.isOverrideSystemProperties()) &#123; for (PropertySource&lt;?&gt; p : reversedComposite) &#123; propertySources.addAfter(SYSTEM_ENVIRONMENT_PROPERTY_SOURCE_NAME, p); &#125; &#125; else &#123; for (PropertySource&lt;?&gt; p : composite) &#123; propertySources.addBefore(SYSTEM_ENVIRONMENT_PROPERTY_SOURCE_NAME, p); &#125; &#125; &#125; else &#123; for (PropertySource&lt;?&gt; p : composite) &#123; propertySources.addLast(p); &#125; &#125;&#125; 一张图看清楚变量间的关系 根据重载的具体属性，将远程属性源插入到不同的位置，由此我可以猜测出属性的优先级是由属性源在列表中的位置决定的，排在前面的优先级高，get属性是从前往后遍历，get到就返回。 若发生普通属性重载，将远程属性源添加到列表最前面，addfirst 优先级最高 若远程配置没有重载本地属性，将远程属性源添加到最后面位置 addlast 若是重载了系统环境变量属性，则根据是否能重载环境变量属性的配置将该属性添加到元属性源之前或者之后 ConfigServicePropertySourceLocator下面分析一下远程属性的获取流程，ConfigServicePropertySourceLocator类就是用来定位远程属性的 重点看locate方法：它会通过RestTemplate调用一个远程地址获得配置信息， getRemoteEnvironment 。然后把这个配置PropertySources，然后将这个信息包装成一个OriginTrackedMapPropertySource，设置到 Composite 中。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Override@Retryable(interceptor = \"configServerRetryInterceptor\")public org.springframework.core.env.PropertySource&lt;?&gt; locate( org.springframework.core.env.Environment environment) &#123; ConfigClientProperties properties = this.defaultProperties.override(environment); CompositePropertySource composite = new OriginTrackedCompositePropertySource( \"configService\"); // 使用restTemplate发起远程调用 RestTemplate restTemplate = this.restTemplate == null ? getSecureRestTemplate(properties) : this.restTemplate; Exception error = null; String errorBody = null; try &#123; String[] labels = new String[] &#123; \"\" &#125;; ... for (String label : labels) &#123; //获取远程Environment对象，重点 &gt;&gt; Environment result = getRemoteEnvironment(restTemplate, properties, label.trim(), state); if (result != null) &#123; log(result); // result.getPropertySources() can be null if using xml if (result.getPropertySources() != null) &#123; for (PropertySource source : result.getPropertySources()) &#123; @SuppressWarnings(\"unchecked\") Map&lt;String, Object&gt; map = translateOrigins(source.getName(), (Map&lt;String, Object&gt;) source.getSource()); composite.addPropertySource( new OriginTrackedMapPropertySource(source.getName(), map)); &#125; &#125; if (StringUtils.hasText(result.getState()) || StringUtils.hasText(result.getVersion())) &#123; HashMap&lt;String, Object&gt; map = new HashMap&lt;&gt;(); putValue(map, \"config.client.state\", result.getState()); putValue(map, \"config.client.version\", result.getVersion()); composite.addFirstPropertySource( new MapPropertySource(\"configClient\", map)); &#125; return composite; &#125; &#125; errorBody = String.format(\"None of labels %s found\", Arrays.toString(labels)); &#125; ... return null;&#125; OriginTrackedMapPropertySource 表示可追踪源的属性源 2.2. 服务运行中配置中心需要解决的另一个问题是，服务运行中如何将配置中心配置变更在不重启服务的前提下同步到服务端。 解决方案是利用回调actuator接口+消息总线广播的方式。 它提供了一个刷新机制，但是需要我们主动触发。那就是 @RefreshScope 注解并结合 actuator ，注意要引入 spring-boot-starter-actuator 包。 1、在 config client 端配置中增加 actuator 配置，上面大家可能就注意到了。 12345678management: endpoint: shutdown: enabled: false endpoints: web: exposure: include: \"*\" 其实这里主要用到的是 refresh 这个接口 2、在需要读取配置的类上增加 @RefreshScope 注解，我们是 controller 中使用配置，所以加在 controller 中。 注意，以上都是在 client 端做的修改。 之后，重启 client 端，重启后，我们修改 github 上的配置文件内容，并提交更改，再次刷新页面，没有反应。没有问题。 接下来，我们发送 POST 请求到 http://localhost:XXXX/actuator/refresh 这个接口，用 postman 之类的工具即可，此接口就是用来触发加载新配置的，返回内容如下: 1234[ &quot;config.client.version&quot;, &quot;data.env&quot; ] 这就结束了吗，并没有，总不能每次改了配置后，就用 postman 访问一下 refresh 接口吧，还是不够方便呀。 github 提供了一种 webhook 的方式，当有代码变更的时候，会调用我们设置的地址，来实现我们想达到的目的。 1、进入 github 仓库配置页面，选择 Webhooks ，并点击 add webhook； 2、之后填上回调的地址，也就是上面提到的 actuator/refresh 这个地址，但是必须保证这个地址是可以被 github 访问到的。如果是内网就没办法了。这也仅仅是个演示，一般公司内的项目都会有自己的代码管理工具，例如自建的 gitlab，gitlab 也有 webhook 的功能，这样就可以调用到内网的地址了。 那么当服务部署多个实例的情况下怎么办呢，总不能在git上设置多个webhook呀，这也不被允许。此时可是使用Spring Cloud Bus 来自动刷新多个端 Spring Cloud Bus 将分布式系统的节点与轻量级消息代理链接。这可以用于广播状态更改（例如配置更改）或其他管理指令。一个关键的想法是，Bus 就像一个扩展的 Spring Boot 应用程序的分布式执行器，但也可以用作应用程序之间的通信渠道。 —— Spring Cloud Bus 官方解释 如果只有一个 client 端的话，那我们用 webhook ，设置手动刷新都不算太费事，但是如果端比较多的话呢，一个一个去手动刷新未免有点复杂。这样的话，我们可以借助 Spring Cloud Bus 的广播功能，让 client 端都订阅配置更新事件，当配置更新时，触发其中一个端的更新事件，Spring Cloud Bus 就把此事件广播到其他订阅端，以此来达到批量更新。 1、Spring Cloud Bus 核心原理其实就是利用消息队列做广播，所以要先有个消息队列，目前官方支持 RabbitMQ 和 kafka。 这里用的是 RabbitMQ， 所以先要搭一套 RabbitMQ 环境 2、在 client 端增加相关的包，注意，只在 client 端引入就可以。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 3、在配置文件中增加 RabbitMQ 相关配置，默认的端口应该是 5672 ，因为我是用 docker 创建的，所以有所不同。 123456spring: rabbitmq: host: localhost port: 5672 username: guest password: guest 4、启动两个或多个 client 端，准备来做个测试 在启动的时候分别加上 vm option：-Dserver.port=3302 和 -Dserver.port=3303 ，然后分别启动就可以了。 访问其中一个的 actuator/bus-refresh 地址，注意还是要用 POST 方式访问。之后查看控制台输出，会看到这两个端都有一条这样的日志输出","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/tags/SpringCloud/"}],"keywords":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}]},{"title":"SpringCloud-Gateway网关","slug":"SpringCloud-Gateway网关","date":"2019-07-19T16:00:00.000Z","updated":"2020-12-08T02:26:47.597Z","comments":true,"path":"2019/07/20/SpringCloud-Gateway网关/","link":"","permalink":"https://zzkenyon.github.io/2019/07/20/SpringCloud-Gateway网关/","excerpt":"","text":"在微服务架构中，每个服务都是一个可以独立开发和运行的组件，而一个完整的微服务架构由一系列独 立运行的微服务组成。其中每个服务都只会完成特定领域的功能，比如订单服务提供与订单业务场景有 关的功能、商品服务提供商品展示功能等。各个微服务之间通过轻量级通信机制 REST API 或者 RPC 完 成通信。 微服务之后在某些层面会带来一定的影响，比如，一个用户查看一个商品的详情，对于客户端 来说，可能需要调用商品服务、评论服务、库存服务、营销服务等多个服务来完成数据的渲染 在这个场景中，客户端虽然能通过调用多个服务实现数据的获取，但是会存在一 些问题，比如: 客户端需要发起多次请求，增加了网络通信的成本及客户端处理的复杂性。 服务的鉴权会分布在每个微服务中处理，客户端对于每个服务的调用都需要重复鉴权。 在后端的微服务架构中，可能不同的服务采用的协议不同，比如有 HTTP、RPC 等。客户端如果需要调用多个服务，需要对不同协议进行适配 所以，我们可以在微服务之前增加一个前置节点，这个节点就是网关， 什么是网关呢? 大家都知道，从一个房间走到另一个房间，必然要经过一扇门，同样，从一个网络向另一个网络发送信息，也必须经过一道关口，顾名思义，网关就是一个网络连接到另一个网络的“关口”。 也就是网络。 而在微服务架构中，它不仅仅只是一个网络互连的一个关口，还有更多的作用，以前面分析的这个场景 为例，增加网关之后。 对于商品详情展示的场景来说，增加了 API 网关之后，在 API 网关层可以把后端的多个服务进行整合，然后提供一个唯一的业务接口，客户端只需要调用这个接口即可完成数据的获取及展示。在网关中会再去消费后端的多个微服务进行统一的整合，给客户端返回一个唯一的响应。 当然，网关不仅只是做一个请求转发以及服务整合，有了网关这个统一的入口之后，它还能提供 针对所有请求进行统一鉴权、限流、熔断、日志。 协议转化。针对后端多种不同的协议，在网关层统一处理后以 HTTP 协议对外提供服务。 用过 Dubbo 框架应该知道，针对 Dubbo 服务还需要提供一个 Web 应用来进行协议 转 化。 统一错误码处理。 请求转发，并且可以基于网关实现内外网隔离 1. 网关的作用以及要求作用： 性能:API高可用，负载均衡，容错机制。 安全:权限身份认证、脱敏，流量清洗，后端签名(保证全链路可信调用),黑名单(非法调用的限制)。 日志:日志记录(spainid,traceid)一旦涉及分布式，全链路跟踪必不可少。 缓存:数据缓存。 监控:记录请求响应数据，api耗时分析，性能监控。 限流:流量控制，错峰流控，可以定义多种限流规则。 灰度:线上灰度部署，可以减小风险。 路由:动态路由规则。 要求： 网关成了所有流量的入口，那么对于这样一个角色来说，它需要在某些方面 有很高的要求。 稳定性， 安全性，防止恶意请求，以及保障数据传输的安全性 高性能、可用性， 网关作为所有流量的入口，那么对于性能这块的要求就非常高了，因为一旦网关的性能出现 瓶颈，几遍后端的服务性能再高，意义也不大 网关必须要支持集群部署，这个是分布式架构的基本要求。否则网关服务挂掉就会导致整个 系统不可用 扩展性，可维护性，对于定制化需求方面，如何实现可扩展; 2. 常见的网关解决方案以及选型 OpenResty(Nginx+lua) Kong，是基于openresty之上的一个封装，提供了更简单的配置方式。 它还提供了付费的商业插 件 Tyk(开源、轻量级)，Tyk 是一个开源的、轻量级的、快速可伸缩的 API 网关，支持配额和速度 限制，支持认证和数据分析，支持多用户多组织，提供全 RESTful API。它是基于go语言开发的组 件。 Zuul，是spring cloud生态下提供的一个网关服务，性能相对来说不是很高 Spring Cloud Gateway，是Spring团队开发的高性能网关 网关选型主要关注几个方面 部署和维护成本 开源还是闭源 是否私有化部署 功能是否满足当前需求 社区资料的完善以及版本迭代和功能维护 3. Spring Cloud Gateway的核心概念 Route 路由，它是网关的基础元素，包含ID、目标URI、断言、过滤器组成，当前请求到达网关 时，会通过Gateway Handler Mapping，基于断言进行路由匹配，当断言为true时，匹配到路由 进行转发 Predicate，断言，学过java8的同学应该知道这个函数，它可以允许开发人员去匹配HTTP请求中 的元素，一旦匹配为true，则表示匹配到合适的路由进行转发 Filter，过滤器，可以在请求发出的前后进行一些业务上的处理，比如授权、埋点、限流等。 它的整体工作原理如下。 其中，predicate就是我们的匹配条件；而filter，就可以理解为一个无所不能的拦截器。有了这两个元素，再加上目标uri，就可以实现一个具体的路由了。 客户端向 Spring Cloud Gateway 发出请求，如果请求与网关程序定义的路由匹配，则该请求就会被发送到网关 Web 处理程序，此时处理程序运行特定的请求过滤器链。 过滤器之间用虚线分开的原因是过滤器可能会在发送代理请求的前后执行逻辑。所有 pre 过滤器逻辑先 执行，然后执行代理请求;代理请求完成后，执行 post 过滤器逻辑 路由规则示例： 123456789101112spring: application: name: gateway-server cloud: gateway: routes: - id: lb_route # 指定id，用户自定义 pridicates: - Path=/lb/** # 断言，请求网关的请求uri要满足此要求，还有其他断言类型 filters: - StripPrefix=1 # 过滤器，跳过url第一个前缀 uri: lb://order-service # 目标uri，lb是负载均衡协议，需要配置注册中心客户端 3.1 断言gateway为我们定义了14种断言工厂，在包org.springframework.cloud.gateway.handler.predicate中。 示例中配置的断言Path=/lb/**实际用到的是PathRoutePredicateFactory工厂类，配置时只需要使用工厂类的前缀path。 AfterRoutePredicateFactory 接收一个时间参数，当前时间在此时间之后，返回true 12345678spring: cloud: gateway: routes: - id: after_route uri: https://example.org predicates: - After=2017-01-20T17:42:47.789-07: BeforeRoutePredicateFactory 接收一个时间参数，当前时间在此时间之前，返回true 12345678spring: cloud: gateway: routes: - id: before_route uri: https://example.org predicates: - Before=2017-01-20T17:42:47.789-07:00[America/Denver] BetweenRoutePredicateFactory 接收两个时间参数，当前时间在两时间之内，返回true 12345678spring: cloud: gateway: routes: - id: between_route uri: https://example.org predicates: - Between=2017-01-20T17:42:47.789-07:00[America/Denver], 2017-01-21T17:42:47.789-07:00[America/Denver] 此路由匹配在2017年1月20日17点42分(丹佛)之后和2017年1月21日17点42分(丹佛)之前发出的请求。这对于维护窗口非常有用。 CookieRoutePredicateFactory 工厂接受两个参数，Cookie名称和regexp(一个Java正则表达式)。此断言匹配具有给定名称且其值与正则表达式匹配的cookie。下面的示例配置了一个cookie路由谓词工厂: 12345678spring: cloud: gateway: routes: - id: cookie_route uri: https://example.org predicates: - Cookie=chocolate, ch.p HeaderRoutePredicateFactory 消息头路由工厂接受两个参数，消息头名称和regexp(一个Java正则表达式)。此谓词与具有给定名称的头匹配，该头的值与正则表达式匹配。下面的示例配置了一个头路由谓词: 12345678spring: cloud: gateway: routes: - id: header_route uri: https://example.org predicates: - Header=X-Request-Id, \\d+ HostRoutePredicateFactory主机路由工厂接受一个参数:主机名模式列表。该模式是一个ant样式的模式。作为分隔符。此谓词匹配与模式匹配的主机头。下面的示例配置了一个主机路由谓词: 12345678spring: cloud: gateway: routes: - id: host_route uri: https://example.org predicates: - Host=**.somehost.org,**.anotherhost.org MethodRoutePredicateFactory 方法路由工厂接受一个方法参数，该参数是一个或多个参数:要匹配的HTTP方法。下面的示例配置了一个方法路由谓词: 12345678spring: cloud: gateway: routes: - id: method_route uri: https://example.org predicates: - Method=GET,POST PathRoutePredicateFactory 路径路由工厂接受两个参数:Spring PathMatcher模式列表和一个称为matchOptionalTrailingSeparator的可选标志。下面的示例配置了一个路径路由谓词: 12345678spring: cloud: gateway: routes: - id: path_route uri: https://example.org predicates: - Path=/red/&#123;segment&#125;,/ QueryRoutePredicateFactory 查询路由工厂接受两个参数:一个必需的param和一个可选的regexp(一个Java正则表达式)。下面的示例配置了一个查询路由谓词: 12345678spring: cloud: gateway: routes: - id: query_route uri: https://example.org predicates: - Query=green 如果请求包含green查询参数，则匹配成功。 RemoteAddrRoutePredicateFactory 匹配请求源的ip地址 12345678spring: cloud: gateway: routes: - id: remoteaddr_route uri: https://example.org predicates: - RemoteAddr=192.168.1.1/24 WeightRoutePredicateFactory 权重路由工厂有两个参数:group和weight(int)。权重按组计算。下面的示例配置了一个权重路由谓词: 123456789101112spring: cloud: gateway: routes: - id: weight_high uri: https://weighthigh.org predicates: - Weight=group1, 8 - id: weight_low uri: https://weightlow.org predicates: - Weight=group1, 2 这路由配置将把~80%的流量转发到weighthigh.org，并将~20%的流量转发到weighlow.org 注意：一个router中可以配置多个predicate，他们之间是&amp;关系，即所有的条件都满足才会进入filter 自定义断言 继承AbstractRoutePredicateFactory 3.2 过滤器3.2.1全局过滤器自定义全局过滤器： 1implements GlobalFilter 3.2.2 过滤器工厂gateway为我们定义了30种过滤器工厂，在包org.springframework.cloud.gateway.filter.factory中。 示例中配置的StripPrefix=1实际使用的是StripPrefixGatewayFilterFactory工厂，配置时只需要使用工厂类的前缀StripPrefix。 AddRequestHeaderGatewayFilterFactory 12345678spring: cloud: gateway: routes: - id: add_request_header_route uri: https://example.org filters: - AddRequestHeader=X-Request-red, blue 该过滤器向请求头中添加参数 X-Request-red = blue ，参数的值可以动态指定： 12345678910spring: cloud: gateway: routes: - id: add_request_header_route uri: https://example.org predicates: - Path=/red/&#123;segment&#125; # 请求uri中传入segment filters: - AddRequestHeader=X-Request-Red, Blue-&#123;segment&#125; #将segment添加到请求头中 AddRequestParameterGatewayFilterFactory 添加请求参数 AddResponseHeaderGatewayFilterFactory 添加响应头 RemoveRequestHeaderGatewayFilterFactory 移除 RemoveRequestParameterGatewayFilterFactory 移除 RemoveResponseHeaderGatewayFilterFactory 移除 SetRequestHeaderGatewayFilterFactory 修改 SetResponseHeaderGatewayFilterFactory 修改 DedupeResponseHeaderGatewayFilterFactory DedupeResponseHeader网关过滤器工厂接受一个name参数和一个可选的策略参数。name可以包含一个以空格分隔的标题名称列表。下面的示例配置了DedupeResponseHeader网关过滤器: 12345678spring: cloud: gateway: routes: - id: dedupe_response_header_route uri: https://example.org filters: - DedupeResponseHeader=Access-Control-Allow-Credentials Access-Control-Allow-Origin 当网关CORS逻辑和下游逻辑都添加Access-Control-Allow-Credentials和访Access-Control-Allow-Origin响应头时，这将删除它们的重复值。 DedupeResponseHeader过滤器还接受一个可选的策略参数。接受的值是RETAIN_FIRST(默认)、RETAIN_LAST和RETAIN_UNIQUE。 HystrixGatewayFilterFactory 该工厂需要一个name参数，它是HystrixCommand的名称。以下示例配置HystrixGatewayFilter： 12345678spring: cloud: gateway: routes: - id: hystrix_route uri: https://example.org filters: - Hystrix=myCommandName 这会将其余过滤器(配置在它之后的过滤器)包装HystrixCommand，并命名为myCommandName。 Hystrix过滤器也可以接受可选fallbackUri参数。当前，仅支持forward:格式的URI。 如果调用了fallback，则请求将转发到与URI匹配的控制器。以下示例配置了这种后备： 12345678910- id: hystrix_route uri: lb://backing-service:8088 predicates: - Path=/consumingserviceendpoint filters: - name: Hystrix args: name: fallbackcmd fallbackUri: forward:/incaseoffailureusethis - RewritePath=/consumingservic 调用Hystrix fallback时将转发到URI/incaseoffailureusethis。请注意，此示例还演示了（可选）Spring Cloud Netflix Ribbon负载平衡（lb在目标URI上定义了前缀）。 主要方案是通过fallbackUri跳转到网关应用程序中的内部控制器或处理程序。但是，您还可以将请求重新路由到外部应用程序中的控制器或处理程序，如下所示： 12345678910111213- id: ingredients uri: lb://ingredients predicates: - Path=//ingredients/** filters: - name: Hystrix args: name: fetchIngredients fallbackUri: forward:/fallback - id: ingredients-fallback uri: http://localhost:9994 predicates: - Path=/fallback 在此示例中，网管服务中没有定义fallback处理程序，而是将fallback转发到了http://localhost:9994上 万一请求转发给fallback，则Hystrix网关过滤器还会提供引起fallback的Throwable详细信息。它作为ServerWebExchangeUtils.HYSTRIX_EXECUTION_EXCEPTION_ATTR属性添加到ServerWebExchange中，可以在处理网关应用程序中的fallback时使用该属性。 对于外部控制器/处理程序方案，您可以添加带有异常详细信息的标头。详见下面的FallbackHeadersGatewayFilterFactory介绍 您可以使用使用全局默认值或逐条路由配置Hystrix设置（例如超时）来hystrix的配置。 要为前面显示的示例路由设置五秒钟的超时时间，可以使用以下配置： 1hystrix.command.fallbackcmd.execution.isolation.thread.timeoutInMilliseconds: 5000 FallbackHeadersGatewayFilterFactory 通过FallbackHeaders工厂，可以将Hystrix或Spring Cloud CircuitBreaker执行异常的详细信息添加到fallbackUri指定请求头中，如以下情况： 12345678910111213141516171819202122spring: cloud: gateway: routes: - id: ingredients uri: lb://ingredients predicates: - Path=//ingredients/** filters: - name: CircuitBreaker args: name: fetchIngredients fallbackUri: forward:/fallback # 发生熔断转发到 /fallback - id: ingredients-fallback uri: http://localhost:9994 predicates: - Path=/fallback # fallback 路由到http://localhost:9994，且转发请求投中添加熔断详细信息 filters: - name: FallbackHeaders args: executionExceptionTypeHeaderName: Test-Header 在此示例中，在运行断路器时发生执行异常后，该请求将转发到在上fallback运行的应用程序中的端点或处理程序localhost:9994。FallbackHeaders过滤器会将具有异常类型，消息和（如果有）根本原因异常类型和消息的标头添加到该请求。 您可以通过设置以下参数的值（以其默认值显示）来覆盖配置中标头的名称： executionExceptionTypeHeaderName（&quot;Execution-Exception-Type&quot;） executionExceptionMessageHeaderName（&quot;Execution-Exception-Message&quot;） rootCauseExceptionTypeHeaderName（&quot;Root-Cause-Exception-Type&quot;） rootCauseExceptionMessageHeaderName（&quot;Root-Cause-Exception-Message&quot;） SpringCloudCircuitBreakerFilterFactory 12345678spring: cloud: gateway: routes: - id: circuitbreaker_route uri: https://example.org filters: - CircuitBreaker=myCircuitBreaker 1234567891011121314spring: cloud: gateway: routes: - id: circuitbreaker_route uri: lb://backing-service:8088 predicates: - Path=/consumingServiceEndpoint filters: - name: CircuitBreaker args: name: myCircuitBreaker fallbackUri: forward:/inCaseOfFailureUseThis - RewritePath=/consumingServiceEndpoint, /backingServiceEndpoint 12345678@Beanpublic RouteLocator routes(RouteLocatorBuilder builder) &#123; return builder.routes() .route(\"circuitbreaker_route\", r -&gt; r.path(\"/consumingServiceEndpoint\") .filters(f -&gt; f.circuitBreaker(c -&gt; c.name(\"myCircuitBreaker\").fallbackUri(\"forward:/inCaseOfFailureUseThis\")) .rewritePath(\"/consumingServiceEndpoint\", \"/backingServiceEndpoint\")).uri(\"lb://backing-service:8088\") .build();&#125; MapRequestHeaderGatewayFilterFactory PrefixPathGatewayFilterFactory 对网关请求的uri添加前缀 12345678pring: cloud: gateway: routes: - id: prefixpath_route uri: https://example.org filters: - PrefixPath=/mypath PreserveHostHeaderGatewayFilterFactory 此过滤器设置一个请求属性，对该属性进行检查，以确定是否应该发送原始host 头，而不是由HTTP客户机确定的host头 12345678spring: cloud: gateway: routes: - id: preserve_host_route uri: https://example.org filters: - PreserveHostHeader Host 是 HTTP 1.1 协议中新增的一个请求头，主要用来实现虚拟主机技术。一台主机内使用端口号区分不同的应用进程，在一台部署了很多虚拟机的主机上，使用host头来决定请求发往哪一台虚拟机。 举个栗子，有一台 ip 地址为 61.135.169.125 的服务器，在这台服务器上使用虚拟主机部署着谷歌、百度、淘宝的网站。为什么我们访问 https://www.google.com 时，看到的是 Google 的首页而不是百度或者淘宝的首页？原因就是 Host 请求头决定着访问哪个虚拟主机。 RedirectToGatewayFilterFactory RequestHeaderSizeGatewayFilterFactory RequestHeaderToRequestUriGatewayFilterFactory RequestRateLimiterGatewayFilterFactory 该过滤器使用一个RateLimiter的实现来决定当前的请求是否能发送出去，如果不能访问，返回429（too many request） 该过滤器有一个可选的参数keyResolver用于指定RateLimiter限制的内容，默认是用户名，即一个用户在一定的时间内访问次数是受限制的，可以自定义keyResolver，例如设置成IP地址，用keyResolver: &#39;#{@ipAddressKeyResolver}&#39;的方式配置进去，@符号后面是beanName 123456789101112- id: ratelimiter_route predicates: - Path=/ratelimiter/** filters: - StripPrefix=1 - name: RequestRateLimiter args: deny-empty-key: true keyResolver: '#&#123;@ipAddressKeyResolver&#125;' redis-rate-limiter.replenishRate: 1 redis-rate-limiter.burstCapacity: 2 uri: lb://order-service 基于redis的流量限制策略： 参数说明： redis-rate-limiter.replenishRate希望用户每秒可以执行多少请求，而不需要丢弃任何请求。这是令牌桶被填充的速率。 redis-rate-limiter.burstCapacity一个用户在一秒内允许执行的最大请求数。这是令牌桶可以容纳的令牌的数量。将此值设置为零将阻止所有请求。 redis-rate-limiter.requestedTokens一个请求需要多少开销。这是每个请求从桶中取出的令牌的数量，默认值为1。 RequestSizeGatewayFilterFactory RetryGatewayFilterFactory RewriteLocationResponseHeaderGatewayFilterFactory RewritePathGatewayFilterFactory RewriteResponseHeaderGatewayFilterFactory SaveSessionGatewayFilterFactory SecureHeadersGatewayFilterFactory SetPathGatewayFilterFactory SetStatusGatewayFilterFactory SpringCloudCircuitBreakerHystrixFilterFactory SpringCloudCircuitBreakerResilience4JFilterFactory StripPrefixGatewayFilterFactory 3.2.3 自定义过滤器工厂自定义过滤器 4. 高级用法4.1 负载均衡网关需要接入注册中心，路由配置中的uri采用 lb:// 协议，框架会使用ribbon实现负载均衡。 4.3 限流基于redis，使用方式参考官网。 引入redis的jar包 配置redis服务器信息 配置路由： 123456789101112- id: redis_rate_limiter predicates: - Path=/ratelimiter/** filters: - StripPrefix=1 - name: RequestRateLimiter args: keyResolver: '#&#123;@ipAddressKeyResolver&#125;' deny-empty-key: true redis-rate-limiter.replenishRate: 1 redis-rate-limiter.burstCapacity: 2 uri: lb://order-service 这里使用自定义的KeyResolver，这里的自定义就需要根据应用场景进行自定义了，比如想要配置基于IP地址的限流策略，那么就需要使用Ip地址作为key RequestRateLimiter 使用令牌桶算法， 配置的参数 replenishRate 表示：令牌生成速度，也就是每秒允许请求的次数。 burstCapacity 表示： 令牌桶的容量。 4.4 动态路由添加actuator组件 spring gateway 提供了了一个endpoint用于动态路由的实现 使用GET 请求 actuator/gateway/routes 可以查看已配置的路由信息 使用POST请求 actuator/gateway/routes/{router_id} 动态添加路由信息 使用DELETE请求 actuator/gateway/routes/{router_id} 动态删除 修改完路由表 需要调用 actuator/gateway/refresh 刷新使之生效 默认动态路由只在应用运行期间存在，重启就消失 但是这里可以扩展： 默认动态信息是添加到内存中，我我们只要扩展RouteDifinitionRepository接口进行配置，就可以将动态的路由信息持久化。 将自定义的RouteDifinitionRepository注入到spring容器中，然后重启网关，该配置就生效了","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/tags/SpringCloud/"}],"keywords":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}]},{"title":"SpringCloud-Hystrix源码分析","slug":"SpringCloud-Hystrix源码分析","date":"2019-07-16T16:00:00.000Z","updated":"2020-08-10T07:25:15.209Z","comments":true,"path":"2019/07/17/SpringCloud-Hystrix源码分析/","link":"","permalink":"https://zzkenyon.github.io/2019/07/17/SpringCloud-Hystrix源码分析/","excerpt":"","text":"Hystrix实现核心 可配置化的降级策略 信号量、线程实现资源隔离，超时降级，熔断降级 HystrixCommandProperty 可以识别的降级边界 @HystrixCommand HystrixCommand抽象类 数据采集 如何触发熔断-&gt; 如何采集数据 -&gt; 如何统计数据 信号量 ，最大并发数 行为干预 ：触发降级之后对正常业务产生影响 结果干预：fallBack 自动恢复：处于熔断状态会每个5秒尝试恢复 Hystrix熔断的@HystrixCommand注解，是通过HystrixCommandAspect这个切面来处理的。 其中我们关注@Around注解声明的方法，它针对于请求合并，以及降级的注解进行代理。这里我们重点针对HystrixCommand这个注解进行详细分析。 getMethodFromTarget 获取目标方法信息 MetaHolder metaHolder = metaHolderFactory.create(joinPoint); 获取元数据，比如调用方法， HystrixProperty注解数据、方法参数等 HystrixCommandFactory.getInstance().create 获取调用者，它持有一个命令对象，并且可 以在合适的时候通过这个命令对象完成具体的业务逻辑 execute，执行命令 12345678910111213141516171819202122232425262728@Around(\"hystrixCommandAnnotationPointcut() || hystrixCollapserAnnotationPointcut()\")public Object methodsAnnotatedWithHystrixCommand(final ProceedingJoinPoint joinPoint) throws Throwable &#123; Method method = getMethodFromTarget(joinPoint); Validate.notNull(method, \"failed to get method from joinPoint: %s\", joinPoint); if (method.isAnnotationPresent(HystrixCommand.class) &amp;&amp; method.isAnnotationPresent(HystrixCollapser.class)) &#123; throw new IllegalStateException(\"method cannot be annotated with HystrixCommand and HystrixCollapser \" + \"annotations at the same time\"); &#125; MetaHolderFactory metaHolderFactory = META_HOLDER_FACTORY_MAP.get(HystrixPointcutType.of(method)); MetaHolder metaHolder = metaHolderFactory.create(joinPoint); HystrixInvokable invokable = HystrixCommandFactory.getInstance().create(metaHolder); ExecutionType executionType = metaHolder.isCollapserAnnotationPresent() ? metaHolder.getCollapserExecutionType() : metaHolder.getExecutionType(); Object result; try &#123; if (!metaHolder.isObservable()) &#123; result = CommandExecutor.execute(invokable, executionType, metaHolder); &#125; else &#123; result = executeObservable(invokable, executionType, metaHolder); &#125; &#125; catch (HystrixBadRequestException e) &#123; throw e.getCause(); &#125; catch (HystrixRuntimeException e) &#123; throw hystrixRuntimeExceptionToThrowable(metaHolder, e); &#125; return result;&#125;","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/tags/SpringCloud/"}],"keywords":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}]},{"title":"tools-对象映射工具MapStruct","slug":"tools-对象映射工具MapStruct","date":"2019-07-16T16:00:00.000Z","updated":"2020-12-18T09:06:21.996Z","comments":true,"path":"2019/07/17/tools-对象映射工具MapStruct/","link":"","permalink":"https://zzkenyon.github.io/2019/07/17/tools-对象映射工具MapStruct/","excerpt":"","text":"1. 实体对象分类1.1 领域模型中的实体分类VO (View Object) 视图对象，用于展示层，它的作用是把某个指定页面（或组件）的所有数据封装起来。 DTO (Data Transfer Object) 数据传输对象，这个概念来源于J2EE的设计模式，原来的目的是为了EJB的分布式应用提供粗粒度的数据实体，以减少分布式调用的次数，从而提高分布式调用的性能和降低网络负载，但在这里，我泛指用于展示层与服务层之间的数据传输对象。 DO (Domain Object) 领域对象，就是从现实世界中抽象出来的有形或无形的业务实体。会包含属性和方法。 PO (Persistent Object) 持久化对象，它跟持久层（通常是关系型数据库）的数据结构形成一一对应的映射关系，如果持久层是关系型数据库，那么，数据表中的每个字段（或若干个）就对应PO的一个（或若干个）属性。 各种实体类用于不同业务层次间的交互，并会在层次内实现实体类之间的转化。 业务分层为：视图层（VIEW+ACTION），服务层（SERVICE），持久层（DAO） 下面以一个时序图建立简单模型来描述上述对象在三层架构应用中的位置 用户发出请求（可能是填写表单），表单的数据在展示层被匹配为VO。 展示层把VO转换为服务层对应方法所要求的DTO，传送给服务层。 服务层首先根据DTO的数据构造（或重建）一个DO，调用DO的业务方法完成具体业务。 服务层把DO转换为持久层对应的PO（可以使用ORM工具，也可以不用），调用持久层的持久化方法，把PO传递给它，完成持久化操作。 对于一个逆向操作，如读取数据，也是用类似的方式转换和传递，略。 1.2 项目中的实体分类PO(persistant object) 持久对象 — 与数据库记录对应的实体对象 在 o/r 映射的时候出现的概念，如果没有 o/r 映射，没有这个概念存在了。通常对应数据模型 ( 数据库 ), 本身还有部分业务逻辑的处理。可以看成是与数据库中的表相映射的 java 对象。最简单的 PO 就是对应数据库中某个表中的一条记录，多个记录可以用 PO 的集合。 PO 中应该不包含任何对数据库的操作。 DO（Domain Object）领域对象 —就是从现实世界中抽象出来的有形或无形的业务实体。 DTO（Data Transfer Object）数据传输对象 — 后端接收前段请求参数的对象，一般作为controller方法的入参对象 这个概念来源于J2EE的设计模式，原来的目的是为了EJB的分布式应用提供粗粒度的数据实体，以减少分布式调用的次数，从而提高分布式调用的性能和降低网络负载，但在这里，我泛指用于展示层与服务层之间的数据传输对象。 VO(value object) 值对象 — 后端返回给前端展示的对象，一般作为controller方法的返回值 通常用于业务层之间的数据传递，和 PO 一样也是仅仅包含数据而已。但应是抽象出的业务对象 , 可以和表对应 , 也可以不 , 这根据业务的需要 。用 new 关键字创建，由 GC 回收的。 DAO(data access object) 数据访问对象 — 数据接入层对象 是一个 sun 的一个标准 j2ee 设计模式， 这个模式中有个接口就是 DAO ，它负持久层的操作。为业务层提供接口。此对象用于访问数据库。通常和 PO 结合使用， DAO 中包含了各种数据库的操作方法。通过它的方法 , 结合 PO 对数据库进行相关的操作。夹在业务逻辑与数据库资源中间。配合 VO, 提供数据库的 CRUD 操作. BO(business object) 业务对象—服务层对象 从业务模型的角度看 , 见 UML 元件领域模型中的领域对象。封装业务逻辑的 java 对象 , 通过调用 DAO 方法 , 结合 PO,VO 进行业务操作。 business object: 业务对象 主要作用是把业务逻辑封装为一个对象。这个对象可以包括一个或多个其它的对象。 比如一个简历，有教育经历、工作经历、社会关系等等。 我们可以把教育经历对应一个 PO ，工作经历对应一个 PO ，社会关系对应一个 PO 。 建立一个对应简历的 BO 对象处理简历，每个 BO 包含这些 PO 。 这样处理业务逻辑时，我们就可以针对 BO 去处理。 POJO(plain ordinary java object) 简单无规则 java 对象 纯的传统意义的 java 对象。就是说在一些 Object/Relation Mapping 工具中，能够做到维护数据库表记录的 persisent object 完全是一个符合 Java Bean 规范的纯 Java 对象，没有增加别的属性和方法。我的理解就是最基本的 Java Bean ，只有属性字段及 setter 和 getter 方法！ 2. 实体转换在一个成熟的工程中，尤其是现在的分布式系统中，应用与应用之间，还有单独的应用细分模块之后，DO 一般不会让外部依赖，这时候需要在提供对外接口的模块里放 DTO 用于对象传输，也即是 DO 对象对内，DTO对象对外，DTO 可以根据业务需要变更，并不需要映射 DO 的全部属性。 这种 对象与对象之间的互相转换，就需要有一个专门用来解决转换问题的工具，毕竟每一个字段都 get/set 会很麻烦。 MapStruct 就是这样的一个属性映射工具，只需要定义一个 Mapper 接口，MapStruct 就会自动实现这个映射接口，避免了复杂繁琐的映射实现。 MapStruct官网地址 MapSturct 是一个生成类型安全， 高性能且无依赖的 JavaBean 映射代码的注解处理器（annotation processor）。 抓一下重点： 注解处理器 可以生成 JavaBean 之间那的映射代码 类型安全， 高性能， 无依赖性 从字面的理解， 我们可以知道， 该工具可以帮我们实现 JavaBean 之间的转换， 通过注解的方式。 同时， 作为一个工具类，相比于手写， 其应该具有便捷， 不容易出错的特点。 2.1 使用入门2.1.1 引入依赖12345678910111213&lt;properties&gt; &lt;org.mapstruct.version&gt;1.3.0.Final&lt;/org.mapstruct.version&gt;&lt;/properties&gt;&lt;dependency&gt; &lt;groupId&gt;org.mapstruct&lt;/groupId&gt; &lt;artifactId&gt;mapstruct-jdk8&lt;/artifactId&gt; &lt;version&gt;$&#123;org.mapstruct.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mapstruct&lt;/groupId&gt; &lt;artifactId&gt;mapstruct-processor&lt;/artifactId&gt; &lt;version&gt;$&#123;org.mapstruct.version&#125;&lt;/version&gt;&lt;/dependency&gt; 2.1.2 基本映射这里定义两个 DO 对象 Person 和 User，其中 user 是 Person 的一个属性 ，一个 DTO 对象 PersonDTO 12345678910111213141516171819202122232425262728293031323334353637383940414243@NoArgsConstructor@AllArgsConstructor@Datapublic class Person &#123; private Long id; private String name; private String email; private Date birthday; private User user;&#125;@NoArgsConstructor@AllArgsConstructor@Datapublic class User &#123; private Integer age;&#125;@NoArgsConstructor@AllArgsConstructor@Datapublic class PersonDTO &#123; private Long id; private String name; /** * 对应 Person.user.age */ private Integer age; private String email; /** * 与 DO 里面的字段名称(birthDay)不一致 */ private Date birth; /** * 对 DO 里面的字段(birthDay)进行拓展,dateFormat 的形式 */ private String birthDateFormat; /** * 对 DO 里面的字段(birthDay)进行拓展,expression 的形式 */ private String birthExpressionFormat;&#125; 写一个 Mapper 接口 PersonConverter，其中两个方法，一个是单实体映射，另一个是List映射 若源对象属性与目标对象属性名字一致，会自动映射对应属性，不一样的需要指定，也可以用 format 转成自己想要的类型，也支持表达式的方式，可以看到像 id、name、email这些名词一致的我并没有指定 source-target，而birthday-birth指定了，转换格式的 birthDateFormat 加了dateFormat 或者 birthExpressionFormat 加了 expression，如果某个属性你不想映射，可以加个 ignore=true 1234567891011121314@Mapperpublic interface PersonConverter &#123; PersonConverter INSTANCE = Mappers.getMapper(PersonConverter.class); @Mappings(&#123; @Mapping(source = \"birthday\", target = \"birth\"), @Mapping(source = \"birthday\", target = \"birthDateFormat\", dateFormat = \"yyyy-MM-dd HH:mm:ss\"), @Mapping(target = \"birthExpressionFormat\", expression = \"java(org.apache.commons.lang3.time.DateFormatUtils.format(person.getBirthday(),\\\"yyyy-MM-dd HH:mm:ss\\\"))\"), @Mapping(source = \"user.age\", target = \"age\"), @Mapping(target = \"email\", ignore = true) &#125;) PersonDTO domain2dto(Person person); List&lt;PersonDTO&gt; domain2dto(List&lt;Person&gt; people);&#125; 编译之后，手工编译或者启动 IDE 的时候 IDE 也会帮我们编译， 会自动在 target/classes 下生成对应的实现类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class PersonConverterImpl implements PersonConverter &#123; public PersonConverterImpl() &#123; &#125; public PersonDTO domain2dto(Person person) &#123; if (person == null) &#123; return null; &#125; else &#123; PersonDTO personDTO = new PersonDTO(); personDTO.setBirth(person.getBirthday()); if (person.getBirthday() != null) &#123; personDTO.setBirthDateFormat((new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\")).format(person.getBirthday())); &#125; Integer age = this.personUserAge(person); if (age != null) &#123; personDTO.setAge(age); &#125; personDTO.setId(person.getId()); personDTO.setName(person.getName()); personDTO.setBirthExpressionFormat(DateFormatUtils.format(person.getBirthday(), \"yyyy-MM-dd HH:mm:ss\")); return personDTO; &#125; &#125; public List&lt;PersonDTO&gt; domain2dto(List&lt;Person&gt; people) &#123; if (people == null) &#123; return null; &#125; else &#123; List&lt;PersonDTO&gt; list = new ArrayList(people.size()); Iterator var3 = people.iterator(); while(var3.hasNext()) &#123; Person person = (Person)var3.next(); list.add(this.domain2dto(person)); &#125; return list; &#125; &#125; private Integer personUserAge(Person person) &#123; if (person == null) &#123; return null; &#125; else &#123; User user = person.getUser(); if (user == null) &#123; return null; &#125; else &#123; Integer age = user.getAge(); return age == null ? null : age; &#125; &#125; &#125;&#125; 写一个单元测试类 PersonConverterTest 测试一下，看看效果 12345678910111213141516171819public class PersonConverterTest &#123; @Test public void test() &#123; Person person = new Person(1L,\"zhige\",\"zhige.me@gmail.com\",new Date(),new User(1)); PersonDTO personDTO = PersonConverter.INSTANCE.domain2dto(person); assertNotNull(personDTO); assertEquals(personDTO.getId(), person.getId()); assertEquals(personDTO.getName(), person.getName()); assertEquals(personDTO.getBirth(), person.getBirthday()); String format = DateFormatUtils.format(personDTO.getBirth(), \"yyyy-MM-dd HH:mm:ss\"); assertEquals(personDTO.getBirthDateFormat(),format); assertEquals(personDTO.getBirthExpressionFormat(),format); List&lt;Person&gt; people = new ArrayList&lt;&gt;(); people.add(person); List&lt;PersonDTO&gt; personDTOs = PersonConverter.INSTANCE.domain2dto(people); assertNotNull(personDTOs); &#125;&#125; 2.1.3 多对一映射MapStruct 可以将几种类型的对象映射为另外一种类型，比如将多个 DO 对象转换为 DTO 例子 两个 DO 对象 Item 和 Sku，一个 DTO 对象 SkuDTO 123456789101112131415161718192021222324252627@NoArgsConstructor@AllArgsConstructor@Datapublic class Item &#123; private Long id; private String title;&#125;@NoArgsConstructor@AllArgsConstructor@Datapublic class Sku &#123; private Long id; private String code; private Integer price;&#125;@NoArgsConstructor@AllArgsConstructor@Datapublic class SkuDTO &#123; private Long skuId; private String skuCode; private Integer skuPrice; private Long itemId; private String itemName;&#125; 创建 ItemConverter（映射）接口，MapStruct 就会自动实现该接口 12345678910111213@Mapperpublic interface ItemConverter &#123; ItemConverter INSTANCE = Mappers.getMapper(ItemConverter.class); @Mappings(&#123; @Mapping(source = \"sku.id\",target = \"skuId\"), @Mapping(source = \"sku.code\",target = \"skuCode\"), @Mapping(source = \"sku.price\",target = \"skuPrice\"), @Mapping(source = \"item.id\",target = \"itemId\"), @Mapping(source = \"item.title\",target = \"itemName\") &#125;) SkuDTO domain2dto(Item item, Sku sku);&#125; 创建测试类，讲 Item 和 Sku 两个 DO对象，映射成一个 DTO 对象 SkuDTO 1234567891011121314public class ItemConverterTest &#123; @Test public void test() &#123; Item item = new Item(1L, \"iPhone X\"); Sku sku = new Sku(2L, \"phone12345\", 1000000); SkuDTO skuDTO = ItemConverter.INSTANCE.domain2dto(item, sku); assertNotNull(skuDTO); assertEquals(skuDTO.getSkuId(),sku.getId()); assertEquals(skuDTO.getSkuCode(),sku.getCode()); assertEquals(skuDTO.getSkuPrice(),sku.getPrice()); assertEquals(skuDTO.getItemId(),item.getId()); assertEquals(skuDTO.getItemName(),item.getTitle()); &#125;&#125; 2.1.4 添加自定义方法1234567891011121314151617181920212223242526// 形式如下 default PersonDTO personToPersonDTO(Person person) &#123; //hand-written mapping logic&#125;// 比如在 PersonConverter 里面加入如下default Boolean convert2Bool(Integer value) &#123; if (value == null || value &lt; 1) &#123; return Boolean.FALSE; &#125; else &#123; return Boolean.TRUE; &#125;&#125;default Integer convert2Int(Boolean value) &#123; if (value == null) &#123; return null; &#125; if (Boolean.TRUE.equals(value)) &#123; return 1; &#125; return 0;&#125;// 测试类 PersonConverterTest 加入assertTrue(PersonConverter.INSTANCE.convert2Bool(1));assertEquals((int)PersonConverter.INSTANCE.convert2Int(true),1); 如果已经有了接收对象，更新目标对象 1234567891011// 比如在 PersonConverter 里面加入如下，@InheritConfiguration 用于继承刚才的配置@InheritConfiguration(name = \"domain2dto\")void update(Person person, @MappingTarget PersonDTO personDTO);// 测试类 PersonConverterTest 加入如下Person person = new Person(1L,\"zhige\",\"zhige.me@gmail.com\",new Date(),new User(1));PersonDTO personDTO = PersonConverter.INSTANCE.domain2dto(person);assertEquals(\"zhige\", personDTO.getName());person.setName(\"xiaozhi\");PersonConverter.INSTANCE.update(person, personDTO);assertEquals(\"xiaozhi\", personDTO.getName()); 2.1.5 Spring 注入的方式12// 刚才一直写的例子是默认的方式PersonConverter INSTANCE = Mappers.getMapper(PersonConverter.class); 还有一种常用的方式，是和常用的框架 Spring 结合，在 @Mapper 后面加入 componentModel=&quot;spring&quot; 1234567891011@Mapper(componentModel=\"spring\")public interface PersonConverter &#123; @Mappings(&#123; @Mapping(source = \"birthday\", target = \"birth\"), @Mapping(source = \"birthday\", target = \"birthDateFormat\", dateFormat = \"yyyy-MM-dd HH:mm:ss\"), @Mapping(target = \"birthExpressionFormat\", expression = \"java(org.apache.commons.lang3.time.DateFormatUtils.format(person.getBirthday(),\\\"yyyy-MM-dd HH:mm:ss\\\"))\"), @Mapping(source = \"user.age\", target = \"age\"), @Mapping(target = \"email\", ignore = true) &#125;) PersonDTO domain2dto(Person person);&#125; 这时候测试类改一下，我用的 spring boot 的形式 123456789101112131415161718192021@RunWith(SpringRunner.class)@SpringBootTest(classes = BaseTestConfiguration.class)public class PersonConverterTest &#123; //这里把转换器装配进来 @Autowired private PersonConverter personConverter; @Test public void test() &#123; Person person = new Person(1L,\"zhige\",\"zhige.me@gmail.com\",new Date(),new User(1)); PersonDTO personDTO = personConverter.domain2dto(person); assertNotNull(personDTO); assertEquals(personDTO.getId(), person.getId()); assertEquals(personDTO.getName(), person.getName()); assertEquals(personDTO.getBirth(), person.getBirthday()); String format = DateFormatUtils.format(personDTO.getBirth(), \"yyyy-MM-dd HH:mm:ss\"); assertEquals(personDTO.getBirthDateFormat(),format); assertEquals(personDTO.getBirthExpressionFormat(),format); &#125;&#125; 我 test 路径下加入了一个配置类 12345@EnableAutoConfiguration@Configuration@ComponentScanpublic class BaseTestConfiguration &#123;&#125; 2.2 MapStruct 注解的关键词123456789101112@Mapper 只有在接口加上这个注解， MapStruct 才会去实现该接口 @Mapper 里有个 componentModel 属性，主要是指定实现类的类型，一般用到两个 default：默认，可以通过 Mappers.getMapper(Class) 方式获取实例对象 spring：在接口的实现类上自动添加注解 @Component，可通过 @Autowired 方式注入@Mapping：属性映射，若源对象属性与目标对象名字一致，会自动映射对应属性 source：源属性 target：目标属性 dateFormat：String 到 Date 日期之间相互转换，通过 SimpleDateFormat，该值为 SimpleDateFormat 的日期格式 ignore: 忽略这个字段@Mappings：配置多个@Mapping@MappingTarget 用于更新已有对象@InheritConfiguration 用于继承配置 3. gradle 构建使用依赖这样写 123implementation 'org.mapstruct:mapstruct:1.4.1.Final'implementation 'org.mapstruct:mapstruct-processor:1.4.1.Final'annotationProcessor 'org.mapstruct:mapstruct-processor:1.4.1.Final' 4. 与lombok冲突与lombok同时使用，指定@Mapping时，会报错，提示找不到指定名称的属性 添加依赖 1annotationProcessor 'org.projectlombok:lombok-mapstruct-binding:0.2.0'","categories":[{"name":"tools","slug":"tools","permalink":"https://zzkenyon.github.io/categories/tools/"}],"tags":[{"name":"tools","slug":"tools","permalink":"https://zzkenyon.github.io/tags/tools/"}],"keywords":[{"name":"tools","slug":"tools","permalink":"https://zzkenyon.github.io/categories/tools/"}]},{"title":"rabbitmq-消息收发流程","slug":"MQ-rabbit消息收发流程","date":"2019-07-10T16:00:00.000Z","updated":"2020-06-03T09:30:25.165Z","comments":true,"path":"2019/07/11/MQ-rabbit消息收发流程/","link":"","permalink":"https://zzkenyon.github.io/2019/07/11/MQ-rabbit消息收发流程/","excerpt":"","text":"由于 RabbitMQ 实现了 AMQP 协议，所以 RabbitMQ 的工作模型也是基于 AMQP 的，理解这张图片至关重要。 rabbit的概念Broker–主机节点，中文翻译是代理/中介，因为 MQ 服务器帮助我们做的事 情就是存储、转发消息。 Connection–无论是生产者发送消息，还是消费者接收消息，都必须要跟 Broker 之间建立一个连接，这个连接是一个 TCP 的长连接。 Channel–如果所有的生产者发送消息和消费者接收消息，都直接创建和释放 TCP 长连接的话， 对于 Broker 来说肯定会造成很大的性能损耗，因为 TCP 连接是非常宝贵的资源，创建和 释放也要消耗时间。 所以在 AMQP 里面引入了 Channel 的概念，它是一个虚拟的连接。我们把它翻译 成通道，或者消息信道。这样我们就可以在保持的 TCP 长连接里面去创建和释放 Channel，大大了减少了资源消耗。另外一个需要注意的是，Channel 是 RabbitMQ 原 生 API 里面的最重要的编程接口，也就是说我们定义交换机、队列、绑定关系，发送消 息消费消息，调用的都是 Channel 接口上的方法。 Queue–队列是真正用来存储消息的，是一个独立运行的进程，有自己的数据库（Mnesia）。 消费者获取消息有两种模式，一种是 Push 模式，只要生产者发到服务器，就马上推 送给消费者。另一种是 Pull 模式，消息存放在服务端，只有消费者主动获取才能拿到消 息。消费者需要写一个 while 循环不断地从队列获取消息吗？不需要，我们可以基于事件机制，实现消费者对队列的监听。 由于队列有 FIFO 的特性，只有确定前一条消息被消费者接收之后，才会把这条消息 从数据库删除，继续投递下一条消息。 Exchange–交换机是一个绑定列表，用来查找匹配的绑定关系。 队列使用绑定键（Binding Key）跟交换机建立绑定关系。 生产者发送的消息需要携带路由键（Routing Key），交换机收到消息时会根据它保存的绑定列表，决定将消息路由到哪些与它绑定的队列上。 注意：交换机与队列、队列与消费者都是多对多的关系。 vhost–我们每个需要实现基于 RabbitMQ 的异步通信的系统，都需要在服务器上创建自己 要用到的交换机、队列和它们的绑定关系。如果某个业务系统不想跟别人混用一个系统， 怎么办？再采购一台硬件服务器单独安装一个 RabbitMQ 服务？这种方式成本太高了。 在同一个硬件服务器上安装多个 RabbitMQ 的服务呢？比如再运行一个 5673 的端口？ 没有必要，因为 RabbitMQ 提供了虚拟主机 VHOST。 VHOST 除了可以提高硬件资源的利用率之外，还可以实现资源的隔离和权限的控制。它的作用类似于编程语言中的 namespace 和 package，不同的 VHOST 中可以有 同名的 Exchange 和 Queue，它们是完全透明的。 我们可以为不同的业务系统创建不同的用户（User），然后给这些用户 分配 VHOST 的权限。比如给风控系统的用户分配风控系统的 VHOST 的权限，这个用户可以访问里面的交换机和队列。给超级管理员分配所VHOST 的权限。 queue的绑定将queue绑定到exchange上时，会指定一个BindingKey 生产者消息发送到exchange，会携带一个rountKey exchange将根据消息的rountKey路由到已绑定的且BindingKey匹配的queue上 三种常用的exchange1、Direct exchange：交换机路由消息，要精确匹配rountKey，即消息的rountKey与绑定queue的rountKey要完全一致 2、Topic exchange：queue的rountKey中含有通配符，交换机路由消息，只要消息的rountKey能匹配topic patten就能路由 ​ “#” 表示0个或多个word ​ ”*“ 表示不多不少一个word 如果 queue指定的rountKey是 ： #.panda.*，则消息的rountKey为 panda.txt / zhao.panda.name / zhao.test.panda.zzk 这些都能路由到该queue中 3、Fanout exchange：扇形交换机，queue与其绑定时不需要指定rountKey，生产者向该类exchange发送消息时也不用携带rountKey，该类交换机会将收到的消息广播给所有的与其绑定的queue。 java-api编程创建 Maven 工程，pom.xml 引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;5.6.0&lt;/version&gt; &lt;/dependency&gt; 生产者： 12345678910111213141516171819public class MyProducer &#123; private final static String EXCHANGE_NAME = \"SIMPLE_EXCHANGE\"; public static void main(String[] args) throws Exception &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost(\"10.0.12.74\"); factory.setPort(5672); factory.setVirtualHost(\"/\"); factory.setUsername(\"admin\"); factory.setPassword(\"admin\"); // 建立连接 Connection connection = factory.newConnection(); // 创建消息通道 Channel channel = connection.createChannel(); String msg = \"Hello Rabbit Mq!\"; // 向交换机投递消息，携带路由键，没有额外参数 channel.basicPublish(EXCHANGE_NAME,\"panda.test\",null,msg.getBytes()); &#125;&#125; 消费者： 123456789101112131415161718192021222324252627282930public class MyConsumer &#123; private final static String EXCHANGE_NAME = \"SIMPLE_EXCHANGE\"; private final static String QUEUE_NAME = \"SIMPLE_QUEUE\"; public static void main(String[] args) throws IOException, TimeoutException &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost(\"10.0.12.74\"); factory.setPort(5672); factory.setVirtualHost(\"/\"); factory.setUsername(\"admin\"); factory.setPassword(\"admin\"); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); channel.exchangeDeclare(EXCHANGE_NAME,\"direct\" ,true); //声明交换机 channel.queueDeclare(QUEUE_NAME,false,false,false,null); //声明队列 System.out.println(\"Waiting for msg...\"); channel.queueBind(QUEUE_NAME,EXCHANGE_NAME,\"panda.test\");//绑定 Consumer consumer = new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String msg = new String(body); System.out.println(\"message is: \" + msg); System.out.println(\"consumer tag: \" + consumerTag); System.out.println(\"delivery tag: \" + envelope.getDeliveryTag()); &#125; &#125;; channel.basicConsume(QUEUE_NAME,true,consumer); &#125;&#125; 启动消费者，再启动生产者 参数详解 1）声明交换机的参数 String type：交换机的类型，direct, topic, fanout 中的一种。 boolean durable：是否持久化，代表交换机在服务器重启后是否还存在。 2）声明队列的参数 boolean durable：是否持久化，代表队列在服务器重启后是否还存在。 boolean exclusive：是否排他性队列。排他性队列只能在声明它的 Connection 中使用（可以在同一个 Connection 的不同的 channel 中使用），连接断开时自动删 除。 boolean autoDelete：是否自动删除。如果为 true，所有与这个队列连接的消费者都断开时，队列会自动删除。 Map&lt;String, Object&gt; arguments：队列的其他属性 | 属性 | 含义 || ————————- | ———————————————- || x-message-ttl | 队列中消息的存活时间，单位毫秒 || x-expirs | 队列在多久没有消费者访问以后会被删除 || x-max-length | 队列的最大消息数 || x-max-length-bytes | 队列最大容量，单位字节 || x-dead-letter-exchange | 队列指定的死信交换机 || x-dead-letter-routing-key | 队列指定死信交换机的路由键 || x-max-priority | 队列中消息的最大优先级，消息的优先级不能超过它 | 3）消息属性 BasicProperties 以下列举了一些主要的参数： | 参数 | 含义 || ————————– | ——————————– || Map&lt;String,Object&gt; headers | 消息的其他自然参数 || Integer deliveryMode | 2持久化，其他：瞬态 || Integer priority | 消息的优先级 || String correlationId | 关联 ID，方便 RPC 相应与请求关联 || String replyTo | 回调队列 || String expiration | TTL，消息过期时间，单位毫秒 | 注意：队列和消息同时指定了消息过期时间，以时间短的为准","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://zzkenyon.github.io/categories/消息中间件/"}],"tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://zzkenyon.github.io/tags/rabbitmq/"}],"keywords":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://zzkenyon.github.io/categories/消息中间件/"}]},{"title":"rabbitmq-消息的存储","slug":"MQ-rabbit centos7部署","date":"2019-07-09T16:00:00.000Z","updated":"2020-06-03T09:29:47.605Z","comments":true,"path":"2019/07/10/MQ-rabbit centos7部署/","link":"","permalink":"https://zzkenyon.github.io/2019/07/10/MQ-rabbit centos7部署/","excerpt":"","text":"一、下载erlang和rabbitmq-server的rpm:erlang-19.0.4-1.el7.centos.x86_64.rpm rabbitmq-server-3.6.6-1.el7.noarch.rpm 二、安装erlang:1rpm -ivh erlang-19.0.4-1.el7.centos.x86_64.rpm 测试是否安装成功: 123erl #进入脚本环境&gt;halt(). #退出 三、安装rabbitmq:1rpm -ivh rabbitmq-server-3.6.6-1.el7.noarch.rpm 在安装rabbitmq时提示依赖socat 1yum install socat 然后再次安装rabbitmq 四、启动和关闭:1234567/sbin/service rabbitmq-server stop #关闭/sbin/service rabbitmq-server start #启动/sbin/service rabbitmq-server restart #重启/sbin/service rabbitmq-server status #状态 连接服务器使用address： host_ip:5672 五、开启web插件1rabbitmq-plugins enable rabbitmq_management 重启rabbitmq 访问 http://host_ip:15672/ 六、guest账号登录失败处于安全的考虑，guest这个默认的用户只能通过localhost来登录，其他的IP无法直接使用这个账号。 为了解决这个问题，需要在rabbitmq的配置文件中将loopback_users配置设置为空，如编写配置文件:/etc/rabbitmq/rabbitmq.config，并在其中添加以下内容 1[&#123;rabbit, [&#123;loopback_users, []&#125;]&#125;]. 保存后重启rabbitmq-server即可随意使用guest用户名和密码来登录了(当然这个做法非常不安全)。 使用guest登录之后，在admin中添加管理员账户，然后再删除以上配置，重启rabbitmq-server。 以后登录都使用新添加的账号就可以了。","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://zzkenyon.github.io/categories/消息中间件/"}],"tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://zzkenyon.github.io/tags/rabbitmq/"}],"keywords":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://zzkenyon.github.io/categories/消息中间件/"}]},{"title":"rabbitmq-消息的可靠性投递","slug":"MQ-rabbit消息的可靠性投递","date":"2019-07-09T16:00:00.000Z","updated":"2020-06-03T09:30:45.136Z","comments":true,"path":"2019/07/10/MQ-rabbit消息的可靠性投递/","link":"","permalink":"https://zzkenyon.github.io/2019/07/10/MQ-rabbit消息的可靠性投递/","excerpt":"","text":"如何保证消息可靠性投递 从四个环节分析 生产者把消息发送到broker，怎么知道自己的消息有没有被broke接收？ 消息从交换机路由到queue，如果消息没有办法路由到指定的queue，会发生什么？该怎么处理？ 消息在queue中存储，怎么保证消息在队列中稳定的存储？ 消费者消费消息，消费完queue要删除这条消息。borker怎么知道消费者已经接收消息了呢？ 1. 生产者发送消息RabbitMQ提供了两种服务端确认机制，也就是生产者投递消息给服务端之后，服务端会通过某种方式返回一个应答，只要生产者收到这个应答，就知道消息成功发送了 一种是事务模式（Transaction），一种是确认模式（Confirm） 事务模式 获取channel之后，调用channel.txSelect()方法将信道设置成事务模式 1234567891011try&#123; channel.txSelect(); // 发送消息 // 参数：String exchange, String routingKey, BasicProperties props, byte[] body channel.basicPublish(\"\", QUEUE_NAME, null, (msg).getBytes()); // int i =1/0; channel.txCommit();&#125;catch(Exeception e)&#123; //回滚 channel.txRollback()&#125; 如果channel.txCommit()方法能正常返回，说明事务提交成功，消息一定到达了RabbitMQ 如果事务提交方法执行之前由于RabbitMQ异常崩溃或者其他原因排除异常，这时我们可以将其捕获，执行回滚操作。 在事务模式中，只有收到了服务端的Commit-OK指令才算提交成功。 事务模式的缺点： 整个过程是阻塞的，意味着一条消息没有确认提交就不能发送下一条消息，所以不建议在生产环境下使用。 事务模式在spring-boot中设置： 1rabbitTemplate.setChannelTransacted(true); 确认模式 Confirm模式有三种，一种是普通确认模式 生产者通过调用channel.confirmSelect()方法将信道设置为 Confirm 模式，一旦消息被投递到的所有匹配的队列之后，RMQ就会发送一个确认（Basic.Ack）给生产者，也就是调用channel.waitForConfirms()返回 true，这是生产者就知道服务端已接收消息。 1234567// 开启发送方确认模式channel.confirmSelect();channel.basicPublish(\"\", QUEUE_NAME, null, msg.getBytes());// 普通Confirm，发送一条，确认一条if (channel.waitForConfirms()) &#123; System.out.println(\"消息发送成功\" );&#125; 这种发送一条确认一条的的方式性能还是不高，所以有了批量确认模式。 批量确认笔普通单条确认效率要高，但是也存在两个问题： 批处理消息数量太小对性能提升有限 太大的话如果第1000条消息被拒绝，那么前面的999条都要重发 12345678910111213141516try &#123; channel.confirmSelect(); for (int i = 0; i &lt; 5; i++) &#123; // 发送消息 // String exchange, String routingKey, BasicProperties props, byte[] body channel.basicPublish(\"\", QUEUE_NAME, null, (msg +\"-\"+ i).getBytes()); &#125; // 批量确认结果，ACK如果是Multiple=True，代表ACK里面的Delivery-Tag之前的消息都被确认了 // 比如5条消息可能只收到1个ACK，也可能收到2个（抓包才看得到） // 直到所有信息都发布，只要有一个未被Broker确认就会IOException channel.waitForConfirmsOrDie(); System.out.println(\"消息发送完毕，批量确认成功\");&#125; catch (Exception e) &#123; // 发生异常，可能需要对所有消息进行重发 e.printStackTrace();&#125; 有没有一种方式可以一边发送一遍确认呢？ 异步确认模式 异步确认需要添加一个ConfrimListener，并用一个SortedSet来维护没有被确认的消息。 12345678910111213141516171819202122232425262728293031323334353637383940// 用来维护未确认消息的deliveryTagfinal SortedSet&lt;Long&gt; confirmSet = Collections.synchronizedSortedSet(new TreeSet&lt;Long&gt;());// 这里不会打印所有响应的ACK；ACK可能有多个，有可能一次确认多条，也有可能一次确认一条// 异步监听确认和未确认的消息// 如果要重复运行，先停掉之前的生产者，清空队列channel.addConfirmListener(new ConfirmListener() &#123; public void handleNack(long deliveryTag, boolean multiple) throws IOException &#123; System.out.println(\"Broker未确认消息，标识：\" + deliveryTag); if (multiple) &#123; // headSet表示后面参数之前的所有元素，全部删除 confirmSet.headSet(deliveryTag + 1L).clear(); &#125; else &#123; confirmSet.remove(deliveryTag); &#125; // 这里添加重发的方法 &#125; public void handleAck(long deliveryTag, boolean multiple) throws IOException &#123; // 如果true表示批量执行了deliveryTag这个值以前（小于deliveryTag的）的所有消息， // 如果为false的话表示单条确认 System.out.println(String.format(\"Broker已确认消息，标识：%d，多个消息：%b\", deliveryTag, multiple)); if (multiple) &#123; // headSet表示后面参数之前的所有元素，全部删除 confirmSet.headSet(deliveryTag + 1L).clear(); &#125; else &#123; // 只移除一个元素 confirmSet.remove(deliveryTag); &#125; System.out.println(\"未确认的消息:\"+confirmSet); &#125;&#125;);// 开启发送方确认模式channel.confirmSelect();for (int i = 0; i &lt; 10; i++) &#123; long nextSeqNo = channel.getNextPublishSeqNo(); // 发送消息 // String exchange, String routingKey, BasicProperties props, byte[] body channel.basicPublish(\"\", QUEUE_NAME, null, (msg +\"-\"+ i).getBytes()); confirmSet.add(nextSeqNo);&#125; spring-boot中因为 RabbitTemplate 对 Channel 进行了封装，所以要使用RabbitTemplate封装的回调对象ConfimrCallback。 123456789rabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback() &#123; @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123; if (!ack) &#123; System.out.println(\"发送消息失败：\" + cause); throw new RuntimeException(\"发送异常：\" + cause); &#125; &#125; &#125;); 2. 交换机路由消息再什么情况下消息会无法路由到正确的queue？ 路由键错误 或者 queue不存在 两种方式出路无法路由的消息，一种是让服务端重发给生产者，一种是让交换机路由到另一个备份的交换机。 消息回发的方式：使用mandatory参数和ReturnListener（在spring amqp中叫ReturnCallback） 12345678910rabbitTemplate.setMandatory(true); rabbitTemplate.setReturnCallback(new RabbitTemplate.ReturnCallback()&#123; public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey&#123; System.out.println(\"回发的消息：\"); System.out.println(\"replyCode: \"+replyCode); System.out.println(\"replyText: \"+replyText); System.out.println(\"exchange: \"+exchange); System.out.println(\"routingKey: \"+routingKey); &#125;&#125;); 消息路由到备份交换机：在创建交换机的时候，指定备份交换机 123Map&lt;String,Object&gt; arguments = new HashMap&lt;String,Object&gt;(); arguments.put(\"alternate-exchange\",\"ALTERNATE_EXCHANGE\"); // 指定交换机的备份交换机 channel.exchangeDeclare(\"TEST_EXCHANGE\",\"topic\", false, false, false, arguments); 注意与死信交换机区别，死信交换机是由queue指定的，备份交换机是由交换机指定的 3. 消息的存储消息没有被消费的话会一直存储在队列中。 如果RabbitMQ服务发生硬件故障：宕机重启关闭等等，会导致内存中的消息丢失，所以我们要把消息本省和元数据都保存到磁盘。 注意：元数据指的是交换机、队列、绑定 解决方案： 1、队列持久化 声明队列的时候，指定参数durable=true 2、交换机持久化 声明交换机的时候，指定参数durable=true 3、消息持久化 指定消息属性DeliveryMode 123MessageProperties messageProperties = new MessageProperties(); messageProperties.setDeliveryMode(MessageDeliveryMode.PERSISTENT); Message message = new Message(\"msg content\".getBytes(), messageProperties);template.send(\"exchange name\",\"route key\",message); 4、 集群 以上三点做了持久化，但还是存在单点故障风险，因此需要mq集群。 4. 投递消息消费者拿到消息后没处理就发生异常或者处理过程中发生异常，会导致消费失败。服务端应该使用某种方式的值消费者对消息的消费情况，并决定是否重新投递消息。 RMQ提供了消费者的消息确认机制，消费者可以自动或者手动的发送ACK给服务端。 没有收到ACK的消息，消费者断开连接后，RMQ会把这条消息发送给其他消费者，如果没有其他消费者，消费者重启后会重新消费者条消息。 消费者在订阅是可以指定autoACK参数，当该参数为false时，RMQ会等待消费者显示回复确认信号后在从队列中移除消息。 如何设置手动确认？ 1spring.rabbitmq.listener.simple.acknowledge-mode=manual 该配置有三个值： none–自动ack manual–手动ack auto–方法为抛出异常，发送ack 当抛出 AmqpRejectAndDontRequeueException 异常的时候，则消息会被拒绝， 且不重新入队。当抛出 ImmediateAcknowledgeAmqpException 异常，则消费者会发送 ACK。其他的异常，则消息会被拒绝，且 requeue 思考：服务端收到了 ACK 或者 NACK，生产者会知道吗？ 即使消费者没有接收到消 息，或者消费时出现异常，生产者也是完全不知情的。 例如，我们寄出去一个快递，是怎么知道收件人有没有收到的？因为有物流跟踪和 签收反馈，所以寄件人可以知道。 在没有用上电话的年代，我们寄出去一封信，是怎么知道收信人有没有收到信件？ 只有收到回信，才知道寄出的信被收到了。 所以，这个是生产者最终确定消费者有没有消费成功的两种方式： 1） 消费者收到消息，处理完毕后，调用生产者的 API（思考：是否破坏解耦？） 2） 消费者收到消息，处理完毕后，发送一条响应消息给生产者 RabbitMq没有提供上述的回调机制，若业务需求，可以自己实现。 消费者回调 1） 调用生产者 API 例如：提单系统给其他系统发送了碎屏保消息后，其他系统必须在处理完消息 后调用提单系统提供的 API，来修改提单系统中数据的状态。只要 API 没有被调用， 数据状态没有被修改，提单系统就认为下游系统没有收到这条消息。 2） 发送响应消息给生产者 例如：商业银行与人民银行二代支付通信，无论是人行收到了商业银行的消息，还是商业银行收到了人行的消息，都必须发送一条响应消息（叫做回执报文）。 补偿机制 如果生产者的 API 就是没有被调用，也没有收到消费者的响应消息，怎么办？ 不要着急，可能是消费者处理时间太长或者网络超时。 生产者与消费者之间应该约定一个超时时间，比如 5 分钟，对于超出这个时间没有 得到响应的消息，可以设置一个定时重发的机制，但要发送间隔和控制次数，比如每隔 2 分钟发送一次，最多重发 3 次，否则会造成消息堆积。 重发可以通过消息落库+定时任务来实现。 重发，是否发送一模一样的消息？ 消息幂等性 如果消费者每一次接收生产者的消息都成功了，只是在响应或者调用 API 的时候出了问题，会不会出现消息的重复处理？例如：存款 100 元，ATM 重发了 5 次，核心系统一共处理了 6 次，余额增加了 600 元。 为了避免相同消息的重复处理，必须要采取一定的措施。RabbitMQ 服务端是没有这种控制的（同一批的消息有个递增的 DeliveryTag），它不知道你是不是就要把 一条消息发送两次，只能在消费端控制。 如何避免消息的重复消费？ 消息出现重复可能会有两个原因： 1、生产者的问题，环节①重复发送消息，比如在开启了 Confirm 模式但未收到确认，生产者重复投递。 2、环节④出了问题，由于消费者未发送 ACK 或者其他原因，消息重复投递。 3、生产者代码或者网络问题。 对于重复发送的消息，可以对每一条消息生成一个唯一的业务ID，通过日志或者消息落库来做重复控制。 消息的顺序性 消息的顺序性指的是消费者消费消息的顺序跟生产者生产消息的顺序是一致的。 例如：商户信息同步到其他系统，有三个业务操作：1、新增门店 2、绑定产品 3、 激活门店，这种情况下消息消费顺序不能颠倒（门店不存在时无法绑定产品和激活）。 又比如：1、发表微博；2、发表评论；3、删除微博。顺序不能颠倒。 在 RabbitMQ 中，一个队列有多个消费者时，由于不同的消费者消费消息的速度是 不一样的，顺序无法保证。只有一个队列仅有一个消费者的情况才能保证顺序消费（不同的业务消息发送到不同的专用的队列）。 除非负载的场景，不要用多个消费者消费消息。","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://zzkenyon.github.io/categories/消息中间件/"}],"tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://zzkenyon.github.io/tags/rabbitmq/"}],"keywords":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://zzkenyon.github.io/categories/消息中间件/"}]},{"title":"SpringCloud-Eureka底层源码分析","slug":"SpringCloud-Eureka底层源码分析","date":"2019-07-09T16:00:00.000Z","updated":"2021-01-06T02:40:45.990Z","comments":true,"path":"2019/07/10/SpringCloud-Eureka底层源码分析/","link":"","permalink":"https://zzkenyon.github.io/2019/07/10/SpringCloud-Eureka底层源码分析/","excerpt":"","text":"*设计思想：*执行流程：Registry 名词 登记处、挂号处 Registration 名词 登记、注册、挂号 EurekaServiceRegistry 这个类顾名思义就是服务注册的地方，登记处，这个类实现了ServiceRegistry&lt;EurekaRegistration&gt;接口，其中的泛型EurekaRegistration顾名思义就是一次eureka注册，也是一个名词对象。EurekaServiceRegistry负责将EurekaRegistration注册到注册中心 1. 客户端服务注册流程1.1 启动时注册容器在实例化CloudEurekaClient时，父类的构造函数会执行第一次注册，不做配置的话默认是不会进行注册的。 123456789101112// DiscoveryClient // registration.enabled=true(默认是true) &amp;&amp; shouldEnforceRegistrationAtInit=true(默认是false)时，会进行一次注册if (clientConfig.shouldRegisterWithEureka() &amp;&amp; clientConfig.shouldEnforceRegistrationAtInit()) &#123; try &#123; if (!register() ) &#123; throw new IllegalStateException(\"Registration error at startup. Invalid server response.\"); &#125; &#125; catch (Throwable th) &#123; logger.error(\"Registration error at startup: &#123;&#125;\", th.getMessage()); throw new IllegalStateException(th); &#125;&#125; 1.2 启动后注册以下的流程是应用在启动完成之后，触发定时注册任务执行的流程： 服务启动后会调用SmartLifeCycle.start()方法，EurekaAutoServiceRegistration这个类实现了SmartLifecycle接口，所以它是服务注册流程的发起者。 从start()方法中最终会调用到EurekaServiceRegistry的register方法，这个方法并没有立即执行服务注册，仅仅向ApplicationInfoManager中设置了一个状态以及健康检查处理器。ApplicationInfoManager是用于管理即将发布的服务具体信息对象。 12345678910// EurekaServiceRegistrypublic void register(EurekaRegistration reg) &#123; maybeInitializeClient(reg); ... reg.getApplicationInfoManager() //getInitialStatus 结果是UP .setInstanceStatus(reg.getInstanceConfig().getInitialStatus()); reg.getHealthCheckHandler().ifAvailable(healthCheckHandler -&gt; reg .getEurekaClient().registerHealthCheck(healthCheckHandler));&#125; 关键在设置状态这块，服务启动时的状态是STARTING，发布之后的状态是UP，因此这里要做一个状态切换，切换之后，会向状态监听器发送一个StatusChangeEvent事件。状态监听器 listener 的实例化在DiscoveryClient的构造函数中执行，见后文。 1234567891011121314151617public synchronized void setInstanceStatus(InstanceStatus status) &#123; InstanceStatus next = instanceStatusMapper.map(status); if (next == null) &#123; return; &#125; InstanceStatus prev = instanceInfo.setStatus(next); if (prev != null) &#123; for (StatusChangeListener listener : listeners.values()) &#123; try &#123; //发布状态变更通知，listener的初始化需要关注 listener.notify(new StatusChangeEvent(prev, next)); &#125; catch (Exception e) &#123; ... &#125; &#125; &#125;&#125; 客户端自动装配会装载一个CloudEurekaClient实例，它是DiscoveryClient的子类，父类DiscoveryClient的构造函数最终会执行initScheduledTasks()方法，开启几个定时服务: 如果配置了服务列表刷新，则会开启 cacheRefresh 定时任务； 如果开启了服务注册开关，则会建立心跳机制，开启定时任务发送心跳； 通过内部类实例化一个服务状态监听器StatusChangeListener添加到ApplicationInfoManager的listener变量中，重点关注该监听器的notify()方法： 123456789101112// initScheduledTasks方法中的匿名类对象statusChangeListener = new ApplicationInfoManager.StatusChangeListener() &#123; @Override public String getId() &#123; return \"statusChangeListener\"; &#125; @Override public void notify(StatusChangeEvent statusChangeEvent) &#123; ... // log instanceInfoReplicator.onDemandUpdate(); //&gt;&gt; &#125;&#125;); 该监听器接收到StatusChangeEvent后，会执行InstanceInfoReplicator的onDemandUpdate方法。InstanceInfoReplicator是一个Runnable实例，它是一个用于更新和复制本地的服务实例信息到Eureka服务器的任务。 1InstanceInfoReplicator is A task for updating and replicating the local instanceinfo to the remote server. Demand是强烈要求的意思，所以该方法执行强制刷新 12345678910111213141516171819202122public boolean onDemandUpdate() &#123; if (rateLimiter.acquire(burstSize, allowedRatePerMinute)) &#123; if (!scheduler.isShutdown()) &#123; scheduler.submit(new Runnable() &#123; @Override public void run() &#123; Future latestPeriodic = scheduledPeriodicRef.get(); if (latestPeriodic != null &amp;&amp; !latestPeriodic.isDone()) &#123; ... // log latestPeriodic.cancel(false); &#125; InstanceInfoReplicator.this.run(); &#125; &#125;); return true; &#125; else &#123; return false; &#125; &#125; else &#123; return false; &#125;&#125; onDemandUpdate方法向线程池提交一个任务，执行run函数，run函数中调用了DiscoveryClient的registy方法，这里才是真正的注册逻辑，构造一个http请求发送给Eureka服务器。 12345678910111213141516public void run() &#123; try &#123; discoveryClient.refreshInstanceInfo(); Long dirtyTimestamp = instanceInfo.isDirtyWithTime(); if (dirtyTimestamp != null) &#123; discoveryClient.register(); // 这里执行注册 &gt;&gt; instanceInfo.unsetIsDirty(dirtyTimestamp); &#125; &#125; catch (Throwable t) &#123; logger.warn(\"There was a problem with the instance info replicator\", t); &#125; finally &#123; Future next = scheduler.schedule(this, replicationIntervalSeconds, TimeUnit.SECONDS); scheduledPeriodicRef.set(next); &#125;&#125; 1234567boolean register() throws Throwable &#123; EurekaHttpResponse&lt;Void&gt; httpResponse; try &#123; httpResponse = eurekaTransport.registrationClient.register(instanceInfo); &#125; ... return httpResponse.getStatusCode() == Status.NO_CONTENT.getStatusCode();&#125; 总结–Eureka Client发起服务注册时，有两个地方会执行服务注册的任务： 在Spring Boot启动时，由于自动装配机制将CloudEurekaClient注入到了容器，并且执行了构造方法，而在构造DiscoveryClient时会执行第一次注册。 DiscoveryClient启动的定时任务，会实例化一个状态监听器statusChangeListener，每当服务状态发生变化的时候会执行StatusChangeListener.notify()进行服务状态变更，更新服务状态会执行服务注册，默认是40秒检查一次。 2. 客户端服务发现流程继续来研究服务的发现过程，就是客户端需要能够满足两个功能 在启动的时候获取指定服务提供者的地址列表 Eureka server端服务提供者地址发生变化时，消费者需要动态感知 DiscoveryClient构造时进行查询DiscoveryClient构造方法中，如果当前的客户端默认开启了fetchRegistry，则会从eureka-server中拉取数据。 1234//DiscoveryClientif (clientConfig.shouldFetchRegistry() &amp;&amp; !fetchRegistry(false)) &#123; fetchRegistryFromBackup();&#125; 在DiscoveryClient构造的时候，会初始化一些任务，这个在前面咱们分析过了。其中有一个任务动态更新本地服务地址列表，叫 cacheRefreshTask 。 这个任务最终执行的是CacheRefreshThread这个线程。它是一个周期性执行的任务，具体我们来看一下。 12345678910111213cacheRefreshTask = new TimedSupervisorTask( \"cacheRefresh\", scheduler, cacheRefreshExecutor, registryFetchIntervalSeconds, TimeUnit.SECONDS, expBackOffBound, new CacheRefreshThread() ); scheduler.schedule( cacheRefreshTask, registryFetchIntervalSeconds, TimeUnit.SECONDS);&#125; 从整体上看，TimedSupervisorTask是固定间隔的周期性任务，一旦遇到超时就会将下一个周期的间隔 时间调大，如果连续超时，那么每次间隔时间都会增大一倍，一直到达外部参数设定的上限为止，一旦 新任务不再超时，间隔时间又会自动恢复为初始值。这种设计还是值得学习的。 CacheRefreshThread.refreshRegistry 12345class CacheRefreshThread implements Runnable &#123; public void run() &#123; refreshRegistry(); &#125;&#125; 123456@VisibleForTestingvoid refreshRegistry() ... boolean success = fetchRegistry(remoteRegionsModified); ...&#125; DisccoveryClient.fetchRegistry 12345678910111213141516171819202122232425262728293031323334353637383940414243private boolean fetchRegistry(boolean forceFullRegistryFetch) &#123; Stopwatch tracer = FETCH_REGISTRY_TIMER.start(); try &#123; // 取出本地缓存的服务列表信息 Applications applications = getApplications(); //判断多个条件，确定是否触发全量更新，如下任一个满足都会全量更新: //1. 是否禁用增量更新; //2. 是否对某个region特别关注; //3. 外部调用时是否通过入参指定全量更新; //4. 本地还未缓存有效的服务列表信息; if (clientConfig.shouldDisableDelta() || (!Strings.isNullOrEmpty(clientConfig.getRegistryRefreshSingleVipAddress())) || forceFullRegistryFetch || (applications == null) || (applications.getRegisteredApplications().size() == 0) || (applications.getVersion() == -1)) //Client application does not have latest library supporting delta &#123; //调用全量更新 getAndStoreFullRegistry(); &#125; else &#123; //调用增量更新 getAndUpdateDelta(applications); &#125; //重新计算和设置一致性hash码 applications.setAppsHashCode(applications.getReconcileHashCode()); logTotalInstances();//日志打印所有应用的所有实例数之和 &#125; catch (Throwable e) &#123; logger.error(PREFIX + \"&#123;&#125; - was unable to refresh its cache! status = &#123;&#125;\", appPathIdentifier, e.getMessage(), e); return false; &#125; finally &#123; if (tracer != null) &#123; tracer.stop(); &#125; &#125; //将本地缓存更新的事件广播给所有已注册的监听器，注意该方法已被CloudEurekaClient类重写 onCacheRefreshed(); //检查刚刚更新的缓存中，有来自Eureka server的服务列表，其中包含了当前应用的状态， //当前实例的成员变量lastRemoteInstanceStatus，记录的是最后一次更新的当前应用状态， //上述两种状态在updateInstanceRemoteStatus方法中作比较 ，如果不一致，就更新lastRemoteInstanceStatus，并且广播对应的事件 updateInstanceRemoteStatus(); return true;&#125; DiscoveryClient.getAndStoreFullRegistry 从eureka server端获取服务注册中心的地址信息，然后更新并设置到本地缓存 localRegionApps 。 1234567891011121314151617181920212223private void getAndStoreFullRegistry() throws Throwable &#123; long currentUpdateGeneration = fetchRegistryGeneration.get(); logger.info(\"Getting all instance registry info from the eureka server\"); Applications apps = null; EurekaHttpResponse&lt;Applications&gt; httpResponse = clientConfig.getRegistryRefreshSingleVipAddress() == null ? eurekaTransport.queryClient.getApplications(remoteRegionsRef.get()) : eurekaTransport.queryClient.getVip(clientConfig.getRegistryRefreshSingleVipAddress(), remoteRegionsRef.get()); if (httpResponse.getStatusCode() == Status.OK.getStatusCode()) &#123; apps = httpResponse.getEntity(); &#125; logger.info(\"The response status is &#123;&#125;\", httpResponse.getStatusCode()); if (apps == null) &#123; logger.error(\"The application is null for some reason. Not storing this information\"); &#125; else if (fetchRegistryGeneration.compareAndSet(currentUpdateGeneration, currentUpdateGeneration + 1)) &#123; localRegionApps.set(this.filterAndShuffle(apps)); logger.debug(\"Got full registry with apps hashcode &#123;&#125;\", apps.getAppsHashCode()); &#125; else &#123; logger.warn(\"Not updating applications as another thread is updating it already\"); &#125;&#125; ​ 3. Eureka Server收到请求之后的处理3.1 执行流程我们就把服务注册在客户端和服务端的处理过程做了一个详细的分析，实际上在Eureka Server 端，会把客户端的地址信息保存到ConcurrentHashMap中存储。并且服务提供者和注册中心之间，会 建立一个心跳检测机制，用于监控服务提供者的健康状态。 在没分析源码实现之前，我们一定知道它肯定对请求过来的服务实例数据进行了存储。那么我们去Eureka Server端看一下处理流程。 请求入口在: com.netflix.eureka.resources.ApplicationResource.addInstance() 可以发现，这里所提供的REST服务，采用的是jersey来实现的。Jersey是基于JAX-RS标准，提供 REST的实现的支持，这里就不展开分析了。 当EurekaClient调用register方法发起注册时，会调用ApplicationResource.addInstance方法。 服务注册就是发送一个 POST 请求带上当前实例信息到类 ApplicationResource 的 addInstance 方法进行服务注册 ApplicationResource.addInstance() 12345678910 @POST //ApplicationResource@Consumes(&#123;\"application/json\", \"application/xml\"&#125;)public Response addInstance(InstanceInfo info, @HeaderParam(PeerEurekaNode.HEADER_REPLICATION) String isReplication) &#123; ... // 处理客户端可能注册了错误的DataCenterInfo并丢失数据的情况 ... registry.register(info, \"true\".equals(isReplication)); // 注册 return Response.status(204).build(); // 204 to be backwards compatible&#125; 在 addInstance 方法中，最终调用的是 PeerAwareInstanceRegistryImpl.register 方法。 PeerAwareInstanceRegistryImpl.register 12345678910@Overridepublic void register(final InstanceInfo info, final boolean isReplication) &#123; int leaseDuration = Lease.DEFAULT_DURATION_IN_SECS; // 租约过期时间，默认90s if (info.getLeaseInfo() != null &amp;&amp; info.getLeaseInfo().getDurationInSecs() &gt; 0) &#123; leaseDuration = info.getLeaseInfo().getDurationInSecs(); &#125; super.register(info, leaseDuration, isReplication); // 调用父类 // 将信息复制到Eureka Server集群的其他机器上， replicateToPeers(Action.Register, info.getAppName(), info.getId(), info, null, isReplication);&#125; PeerAwareInstanceRegistry的最顶层接口为LeaseManager与LookupService，其中LookupService定义了最基本的发现示例的行为，LeaseManager定义了处理客户端注册，续约，注销等操作. leaseDuration 表示租约过期时间，默认90s，当服务器超过90s没有收到客户端的心跳，主动剔除该节点； 调用父类方法发起服务注册 同步实现很简单，获取及群众的所有节点，逐个发起注册。 AbstractInstanceRegistry.register 简单来说，Eureka-Server的服务注册，实际上是将客户端传递过来的实例数据保存到Eureka-Server中的ConcurrentHashMap中。 首先看一下注册表的结构：Map&lt;String,Map&lt;String,Lease&lt;InstanceInfo&gt;&gt;&gt;，第一层映射是appName到服务列表的映射，第二层映射是在一个AppName中，服务InstanceId到租约的映射。 Lease是租约，持有一个InstanceInfo引用，以及该实例信息的注册时间、上次更新时间、剔除时间、服务上线时间、租约有效期限等等信息 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586// AbstractInstanceRegistrypublic void register(InstanceInfo registrant, int leaseDuration, boolean isReplication) &#123; try &#123; read.lock(); //从registry中获得当前实例信息，根据appName Map&lt;String, Lease&lt;InstanceInfo&gt;&gt; gMap = registry.get(registrant.getAppName()); REGISTER.increment(isReplication);//增加注册次数到监控信息中 if (gMap == null) &#123;//如果当前appName是第一次注册，则初始化一个ConcurrentHashMap final ConcurrentHashMap&lt;String, Lease&lt;InstanceInfo&gt;&gt; gNewMap = new ConcurrentHashMap&lt;String, Lease&lt;InstanceInfo&gt;&gt;(); gMap = registry.putIfAbsent(registrant.getAppName(), gNewMap); if (gMap == null) &#123; gMap = gNewMap; &#125; &#125; //从gMap中查询已经存在的Lease信息，Lease中文翻译为租约 //实际上它把服务提供者的实例信息包装成了一个lease，里面提供了对于服务实例的租约管理 Lease&lt;InstanceInfo&gt; existingLease = gMap.get(registrant.getId()); //当instance已经存在，和客户端的instance的信息做比较，时间最新的那个，为有效 instance信息 if (existingLease != null &amp;&amp; (existingLease.getHolder() != null)) &#123; Long existingLastDirtyTimestamp = existingLease.getHolder().getLastDirtyTimestamp(); Long registrationLastDirtyTimestamp = registrant.getLastDirtyTimestamp(); ... if (existingLastDirtyTimestamp &gt; registrationLastDirtyTimestamp) &#123; ... registrant = existingLease.getHolder(); &#125; &#125; else &#123; // 当租约不存在 synchronized (lock) &#123; if (this.expectedNumberOfClientsSendingRenews &gt; 0) &#123; //客户端续约次数+1 this.expectedNumberOfClientsSendingRenews = this.expectedNumberOfClientsSendingRenews + 1; updateRenewsPerMinThreshold(); &#125; &#125; logger.debug(\"No previous lease information found; it is new registration\"); &#125; // 构建一个租约 Lease&lt;InstanceInfo&gt; lease = new Lease&lt;InstanceInfo&gt;(registrant, leaseDuration); if (existingLease != null) &#123; // 当原来存在Lease的信息时，设置serviceUpTimestamp, //保证服务启动的时间一直是第一次注册的那个 lease.setServiceUpTimestamp(existingLease.getServiceUpTimestamp()); &#125; gMap.put(registrant.getId(), lease); recentRegisteredQueue.add(new Pair&lt;Long, String&gt;( //添加到最近注册的队列中 System.currentTimeMillis(), registrant.getAppName() + \"(\" + registrant.getId() + \")\")); // 检查实例状态是否发生变化，如果是并且存在，则覆盖原来的状态 if (!InstanceStatus.UNKNOWN.equals(registrant.getOverriddenStatus())) &#123; ... if (!overriddenInstanceStatusMap.containsKey(registrant.getId())) &#123; logger.info(\"Not found overridden id &#123;&#125; and hence adding it\", registrant.getId()); overriddenInstanceStatusMap.put(registrant.getId(), registrant.getOverriddenStatus()); &#125; &#125; InstanceStatus overriddenStatusFromMap = overriddenInstanceStatusMap.get(registrant.getId()); if (overriddenStatusFromMap != null) &#123; logger.info(\"Storing overridden status &#123;&#125; from map\", overriddenStatusFromMap); registrant.setOverriddenStatus(overriddenStatusFromMap); &#125; // Set the status based on the overridden status rules InstanceStatus overriddenInstanceStatus = getOverriddenInstanceStatus(registrant, existingLease, isReplication); registrant.setStatusWithoutDirty(overriddenInstanceStatus); // 得到instanceStatus，判断是否是UP状态， if (InstanceStatus.UP.equals(registrant.getStatus())) &#123; lease.serviceUp(); &#125; // 设置注册类型为添加 registrant.setActionType(ActionType.ADDED); // 租约变更记录队列，记录了实例的每次变化， 用于注册信息的增量获取 recentlyChangedQueue.add(new RecentlyChangedItem(lease)); registrant.setLastUpdatedTimestamp(); // 让缓存失效 invalidateCache(registrant.getAppName(), registrant.getVIPAddress(), registrant.getSecureVipAddress()); ... &#125; finally &#123; read.unlock(); &#125;&#125; 3.2 Eureka 的多级缓存设计Eureka Server存在三个变量：(registry、readWriteCacheMap、readOnlyCacheMap)保存服务注册信息，默认情况下定时任务每30s将readWriteCacheMap同步至readOnlyCacheMap，每60s清理超过90s未续约的节点，Eureka Client每30s从readOnlyCacheMap更新服务注册信息，而客户端服务的注册则从registry更新服务注册信息 1、多级缓存的意义这里为什么要设计多级缓存呢？原因很简单，就是当存在大规模的服务注册和更新时，如果只是修改一 个ConcurrentHashMap数据，那么势必因为锁的存在导致竞争，影响性能。 而Eureka又是AP模型，只需要满足最终可用就行。所以它在这里用到多级缓存来实现读写分离。注册方法写的时候直接写内存注册表，写完表之后主动失效读写缓存。 获取注册信息接口先从只读缓存取，只读缓存没有再去读写缓存取，读写缓存没有再去内存注册表里取(不只是取，此处较复杂)。并且，读写缓存会更新回写只读缓存 responseCacheUpdateIntervalMs : readOnlyCacheMap 缓存更新的定时器时间间隔，默认为 30秒 responseCacheAutoExpirationInSeconds : readWriteCacheMap 缓存过期时间，默认为 180 秒 。 2、服务注册的缓存失效在AbstractInstanceRegistry.register方法的最后，会调用invalidateCache方法，使得读写缓存失效。 1234567891011121314public void invalidate(Key... keys) &#123; for (Key key : keys) &#123; ... readWriteCacheMap.invalidate(key); Collection&lt;Key&gt; keysWithRegions = regionSpecificKeys.get(key); if (null != keysWithRegions &amp;&amp; !keysWithRegions.isEmpty()) &#123; for (Key keysWithRegion : keysWithRegions) &#123; logger.debug(\"Invalidating the response cache key : &#123;&#125; &#123;&#125; &#123;&#125; &#123;&#125; &#123;&#125;\", key.getEntityType(), key.getName(), key.getVersion(), key.getType(), key.getEurekaAccept()); readWriteCacheMap.invalidate(keysWithRegion); &#125; &#125; &#125;&#125; 3、定时同步缓存ResponseCacheImpl的构造方法中，会启动一个定时任务，这个任务会定时检查读写缓存中的数据变化，进行更新和同步。 123456789101112131415161718192021222324private TimerTask getCacheUpdateTask() &#123; return new TimerTask() &#123; @Override public void run() &#123; for (Key key : readOnlyCacheMap.keySet()) &#123; if (logger.isDebugEnabled()) &#123; ... &#125; try &#123; CurrentRequestVersion.set(key.getVersion()); Value cacheValue = readWriteCacheMap.get(key); Value currentCacheValue = readOnlyCacheMap.get(key); if (cacheValue != currentCacheValue) &#123; readOnlyCacheMap.put(key, cacheValue); &#125; &#125; catch (Throwable th) &#123; ... &#125; finally &#123; CurrentRequestVersion.remove(); &#125; &#125; &#125; &#125;;&#125; 3.3 服务续约所谓的服务续约，其实就是一种心跳检查机制。客户端会定期发送心跳来续约。那么简单看一下代码的实现 前文第一部分分析了客户端会在 initScheduledTasks 中，创建一个心跳检测的定时任务 123456789heartbeatTask = new TimedSupervisorTask( \"heartbeat\", scheduler, heartbeatExecutor, renewalIntervalInSecs, TimeUnit.SECONDS, expBackOffBound, new HeartbeatThread()); 然后这个定时任务中，会执行一个 HearbeatThread 的线程，这个线程会定时调用renew()来做续约。 1234567private class HeartbeatThread implements Runnable &#123; public void run() &#123; if (renew()) &#123; lastSuccessfulHeartbeatTimestamp = System.currentTimeMillis(); &#125; &#125;&#125; 服务端收到心跳请求之后 在ApplicationResource.getInstanceInfo这个接口中，会返回一个InstanceResource的实例，在该实例 下，定义了一个statusUpdate的接口来更新状态 1234@Path(\"&#123;id&#125;\")public InstanceResource getInstanceInfo(@PathParam(\"id\") String id) &#123; return new InstanceResource(this, id, serverConfig, registry);&#125; InstanceResource.statusUpdate() 在该方法中，我们重点关注 这个方法，它会调用 AbstractInstanceRegistry.statusUpdate来更新指定服务提供者在服务端存储的信息中的变化。 123456789101112131415161718192021222324@PUT@Path(\"status\")public Response statusUpdate( @QueryParam(\"value\") String newStatus, @HeaderParam(PeerEurekaNode.HEADER_REPLICATION) String isReplication, @QueryParam(\"lastDirtyTimestamp\") String lastDirtyTimestamp) &#123; try &#123; if (registry.getInstanceByAppAndId(app.getName(), id) == null) &#123; logger.warn(\"Instance not found: &#123;&#125;/&#123;&#125;\", app.getName(), id); return Response.status(Status.NOT_FOUND).build(); &#125; boolean isSuccess = registry.statusUpdate(app.getName(), id, InstanceStatus.valueOf(newStatus), lastDirtyTimestamp, \"true\".equals(isReplication)); if (isSuccess) &#123; return Response.ok().build(); &#125; else &#123; return Response.serverError().build(); &#125; &#125; catch (Throwable e) &#123; return Response.serverError().build(); &#125;&#125; AbstractInstanceRegistry.statusUpdate 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Overridepublic boolean statusUpdate(String appName, String id, InstanceStatus newStatus, String lastDirtyTimestamp, boolean isReplication) &#123; try &#123; read.lock(); // 更新状态的次数 状态统计 STATUS_UPDATE.increment(isReplication); // 从本地数据里面获取实例信息， Map&lt;String, Lease&lt;InstanceInfo&gt;&gt; gMap = registry.get(appName); Lease&lt;InstanceInfo&gt; lease = null; if (gMap != null) &#123; lease = gMap.get(id); &#125; // 实例不存在，则直接返回，表示失败 if (lease == null) &#123; return false; &#125; else &#123; // 执行一下lease的renew方法，里面主要是更新了这个instance的最后更新时间。 lease.renew(); InstanceInfo info = lease.getHolder(); // 获取instance实例信息 ... // 当instance信息不为空时，并且实例状态发生了变化 if ((info != null) &amp;&amp; !(info.getStatus().equals(newStatus))) &#123; // 如果新状态是UP的状态，那么启动一下serviceUp() , 主要是更新服务的注册时间 if (InstanceStatus.UP.equals(newStatus)) &#123; lease.serviceUp(); &#125; // 将instance Id 和这个状态的映射信息放入覆盖缓存MAP里面去 overriddenInstanceStatusMap.put(id, newStatus); // 设置覆盖状态到实例信息里面去 info.setOverriddenStatus(newStatus); long replicaDirtyTimestamp = 0; info.setStatusWithoutDirty(newStatus); if (lastDirtyTimestamp != null) &#123; replicaDirtyTimestamp = Long.valueOf(lastDirtyTimestamp); &#125; //如果replicaDirtyTimestamp 的时间大于instance的 getLastDirtyTimestamp() ,则更新 if (replicaDirtyTimestamp &gt; info.getLastDirtyTimestamp()) &#123; info.setLastDirtyTimestamp(replicaDirtyTimestamp); &#125; info.setActionType(ActionType.MODIFIED); recentlyChangedQueue.add(new RecentlyChangedItem(lease)); info.setLastUpdatedTimestamp(); //更新写缓存 invalidateCache(appName, info.getVIPAddress(), info.getSecureVipAddress()); &#125; return true; &#125; &#125; finally &#123; read.unlock(); &#125;&#125; 至此，心跳续约功能就分析完成了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public void run() &#123; Future&lt;?&gt; future = null; try &#123; //使用Future，可以设定子线程的超时时间，这样当前线程就不用无限等待了 future = executor.submit(task); threadPoolLevelGauge.set((long) executor.getActiveCount()); //指定等待子线程的最长时间 future.get(timeoutMillis, TimeUnit.MILLISECONDS); // block until done or timeout //delay是个很有用的变量，后面会用到，这里记得每次执行任务成功都会将delay重置 delay.set(timeoutMillis); threadPoolLevelGauge.set((long) executor.getActiveCount()); successCounter.increment(); &#125; catch (TimeoutException e) &#123; logger.warn(\"task supervisor timed out\", e); timeoutCounter.increment(); long currentDelay = delay.get(); //任务线程超时的时候，就把delay变量翻倍，但不会超过外部调用时设定的最大延时时间 long newDelay = Math.min(maxDelay, currentDelay * 2); //设置为最新的值，考虑到多线程，所以用了CAS delay.compareAndSet(currentDelay, newDelay); &#125; catch (RejectedExecutionException e) &#123; //一旦线程池的阻塞队列中放满了待处理任务，触发了拒绝策略，就会将调度器停掉 if (executor.isShutdown() || scheduler.isShutdown()) &#123; logger.warn(\"task supervisor shutting down, reject the task\", e); &#125; else &#123; logger.warn(\"task supervisor rejected the task\", e); &#125; rejectedCounter.increment(); &#125; catch (Throwable e) &#123;//一旦出现未知的异常，就停掉调度器 if (executor.isShutdown() || scheduler.isShutdown()) &#123; logger.warn(\"task supervisor shutting down, can't accept the task\"); &#125; else &#123; logger.warn(\"task supervisor threw an exception\", e); &#125; throwableCounter.increment(); &#125; finally &#123; //这里任务要么执行完毕，要么发生异常，都用cancel方法来清理任务; if (future != null) &#123; future.cancel(true); &#125; //只要调度器没有停止，就再指定等待时间之后在执行一次同样的任务 if (!scheduler.isShutdown()) &#123; scheduler.schedule(this, delay.get(), TimeUnit.MILLISECONDS); &#125; &#125;&#125; 这里就是周期性任务的原因:只要没有停止调度器，就再创建一次性任务，执行时间时dealy的值，假设外部调用时传入的超时时间为30秒(构造方法的入参timeout)，最大间隔时间为50 秒(构造方法的入参expBackOffBound) 如果最近一次任务没有超时，那么就在30秒后开始新任务，如果最近一次任务超时了，那么就在50秒后开始新任务(异常处理中有个乘以二的操作， 乘以二后的60秒超过了最大间隔50秒) 3.4 服务端查询服务地址流程前面我们知道，客户端发起服务地址的查询有两种，一种是全量、另一种是增量。对于全量查询请求， 会调用Eureka-server的ApplicationsResource的getContainers方法。 而对于增量请求，会调用ApplicationsResource.getContainerDifferential。 ApplicationsResource.getContainers 接收客户端发送的获取全量注册信息请求。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@GETpublic Response getContainers(@PathParam(\"version\") String version, @HeaderParam(HEADER_ACCEPT) String acceptHeader, @HeaderParam(HEADER_ACCEPT_ENCODING) String acceptEncoding, @HeaderParam(EurekaAccept.HTTP_X_EUREKA_ACCEPT) String eurekaAccept, @Context UriInfo uriInfo, @Nullable @QueryParam(\"regions\") String regionsStr) &#123; boolean isRemoteRegionRequested = null != regionsStr &amp;&amp; !regionsStr.isEmpty(); String[] regions = null; if (!isRemoteRegionRequested) &#123; EurekaMonitors.GET_ALL.increment(); &#125; else &#123; regions = regionsStr.toLowerCase().split(\",\"); Arrays.sort(regions); // So we don't have different caches for same regions queried in different order. EurekaMonitors.GET_ALL_WITH_REMOTE_REGIONS.increment(); &#125; // EurekaServer无法提供服务，返回403 if (!registry.shouldAllowAccess(isRemoteRegionRequested)) &#123; return Response.status(Status.FORBIDDEN).build(); &#125; CurrentRequestVersion.set(Version.toEnum(version)); KeyType keyType = Key.KeyType.JSON;// 设置返回数据格式，默认JSON String returnMediaType = MediaType.APPLICATION_JSON; if (acceptHeader == null || !acceptHeader.contains(HEADER_JSON_VALUE)) &#123; // 如果接收到的请求头部没有具体格式信息，则返回格式为XML keyType = Key.KeyType.XML; returnMediaType = MediaType.APPLICATION_XML; &#125; // 构建缓存键 Key cacheKey = new Key(Key.EntityType.Application, ResponseCacheImpl.ALL_APPS, keyType, CurrentRequestVersion.get(), EurekaAccept.fromString(eurekaAccept), regions ); // 返回不同的编码类型的数据，去缓存中取数据的方法基本一致 Response response; if (acceptEncoding != null &amp;&amp; acceptEncoding.contains(HEADER_GZIP_VALUE)) &#123; response = Response.ok(responseCache.getGZIP(cacheKey)) .header(HEADER_CONTENT_ENCODING, HEADER_GZIP_VALUE) .header(HEADER_CONTENT_TYPE, returnMediaType) .build(); &#125; else &#123; response = Response.ok(responseCache.get(cacheKey)) .build(); &#125; CurrentRequestVersion.remove(); return response;&#125; responseCache.getGZIP 从缓存中读取数据。 1234567public byte[] getGZIP(Key key) &#123; Value payload = getValue(key, shouldUseReadOnlyResponseCache); if (payload == null) &#123; return null; &#125; return payload.getGzipped();&#125; 1234567891011121314151617181920@VisibleForTestingValue getValue(final Key key, boolean useReadOnlyCache) &#123; Value payload = null; try &#123; if (useReadOnlyCache) &#123; final Value currentPayload = readOnlyCacheMap.get(key); if (currentPayload != null) &#123; payload = currentPayload; &#125; else &#123; payload = readWriteCacheMap.get(key); readOnlyCacheMap.put(key, payload); &#125; &#125; else &#123; payload = readWriteCacheMap.get(key); &#125; &#125; catch (Throwable t) &#123; logger.error(\"Cannot get value for key : &#123;&#125;\", key, t); &#125; return payload;&#125;","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/tags/SpringCloud/"}],"keywords":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}]},{"title":"SpringCloud-Eureka自我保护机制","slug":"SpringCloud-Eureka自我保护机制","date":"2019-07-06T16:00:00.000Z","updated":"2020-07-20T02:54:43.838Z","comments":true,"path":"2019/07/07/SpringCloud-Eureka自我保护机制/","link":"","permalink":"https://zzkenyon.github.io/2019/07/07/SpringCloud-Eureka自我保护机制/","excerpt":"","text":"常用的注册中解决方案： Eureka 非持久化存储、ap模型、去中心化集群模式 Zookeeper zab协议 Consul Nacos Redis Etcd 服务信息发生变化，消费者如何感知 等待注册中心push 优点：实时性高 缺点：注册中心需要维护所有活动消费者的信息才能完成推送 主动pull 优点：没有以上的缺点 缺点：服务信息更新的延迟时间可能会导致请求发送到实效节点 long polling Eureka的自我保护机制Eureka Server在运行期间会去统计心跳成功的比例在15分钟之内是否低于85% , 如果低于85%， Eureka Server会认为当前实例的客户端与自己的心跳连接出现了网络故障，那么Eureka Server会把这 些实例保护起来，让这些实例不会过期导致实例剔除。 这样做的目的是为了减少网络不稳定或者网络分区的情况下，Eureka Server将健康服务剔除下线的问题。 使用自我保护机制可以使得Eureka 集群更加健壮和稳定的运行。 进入自我保护状态后，会出现以下几种情况： Eureka Server不再从注册列表中移除因为长时间没有收到心跳而应该剔除的过期服务 Eureka Server仍然能够接受新服务的注册和查询请求，但是不会被同步到其他节点上，保证当前节点依然可用。 开启自我保护为了演示效果，我们通过如下配置，将判定时间改为10s，接着启动Eureka Server，等待10s之 后，就会出现以上提示信息，表示自我保护被激活了。 123#设置 eureka server同步失败的等待时间默认5分#在这期间，它不向客户端提供服务注册信息 eureka.server.wait-time-in-ms-when-sync-empty=10000 两个变量在Eureka的自我保护机制中，有两个很重要的变量，Eureka的自我保护机制，都是围绕这两个变量来 实现的，在AbstractInstanceRegistry这个类中定义的 1234//每分钟最小续约数量protected volatile int numberOfRenewsPerMinThreshold; //预期每分钟收到续约的 客户端数量，取决于注册到eureka server上的服务数量protected volatile int expectedNumberOfClientsSendingRenews; numberOfRenewsPerMinThreshold 表示每分钟的最小续约数量，它表示什么意思呢?就是Eureka Server期望每分钟收到客户端实例续约的总数的阈值。如果小于这个阈值，就会触发自我保护机制。 它是在以下代码中赋值的： 123456protected void updateRenewsPerMinThreshold() &#123; this.numberOfRenewsPerMinThreshold = (int)(this.expectedNumberOfClientsSendingRenews * (60.0 / serverConfig.getExpectedClientRenewalIntervalSeconds()) * serverConfig.getRenewalPercentThreshold());&#125;//自我保护阀值 = 服务总数 * 每分钟续约数(60S/客户端续约间隔) * 自我保护续约百分比阀值因子 getExpectedClientRenewalIntervalSeconds，客户端的续约间隔，默认为30s getRenewalPercentThreshold，自我保护续约百分比阈值因子，默认0.85。 也就是说每分钟的续 约数量要大于85% 这两个变量的更新需要注意的是，这两个变量是动态更新的，有四个地方来更新这两个值 Eureka-Server的初始化 在EurekaBootstrap这个类中，有一个 initEurekaServerContext 方法 12345 protected void initEurekaServerContext() throws Exception &#123; EurekaServerConfig eurekaServerConfig = new DefaultEurekaServerConfig(); //... registry.openForTraffic(applicationInfoManager, registryCount);&#125; 1234567891011121314151617181920// PeerAwareInstanceRegistryImpl.openForTrafficpublic void openForTraffic(ApplicationInfoManager applicationInfoManager, intcount) &#123; this.expectedNumberOfClientsSendingRenews = count; //初始化 updateRenewsPerMinThreshold(); //更新numberOfRenewsPerMinThreshold logger.info(\"Got &#123;&#125; instances from neighboring DS node\", count); logger.info(\"Renew threshold is: &#123;&#125;\", numberOfRenewsPerMinThreshold); this.startupTime = System.currentTimeMillis(); if (count &gt; 0) &#123; this.peerInstancesTransferEmptyOnStartup = false; &#125; DataCenterInfo.Name selfName =applicationInfoManager.getInfo().getDataCenterInfo().getName(); boolean isAws = Name.Amazon == selfName; if (isAws &amp;&amp; serverConfig.shouldPrimeAwsReplicaConnections()) &#123; logger.info(\"Priming AWS connections for all replicas..\"); primeAwsReplicas(applicationInfoManager); &#125; logger.info(\"Changing status to UP\"); applicationInfoManager.setInstanceStatus(InstanceStatus.UP); super.postInit();&#125; PeerAwareInstanceRegistryImpl.cancel 当服务提供者主动下线时，表示这个时候Eureka-Server要剔除这个服务提供者的地址，同时也代表这 这个心跳续约的阈值要发生变化。所以在 PeerAwareInstanceRegistryImpl.cancel 中可以看到数据 的更新 调用路径 PeerAwareInstanceRegistryImpl.cancel -&gt; AbstractInstanceRegistry.cancel- &gt;internalCancel 服务下线之后，意味着需要发送续约的客户端数量递减了，所以在这里进行修改 1234567891011protected boolean internalCancel(String appName, String id, booleanisReplication) &#123; //.... synchronized (lock) &#123; if (this.expectedNumberOfClientsSendingRenews &gt; 0) &#123; // Since the client wants to cancel it, reduce the number of clientsto send renews. this.expectedNumberOfClientsSendingRenews =this.expectedNumberOfClientsSendingRenews - 1; updateRenewsPerMinThreshold(); &#125; &#125;&#125; PeerAwareInstanceRegistryImpl.register 当有新的服务提供者注册到eureka-server上时，需要增加续约的客户端数量，所以在register方法中会 进行处理 register -&gt;super.register(AbstractInstanceRegistry) 123456789public void register(InstanceInfo registrant, int leaseDuration, booleanisReplication) &#123; // The lease does not exist and hence it is a new registration synchronized (lock) &#123; if (this.expectedNumberOfClientsSendingRenews &gt; 0) &#123; this.expectedNumberOfClientsSendingRenews =this.expectedNumberOfClientsSendingRenews + 1; updateRenewsPerMinThreshold(); &#125; &#125;&#125; PeerAwareInstanceRegistryImpl.scheduleRenewalThreshold UpdateTask 15分钟运行一次，判断在15分钟之内心跳失败比例是否低于85%。在 DefaultEurekaServerContext 》@PostConstruct修饰的initialize()方法》init() 1234567891011121314151617181920212223242526272829303132333435private void scheduleRenewalThresholdUpdateTask() &#123; timer.schedule(new TimerTask() &#123; @Override public void run() &#123; updateRenewalThreshold(); &#125; &#125;, serverConfig.getRenewalThresholdUpdateIntervalMs(), serverConfig.getRenewalThresholdUpdateIntervalMs());&#125;private void updateRenewalThreshold() &#123; try &#123; Applications apps = eurekaClient.getApplications(); int count = 0; for (Application app : apps.getRegisteredApplications()) &#123; for (InstanceInfo instance : app.getInstances()) &#123; if (this.isRegisterable(instance)) &#123; ++count; &#125; &#125; &#125; synchronized (lock) &#123; // Update threshold only if the threshold is greater than the // current expected threshold or if self preservation is disabled. if ((count) &gt; (serverConfig.getRenewalPercentThreshold() *expectedNumberOfClientsSendingRenews) || (!this.isSelfPreservationModeEnabled())) &#123; this.expectedNumberOfClientsSendingRenews = count; updateRenewsPerMinThreshold(); &#125; &#125; logger.info(\"Current renewal threshold is : &#123;&#125;\",numberOfRenewsPerMinThreshold); &#125; catch (Throwable e) &#123; logger.error(\"Cannot update renewal threshold\", e); &#125; &#125; 自我保护机制触发任务在AbstractInstanceRegistry的postInit方法中，会开启一个EvictionTask的任务，这个任务用来检测是 否需要开启自我保护机制。 12345678910protected void postInit() &#123; renewsLastMin.start(); if (evictionTaskRef.get() != null) &#123; evictionTaskRef.get().cancel(); &#125; evictionTaskRef.set(new EvictionTask()); evictionTimer.schedule(evictionTaskRef.get(), serverConfig.getEvictionIntervalTimerInMs(), serverConfig.getEvictionIntervalTimerInMs()); &#125; 其中，EvictionTask表示最终执行的任务 1234567891011 private final AtomicLong lastExecutionNanosRef = new AtomicLong(0l);@Overridepublic void run() &#123; try &#123; long compensationTimeMs = getCompensationTimeMs(); logger.info(\"Running the evict task with compensationTime &#123;&#125;ms\",compensationTimeMs); evict(compensationTimeMs); &#125; catch (Throwable e) &#123; logger.error(\"Could not run the evict task\", e); &#125;&#125; 123456789 public void evict(long additionalLeaseMs) &#123; logger.debug(\"Running the evict task\"); // 是否需要开启自我保护机制，如果需要，那么直接RETURE， 不需要继续往下执行了 if (!isLeaseExpirationEnabled()) &#123; logger.debug(\"DS: lease expiration is currently disabled.\"); return; &#125;//这下面主要是做服务自动下线的操作的 &#125; isLeaseExpirationEnabled 是否开启了自我保护机制，如果没有，则跳过，默认是开启 计算是否需要开启自我保护，判断最后一分钟收到的续约数量是否大于 numberOfRenewsPerMinThreshold 12345678 public boolean isLeaseExpirationEnabled() &#123; if (!isSelfPreservationModeEnabled()) &#123; // The self preservation mode is disabled, hence allowing the instancesto expire. return true; &#125; return numberOfRenewsPerMinThreshold &gt; 0 &amp;&amp; getNumOfRenewsInLastMin() &gt;numberOfRenewsPerMinThreshold;&#125;","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/tags/SpringCloud/"}],"keywords":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}]},{"title":"kafka-消息的存储","slug":"MQ-kafka-消息的存储","date":"2019-07-04T16:00:00.000Z","updated":"2020-06-01T07:10:01.049Z","comments":true,"path":"2019/07/05/MQ-kafka-消息的存储/","link":"","permalink":"https://zzkenyon.github.io/2019/07/05/MQ-kafka-消息的存储/","excerpt":"","text":"一个topic的多个partition在物理磁盘上的保存路径，路径保存在 /tmp/kafka-logs/topic_partition，包 含日志文件、索引文件和时间索引文件 kafka是通过分段的方式将Log分为多个LogSegment，LogSegment是一个逻辑上的概念，一个 LogSegment对应磁盘上的一个日志文件和一个索引文件，其中日志文件是用来记录消息的。索引文件是用来保存消息的索引。那么这个LogSegment是什么呢？ LogSegment假设kafka以partition为最小存储单位，那么我们可以想象当kafka producer不断发送消息，必然会引起partition文件的无线扩张，这样对于消息文件的维护以及被消费的消息的清理带来非常大的挑战，所以kafka以segment为单位又把partition进行细分。每个partition相当于一个巨型文件被平均分配到多个大小相等的segment数据文件中（每个segment文件中的消息不一定相等），这种特性方便已经被消费的消息的清理，提高磁盘的利用率。 log.segment.bytes=107370 (设置分段大小)，默认是1gb，我们把这个值调小以后，可以看到日志分段的效果 抽取其中3个分段来进行分析 segment fifile由2大部分组成，分别为index fifile和data fifile，此2个文件一一对应，成对出现，后 缀”.index”和“.log”分别表示为segment索引文件、数据文件。 segment文件命名规则：partion全局的第一个segment从0开始，后续每个segment文件名为上一个 segment文件最后一条消息的offset值进行递增。数值最大为64位long大小，20位数字字符长度，没有数字用0填充 segment文件命名规则通过下面这条命令可以看到kafka消息日志的内容，假如第一个log文件的最后一个offset为:5376，所以下一个segment的文件命名为: 00000000000000005376.log。对应的index为00000000000000005376.index index和log的对应关系从所有分段中，找一个分段进行分析 为了提高查找消息的性能，为每一个日志文件添加2个索引索引文件：OffsetIndex 和 TimeIndex，分别对应.index以及.timeindex， TimeIndex索引文件格式：它是映射时间戳和相对offset 查看索引内容： 1sh kafka-run-class.sh kafka.tools.DumpLogSegments --files /tmp/kafka-logs/test-0/00000000000000000000.log --print-data-log 如图所示，index中存储了索引以及物理偏移量。 log存储了消息的内容。索引文件的元数据执行对应数据文件中message的物理偏移地址。举个简单的案例来说，以[4053，80899]为例，在log文件中，对应的是第4053条记录，物理偏移量（position）为80899. position是ByteBuffer的指针位置 通过offset查找message查找的算法是 根据offset的值，查找segment段中的index索引文件。由于索引文件命名是以上一个文件的最后 一个offset进行命名的，所以，使用二分查找算法能够根据offset快速定位到指定的索引文件。 找到索引文件后，根据offset进行定位，找到索引文件中的符合范围的索引。（kafka采用稀疏索引的方式来提高查找性能） 得到position以后，再到对应的log文件中，从position出开始查找offset对应的消息，将每条消息的offffset与目标offset进行比较，直到找到消息 。 比如说，我们要查找offset=2490这条消息，那么先找到00000000000000000000.index， 然后找到 [2487，49111]这个索引，再到log文件中，根据49111这个position开始查找，比较每条消息的offset是 否大于等于2490。最后查找到对应的消息以后返回 Log文件的消息内容分析 前面我们通过kafka提供的命令，可以查看二进制的日志文件信息，一条消息，会包含很多的字段。 123offset: 5371 position: 102124 CreateTime: 1531477349286 isvalid: true keysize: -1 valuesize: 12 magic: 2 compresscodec: NONE producerId: -1 producerEpoch: -1 sequence: -1 isTransactional: false headerKeys: [] payload: message_5371 offset和position这两个前面已经讲过了、 createTime表示创建时间、keysize和valuesize表示key和 value的大小、 compresscodec表示压缩编码、payload:表示消息的具体内容 日志的清除策略以及压缩策略前面提到过，日志的分段存储，一方面能够减少单个文件内容的大小，另一方面，方便kafka进行日志 清理。日志的清理策略有两个 根据消息的保留时间，当消息在kafka中保存的时间超过了指定的时间，就会触发清理过程 根据topic存储的数据大小，当topic所占的日志文件大小大于一定的阀值，则可以开始删除最旧的消息。kafka会启动一个后台线程，定期检查是否存在可以删除的消息 通过log.retention.bytes和log.retention.hours这两个参数来设置，当其中任意一个达到要求，都会执 行删除。 默认的保留时间是：7天 日志压缩策略Kafka还提供了“日志压缩（Log Compaction）”功能，通过这个功能可以有效的减少日志文件的大小， 缓解磁盘紧张的情况，在很多实际场景中，消息的key和value的值之间的对应关系是不断变化的，就像 数据库中的数据会不断被修改一样，消费者只关心key对应的最新的value。因此，我们可以开启kafka 的日志压缩功能，服务端会在后台启动启动Cleaner线程池，定期将相同的key进行合并，只保留最新的 value值。日志的压缩原理是 磁盘存储的性能问题磁盘存储的性能优化我们现在大部分企业仍然用的是机械结构的磁盘，如果把消息以随机的方式写入到磁盘，那么磁盘首先 要做的就是寻址，也就是定位到数据所在的物理地址，在磁盘上就要找到对应的柱面、磁头以及对应的 扇区；这个过程相对内存来说会消耗大量时间，为了规避随机读写带来的时间消耗，kafka采用顺序写 的方式存储数据。即使是这样，但是频繁的I/O操作仍然会造成磁盘的性能瓶颈 零拷贝消息从发送到落地保存，broker维护的消息日志本身就是文件目录，每个文件都是二进制保存，生产者 和消费者使用相同的格式来处理。在消费者获取消息时，服务器先从硬盘读取数据到内存，然后把内存 中的数据原封不动的通过socket发送给消费者。虽然这个操作描述起来很简单，但实际上经历了很多步骤。 通过“零拷贝”技术，可以去掉这些没必要的数据复制操作，同时也会减少上下文切换次数。现代的unix 操作系统提供一个优化的代码路径，用于将数据从页缓存传输到socket；在Linux中，是通过sendfifile系 统调用来完成的。Java提供了访问这个系统调用的方法：FileChannel.transferTo API 使用sendfifile，只需要一次拷贝就行，允许操作系统将数据直接从页缓存发送到网络上。所以在这个优化的路径中，只有最后一步将数据拷贝到网卡缓存中是需要的 页缓存页缓存是操作系统实现的一种主要的磁盘缓存，但凡设计到缓存的，基本都是为了提升i/o性能，所以页 缓存是用来减少磁盘I/O操作的。 磁盘高速缓存有两个重要因素： 第一，访问磁盘的速度要远低于访问内存的速度，若从处理器L1和L2高速缓存访问则速度更快。 第二，数据一旦被访问，就很有可能短时间内再次访问。正是由于基于访问内存比磁盘快的多，所 以磁盘的内存缓存将给系统存储性能带来质的飞越。 当 一 个进程准备读取磁盘上的文件内容时， 操作系统会先查看待读取的数据所在的页(page)是否在页 缓存(pagecache)中，如果存在（命中）则直接返回数据， 从而避免了对物理磁盘的I/0操作；如果没有 命中， 则操作系统会向磁盘发起读取请求并将读取的数据页存入页缓存， 之后再将数据返回给进程。 同样，如果 一 个进程需要将数据写入磁盘， 那么操作系统也会检测数据对应的页是否在页缓存中，如 果不存在， 则会先在页缓存中添加相应的页， 最后将数据写入对应的页。 被修改过后的页也就变成了 脏页， 操作系统会在合适的时间把脏页中的数据写入磁盘， 以保持数据的 一 致性 Kafka中大量使用了页缓存， 这是Kafka实现高吞吐的重要因素之 一 。 虽然消息都是先被写入页缓存， 然后由操作系统负责具体的刷盘任务的， 但在Kafka中同样提供了同步刷盘及间断性强制刷盘(fsync)， 可以通过 log.flush.interval.messages 和 log.flush.interval.ms 参数来控制。 同步刷盘能够保证消息的可靠性，避免因为宕机导致页缓存数据还未完成同步时造成的数据丢失。但是 实际使用上，我们没必要去考虑这样的因素以及这种问题带来的损失，消息可靠性可以由多副本来解 决，同步刷盘会带来性能的影响。 刷盘的操作由操作系统去完成即可 Kafka消息的可靠性没有一个中间件能够做到百分之百的完全可靠，可靠性更多的还是基于几个9的衡量指标，比如4个9、5 个9. 软件系统的可靠性只能够无限去接近100%，但不可能达到100%。所以kafka如何是实现最大可能 的可靠性呢？ 分区副本， 你可以创建更多的分区来提升可靠性，但是分区数过多也会带来性能上的开销，一般 来说，3个副本就能满足对大部分场景的可靠性要求 acks，生产者发送消息的可靠性，也就是我要保证我这个消息一定是到了broker并且完成了多副 本的持久化，但这种要求也同样会带来性能上的开销。它有几个可选项 1 ，生产者把消息发送到leader副本，leader副本在成功写入到本地日志之后就告诉生产者 消息提交成功，但是如果isr集合中的follower副本还没来得及同步leader副本的消息， leader挂了，就会造成消息丢失 -1 ，消息不仅仅写入到leader副本，并且被ISR集合中所有副本同步完成之后才告诉生产者已 经提交成功，这个时候即使leader副本挂了也不会造成数据丢失。 0：表示producer不需要等待broker的消息确认。这个选项时延最小但同时风险最大（因为 当server宕机时，数据将会丢失）。 保障消息到了broker之后，消费者也需要有一定的保证，因为消费者也可能出现某些问题导致消 息没有消费到 enable.auto.commit默认为true，也就是自动提交offffset，自动提交是批量执行的，有一个时间窗 口，这种方式会带来重复提交或者消息丢失的问题，所以对于高可靠性要求的程序，要使用手动提 交。 对于高可靠要求的应用来说，宁愿重复消费也不应该因为消费异常而导致消息丢失","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://zzkenyon.github.io/categories/消息中间件/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://zzkenyon.github.io/tags/kafka/"}],"keywords":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://zzkenyon.github.io/categories/消息中间件/"}]},{"title":"SpringCloud-Feign底层源码分析","slug":"SpringCloud-Feign底层源码分析","date":"2019-07-03T16:00:00.000Z","updated":"2021-01-19T05:56:33.833Z","comments":true,"path":"2019/07/04/SpringCloud-Feign底层源码分析/","link":"","permalink":"https://zzkenyon.github.io/2019/07/04/SpringCloud-Feign底层源码分析/","excerpt":"","text":"Feign能实现什么： 远程调用 负载均衡 在Feign之前，我们使用RestTemplate + Ribbon 来处理服务的远程调用和负载均衡，那为什么要重新开发一套呢？ 主要是使用RestTemplate进行远程调用需要进行字符串的拼接，拼接http请求的url，而在微服务架构中，我们期望的方式是能够像调用本地方法一样调用远程服务提供的接口方法，Feign让这个需求得到了实现。 具体的用法之前文章已经讲过了，本文着重分析Feign的底层实现原理。 思考Feign要做的事情 feginClient参数的解析和装载 针对指定的client，生成动态代理 调用client中的方法时解析方法，组装出一个request对象发起请求，解析过程中包含负载均衡 注解@EnableFeignClients12345@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Documented@Import(FeignClientsRegistrar.class)public @interface EnableFeignClients &#123;...&#125; 当我们在启动类上注解了@EnableFeignClients，启动时会导入@Import(FeignClientsRegistrar.class)，这是Bean动态装载的用法，FeignClientsRegistrar就是开启feign的入口类。 FeignClientsRegistrar 1234567//FeignClientsRegistrar@Override // springboot启动时会调用这个方法public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry) &#123; registerDefaultConfiguration(metadata, registry); registerFeignClients(metadata, registry);&#125; registerDefaultConfiguration() 方法从 SpringBoot 启动类上检查是否有 @EnableFeignClients，有该注解的话， 则完成 Feign 框架相关的一些配置内容注册 registerFeignClients() 方法从 classpath 中， 扫描获得注解了 @FeignClient 的类， 将类的内容解析为 BeanDefinition ，最终通过调用 Spring 框架中的 BeanDefinitionReaderUtils.resgisterBeanDefinition 将解析处理过的 FeignClient BeanDeifinition 添加到 spring 容器中。 重点在第二个方法，registerFeignClients()最终会在一个for循环中调用registerFeignClient方法，注册每一个feginClient， 1234567891011//FeignClientsRegistrarpublic void registerFeignClients(AnnotationMetadata metadata,BeanDefinitionRegistry registry) &#123; ... for (String basePackage : basePackages) &#123; Set&lt;BeanDefinition&gt; candidateComponents = scanner.findCandidateComponents(basePackage); for (BeanDefinition candidateComponent : candidateComponents) &#123; ... registerFeignClient(registry, annotationMetadata, attributes); &#125; &#125; &#125; registerFeignClient方法，就是去组装BeanDefinition，也就是Bean的定义，然后注册到Spring IOC容器。 123456789private void registerFeignClient(BeanDefinitionRegistry registry, AnnotationMetadata annotationMetadata, Map&lt;String, Object&gt; attributes) &#123; String className = annotationMetadata.getClassName(); BeanDefinitionBuilder definition = BeanDefinitionBuilder .genericBeanDefinition(FeignClientFactoryBean.class); ... // BeanDefinitionHolder holder = new BeanDefinitionHolder(beanDefinition, className,new String[] &#123; alias &#125;); BeanDefinitionReaderUtils.registerBeanDefinition(holder, registry);&#125; 此处关注一下，BeanDefinitionBuilder是用来构建一个BeanDefinition的，它是通过 genericBeanDefinition 来构建的，并且传入了一个FeignClientFactoryBean的类对象。 所以每个@FeginClient注解的类最终都会注册一个FactoryBean到容器中，简单来说，当我们代码自动注入feignClient时，会通过对应的FactoryBean的getObject方法获得一个实例。 FeignClientFactoryBean.getObject()getObject调用的是getTarget方法，它从applicationContext取出FeignContext，FeignContext继承了 NamedContextFactory，它是用来统一维护feign中各个feign客户端相互隔离的上下文。 FeignContext注册到容器是在FeignAutoConfiguration上完成的 123456789// FeignAutoConfiguration@Autowired(required = false)private List&lt;FeignClientSpecification&gt; configurations = new ArrayList&lt;&gt;();@Beanpublic FeignContext feignContext() &#123; FeignContext context = new FeignContext(); context.setConfigurations(this.configurations); return context;&#125; 在初始化FeignContext时，会把configurations在容器中放入FeignContext中。configurations的来源就是在前面registerFeignClients方法中将@FeignClient的配置configuration，每个feginClient对应了一个FeignClientSpecification，内含serviceid和配置类的类对象引用。 贴一下源码： 1234567891011121314151617181920212223//FeignClientFactoryBean@Overridepublic Object getObject() throws Exception &#123; return getTarget();&#125;// T泛型在这里表示的应该是FeignClient的代理类型&lt;T&gt; T getTarget() &#123; FeignContext context = this.applicationContext.getBean(FeignContext.class); Feign.Builder builder = feign(context); // 一般使用中都是使用服务名称调用服务，所以通常会执行这段代码 if (!StringUtils.hasText(this.url)) &#123; // 如果url为空，则走负载均衡，生成能负载均衡的代理类 if (!this.name.startsWith(\"http\")) &#123; this.url = \"http://\" + this.name; &#125; else &#123; this.url = this.name; &#125; this.url += cleanPath(); return (T) loadBalance(builder, context, new HardCodedTarget&lt;&gt;(this.type, this.name, this.url)); &#125; ...// 如果制定了url，则生成默认的代理类,不常用省略不分析&#125; 接着，构建feign.builder，在构建时会向FeignContext获取配置的Encoder，Decoder等各种信息。 FeignContext在上篇中已经提到会为每个Feign客户端分配了一个容器，它们的父容器就是spring容器 配置完Feign.Builder之后，再判断是否需要LoadBalance，如果需要，则通过LoadBalance的方法来设置。实际上他们最终调用的是Targeter.target()方法。 loadBalance该方法生成具备负载均衡能力的feign客户端 123456789101112protected &lt;T&gt; T loadBalance(Feign.Builder builder, FeignContext context, HardCodedTarget&lt;T&gt; target) &#123; // 从上下文中获取一个Client，默认是LoadBalanceFeignClient Client client = getOptional(context, Client.class); if (client != null) &#123; builder.client(client); // 先根据服务名称获取对应上下文，再在上下文中getbean（Targeter.class） Targeter targeter = get(context, Targeter.class); return targeter.target(this, builder, context, target); &#125; ...&#125; LoadBalanceFeignClient在FeignRibbonClientAutoConfiguration这个自动装配类中通过Import注解进行装配的。 123@Import(&#123; HttpClientFeignLoadBalancedConfiguration.class, OkHttpFeignLoadBalancedConfiguration.class, DefaultFeignLoadBalancedConfiguration.class &#125;) DefaultTarget.target123456// DefaultTarget@Overridepublic &lt;T&gt; T target(FeignClientFactoryBean factory, Feign.Builder feign, FeignContext context, Target.HardCodedTarget&lt;T&gt; target) &#123; return feign.target(target);&#125; 直接执行Feign.Builder的target方法 1234//Feign.Bulderpublic &lt;T&gt; T target(Target&lt;T&gt; target) &#123; return build().newInstance(target);&#125; build()方法构建出一个ReflectiveFeign，再执行newInstance(target)，参数Target&lt;T&gt; target表示即将被代理的目标 123456789101112131415161718192021222324252627@Overridepublic &lt;T&gt; T newInstance(Target&lt;T&gt; target) &#123; Map&lt;String, MethodHandler&gt; nameToHandler = targetToHandlersByName.apply(target); Map&lt;Method, MethodHandler&gt; methodToHandler = new LinkedHashMap&lt;Method, MethodHandler&gt;(); List&lt;DefaultMethodHandler&gt; defaultMethodHandlers = new LinkedList&lt;DefaultMethodHandler&gt;(); for (Method method : target.type().getMethods()) &#123; if (method.getDeclaringClass() == Object.class) &#123; continue; &#125; else if (Util.isDefault(method)) &#123; DefaultMethodHandler handler = new DefaultMethodHandler(method); defaultMethodHandlers.add(handler); methodToHandler.put(method, handler); &#125; else &#123; methodToHandler.put(method, nameToHandler.get(Feign.configKey(target.type(), method))); &#125; &#125; InvocationHandler handler = factory.create(target, methodToHandler); // jdk动态代理 T proxy = (T) Proxy.newProxyInstance(target.type().getClassLoader(), new Class&lt;?&gt;[] &#123;target.type()&#125;, handler); for (DefaultMethodHandler defaultMethodHandler : defaultMethodHandlers) &#123; defaultMethodHandler.bindTo(proxy); &#125; return proxy;&#125; 这个方法是用来创建一个动态代理的方法，在生成动态代理之前，会根据Contract协议(协议解析规 则，解析接口类的注解信息，解析成内部的MethodHandler的处理方式。 从实现的代码中可以看到熟悉的Proxy.newProxyInstance方法产生代理类。而这里需要对每个定义的接 口方法进行特定的处理实现，所以这里会出现一个MethodHandler的概念，就是对应方法级别的 InvocationHandler。 targetToHandlersByName.apply(target)根据FeignClient接口的描述解析出对应的请求数据，根据Contract协议规则，解析接口类的注解信息，解析成内部表现：会解析接口方法上的注解，从而解析出方法粒度的特定的配置信息，然后生产一个SynchronousMethodHandler 然后需要维护一个&lt;method，MethodHandler&gt; 的map，放入InvocationHandler接口的实现FeignInvocationHandler中。 OpenFeign的调用过程在前面的分析中，我们知道OpenFeign最终返回的是一个ReflectiveFeign.FeignInvocationHandler的对象。 那么当客户端发起请求时，会进入到FeignInvocationHandler.invoke方法中，这个大家都知道，它是 一个动态代理的实现。 123456789101112131415161718@Override //FeignInvocationHandlerpublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; if (\"equals\".equals(method.getName())) &#123; try &#123; Object otherHandler = args.length &gt; 0 &amp;&amp; args[0] != null ? Proxy.getInvocationHandler(args[0]) : null; return equals(otherHandler); &#125; catch (IllegalArgumentException e) &#123; return false; &#125; &#125; else if (\"hashCode\".equals(method.getName())) &#123; return hashCode(); &#125; else if (\"toString\".equals(method.getName())) &#123; return toString(); &#125; return dispatch.get(method).invoke(args);&#125; 在invoke方法中，会调用 this.dispatch.get(method) 会返回一个SynchronousMethodHandler，进行拦截处理。dispatch是分发的意思，这里的dispatch就是解析阶段生成的Map&lt;Method, MethodHandler&gt;，根据调用的方法，执行指定方法的SynchronousMethodHandler.invoke方法。 这个方法会根据参数生成完成的RequestTemplate对象，这个对象是Http请求的模版，代码如下。 1234567891011121314151617181920212223242526@Override //SynchronousMethodHandlerpublic Object invoke(Object[] argv) throws Throwable &#123; RequestTemplate template = buildTemplateFromArgs.create(argv); Options options = findOptions(argv); Retryer retryer = this.retryer.clone(); while (true) &#123; try &#123; return executeAndDecode(template, options); // 执行到这里还没有进行负载均衡 &#125; catch (RetryableException e) &#123; try &#123; retryer.continueOrPropagate(e); &#125; catch (RetryableException th) &#123; Throwable cause = th.getCause(); if (propagationPolicy == UNWRAP &amp;&amp; cause != null) &#123; throw cause; &#125; else &#123; throw th; &#125; &#125; if (logLevel != Logger.Level.NONE) &#123; logger.logRetry(metadata.configKey(), logLevel); &#125; continue; &#125; &#125;&#125;","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/tags/SpringCloud/"}],"keywords":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}]},{"title":"kafka-提交offset存储","slug":"MQ-kafka-提交offset存储","date":"2019-07-01T16:00:00.000Z","updated":"2020-06-01T07:09:46.103Z","comments":true,"path":"2019/07/02/MQ-kafka-提交offset存储/","link":"","permalink":"https://zzkenyon.github.io/2019/07/02/MQ-kafka-提交offset存储/","excerpt":"","text":"每个topic可以划分多个分区partition，同一个topic下的不同分区存储的消息是不重复的。在每个消息被分配给一个分区时，会生成一个偏移量offset，它是消息在分区中的唯一编号。kafka通过offset来保证消息在分区内的顺序，分区之间不能保证消息的顺序性。 消费者可以通过以下配置来开启自动提交： 1234props.put(ConsumerConfig.GROUP_ID_CONFIG, \"group_2\");props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \"true\"); // 开启自动提交props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, \"1000\"); //自动提交时间间隔props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG,\"earliest\"); //消费者启动时从哪里开始消费 对于消费者来说，每次消费一个消息并且提交以后，kafka会保存当前消费到的最后的一个offset，那么offset保存在哪里？ 在kafka中提供了一个名为__consumer_offsets-*的topic，默认有50个分区。消费者消费数据并提交之后，offset将存储到该topic的某个分区中。 如何确定在哪个分区？通过以下公式 1Math.abs(\"group_2\".hashCode()%50) 能获取一个0-49的整型值，假如是0，那么意味着当前group的offset信息保存在__consumer_offsets-0这个文分区中。 执行以下命令可以查看指定分区中offset位移提交信息 1kafka-console-consumer.sh --topic __consumer_offsets --partition 0 --bootstrap server 192.168.2.112:9092 --formatter 'kafka.coordinator.group.GroupMetadataManager$OffsetMessageFormatter' 结果如下图所示： 根据结果可以看出，组gropu_2消费的test-topic的0分区，offset是40","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://zzkenyon.github.io/categories/消息中间件/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://zzkenyon.github.io/tags/kafka/"}],"keywords":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://zzkenyon.github.io/categories/消息中间件/"}]},{"title":"SpringCloud-Ribbon实现源码分析","slug":"SpringCloud-Ribbon实现源码分析","date":"2019-06-30T16:00:00.000Z","updated":"2020-10-14T16:13:24.665Z","comments":true,"path":"2019/07/01/SpringCloud-Ribbon实现源码分析/","link":"","permalink":"https://zzkenyon.github.io/2019/07/01/SpringCloud-Ribbon实现源码分析/","excerpt":"","text":"客户端的负载均衡解决的问题：从配置文件或注册中心获取需要调用的服务列表，使用指定的算法选择一个服务实例，发送调用请求。 流程总结： 从RestTemplate.getObject方法开始流程，执行到doExcute()方法中，该方法创建一个Http请求发送请求 创建http请求是一个InterceptingClientHttpRequest对象，表示这是一个正在被拦截的客户端http请求，ribbon负载均衡就是基于拦截器实现的 InterceptingClientHttpRequest有方法excute()，此方法对请求执行拦截处理，最后发送出去。 在excute()方法中，获取到LoadBalancerInterceptor即负载均衡拦截器，执行该拦截器的intercept()方法进行拦截处理。该拦截器对象有两个成员 LoadBalancerRequestFactory，用于构建负载均衡请求的工厂对象 LoadBalancerClient，主要用于执行负载均衡请求，Ribbon中的实现类是RibbonLoadBalanceClient。 RibbonLoadBalanceClient的核心逻辑就是执行负载均衡算法，先获取负载均衡器，再使用负载均衡器获取真正的服务器地址，再使用服务器信息创建一个RibbonServer，执行负载均衡请求的apply方法 负载均衡请求LoadBalancerRequest接口只定义了一个apply()方法，该方法主要负责递归执行InterceptingClientHttpRequest.execute()方法，执行所有拦截器拦截。ribbon只在一个匿名类中定义了apply方法，主要逻辑就是创建了一个请求包装类对象ServiceRequestWrapper，执行拦截。 最后使用SimpleClientHttpRequestFactory创建一个标准的http请求发送出去 采用ribbon做客户端负载，一般会搭配RestTemplate一起使用，在RestTemplate上注解@LoadBalanced，则调用 RestTemplate方法时，ribbon会自动生效实现客户端的负载均衡。 配置负载均衡的RestTemplate 12345@Bean@LoadBalancedpublic RestTemplate getRestTemplate()&#123; return new RestTemplate();&#125; 使用RestTemplate进行远程服务访问： 12345678public class UserServiceImpl implements UserService &#123; @Autowired private RestTemplate restTemplate; public User getUser(Long id) &#123; String url = \"http://USER-PROVIDER\"+\"/user/\"+id; return restTemplate.getForObject(url,User.class); &#125;&#125; 以上代码使用服务名称访问远程主机，因此肯定有一个服务名称解析的过程，可以大致猜测执行流程： 通过服务名称USER-PROVIDER从注册中心拿到该服务的主机列表； 根据配置的负载均衡策略选择一个主机； 重构一个http请求，发送给指定的主机，接收响应数据。 到底是不是这样，下面我将从源代码中找到答案。 1. 注解@LoadBalanced要使用ribbon实现负载均衡，就需要使用到该注解，那么这个注解的是在什么地方进行处理的呢？ 定位到自动配置类：LoadBalancerAutoConfiguration，在该类中也有一个成员变量注解了@LoadBalanced 123@LoadBalanced@Autowired(required = false)private List&lt;RestTemplate&gt; restTemplates = Collections.emptyList(); 看@LoadBalanced注解的声明类： 12345678@Target(&#123; ElementType.FIELD, ElementType.PARAMETER, ElementType.METHOD &#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@Qualifierpublic @interface LoadBalanced &#123;&#125; 注解类中没有定义属性，且类上有一个@Qualifier注解，因此该注解实质上就是一个标志，并不需要注解处理类。在spring中，注解@Qualifier用于在自动注入时指定一个bean（在同一个类存在不止一个bean的情况下）。@Qualifier还有一种用法就是，在一个列表上注解@Qualifier，那么凡是注解了@Qualifier的此类bean都会被注入到该列表中。 所以，@LoadBalanced实质是是一个@Qualifier，在负载均衡场景中换了个名字而已。所以LoadBalancerAutoConfiguration的成员restTemplates将自动注入所有注解了@LoadBalanced的RestTemplate类型的bean。 2. 自动装配ribbon实现负载均衡是基于一种拦截器的设计，ribbon对需要实现负载均衡的请求进行拦截，并做负载均衡处理 在上面的例子中，RestTemplate.getForObject(...)发起rest请求，所以这里是本文源码分析的入口，具体的执行流程在下文分析，此处要分析的是ribbon的自动装配流程，在rest请求过程中，会调用到RibbonLoadBalancerClient.execute()方法，那么我们要找到RibbonLoadBalancerClient在哪里实例化的 Ribbon的自动配置类中，对其进行了实例化： LoadeBalancerIntercepter RibbonLoadBalanceClient 3. 执行流程我们直接进入到RestTemplate这个类的doExecute方法，因为前面部分的代码都比较简单没有太多逻 辑。 这段代码中有一个很重要的逻辑，就是createRequest，这个是构建客户端请求的一个方法。 123456789101112131415161718//RestTemplateprotected &lt;T&gt; T doExecute(URI url, @Nullable HttpMethod method, @Nullable RequestCallback requestCallback, @Nullable ResponseExtractor&lt;T&gt; responseExtractor) throws RestClientException &#123; ... ClientHttpResponse response = null; try &#123; ClientHttpRequest request = createRequest(url, method); //&gt;&gt; if (requestCallback != null) &#123; requestCallback.doWithRequest(request); &#125; response = request.execute(); //&gt;&gt; handleResponse(url, method, response); return (responseExtractor != null ? responseExtractor.extractData(response) : null); &#125; ...&#125; createRequest()这个方法是用来创建一个请求对象，其中getRequestFactory()，调用的是InterceptingHttpAccessor 中的getRequestFactory方法，因为InterceptingHttpAccessor继承了HttpAccessor这个类，重写了 getRequestFactory方法，而RestTemplate是InterceptingHttpAccessor的子类。 1234567//HttpAccessorprotected ClientHttpRequest createRequest(URI url, HttpMethod method) throws IOException &#123; ClientHttpRequest request = getRequestFactory().createRequest(url, method); initialize(request); ... return request;&#125; 1234567891011121314151617//InterceptingHttpAccessorpublic ClientHttpRequestFactory getRequestFactory() &#123; // 获取该客户端请求所有的拦截器，虽然是列表，此处只有LoadBalancerInterceptor List&lt;ClientHttpRequestInterceptor&gt; interceptors = getInterceptors(); if (!CollectionUtils.isEmpty(interceptors)) &#123; ClientHttpRequestFactory factory = this.interceptingRequestFactory; if (factory == null) &#123; // 构建一个拦截的http请求工厂，将拦截器传入 factory = new InterceptingClientHttpRequestFactory(super.getRequestFactory(), interceptors); this.interceptingRequestFactory = factory; &#125; return factory; &#125; else &#123; return super.getRequestFactory(); &#125;&#125; 讲一下getInterceptors()方法 这个方法中返回的拦截器列表，是从InterceptingHttpAccessor.setInterceptors()方法来设置的，而这 个setInterceptors()调用的地方正好是在 LoadBalancerAutoConfiguration中 123456789101112// LoadBalancerAutoConfiguration.LoadBalancerInterceptorConfig@Bean@ConditionalOnMissingBeanpublic RestTemplateCustomizer restTemplateCustomizer( final LoadBalancerInterceptor loadBalancerInterceptor) &#123; return restTemplate -&gt; &#123; List&lt;ClientHttpRequestInterceptor&gt; list = new ArrayList&lt;&gt;( restTemplate.getInterceptors()); list.add(loadBalancerInterceptor); restTemplate.setInterceptors(list); &#125;;&#125; 此处调用了restTemplate.setInterceptors这个方法设置拦截器，其中RestTemplate又继承了 InterceptingHttpAccessor。 所以InterceptingHttpAccessor可以直接获取到负载均衡拦截器。 再回到createRequest方法中，getRequestFactory()方法返回的是 InterceptingClientHttpRequestFactory，而createRequest()方法，最终返回的是 InterceptingClientHttpRequest这个类。 request.execute()继续跳回到RestTemplate.doExecute()方法，最终会调用request.execute()。那么这个时候，request.execute调用谁呢？于是我们看一下InterceptingClientHttpRequest的类关系图，我们发现它有两个父类。这是一种模版方法的设计。 最终，我们进入到InterceptingClientHttpRequest.executeInternal方法 InterceptingRequestExecution.execute() 在InterceptingRequestExecution.execute方法中，有两个处理逻辑 如果有配置多个客户端拦截器，则调用拦截器方法，对请求进行拦截 否则，按照正常的处理逻辑进行远程调用。 而在当前的场景中，自然是调用LoadBalancerInterceptor.intercept方法。 12345678910111213141516171819202122232425//InterceptingClientHttpRequestpublic ClientHttpResponse execute(HttpRequest request, byte[] body) throws IOException &#123; if (this.iterator.hasNext()) &#123; // 获取拦截器执行拦截操作 ClientHttpRequestInterceptor nextInterceptor = this.iterator.next(); return nextInterceptor.intercept(request, body, this); // 进入LoadBalancerInterceptor &gt;&gt; &#125; else &#123; HttpMethod method = request.getMethod(); Assert.state(method != null, \"No standard HTTP method\"); ClientHttpRequest delegate = requestFactory.createRequest(request.getURI(), method); request.getHeaders().forEach((key, value) -&gt; delegate.getHeaders().addAll(key, value)); if (body.length &gt; 0) &#123; if (delegate instanceof StreamingHttpOutputMessage) &#123; StreamingHttpOutputMessage streamingOutputMessage = (StreamingHttpOutputMessage) delegate; streamingOutputMessage.setBody(outputStream -&gt; StreamUtils.copy(body, outputStream)); &#125; else &#123; StreamUtils.copy(body, delegate.getBody()); &#125; &#125; return delegate.execute(); &#125; &#125;&#125; LoadBalancerInterceptor.intercept()这里就是负载均衡行为开始发生的地方了 12345678910111213// LoadBalancerInterceptorprivate LoadBalancerClient loadBalancer; // 该对象执行负载均衡算法private LoadBalancerRequestFactory requestFactory; // public ClientHttpResponse intercept(final HttpRequest request, final byte[] body, final ClientHttpRequestExecution execution) throws IOException &#123; final URI originalUri = request.getURI(); // 此处获取到还是未经处理的url String serviceName = originalUri.getHost(); // 服务名称 Assert.state(serviceName != null, \"Request URI does not contain a valid hostname: \" + originalUri); return this.loadBalancer.execute(serviceName, this.requestFactory.createRequest(request, body, execution));&#125; this.loadBalancer就是RibbonLoadBalanceClient实例，此实例在自动装配阶段被实例化。 先看createRequest(request, body, execution))方法： 参数request是InterceptingClientHttpRequest实例，顾名思义就是正在被拦截的客户端http请求。 参数body是请求体，get方法请求此参数为空数组 参数execution是InterceptingClientHttpRequest的内部类InterceptingRequestExecution的实例，该类封装了拦截器列表以及执行所有拦截器操作的执行逻辑。 12345678910111213141516// LoadBalancerRequestFactorypublic LoadBalancerRequest&lt;ClientHttpResponse&gt; createRequest( final HttpRequest request, final byte[] body, final ClientHttpRequestExecution execution) &#123; return instance -&gt; &#123; HttpRequest serviceRequest = new ServiceRequestWrapper(request, instance, this.loadBalancer); if (this.transformers != null) &#123; for (LoadBalancerRequestTransformer transformer : this.transformers) &#123; serviceRequest = transformer.transformRequest(serviceRequest, instance); &#125; &#125; return execution.execute(serviceRequest, body); &#125;;&#125; 该方法返回了一个负载均衡请求对象，此处是匿名类实现。 注意返回的不是instance对象，这里用拉姆达表达式创建了一个匿名类的对象，instance是返回的对象中唯一方法的形参，在之后被调用的时候才会有值传递进来。 往下看； 创建了LoadBalance请求之后，接着执行this.loadBalancer.execute(..)方法，参数有服务名称serviceName和上面创建的LoadBalance请求对象。 1234567891011121314//RibbonLoadBalancerClientpublic &lt;T&gt; T execute(String serviceId, LoadBalancerRequest&lt;T&gt; request, Object hint) throws IOException &#123; //获取负载均衡器 ILoadBalancer loadBalancer = getLoadBalancer(serviceId); Server server = getServer(loadBalancer, hint); // 使用负载均衡器获取服务器 。。。 // ribbonServer传递给上面形参instance的参数值 RibbonServer ribbonServer = new RibbonServer(serviceId, server, isSecure(server, serviceId), serverIntrospector(serviceId).getMetadata(server)); // 执行 return execute(serviceId, ribbonServer, request);&#125; getLoadBalancer(serviceId)可以深入分析，此处使用serviceId将不用的服务进行了上下文的隔离，设计方法值得借鉴。 getServer() 根据负载均衡算法选择一个服务器 1234567//RibbonLoadBalancerClientprotected Server getServer(ILoadBalancer loadBalancer, Object hint) &#123; if (loadBalancer == null) &#123; return null; &#125; return loadBalancer.chooseServer(hint != null ? hint : \"default\");&#125; loadBalancer是ZoneAwareLoadBalancer实例，进入方法，这里只有一个zone所以执行父类的逻辑 12345678//`ZoneAwareLoadBalancer`public Server chooseServer(Object key) &#123; if (!ENABLED.get() || getLoadBalancerStats().getAvailableZones().size() &lt;= 1) &#123; logger.debug(\"Zone aware logic disabled or there is only one zone\"); return super.chooseServer(key); &#125; ...&#125; 1234567891011121314151617//BaseLoadBalancerpublic Server chooseServer(Object key) &#123; if (counter == null) &#123; counter = createCounter(); &#125; counter.increment(); if (rule == null) &#123; return null; &#125; else &#123; try &#123; return rule.choose(key); // 执行到rule的选择方法 &#125; catch (Exception e) &#123; logger.warn(\"LoadBalancer [&#123;&#125;]: Error choosing server for key &#123;&#125;\", name, key, e); return null; &#125; &#125;&#125; 此处的rule默认是RoundRobinRule，即轮询策略。 此处是一个扩展点，rule可以在配置文件中进行配置，也可以配置自定义的rule 再回到execut方法，选定服务器之后，创建一个RibbonServer实例， 123RibbonServer ribbonServer = new RibbonServer(serviceId, server, isSecure(server, serviceId), serverIntrospector(serviceId).getMetadata(server)); isSecure(server, serviceId)由于使用http协议，这里是false serverIntrospector(serviceId).getMetadata(server)返回一个map，只有一对值：“manage.port-&gt;8001” 拿到创建好的RibbonServer，说明负载均衡操作已经完成了，应用已经确定了请求需要发送给哪一台服务器实例，接下来要做的事就是重新构造一个指向该服务器的http请求发送出去，往下看： 执行execute(serviceId, ribbonServer, request)方法： 1234567891011121314151617181920212223public &lt;T&gt; T execute(String serviceId, ServiceInstance serviceInstance, // RibbonServer实例 LoadBalancerRequest&lt;T&gt; request) // 负载均衡请求，执行负载均衡 throws IOException &#123; Server server = null; if (serviceInstance instanceof RibbonServer) &#123; server = ((RibbonServer) serviceInstance).getServer(); &#125; if (server == null) &#123; throw new IllegalStateException(\"No instances available for \" + serviceId); &#125; RibbonLoadBalancerContext context = this.clientFactory .getLoadBalancerContext(serviceId); // 根据服务名称获取上下文 RibbonStatsRecorder statsRecorder = new RibbonStatsRecorder(context, server); try &#123; // 主要逻辑 T returnVal = request.apply(serviceInstance); // 此处执行apply方法 statsRecorder.recordStats(returnVal); return returnVal; &#125; ... return null;&#125; 执行负载均衡请求的apply方法，负载均衡请求是之前创建的，这里再贴一遍代码： 1234567891011// LoadBalancerRequestFactorypublic LoadBalancerRequest&lt;ClientHttpResponse&gt; createRequest( final HttpRequest request, final byte[] body, final ClientHttpRequestExecution execution) &#123; return instance -&gt; &#123; HttpRequest serviceRequest = new ServiceRequestWrapper(request, instance, this.loadBalancer); ... return execution.execute(serviceRequest, body); &#125;;&#125; apply方法中new 了一个ServiceRequestWrapper对象，该对象提供了重构请求url的方法，然后再进入InterceptingRequestExecution类的execute()方法，再贴一遍代码： 123456789101112131415161718192021222324//InterceptingClientHttpRequestpublic ClientHttpResponse execute(HttpRequest request, byte[] body) throws IOException &#123; if (this.iterator.hasNext()) &#123; ClientHttpRequestInterceptor nextInterceptor = this.iterator.next(); return nextInterceptor.intercept(request, body, this); // 进入LoadBalancerInterceptor &gt;&gt; &#125; else &#123; // 此次进入else分支 HttpMethod method = request.getMethod(); Assert.state(method != null, \"No standard HTTP method\"); ClientHttpRequest delegate = requestFactory.createRequest(request.getURI(), method); request.getHeaders().forEach((key, value) -&gt; delegate.getHeaders().addAll(key, value)); if (body.length &gt; 0) &#123; if (delegate instanceof StreamingHttpOutputMessage) &#123; StreamingHttpOutputMessage streamingOutputMessage = (StreamingHttpOutputMessage) delegate; streamingOutputMessage.setBody(outputStream -&gt; StreamUtils.copy(body, outputStream)); &#125; else &#123; StreamUtils.copy(body, delegate.getBody()); &#125; &#125; return delegate.execute(); &#125; &#125;&#125; 由于拦截器链表中没有未执行了拦截器了，所以这次进入else分支，注意看else第三行代码，创建delegate请求，新的请求url的就是在这里重构的，request.getURI()，request是上一步new出来的ServiceRequestWrapper 12345public URI getURI() &#123; // 这里重构了url URI uri = this.loadBalancer.reconstructURI(this.instance, getRequest().getURI()); return uri;&#125; else分支执行完之后，就完成了请求。 4. 服务列表刷新服务注册中心里注册的服务会发生变化，宕机或主动下线或添加服务器，这时候ribbon客户端需要更新本地的服务器列表，默认是30秒被动刷新一次。刷新过之后30秒请求服务不会调用刷新线程，两次调用之间间隔超过30秒则第二次请求之前会刷新服务器列表 5. ping服务注册到注册中心之后，注册中心会通过发送心跳来check服务的存活状态，ribbon从服务中心获取服务器列表，默认是30s刷新一次，当某台服务器宕机，注册中心需要在一段时间之后才能发现其不在线，ribbon最多需要30秒才能刷新掉不在线的服务器，这个时间延迟有点大了 那么ribbon为了解决这个问题，加入了ping功能，即ribbon客户端自己发送心跳给服务器列表中的服务器，默认是10秒发送一次，一旦发现ping不通，直接剔除该服务器 这里的心跳机制可以借鉴。 此处又是另外的一个扩展点，可以自定义Ping的实现（使用指定的协议），配置到ribbon中","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/tags/SpringCloud/"}],"keywords":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}]},{"title":"kafka-副本机制","slug":"MQ-kafka-副本机制","date":"2019-06-27T16:00:00.000Z","updated":"2020-06-23T13:17:19.692Z","comments":true,"path":"2019/06/28/MQ-kafka-副本机制/","link":"","permalink":"https://zzkenyon.github.io/2019/06/28/MQ-kafka-副本机制/","excerpt":"","text":"kafka虽然可以对topic进行分片，但是对于partition来说，它还是单点的，当partition所在的broker宕机了，那么这部分消息就无法被消费。所以kafka为了提高partition的可靠性，提供了副本replica的概念，通过副本机制来实现冗余备份。 每个分区可以有多个副本，并且在副本集合中会存在一个learder副本，所有的读写请求都是由leader来处理。其余的副本称为follower副本，follower会主动从leader同步消息日志。一般情况下，同一个分区的多个副本会被均匀的分配到集群的不同broker上，当leader所在的broker出现故障，可以重新选举新的leader副本继续向外提供服务。 通过下面的命令创建一个带副本的topic 1sh kafka-topic.sh --create --zookeeper 192.168.2.112:9092 --replication-factor 3 --partition 3 --topic test_topic 如何知道各个分区中对应的leader是谁呢？在zookeeper服务器上，通过如下命令去获取对应分区的信息，比如下面这个是获取Topic第1个分区的状态信息。 1get /brokers/topics/topicName/partitions/1/state {“controller_epoch”:12,”leader”:0,”version”:1,”leader_epoch”:0,”isr”:[0,1]} 或通过这个命令 1sh kafka-topics.sh --zookeeper 192.168.13.106:2181 --describe --topic test_partition leader表示当前分区的leader是那个broker-id。 需要注意的是，kafka集群中的一个broker中最多只能持有一个分区的一个副本，leader副本所在的broker节点叫分区的leader节点，follower副本所在的broker节点叫分区的follower节点。 副本同步中的重要概念Kafka提供了数据复制算法保证，如果leader副本所在的broker节点宕机或者出现故障，或者分区的 leader节点发生故障，这个时候怎么处理呢？ kafka必须要保证从follower副本中选择一个新的leader副本。那么kafka是如何实现选举的呢？ 要了解leader选举，我们需要了解几个概念 Kafka分区下有可能有很多个副本(replica)用于实现冗余，从而进一步实现高可用。副本根据角色的不同可分为3类： leader副本：响应clients端读写请求的副本 follower副本：被动地备份leader副本中的数据，不能响应clients端读写请求。 ISR副本：包含了leader副本和所有与leader副本保持同步的follower副本——如何判定是否与leader同步后面会提到。 每个Kafka副本对象都有两个重要的属性：LEO和HW。注意是所有的副本，而不只是 leader副本。 LEO：日志末端位移（Log End Offset），记录了该副本底层日志(log)中下一条消息的offset。 注意是下 一条消息！也就是说，如果LEO=10，那么表示该副本保存了10条消息，位移值范围是[0, 9]。另外， leader LEO和follower LEO的更新是有区别的。 HW：高水位（High Water），对于同一个副本对象而言，其HW值不会大于LEO值。小于等于HW值的所有消息都被认为是已备份的。 同理，leader副本和follower副本的HW更新是有区别的 从生产者发出的一条消息首先会被写入分区的leader 副本，不过还需要等待ISR集合中的所有 follower副本都同步完之后才能被认为已经提交，之后才会更新分区的HW， 进而消费者可以消费到这条消息。 副本协同机制刚刚提到了，消息的读写操作都只会由leader节点来接收和处理。follower副本只负责同步数据以及当leader副本所在的broker挂了以后，会从follower副本中选取新的leader。写请求首先由Leader副本处理，之后follower副本会从leader上拉取写入的消息，这个过程会有一定的延迟，导致follower副本中保存的消息略少于leader副本，但是只要没有超出阈值都可以容忍。 但是如果一个follower副本出现异常，比如宕机、网络断开等原因长时间没有同步到消息，那这个时候，leader就会把它踢出去。kafka通过ISR集合来维护一个分区副本信息，leader负责维护和跟踪ISR中所有follower滞后的状态。当 producer发送一条消息到broker后，leader写入消息并复制到所有follower。消息提交之后才被成功复制到所有的同步副本。 ISR集合ISR表示目前”可用且消息量与leader相差不多的副本集合，这是整个副本集合的一个子集”。怎么去理解可用和相差不多这两个词呢？具体来说，ISR集合中的副本必须满足两个条件 ： 副本所在节点必须维持着与zookeeper的连接 ； 副本最后一条消息的offset与leader副本的最后一条消息的offset（也就是LEO）之间的差值不能超过指定的阈值 。 ISR数据保存在Zookeeper的 /brokers/topics/&lt;topic&gt;/partitions/&lt;partitionId&gt;/state 节点中。 follower副本把leader副本LEO之前的日志全部同步完成时，则认为follower副本已经追赶上了leader 副本，这个时候会更新这个副本的lastCaughtUpTimeMs标识，顾名思义，最后一次赶上的时间 kafk副本管理器会启动一个副本过期检查的定时任务，这个任务会定期检查当前时间与副本lastCaughtUpTimeMs的差值是否大于参数 replica.lag.time.max.ms 的值，如果大于，则会把这个副本踢出ISR集合 副本同步原理了解了副本的协同过程以后，还有一个最重要的机制，就是数据的同步过程。它需要解决 怎么传播消息 在向消息发送端返回ack之前需要保证多少个Replica已经接收到这个消息 Producer在发布消息到某个Partition时： 先通过ZooKeeper找到该Partition的Leader ，get /brokers/topics/&lt;topic&gt;/partitions/2/state ，然后无论该Topic的Replication Factor为多 少（也即该Partition有多少个Replica），Producer只将该消息发送到该Partition的Leader。 Leader会将该消息写入其本地Log。每个Follower都从Leader pull数据。这种方式上，Follower存储的数据顺序与Leader保持一致。Follower在收到该消息并写入其Log后，向Leader发送ACK。 一旦Leader收到了ISR中的所有follower的ACK，该消息就被认为已经commit了，Leader将增加 HW值并且向Producer发送ACK。 此外， 假如某工作不积极的follower副本被踢出ISR集合，也会导致这个分区的HW发生变化，一般是增加 1、初始状态初始状态下，leader和follower的HW和LEO都是0，leader副本会保存remote LEO，表示所有follower LEO，也会被初始化为0，这个时候，producer没有发送消息。follower会不断地个leader发送FETCH请求，但是因为没有数据，这个请求会被leader寄存，当在指定的时间之后会强制完成请求，这个时间配置是： replica.fetch.wait.max.ms 如果在指定时间内producer有消息发送过来，那么kafka会唤醒 fetch请求，让leader继续处理。 数据的同步处理会分两种情况，这两种情况下处理方式是不一样的 第一种是leader处理完producer请求之后，follower发送一个fetch请求过来 第二种是follower阻塞在leader指定时间之内，leader副本收到producer的请求。 首先要清楚，fetch请求会携带当前follower的LEO，leader响应会携带当前leader的HW 2、第一种情况生产者发送一条消息 leader处理完producer请求之后，follower发送一个fetch请求过来 。 leader副本收到请求以后，会做几件事情 把消息追加到log文件，同时更新leader副本的LEO 尝试更新leader HW值。这个时候由于follower副本还没有发送fetch请求，那么leader的remote LEO仍然是0。leader会比较自己的LEO以及remote LEO的值发现最小值是0，与HW的值相同，所以不会更新HW follower fetch消息 follower 发送第一次fetch请求，leader副本的处理逻辑是: 读取log数据、更新remote LEO=0(follower还没有写入这条消息，这个值是根据follower的fetch 请求中的offset来确定的) ； 尝试更新HW，因为这个时候LEO和remoteLEO还是不一致，所以仍然是HW=0 ； 把消息内容和当前分区的HW值发送给follower副本 。 follower副本收到response以后： 将消息写入到本地log，同时更新follower的LEO ； 更新follower HW，本地的LEO和leader返回的HW进行比较取小的值，所以仍然是0 。 第一次交互结束以后，HW仍然还是0，这个值会在下一次follower发起fetch请求时被更新 follower发第二次fetch请求，leader收到请求以后 ： 读取log数据 更新remote LEO=1， 因为这次fetch携带的offset是1. 更新当前分区的HW，这个时候leader LEO和remote LEO都是1，所以HW的值也更新为1 把数据和当前分区的HW值返回给follower副本，这个时候如果没有数据，则返回为空 follower副本收到response以后 ： 如果有数据则写本地日志，并且更新LEO 更新follower的HW值为 MIN(本地LEO值，leader响应的HW值) 到目前为止，数据的同步就完成了，意味着消费端能够消费offset=1这条消息。 3、第二种情况前面说过，由于leader副本暂时没有数据过来，所以follower的fetch会被阻塞，直到等待超时或者leader接收到新的数据。当leader收到请求以后会唤醒处于阻塞的fetch请求。处理过程基本上和前面说的一致 leader将消息写入本地日志，更新Leader的LEO 唤醒follower的fetch请求 更新HW kafka使用HW和LEO的方式来实现副本数据的同步，本身是一个好的设计，但是在这个地方会存在一个数据丢失的问题，当然这个丢失只出现在特定的背景下。我们回想一下，leader的HW值是在下一轮FETCH 中才会被更新。接下来分析下这个过程为什么会出现数据丢失。 数据丢失当ack=-1（所有ISR集合中的副本一起才能确认提交）且min.insync.replicas=1(设定ISR能允许的最小副本数) 这时候可能会发生数据丢失。 这种情况下，消息一旦被写入leader就会被认为是“已提交”，而延迟一轮FETCH 更新HW值的设计使得follower HW值是异步延迟更新的，倘若在这个过程中leader发生变更，那么成为新leader的 follower的HW值就有可能是过期的，使得clients端认为是成功提交的消息被删除。 日志截断：副本重启之后，会将副本的HW值设为当前副本的LEO值。 数据丢失的解决方案 在kafka0.11.0.0版本之后，引入了一个leader epoch来解决这个问题，所谓的leader epoch实际上是 一对值(epoch，offset)，epoch代表leader的版本号，从0开始递增，当leader发生过变更，epoch 就+1，而offset则是对应这个epoch版本的leader写入第一条消息的offset，比如 (0,0), (1,50) ,表示第一个leader从offset=0开始写消息，一共写了50条。第二个leader版本号是1，从 offset=50开始写，这个信息会持久化在对应的分区的本地磁盘上，文件名是： /tmp/kafka-log/topic/leader-epoch-checkpoint leader broker中会保存这样一个缓存，并且定期写入到checkpoint文件中 当leader写log时它会尝试更新整个缓存: 如果这个leader首次写消息，则会在缓存中增加一个条目；否则就不做更新。而每次副本重新成为leader时会查询这部分缓存，获取出对应leader版本的offset 我们基于同样的情况来分析，follower宕机并且恢复之后，有两种情况，如果这个时候leader副本没有挂，也就是意味着没有发生leader选举，那么follower恢复之后并不会去截断自己的日志，而是先发送 一个OffsetsForLeaderEpochRequest请求给到leader副本，leader副本收到请求之后返回当前的 LEO。 如果follower副本的leaderEpoch和leader副本的epoch相同， leader的LEO只可能大于或者等于 follower副本的LEO值，所以这个时候不会发生截断。 如果follower副本和leader副本的epoch值不同，那么leader副本会查找follower副本传过来的 epoch+1在本地文件中存储的StartOffset返回给follower副本，也就是新leader副本在成为leader之前写的最后一条数据的offset。这样也可以避免了数据丢失的问题。 如果leader副本宕机了重新选举新的leader，那么原本的follower副本就会变成leader，意味着epoch 从0变成1，使得原本follower副本中LEO的值的得到了保留。 Leader副本的选举过程 KafkaController会监听ZooKeeper的/brokers/ids节点路径，一旦发现有broker挂了，执行下面 的逻辑。这里暂时先不考虑KafkaController所在broker挂了的情况，KafkaController挂了，各个 broker会重新leader选举出新的KafkaController leader副本在该broker上的分区就要重新进行leader选举，目前的选举策略是 优先从ISR列表中选出第一个作为leader副本，这个叫优先副本，理想情况下有限副本就是该分区的leader副本 如果ISR列表为空，则查看该topic的unclean.leader.election.enable配置。 unclean.leader.election.enable：为true则代表允许选用非ISR列表中的副本作为leader，那么此时就意味着数据可能丢失；为 false的话，则表示不允许，直接抛出NoReplicaOnlineException异常，造成leader副本选举失败。 如果上述配置为true，则从其他副本中选出一个作为leader副本，并且isr列表只包含该leader 副本。一旦选举成功，则将选举后的leader和ISR和其他副本信息写入到该分区的对应的zk路径上。","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://zzkenyon.github.io/categories/消息中间件/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://zzkenyon.github.io/tags/kafka/"}],"keywords":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://zzkenyon.github.io/categories/消息中间件/"}]},{"title":"kafka-分区分配策略及分配流程","slug":"MQ-kafka-分区分配策略及分配流程","date":"2019-06-25T16:00:00.000Z","updated":"2020-06-23T09:28:37.232Z","comments":true,"path":"2019/06/26/MQ-kafka-分区分配策略及分配流程/","link":"","permalink":"https://zzkenyon.github.io/2019/06/26/MQ-kafka-分区分配策略及分配流程/","excerpt":"","text":"当出现以下几种情况时，kafka会进行一次分区分配操作，也就是kafka consumer的rebalance 同一个consumer group内新增了消费者 消费者离开当前所属的consumer group，比如主动停机或者宕机 topic新增了分区（也就是分区数量发生了变化） kafka consuemr的rebalance机制规定了一个consumer group下的所有consumer如何达成一致来分配订阅的topic的每个分区。 本文涉及到的配置项： 消费者配置： partition.assignment.strategy 1. 分区分配策略同一个group中的消费者对于一个topic中的多个partition，存在一定的分区分配策略。在kafka中，存在三种分区分配策略，一种是Range(默认)、 另一种是RoundRobin（轮询）、StickyAssignor(粘性)。 在消费端中的ConsumerConfifig中，通过这个属性来指定分区分配策略 1public static final String PARTITION_ASSIGNMENT_STRATEGY_CONFIG = \"partition.assignment.strategy\"; 1.2 RangeAssignor（范围分区）Range策略是对每个主题而言的，首先对同一个主题里面的分区按照序号进行排序，并对消费者按照字母顺序进行排序。 123假设n = 分区数／消费者数量 m= 分区数％消费者数量 那么前m个消费者每个分配n+l个分区，后面的（消费者数量-m)个消费者每个分配n个分区 设我们有10个分区，3个消费者，那么n=10/3=3，m=10%3=1，那么前1个消费者分配4个分区，结果如下： C1———– 0, 1, 2, 3 C2———– 4, 5, 6 C3———– 7, 8, 9 假如我们有11个分区，n=10/3=3，m=10%3=2，那么前2个消费者个分配4个分区，分配的结果看起来是这样的： C1———– 0, 1, 2, 3 C2———– 4, 5, 6, 7 C3———– 8, 9, 10 假如group消费2个主题(T1和T2)，分别有10个分区，那么最后分区分配的结果看起来是这样的： C1 将消费 T1主题的 0, 1, 2, 3 分区以及 T2主题的 0, 1, 2, 3分区 C2 将消费 T1主题的 4, 5, 6 分区以及 T2主题的 4, 5, 6分区 C3 将消费 T1主题的 7, 8, 9 分区以及 T2主题的 7, 8, 9分区 可以看出来每个主题将独自进行分区分配，C1负载最大。 因此这种方式的弊端很明显：分配不均匀，主题越多，排在前面的消费者负载越大 1.2 RoundRobinAssignor（轮询分区）轮询分区策略是把所有partition和所有consumer线程都列出来，然后按照hashcode进行排序。最后通过轮询算法分配partition给消费线程。如果所有consumer实例的订阅是相同的，那么partition会均匀分布。 在我们的例子里面，假如按照 hashCode 排序完的topic-partitions组依次为T1-5, T1-3, T1-0, T1-8, T1- 2, T1-1, T1-4, T1-7, T1-6, T1-9，我们的消费者线程排序为C1-0, C1-1, C2-0, C2-1，最后分区分配的结果 为： C1-0 将消费 T1-5, T1-2, T1-6 分区； C1-1 将消费 T1-3, T1-1, T1-9 分区； C2-0 将消费 T1-0, T1-4 分区； C2-1 将消费 T1-8, T1-7 分区； 使用轮询分区策略必须满足两个条件 每个主题的消费者实例具有相同数量的流 每个消费者订阅的主题必须是相同的 1.3 StrickyAssignor （粘性分区）kafka在0.11.x版本支持了StrickyAssignor, 翻译过来叫粘滞策略，它主要有两个目的假设 分区的分配尽可能的均匀 分区的分配尽可能和上次分配保持相同 当两者发生冲突时， 第 一 个目标优先于第二个目标。 鉴于这两个目标， StickyAssignor分配策略的具体实现要比RangeAssignor和RoundRobinAssi gn or这两种分配策略要复杂得多，假设我们有这样一个场景 假设消费组有3个消费者：C0,C1,C2，它们分别订阅了4个Topic(t0,t1,t2,t3),并且每个主题有两个分 区(p0,p1),也就是说，整个消费组订阅了8个分区：t0p0、 t0p1 、 t1p0 、 t1p1 、 t2p0 、 t2p1、t3p0 、 t3p1 那么最终的分配场景结果为 C0: t3p1 、t1p1 、 t3p0 Cl: t0p1 、t2p0 、 t3p1 C2: t1p0 、t2p1 这种分配方式有点类似于轮询策略，但实际上并不是，因为假设这个时候，C1这个消费者挂了，就势必会造成 重新分区（reblance），如果是轮询，那么结果应该是 C0: t3p1 、t1p0 、t2p0、t3p0 C2: t0p1 、t1p1 、t2p1、t3p1 然后，strickyAssignor它是一种粘滞策略，所以它会满足分区的分配尽可能和上次分配保持相同，所以 分配结果应该是 消费者C0: t0p0、t1p1 、 t3p0、t2p0 消费者C2: t1p0、t2p1、t0p1、t3p1 也就是说，C0和C2保留了上一次是的分配结果，并且把原来C1的分区分配给了C0和C2。 这种策略的好处是 使得分区发生变化时，由于分区的“粘性，减少了不必要的分区移动。 2. RebalanceKafka提供了一个角色：coordinator来执行对于consumer group的管理，当consumer group的第一个consumer启动的时候，它会去和kafka server确定谁是它们组的coordinator。之后该group内的所有成员都会和该coordinator进行协调通信。 consumer group如何确定自己的coordinator是谁呢,，首先启动的消费者向kafka集群中的任意一个broker发送一个GroupCoordinatorRequest请求，请求参数就一个group_id，服务端会返回一个负载最小的broker节点的id，并将该broker设置为coordinator，之后只要这个borker不宕机，它永远都是这个消费者组的协调者。 在rebalance之前，需要保证coordinator已经确定好了，整个rebalance的过程分为两个步骤，Join和Sync 2.1 JoinGroup的过程join: 表示加入到consumer group中，在这一步中，所有的成员都会向coordinator发送JoinGroupRequest的请求。coordinator会从发送请求的消费者中选择一个担任leader角色，并把组成员信息和组订阅信息发送给消费者leader。 leader选举算法比较简单，如果消费组内没有leader，那么第一个加入消费组的消费者就是消费者leader，如果这个时候leader消费者退出了消费组，那么重新选举一个leader，这个选举很随意，类似于随机算法 protocol_metadata: 序列化后的消费者的订阅信息 leader_id： 消费组中的消费者，coordinator会选择一个作为leader，对应的就是member_id member_metadata：对应消费者的订阅信息 members：consumer group中全部的消费者的订阅信息 generation_id： 年代信息，类似于之前讲解zookeeper的时候的epoch是一样的，对于每一轮rebalance，generation_id都会递增。主要用来保护consumer group。隔离无效的offset提交。也就是上一轮的consumer成员无法提交offset到新的consumer group中。 每个消费者都可以设置自己的分区分配策略，对于消费组而言，会从各个消费者上报过来的分区分配策略中选举一个彼此都赞同的策略来实现整体的分区分配，这个”赞同”的规则是，消费组内的各个消费者会通过投票来决定 在joingroup阶段，每个consumer都会把自己支持的分区分配策略发送到coordinator coordinator收集到所有消费者的分配策略，组成一个候选集 每个消费者需要从候选集里找出一个自己支持的策略，并且为这个策略投票 最终计算候选集中各个策略的选票数，票数最多的就是当前消费组的分配策略 2.2 Synchronizing Group State阶段consumer leader完成分区分配之后，就进入了Synchronizing Group State阶段，主要逻辑是所有的消费之向coordinator发送SyncGroupRequest请求，并且处理SyncGroupResponse响应，简单来说，就是leader将消费者对应的partition分配方案同步给consumer group 中的所有consumer 注意是每个消费者都会向coordinator发送syncgroup请求，不过只有leader节点会发送分配方案，此时其他消费者只是打打酱油而已。当leader把方案发给coordinator以后，coordinator会把结果设置到SyncGroupResponse中响应给所有消费者。这样所有成员都知道自己应该消费哪个分区。 consumer group的分区分配方案是在客户端执行的！Kafka将这个权利下放给客户端主要是因为这样做可以有更好的灵活性 3. 总结 消费者可以通过配置“partition.assignment.strategy”来选择分区的分配策略，有三种策略：range、roundRobin、strick 一个消费者组第一个消费者启动的时候，会向集群中任意一个broker发送一个GroupCoordinatorRequest请求，集群返回当前负载最小的broker成为该group的coordinator 三种情况会引起Rebalance操作：有新的消费者加入组；有消费者离开组；topic增加新的分区 Rebalance第一步join，所有组内在线的消费者向coordinator发送joinGroup请求，coordinator收到所有的消费者请求后指定一个消费者leader（一般是第一个加入组的消费者），将组成员信息和组订阅信息发送给leader leader根据分配策略进行分配，完成分配之后将分配方案发送给coordinator，使用SyncGroupRequest请求，所有的消费者都会发送该请求，但只有leader的请求会携带分配方案。 coordinator收到分配方案之后，降费配方案放在SyncGroupResponse响应中，响应给所有的消费者，所有的消费者都直到自己应该消费哪些分区了。","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://zzkenyon.github.io/categories/消息中间件/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://zzkenyon.github.io/tags/kafka/"}],"keywords":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://zzkenyon.github.io/categories/消息中间件/"}]},{"title":"kafka-搭建Kafka集群","slug":"MQ-kafka-集群搭建","date":"2019-06-21T16:00:00.000Z","updated":"2020-06-01T07:10:38.965Z","comments":true,"path":"2019/06/22/MQ-kafka-集群搭建/","link":"","permalink":"https://zzkenyon.github.io/2019/06/22/MQ-kafka-集群搭建/","excerpt":"","text":"每台主机都需要安装jdk 本文版本jdk-1.8.0_231 需要搭建好的zookeeper集群 本文zookeeper环境：192.168.2.112:2181,192.168.2.113:2181,192.168.2.114:2181 本文将Kafka搭建在部署zookeeper集群的三台主机上，当然也可以另外准备三台主机。 在每台主机上执行下面步骤：12345678910111213#将安装包移到/usr/local目录下mv kafka_2.11-2.0.0 .tgz /usr/local#解压文件tar -zxvf kafka_2.11-2.0.0 .tgz#重命名文件夹为kafkamv kafka_2.11-2.0.0 kafka#配置kafka环境变量，首先打开profile文件vim /etc/profile#进入编辑模式，在文件末尾添加kafka环境变量export KAFKA_HOME=/usr/local/apache/kafkaPATH=$&#123;KAFKA_HOME&#125;/bin:$PATH#保存文件后，让该环境变量生效source /etc/profile node-1修改server.properties配置文件打开配置文件 1vim /usr/local/apache/kafka/config/server.properties 修改配置如下 123broker.id=0listeners=PLAINTEXT://192.168.2.112:9092zookeeper.connect=192.168.2.112:2181,192.168.2.113:2181,192.168.2.114:2181 node-2修改server.properties配置文件修改配置如下 123broker.id=1listeners=PLAINTEXT://192.168.2.113:9092zookeeper.connect=192.168.2.112:2181,192.168.2.113:2181,192.168.2.114:2181 node-3修改server.properties配置文件修改配置如下 123broker.id=2listeners=PLAINTEXT://192.168.2.114:9092zookeeper.connect=192.168.2.112:2181,192.168.2.113:2181,192.168.2.114:2181 启动Kafka要确保zookeeper节点已全部启动 在每台主机上分别启动Kafka 12cd $KAFKA_HOMEbin/kafka-server-start.sh -daemon config/server.properties 在其中一台虚拟机创建topic ，参数zookeeper可以填写任意主机 1/bin/kafka-topics.sh --create --zookeeper 192.168.2.112:2181 --replication-factor 3 --partitions 1 --topic test-topic 查看创建的topic信息，参数zookeeper可以填写任意主机 1/bin/kafka-topics.sh --describe --zookeeper 192.168.2.114:2181 --topic test-topic","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://zzkenyon.github.io/categories/消息中间件/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://zzkenyon.github.io/tags/kafka/"}],"keywords":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://zzkenyon.github.io/categories/消息中间件/"}]},{"title":"kafka-架构及运行流程","slug":"MQ-kafka-架构介绍","date":"2019-06-20T16:00:00.000Z","updated":"2020-05-29T03:22:38.022Z","comments":true,"path":"2019/06/21/MQ-kafka-架构介绍/","link":"","permalink":"https://zzkenyon.github.io/2019/06/21/MQ-kafka-架构介绍/","excerpt":"","text":"1. 消息队列通信的模式通过上面的例子我们引出了消息中间件，并且介绍了消息队列出现后的好处，这里就需要介绍消息队列通信的两种模式了： 1.1 点对点模式如图所示 点对点模式通常是基于拉取或者轮询的消息传送模型，这个模型的特点是发送到队列的消息被一个且只有一个消费者进行处理。生产者将消息放入消息队列后，由消费者主动的去拉取消息进行消费。点对点模型的的优点是消费者拉取消息的频率可以由自己控制。但是消息队列是否有消息需要消费，在消费者端无法感知，所以在消费者端需要额外的线程去监控。 1.2 发布订阅模式如图所示 发布订阅模式是一个基于消息送的消息传送模型，改模型可以有多种不同的订阅者。生产者将消息放入消息队列后，队列会将消息推送给订阅过该类消息的消费者（类似微信公众号）。由于是消费者被动接收推送，所以无需感知消息队列是否有待消费的消息！但是consumer1、consumer2、consumer3由于机器性能不一样，所以处理消息的能力也会不一样，但消息队列却无法感知消费者消费的速度！所以推送的速度成了发布订阅模模式的一个问题！假设三个消费者处理速度分别是8M/s、5M/s、2M/s，如果队列推送的速度为5M/s，则consumer3无法承受！如果队列推送的速度为2M/s，则consumer1、consumer2会出现资源的极大浪费！ 2. Kafka上面简单的介绍了为什么需要消息队列以及消息队列通信的两种模式，接下来就到了我们本文的主角——kafka闪亮登场的时候了！Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据，具有高性能、持久化、多副本备份、横向扩展能力……… 一些基本的介绍这里就不展开了，网上有太多关于这些的介绍了，读者可以自行百度一下！ 2.1 基础架构及术语话不多说，先看图，通过这张图我们来捋一捋相关的概念及之间的关系： 如果看到这张图你很懵逼，没有关系，我们先来分析相关概念 Producer：Producer即生产者，消息的产生者，是消息的入口。 kafka cluster： Broker：Broker是kafka实例，每个服务器上有一个或多个kafka的实例，我们姑且认为每个broker对应一台服务器。每个kafka集群内的broker都有一个不重复的编号，如图中的broker-0、broker-1等…… Topic：消息的主题，可以理解为消息的分类，kafka的数据就保存在topic。在每个broker上都可以创建多个topic。 Partition：Topic的分区，每个topic可以有多个分区，分区的作用是做负载，提高kafka的吞吐量。同一个topic在不同的分区的数据是不重复的，partition的表现形式就是一个一个的文件夹！ Replication:每一个分区都有多个副本，副本的作用是做备胎。当主分区（Leader）故障的时候会选择一个备胎（Follower）上位，成为Leader。在kafka中默认副本的最大数量是10个，且副本的数量不能大于Broker的数量，follower和leader绝对是在不同的机器，同一机器对同一个分区也只可能存放一个副本（包括自己）。 Message：每一条发送的消息主体。 Consumer：消费者，即消息的消费方，是消息的出口。 Consumer Group：我们可以将多个消费组组成一个消费者组，在kafka的设计中同一个分区的数据只能被消费者组中的某一个消费者消费。同一个消费者组的消费者可以消费同一个topic的不同分区的数据，这也是为了提高kafka的吞吐量！ Zookeeper：kafka集群依赖zookeeper来保存集群的的元信息，来保证系统的可用性。 3. 工作流程分析上面介绍了kafka的基础架构及基本概念，不知道大家看完有没有对kafka有个大致印象，如果对还比较懵也没关系！我们接下来再结合上面的结构图分析kafka的工作流程，最后再回来整个梳理一遍我相信你会更有收获！ 3.1 发送数据我们看上面的架构图中，producer就是生产者，是数据的入口。注意看图中的红色箭头，Producer在写入数据的时候永远的找leader，不会直接将数据写入follower！那leader怎么找呢？写入的流程又是什么样的呢？我们看下图： 发送的流程就在图中已经说明了，就不单独在文字列出来了！需要注意的一点是，消息写入leader后，follower是主动的去leader进行同步的！producer采用push模式将数据发布到broker，每条消息追加到分区中，顺序写入磁盘，所以保证同一分区内的数据是有序的！写入示意图如下： 上面说到数据会写入到不同的分区，那kafka为什么要做分区呢？相信大家应该也能猜到，分区的主要目的是： 方便扩展。因为一个topic可以有多个partition，所以我们可以通过扩展机器去轻松的应对日益增长的数据量。 提高并发。以partition为读写单位，可以多个消费者同时消费数据，提高了消息的处理效率。 注意：每个partition只能被一个consumer消费 熟悉负载均衡的朋友应该知道，当我们向某个服务器发送请求的时候，服务端可能会对请求做一个负载，将流量分发到不同的服务器，那在kafka中，如果某个topic有多个partition，producer又怎么知道该将数据发往哪个partition呢？kafka中有几个原则： partition在写入的时候可以指定需要写入的partition，如果有指定，则写入对应的partition。 如果没有指定partition，但是设置了数据的key，则会根据key的值hash出一个partition。 如果既没指定partition，又没有设置key，则会轮询选出一个partition。 保证消息不丢失是一个消息队列中间件的基本保证，那producer在向kafka写入消息的时候，怎么保证消息不丢失呢？其实上面的写入流程图中有描述出来，那就是通过ACK应答机制！在生产者向队列写入数据的时候可以设置参数来确定是否确认kafka接收到数据，这个参数可设置的值为0、1、all。 0代表producer往集群发送数据不需要等到集群的返回，不确保消息发送成功。安全性最低但是效率最高。 1代表producer往集群发送数据只要leader应答就可以发送下一条，只确保leader发送成功 all代表producer往集群发送数据需要所有的follower都完成从leader的同步才会发送下一条，确保leader发送成功和所有的副本都完成备份。安全性最高，但是效率最低。 注意：如果往不存在的topic写数据，kafka会自动创建topic，分区和副本的数量根据默认配置都是1。 3.2 保存数据Producer将数据写入kafka后，集群就需要对数据进行保存了！kafka将数据保存在磁盘，可能在我们的一般的认知里，写入磁盘是比较耗时的操作，不适合这种高并发的组件。Kafka初始会单独开辟一块磁盘空间，顺序写入数据（效率比随机写入高）。 3.2.1 Partition 结构前面说过了每个topic都可以分为一个或多个partition，如果你觉得topic比较抽象，那partition就是比较具体的东西了！Partition在服务器上的表现形式就是一个一个的文件夹，每个partition的文件夹下面会有多组segment文件，每组segment文件又包含.index文件、.log文件、.timeindex文件（早期版本中没有）三个文件， log文件就实际是存储message的地方，而index和timeindex文件为索引文件，用于检索消息。 如上图，这个partition有三组segment文件，每个log文件的大小是一样的，但是存储的message数量是不一定相等的（每条的message大小不一致）。文件的命名是以该segment最小offset来命名的，如000.index存储offset为0~368795的消息，kafka就是利用分段+索引的方式来解决查找效率的问题。 3.2.2 Message结构上面说到log文件就实际是存储message的地方，我们在producer往kafka写入的也是一条一条的message，那存储在log中的message是什么样子的呢？消息主要包含消息体、消息大小、offset、压缩类型……等等！我们重点需要知道的是下面三个：1、 offset：offset是一个占8byte的有序id号，它可以唯一确定每条消息在parition内的位置！2、 消息大小：消息大小占用4byte，用于描述消息的大小。3、 消息体：消息体存放的是实际的消息数据（被压缩过），占用的空间根据具体的消息而不一样。 3.2.3 存储策略无论消息是否被消费，kafka都会保存所有的消息。那对于旧数据有什么删除策略呢？ 基于时间，默认配置是168小时（7天）。 基于大小，默认配置是1073741824。 注意，kafka读取特定消息的时间复杂度是O(1)，所以这里删除过期的文件并不会提高kafka的性能！ 3.3 消费数据消息存储在log文件后，消费者就可以进行消费了。在讲消息队列通信的两种模式的时候讲到过点对点模式和发布订阅模式。Kafka采用的是点对点的模式，消费者主动的去kafka集群拉取消息，与producer相同的是，消费者在拉取消息的时候也是找leader去拉取。 多个消费者可以组成一个消费者组（consumer group），每个消费者组都有一个组id！同一个消费组者的消费者可以消费同一topic下不同分区的数据，但是不会组内多个消费者消费同一分区的数据！！！是不是有点绕。我们看下图： 图示是消费者组内的消费者小于partition数量的情况，所以会出现某个消费者消费多个partition数据的情况，消费的速度也就不及只处理一个partition的消费者的处理速度！如果是消费者组的消费者多于partition的数量，那会不会出现多个消费者消费同一个partition的数据呢？上面已经提到过不会出现这种情况！多出来的消费者不消费任何partition的数据。所以在实际的应用中，建议消费者组的consumer的数量与partition的数量一致！ 在保存数据的小节里面，我们聊到了partition划分为多组segment，每个segment又包含.log、.index、.timeindex文件，存放的每条message包含offset、消息大小、消息体……我们多次提到segment和offset，查找消息的时候是怎么利用segment+offset配合查找的呢？假如现在需要查找一个offset为368801的message是什么样的过程呢？我们先看看下面的图： 先找到offset的368801message所在的segment文件（利用二分法查找），这里找到的就是在第二个segment文件。 打开找到的segment中的.index文件（也就是368796.index文件，该文件起始偏移量为368796+1，我们要查找的offset为368801的message在该index内的偏移量为368796+5=368801，所以这里要查找的相对offset为5）。由于该文件采用的是稀疏索引的方式存储着相对offset及对应message物理偏移量的关系，所以直接找相对offset为5的索引找不到，这里同样利用二分法查找相对offset小于或者等于指定的相对offset的索引条目中最大的那个相对offset，所以找到的是相对offset为4的这个索引。 根据找到的相对offset为4的索引确定message存储的物理偏移位置为256。打开数据文件，从位置为256的那个地方开始顺序扫描直到找到offset为368801的那条Message。 这套机制是建立在offset为有序的基础上，利用segment+有序offset+稀疏索引+二分查找+顺序查找等多种手段来高效的查找数据！至此，消费者就能拿到需要处理的数据进行处理了。那每个消费者又是怎么记录自己消费的位置呢？在早期的版本中，消费者将消费到的offset维护zookeeper中，consumer每间隔一段时间上报一次，这里容易导致重复消费，且性能不好！在新的版本中消费者消费到的offset已经直接维护在kafk集群的__consumer_offsets这个topic中！","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://zzkenyon.github.io/categories/消息中间件/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://zzkenyon.github.io/tags/kafka/"}],"keywords":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://zzkenyon.github.io/categories/消息中间件/"}]},{"title":"JDK中nio编程的三大件","slug":"nio-jdk中nio编程的三大件","date":"2019-05-26T02:21:34.000Z","updated":"2020-05-22T11:51:08.945Z","comments":true,"path":"2019/05/26/nio-jdk中nio编程的三大件/","link":"","permalink":"https://zzkenyon.github.io/2019/05/26/nio-jdk中nio编程的三大件/","excerpt":"","text":"nio过程： channel注册到selector的时候会指定该通道需要selector监听的事件类型 发送程序使用channel向fd中写入数据，完成之后fd会产生一个写就绪的事件， selector轮询的时候会发现到该事件，并将该事件对应的通道取出来进行处理（将fd中的数据通过socket进行发送） 接收程序将channel注册到selector时会指定监听读就绪事件， socket接收到数据写入fd中，fd产生一个读就绪事件， selector轮询的时候会发现到该事件，并将该事件对应的通道取出来进行处理（将fd中的数据读取到应用中） Linux系统中selector 底层采用epoll模型，监听多个fd的状态（满、非满、空、非空） epollepoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。 基本原理：epoll支持水平触发和边缘触发，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就绪态，并且只会通知一次。还有一个特点是，epoll使用“事件”的就绪通知方式，通过epollctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epollwait便可以收到通知。 epoll的优点： 1、没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）。 2、效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。 只有活跃可用的FD才会调用callback函数；即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll。 3、内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。 channel 与 fd 通信过程使用 buffer 组织数据 因此nio三大件是 channel buffer selector 1. Channel每个连接 至少对应一个fd，每个fd至少对应一个channel channel是nio过程中jvm内存中的对象，类似于inputStream和outStream，但又有些不同： 通道既可以读取数据，又可以写数据到通道，有read和write方法。但流的读写通常是单向的，只有read或只有write。 通道读写是异步进行的，突出的是非阻塞。流的读写则是同步阻塞的。 通道中的数据总是要先读到一个Buffer，或者总是要从一个Buffer中写入。 常见的channel： FileChannel 从文件中读写数据（不作了解）。 DatagramChannel 能通过UDP读写网络中的数据。 SocketChannel 能通过TCP读写网络中的数据。 ServerSocketChannel可以监听新进来的TCP连接，像Web服务器那样。对每一个新进来的连接都会创建一个SocketChannel。 123456789 /** * Reads a sequence of bytes from this channel into the given buffer. */public int read(ByteBuffer dst) throws IOException;/** * Writes a sequence of bytes to this channel from the given buffer. */public int write(ByteBuffer src) throws IOException; 注意对Channel的read和write的理解： channel.read(buffer) 意思是通过channel Read from fd to buffer channel.write(buffer) 意思是通过channel Write to fd from buffer 2. Buffer在channel中传输的是buffer中的数据，而不是buffer对象。buffer是应用程序用来组织传输数据的对象。 使用Buffer读写数据一般遵循以下四个步骤（buffer为读写主体）： 写入数据到Buffer 调用flip()方法 从Buffer中读取数据 调用clear()方法或者compact()方法 说明： 当向buffer写入数据时，buffer会记录下写了多少数据。一旦要读取数据，需要通过flip()方法将Buffer从写模式切换到读模式。在读模式下，可以读取之前写入到buffer的所有数据。 一旦读完了所有的数据，就需要清空缓冲区，让它可以再次被写入。有两种方式能清空缓冲区：调用clear()或compact()方法。clear()方法会清空整个缓冲区。compact()方法只会清除已经读过的数据。任何未读的数据都被移到缓冲区的起始处，新写入的数据将放到缓冲区未读数据的后面。2.1 Buffer抽象类Buffer抽象类中定义的常用方法： Buffer flip() flip方法将Buffer从写模式切换到读模式。调用flip()方法会将position设回0，并将limit设置成之前position的值。 Buffer rewind() 将position设回0，所以你可以重读Buffer中的所有数据。limit保持不变，仍然表示能从Buffer中读取多少个元素（byte、char等） int remaining() 返回position到limit之间的元素个数（未读出元素个数） boolean hasRemaining() 返回是否还有未读出的数据 boolean isReadOnly() 是否此buffer只能读出 Buffer mark() 可以标记Buffer中的一个特定position，之后可以通过调用Buffer.reset()方法恢复到这个position。 Buffer reset() 恢复到mark()标记的状态 Buffer clear() 重置position、limit、capacity和mark，从读模式转换成写模式 此外Buffer还声明了几个抽象方法如下，这些方法都是在Buffer的子类中定义的12345boolean hasArray();boolean isReadOnly();Object array();int arrayOffset();boolean isDirect(); 2.2 Buffer的类型Java NIO 有以下Buffer类型： ByteBuffer MappedByteBuffer CharBuffer DoubleBuffer FloatBuffer IntBuffer LongBuffer ShortBuffer 这些类都是Buffer的子类，其实也是抽象类，它们在Buffer抽象类的基础上扩展了与数据类型相关的功能，下面以ByteBuffer为例介绍 扩展的常用方法： ByteBuffer compact() 将所有未读的数据拷贝到Buffer起始处。然后将position设到最后一个未读元素正后面。limit属性依然像clear()方法一样，设置成capacity。 byte get() 获取position所指的byte，并且position加1 byte get(int index) 获取指定位置的byte ByteBuffer put(byte b) 将指定的byte写入buffer ByteBuffer put(int index,byte b) 将指定的byte写入buffer的指定位置 …许多的不同类型的get/put操作 3. Selector 创建：调用Selector类的静态方法open()创建selector对象 1Selector selector = Selector.open(); 注册通道：调用Channel的实例方法将通道注册到selector上12channel.configureBlocking(false);SelectionKey key = channel.register(selector,Selectionkey.OP_READ); 与Selector一起使用时，Channel必须处于非阻塞模式下。这意味着不能将FileChannel与Selector一起使用，因为FileChannel不能切换到非阻塞模式。而套接字通道都可以。 register()方法的第二个参数是一个“interest集合”，意思是在Selector监听该Channel时对什么事件感兴趣。可以监听四种不同类型的事件： connect accept read write 当以上四种事件就绪的时候，会触发对应的通道事件，通道事件会被selector发现。 客户端channel成功连接到一个服务器称为“连接就绪”。 –OP_CONNECT 一个服务器 socket channel准备好接收新进入的连接称为“接收就绪”。 – OP_ACCEPT 一个有数据可读的通道可以说是“读就绪”。– OP_READ 一个通道等待写数据可以说是“写就绪”。 –OP_WRITE 这四种事件用SelectionKey的四个常量来表示： SelectionKey.OP_CONNECT SelectionKey.OP_ACCEPT SelectionKey.OP_READ SelectionKey.OP_WRITE 如果对不止一种事件感兴趣，那么可以用“位或”操作符将常量连接起来，如下：1int interestSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE; 3.1 SelectionKey当向Selector注册Channel时，register()方法会返回一个SelectionKey对象。这个对象包含了一些有用的属性： interest集合 ready集合 Channel Selector 附件对象（可选） interest集合 可以通过SelectionKey读写interest集合，像这样： 123456int interestSet = selectionKey.interestOps();boolean isInterestedInAccept = (interestSet &amp; SelectionKey.OP_ACCEPT) == SelectionKey.OP_ACCEPT；boolean isInterestedInConnect = interestSet &amp; SelectionKey.OP_CONNECT;boolean isInterestedInRead = interestSet &amp; SelectionKey.OP_READ;boolean isInterestedInWrite = interestSet &amp; SelectionKey.OP_WRITE; 可以看到，用“位与”操作interest 集合和给定的SelectionKey常量，可以确定某个确定的事件是否在interest 集合中。 ready集合 ready 集合是通道已经准备就绪的操作的集合，是四个常量通过‘或’运算生成的。在一次选择(Selection)之后，你会首先访问这个ready set。Selection将在下一小节进行解释。可以这样访问ready集合： 1int readySet = selectionKey.readyOps(); 可以用像检测interest集合那样的方法，来检测channel中什么事件或操作已经就绪。但是，也可以使用以下四个方法，它们都会返回一个布尔类型： 1234selectionKey.isAcceptable();selectionKey.isConnectable();selectionKey.isReadable();selectionKey.isWritable(); Channel &amp; Selector从SelectionKey访问Channel和Selector很简单。如下：12Channel channel = selectionKey.channel();Selector selector = selectionKey.selector(); 在程序中需要对返回的channel做类型转换 附件对象可以将一个对象或者更多信息附着到SelectionKey上，这样就能方便的识别某个给定的通道。例如，可以附加 与通道一起使用的Buffer，或是包含聚集数据的某个对象。使用方法如下：12selectionKey.attach(theObject);Object attachedObj = selectionKey.attachment(); 还可以在用register()方法向Selector注册Channel的时候附加对象。如：1SelectionKey key = channel.register(selector, SelectionKey.OP_READ, theObject); 3.2 Selector选择通道select() 一旦向Selector注册了一或多个通道，就可以调用几个重载的select()方法。这些方法返回你所感兴趣的事件（如连接、接受、读或写）已经准备就绪的那些通道。换句话说，如果你对“读就绪”的通道感兴趣，select()方法会返回读事件已经就绪的那些通道。 三种select： int select() 阻塞方法，阻塞到至少有一个通道在注册的事件上就绪。 int select(long timeout) 超时返回的阻塞方法 int selectNow() 非阻塞方法，不管是否有通道就绪，立即返回。如果自上次select之后没有通道就绪，直接返回0 方法返回的int值表示有多少通道已经就绪。亦即，自上次调用select()方法后有多少通道变成就绪状态。例如第一次调用select()方法，有一个通道变成就绪状态，返回了1，若再次调用select()方法，如果另一个通道就绪了，它会再次返回1，即使对第一个就绪的channel没有做任何操作，现在有两个就绪的通道。 selectedKeys() 一旦调用了select()方法，并且返回值表明有一个或更多个通道就绪了，然后可以通过调用selector的selectedKeys()方法，访问“已选择键集（selected key set）”中的就绪通道。如下所示：1Set selectedKeys = selector.selectedKeys(); 可以遍历这个已选择的键集合来访问就绪通道，像这样： 1234567891011121314151617Iterator&lt;SelectionKey&gt; iter = selector.selectedKeys().iterator();while(iter.hasNext())&#123; SelectionKey key = iter.next(); if(key.isAcceptable())&#123; handleAccept(key); &#125; if(key.isReadable())&#123; handleRead(key); &#125; if(key.isWritable() &amp;&amp; key.isValid())&#123; handleWrite(key); &#125; if(key.isConnectable())&#123; System.out.println(\"isConnectable = true\"); &#125; iter.remove();&#125; 注意每次迭代末尾需要调用remove()。Selector不会自己从已选择键集中移除SelectionKey实例，必须在处理完通道时自己移除。下次该通道变成就绪时，Selector会再次将其放入已选择键集中。 wakeUp() 某个线程调用select()方法后阻塞了，即使没有通道已经就绪，也有办法让其从select()方法返回。只要让其它线程在第一个线程调用select()方法的那个对象上调用Selector.wakeup()方法即可。阻塞在select()方法上的线程会立马返回。 如果有其它线程调用了wakeup()方法，但当前没有线程阻塞在select()方法上，下个调用select()方法的线程会立即“醒来（wake up）”。 close() 用完Selector后调用其close()方法会关闭该Selector，该方法使注册到该Selector上的所有SelectionKey实例无效，通道本身并不会关闭。","categories":[{"name":"I/O和网络编程","slug":"I-O和网络编程","permalink":"https://zzkenyon.github.io/categories/I-O和网络编程/"}],"tags":[{"name":"nio","slug":"nio","permalink":"https://zzkenyon.github.io/tags/nio/"}],"keywords":[{"name":"I/O和网络编程","slug":"I-O和网络编程","permalink":"https://zzkenyon.github.io/categories/I-O和网络编程/"}]},{"title":"zookeeper分布式锁","slug":"分布式-zookeeper分布式锁","date":"2019-05-20T16:00:00.000Z","updated":"2020-05-22T11:47:20.243Z","comments":true,"path":"2019/05/21/分布式-zookeeper分布式锁/","link":"","permalink":"https://zzkenyon.github.io/2019/05/21/分布式-zookeeper分布式锁/","excerpt":"","text":"Zookeeper的每一个节点，都是一个天然的顺序发号器。 在一个节点下面创建子节点时，只要选择的创建类型是有序（EPHEMERAL_SEQUENTIAL 临时有序或者PERSISTENT_SEQUENTIAL 永久有序）类型，那新的子节点后面，会加上一个次序编号，这个次序编号，是上一个生成的次序编号加1。 其次，Zookeeper节点的递增性，可以规定节点编号最小的那个获得锁。 一个zookeeper分布式锁，首先需要创建一个父节点，尽量是持久节点（PERSISTENT类型），然后每个要获得锁的线程都会在这个节点下创建个临时顺序节点，由于序号的递增性，可以规定排号最小的那个获得锁。所以，每个线程在尝试占用锁之前，首先判断自己是排号是不是当前最小，如果是，则获取锁。 第三，Zookeeper的节点监听机制，可以保障占有锁的方式有序而且高效。 每个线程抢占锁之前，先抢号创建自己的ZNode。同样，释放锁的时候，就需要删除抢号的Znode。抢号成功后，如果不是排号最小的节点，就处于等待通知的状态。等谁的通知呢？不需要其他人，只需要等前一个Znode 的通知就可以了。当前一个Znode 删除的时候，就是轮到了自己占有锁的时候。第一个通知第二个、第二个通知第三个，击鼓传花似的依次向后。 Zookeeper的节点监听机制，后面监视前面，就不怕中间截断吗？比如，在分布式环境下，由于网络的原因，或者服务器挂了或则其他的原因，如果前面的那个节点没能被程序删除成功，后面的节点不就永远等待么？ 其实，Zookeeper的内部机制，能保证后面的节点能够正常的监听到删除和获得锁。在创建取号节点的时候，尽量创建临时节点，一旦这个 znode 的客户端与Zookeeper集群服务器失去联系，这个znode 也将自动删除。排在它后面的那个节点，也能收到删除事件，从而获得锁。 Zookeeper这种首尾相接，后面监听前面的方式，可以避免羊群效应。所谓羊群效应就是每个节点挂掉，所有节点都去监听，然后做出反映，这样会给服务器带来巨大压力，所以有了临时顺序节点，当一个节点挂掉，只有它后面的那一个节点才做出反映。 zookeeper开源客户端Curator典型应用场景之-分布式锁","categories":[{"name":"分布式架构技术","slug":"分布式架构技术","permalink":"https://zzkenyon.github.io/categories/分布式架构技术/"}],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://zzkenyon.github.io/tags/zookeeper/"}],"keywords":[{"name":"分布式架构技术","slug":"分布式架构技术","permalink":"https://zzkenyon.github.io/categories/分布式架构技术/"}]},{"title":"linux的i/o模型","slug":"nio-linux的io模型","date":"2019-05-19T16:00:00.000Z","updated":"2020-05-22T11:50:48.220Z","comments":true,"path":"2019/05/20/nio-linux的io模型/","link":"","permalink":"https://zzkenyon.github.io/2019/05/20/nio-linux的io模型/","excerpt":"","text":"同步、异步，阻塞、非阻塞，这四种状态常分不清，主要是这四种状态的定义本身也不是很明确，所以各种解答的方式都有。常见的分类有以下: 同步阻塞IO — BIO (java.io） 同步非阻塞IO —NIO（java.nio） 异步非阻塞IO —AIO (java.nio) 阻塞是指执行I/O操作的线程，在I/O操作过程中能不能处理其他任务； 同步指I/O操作过程中的消息通知机制。 举例说明同步/异步 你打电话问书店老板有没有《分布式系统》这本书，如果是同步通信机制，书店老板会说，你稍等，”我查一下”，然后开始查啊查，等查好了（可能是5秒，也可能是一天）告诉你结果（返回结果）。而异步通信机制，书店老板直接告诉你我查一下啊，查好了打电话给你，然后直接挂电话了（不返回结果）。然后查好了，他会主动打电话给你。在这里老板通过“回电”这种方式来回调。 阻塞/非阻塞 你打电话问书店老板有没有《分布式系统》这本书，你如果是阻塞式调用，你会一直把自己“挂起”，直到得到这本书有没有的结果，如果是非阻塞式调用，你不管老板有没有告诉你，你自己先一边去玩了， 当然你也要偶尔过几分钟check一下老板有没有返回结果。 在这里阻塞与非阻塞与是否同步异步无关。跟老板通过什么方式回答你结果无关。 2. Unix 5种I/O模型在《UNIX网络编程：卷一》的第六章书中列出了五种IO模型： 阻塞式I/O 非阻塞式I/O I/O复用（select，poll，epoll…） 信号驱动式I/O（SIGIO） 异步I/O（POSIX的aio_系列函数） 2.1 阻塞式I/O同步阻塞 IO 模型是最常用的一个模型，也是最简单的模型。在linux中，默认情况下所有的socket都是blocking。它符合人们最常见的思考逻辑。 在这个IO模型中，用户空间的应用程序执行一个系统调用（recvform），这会导致应用程序阻塞，什么也不干，直到数据准备好，等待kernel准备好从网络上接收到的数据报 + 等待收到的报文被从kernel复制到buf中，recvfrom方法才会返回，最后进程再处理数据。 这就是阻塞式IO模型 2.2 非阻塞式I/O非阻塞IO时对一个非阻塞描述符循环调用recvfrom，持续的轮询（polling）,以查看某个操作是否就绪。与阻塞IO不一样，”非阻塞将大的整片时间的阻塞分成N多的小的阻塞, 所以进程不断地有机会 ‘被’ CPU光顾”。 非阻塞的recvform系统调用调用之后，进程并没有被阻塞，内核马上返回给进程，如果数据还没准备好，此时会返回一个error。进程在返回之后，可以干点别的事情，然后再发起recvform系统调用。如此循环的进行recvform系统调用，检查内核数据，直到数据准备好，再拷贝数据到进程。拷贝数据整个过程，进程仍然是属于阻塞的状态。 这就是非阻塞式IO模型 2.3 I/O复用IO multiplexing就是我们说的select，poll，epoll 。为何叫多路复用，是因为它I/O多路复用可以同时监听多个fd，如此就减少了为每个需要监听的fd开启线程的开销。 select调用是内核级别的，可以等待多个socket，能实现同时对多个IO端口进行监听，当其中任何一个socket的数据准好了，就能返回进行可读，然后进程再进行recvform系统调用，将数据由内核拷贝到用户进程，这个过程是阻塞的。 I/O复用模型会用到select、poll、epoll函数，这几个函数也会使进程阻塞，但是和阻塞I/O所不同的的，这几个函数可以同时阻塞多个I/O操作`。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时（不是等到socket数据全部到达再处理, 而是有了一部分数据就会调用用户进程来处理），才真正调用I/O操作函数。 IO复用有人把其成为同步非阻塞的，也有称为同步阻塞。其实这个是否阻塞还需要看第一个阶段，第一个阶段有的阻塞，有的不阻塞。主要也是阻塞在select阶段，属于用户主动等待阶段，我们且规范为阻塞状态，所以，把IO多路复用归为同步阻塞模式。 这是IO复用的模型: select、poll、epoll的不同 2.4 信号驱动式I/O信号驱动式I/O：首先我们允许Socket进行信号驱动IO,并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据。 也就是说第一个阶段，完全是非阻塞的，等数据到达会给一个信号通知，第二个阶段recvfrom还是阻塞过程，和之上无差异。 信号驱动式I/O 过程如下: 2.5 异步I/O异步IO不是顺序执行,用户进程进行aio_read系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程，然后用户态进程可以去做别的事情。等到socket数据准备好了，内核直接复制数据给进程，然后从内核向进程发送通知。IO两个阶段，进程都是非阻塞的。 2.6 总结针对这5中IO模型，我采用一张图来总结一下。 3. java IOUnix中的五种I/O模型，除信号驱动I/O外，Java对其它四种I/O模型都有所支持。其中Java最早提供的blocking I/O即是同步阻塞I/O，而NIO即是同步非阻塞I/O，同时通过NIO实现的Reactor模式即是I/O复用模型的实现，通过AIO实现的Proactor模式即是异步I/O模型的实现。 所以说严格意义上来说，通过Reactor模式实现的NIO，和unix中的I/O多路复用是相同的概念，但这是一种编程模型，而不是原生支持。这也是我们下面所要进行的netty讲解的主要思想。","categories":[{"name":"I/O和网络编程","slug":"I-O和网络编程","permalink":"https://zzkenyon.github.io/categories/I-O和网络编程/"}],"tags":[{"name":"nio","slug":"nio","permalink":"https://zzkenyon.github.io/tags/nio/"}],"keywords":[{"name":"I/O和网络编程","slug":"I-O和网络编程","permalink":"https://zzkenyon.github.io/categories/I-O和网络编程/"}]},{"title":"SpringCloud-分布式事务Seate-TCC","slug":"SpringCloud-分布式事务Seate-TCC","date":"2019-05-19T16:00:00.000Z","updated":"2020-11-27T01:15:26.064Z","comments":true,"path":"2019/05/20/SpringCloud-分布式事务Seate-TCC/","link":"","permalink":"https://zzkenyon.github.io/2019/05/20/SpringCloud-分布式事务Seate-TCC/","excerpt":"","text":"1、基本流程AT就是把每个数据库当做一个 Resource，在本地事务提交时会去注册一个分支事务。 那么对应到 TCC 模式里，也是一样的，Seata 框架把每组 TCC 接口当做一个 Resource，称为 TCC Resource。这套 TCC 接口可以是 RPC，也以是服务内 JVM 调用。在业务启动时，Seata 框架会自动扫描识别到 TCC 接口的调用方和发布方。如果是 RPC 的话，就是 sofa:reference、sofa:service、dubbo:reference、dubbo:service 等。 扫描到 TCC 接口的调用方和发布方之后，如果是发布方，会在业务启动时向 TC 注册 TCC Resource，与 DataSource Resource 一样，每个资源也会带有一个资源 ID。 如果是调用方，Seata 框架会给调用方加上切面，与 AT 模式一样，在运行时，该切面会拦截所有对 TCC 接口的调用。每调用一次 Try 接口，切面会先向 TC 注册一个分支事务，然后才去执行原来的 RPC 调用。当请求链路调用完成后，TC 通过分支事务的资源 ID 回调到正确的参与者去执行对应 TCC 资源的 Confirm 或 Cancel 方法。 原理图如下： 可以看到只有Try接口是业务自己调用的，之后的commit和rollback都是TC调用。 2、基本使用下面以转账为例演示TCC事务模式的使用方法，使用dubbo-spring-boot框架进行开发： 创建表： 12345678create table t_account( uid bigint auto_increment primary key, balance double null, frozen double null);insert into t_accont(uid,balance) values(1,10000);insert into t_accont(uid,balance) values(2,20000); 1、首先定义TCC资源 转账业务拆分成扣款+打款两个action，所以定义两个接口DeductTccAction和AddTccAction(省略代码) 123456789@LocalTCC public interface DeductTccAction &#123; @TwoPhaseBusinessAction(name = \"DeductTccAction\") boolean prepare(BusinessActionContext actionContext, @BusinessActionContextParameter(paramName = \"uid\") int uid, @BusinessActionContextParameter(paramName = \"amount\")double amount); boolean commit(BusinessActionContext actionContext); boolean rollback(BusinessActionContext actionContext);&#125; @LocalTCC标记这是一个TCC资源，缺少该注解事务会以AT模式运行，不会调用到commit和rollback方法 @TwoPhaseBusinessAction注解标记这是个TCC接口，同时指定commitMethod，rollbackMethod的名称 @BusinessActionContext是TCC事务中的上下文对象 @BusinessActionContextParameter注解标记的参数会在上下文中传播，即能通过BusinessActionContext对象在commit方法及rollback方法中取到该参数值 2、开发TCC接口的实现 使用dubbo框架实现 扣款方： prepare – 判断资金是否足够amount-frozen&gt;0，冻结资金frozen+amount commit – balance-amount，并将frozen-amount rollback – frozen-amount 收款方： prepare – 空 commit – balance+amount rollback – 空 源码请见：https://github.com/zzkenyon/seate-tcc 另一个案例：https://www.cnblogs.com/liqbk/p/13643790.html 3、遇到的问题 问题一：报错Could not initialize class io.seata.rm.datasource.undo.UndoLogParserFactory$SingletonHolder https://github.com/seata/seata/issues/1692 添加依赖 1234567 &lt;!-- undo序列化方式 选择了哪个就要依赖哪个jar包--&gt; &lt;!-- https://mvnrepository.com/artifact/com.fasterxml.jackson.core/jackson-databind --&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.11.0&lt;/version&gt;&lt;/dependency&gt; 添加依赖后应用启动失败，提示jar包版本冲突，而且是seata-spring-boot-starter中的4点几版本的spring-xxx包，然后排除掉这些依赖，启动成功 问题二：在TCC资源接口上没有添加@LocalTCC注解，运行之后事务是以AT模式生效的，标志就是只执行了TCC的第一阶段，就在AT中commit了，没有执行我写的commit接口。 3、TCC 异常控制3.1 空回滚什么是空回滚？空回滚就是对于一个分布式事务，在没有调用 TCC 资源 Try 方法的情况下，调用了二阶段的 Cancel 方法，Cancel 方法需要识别出这是一个空回滚，然后直接返回成功。 什么样的情形会造成空回滚呢？可以看图中的第 2 步，前面讲过，注册分支事务是在调用 RPC 时，Seata 框架的切面会拦截到该次调用请求，先向 TC 注册一个分支事务，然后才去执行 RPC 调用逻辑。如果 RPC 调用逻辑有问题，比如调用方机器宕机、网络异常，都会造成 RPC 调用失败，即未执行 Try 方法。但是分布式事务已经开启了，需要推进到终态，因此，TC 会回调参与者二阶段 Cancel 接口，从而形成空回滚。 那会不会有空提交呢？理论上来说不会的，如果调用方宕机，那分布式事务默认是回滚的。如果是网络异常，那 RPC 调用失败，发起方应该通知 TC 回滚分布式事务，这里可以看出为什么是理论上的，就是说发起方可以在 RPC 调用失败的情况下依然通知 TC 提交，这时就会发生空提交，这种情况要么是编码问题，要么开发同学明确知道需要这样做。 那怎么解决空回滚呢？前面提到，Cancel 要识别出空回滚，直接返回成功。那关键就是要识别出这个空回滚。思路很简单就是需要知道一阶段是否执行，如果执行了，那就是正常回滚；如果没执行，那就是空回滚。因此，需要一张额外的事务控制表，其中有分布式事务 ID 和分支事务 ID，第一阶段 Try 方法里会插入一条记录，表示一阶段执行了。Cancel 接口里读取该记录，如果该记录存在，则正常回滚；如果该记录不存在，则是空回滚。 3.2 幂等幂等就是对于同一个分布式事务的同一个分支事务，重复去调用该分支事务的第二阶段接口，因此，要求 TCC 的二阶段 Confirm 和 Cancel 接口保证幂等，不会重复使用或者释放资源。如果幂等控制没有做好，很有可能导致资损等严重问题。 什么样的情形会造成重复提交或回滚？从图中可以看到，提交或回滚是一次 TC 到参与者的网络调用。因此，网络故障、参与者宕机等都有可能造成参与者 TCC 资源实际执行了二阶段防范，但是 TC 没有收到返回结果的情况，这时，TC 就会重复调用，直至调用成功，整个分布式事务结束。 怎么解决重复执行的幂等问题呢？一个简单的思路就是记录每个分支事务的执行状态。在执行前状态，如果已执行，那就不再执行；否则，正常执行。前面在讲空回滚的时候，已经有一张事务控制表了，事务控制表的每条记录关联一个分支事务，那我们完全可以在这张事务控制表上加一个状态字段，用来记录每个分支事务的执行状态。 1234567891011create table 'account_transation'( 'tx_id' varchar(100) NOT NULL COMMENT '事务Txid', 'action_id' varchar(100) NOT NULL COMMENT '分支事务id', 'gmt_create' datetime NOT NULL NOT NULL COMMENT '创建时间', 'gmt_modified' datetime NOT NULL NOT NULL COMMENT '修改时间', 'user_id' varchar(100) NOT NULL NOT NULL COMMENT '账户UID', 'amount' varchar(100) NOT NULL NOT NULL COMMENT '变动金额', 'type' varchar(100) NOT NULL NOT NULL COMMENT '变动类型', 'state' smallint(4) NOT NULL NOT NULL COMMENT '状态：1.初始化；2.已提交；3.已回滚', PRIMARY KEY('tx_id','action_id'))ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='业务流水表' 该状态字段有三个值，分别是初始化、已提交、已回滚。Try 方法插入时，是初始化状态。二阶段 Confirm 和 Cancel 方法执行后修改为已提交或已回滚状态。当重复调用二阶段接口时，先获取该事务控制表对应记录，检查状态，如果已执行，则直接返回成功；否则正常执行。 3.3 悬挂按照惯例，咱们来先讲讲什么是悬挂。悬挂就是对于一个分布式事务，其二阶段 Cancel 接口比 Try 接口先执行。因为允许空回滚的原因，Cancel 接口认为 Try 接口没执行，空回滚直接返回成功，对于 Seata 框架来说，认为分布式事务的二阶段接口已经执行成功，整个分布式事务就结束了。但是这之后 Try 方法才真正开始执行，预留业务资源，前面提到事务并发控制的业务加锁，对于一个 Try 方法预留的业务资源，只有该分布式事务才能使用，然而 Seata 框架认为该分布式事务已经结束，也就是说，当出现这种情况时，该分布式事务第一阶段预留的业务资源就再也没有人能够处理了，对于这种情况，我们就称为悬挂，即业务资源预留后没法继续处理。 什么样的情况会造成悬挂呢？按照前面所讲，在 RPC 调用时，先注册分支事务，再执行 RPC 调用，如果此时 RPC 调用的网络发生拥堵，通常 RPC 调用是有超时时间的，RPC 超时以后，发起方就会通知 TC 回滚该分布式事务，可能回滚完成后，RPC 请求才到达参与者，真正执行，从而造成悬挂。 怎么实现才能做到防悬挂呢？根据悬挂出现的条件先来分析下，悬挂是指二阶段 Cancel 执行完后，一阶段才执行。也就是说，为了避免悬挂，如果二阶段执行完成，那一阶段就不能再继续执行。因此，当一阶段执行时，需要先检查二阶段是否已经执行完成，如果已经执行，则一阶段不再执行；否则可以正常执行。那怎么检查二阶段是否已经执行呢？大家是否想到了刚才解决空回滚和幂等时用到的事务控制表，可以在二阶段执行时插入一条事务控制记录，状态为已回滚，这样当一阶段执行时，先读取该记录，如果记录存在，就认为二阶段已经执行；否则二阶段没执行。 3.4 异常控制实现在分析完空回滚、幂等、悬挂等异常 Case 的成因以及解决方案以后，下面我们就综合起来考虑，一个 TCC 接口如何完整的解决这三个问题。 首先是 Try 方法。结合前面讲到空回滚和悬挂异常，Try 方法主要需要考虑两个问题，一个是 Try 方法需要能够告诉二阶段接口，已经预留业务资源成功。第二个是需要检查第二阶段是否已经执行完成，如果已完成，则不再执行。因此，Try 方法的逻辑可以如图所示： 先插入事务控制表记录，如果插入成功，说明第二阶段还没有执行，可以继续执行第一阶段。如果插入失败，则说明第二阶段已经执行或正在执行，则抛出异常，终止即可。 接下来是 Confirm 方法。因为 Confirm 方法不允许空回滚，也就是说，Confirm 方法一定要在 Try 方法之后执行。因此，Confirm 方法只需要关注重复提交的问题。可以先锁定事务记录，如果事务记录为空，则说明是一个空提交，不允许，终止执行。如果事务记录不为空，则继续检查状态是否为初始化，如果是，则说明一阶段正确执行，那二阶段正常执行即可。如果状态是已提交，则认为是重复提交，直接返回成功即可；如果状态是已回滚，也是一个异常，一个已回滚的事务，不能重新提交，需要能够拦截到这种异常情况，并报警。 最后是 Cancel 方法。因为 Cancel 方法允许空回滚，并且要在先执行的情况下，让 Try 方法感知到 Cancel 已经执行，所以和 Confirm 方法略有不同。首先依然是锁定事务记录。如果事务记录为空，则认为 Try 方法还没执行，即是空回滚。空回滚的情况下，应该先插入一条事务记录，确保后续的 Try 方法不会再执行。如果插入成功，则说明 Try 方法还没有执行，空回滚继续执行。如果插入失败，则认为 Try 方法正再执行，等待 TC 的重试即可。如果一开始读取事务记录不为空，则说明 Try 方法已经执行完毕，再检查状态是否为初始化，如果是，则还没有执行过其他二阶段方法，正常执行 Cancel 逻辑。如果状态为已回滚，则说明这是重复调用，允许幂等，直接返回成功即可。如果状态为已提交，则同样是一个异常，一个已提交的事务，不能再次回滚。 4、TCC 性能优化虽然 TCC 模型已经完备，但是随着业务的增长，对于 TCC 模型的挑战也越来越大，可能还需要一些特殊的优化，才能满足业务需求。下面我们将会给大家讲讲，蚂蚁金服内部在 TCC 模型上都做了哪些优化。 4.1 同库模式第一个优化方案是改为同库模式。同库模式简单来说，就是分支事务记录与业务数据在相同的库中。什么意思呢？之前提到，在注册分支事务记录的时候，框架的调用方切面会先向 TC 注册一个分支事务记录，注册成功后，才会继续往下执行 RPC 调用。TC 在收到分支事务记录注册请求后，会往自己的数据库里插入一条分支事务记录，从而保证事务数据的持久化存储。那同库模式就是调用方切面不再向 TC 注册了，而是直接往业务的数据库里插入一条事务记录。 2.3.2 异步化https://blog.csdn.net/huaishu/article/details/898809711","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/tags/SpringCloud/"}],"keywords":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}]},{"title":"zookeeper配置和基本操纵","slug":"分布式-zookeeper-配置和基本操纵","date":"2019-05-18T16:00:00.000Z","updated":"2020-11-24T07:22:48.711Z","comments":true,"path":"2019/05/19/分布式-zookeeper-配置和基本操纵/","link":"","permalink":"https://zzkenyon.github.io/2019/05/19/分布式-zookeeper-配置和基本操纵/","excerpt":"","text":"1. 配置开机自启把zookeeper做成服务 1、进入到/etc/rc.d/init.d目录下，新建一个zookeeper脚本 1234[root@node1 ~]# cd /etc/rc.d/init.d/ [root@node1 init.d]# pwd /etc/rc.d/init.d [root@node1 init.d]# touch zookeeper 2、给脚本添加执行权限 1[root@node1 init.d]# chmod +x zookeeper 3、使用命令vim zookeeper进行编辑，在脚本中输入如下内容，其中同上面注意事项一样要添加export JAVA_HOME=/usr/java/jdk1.8.0_112这一行，否则无法正常启动。 [root@zookeeper init.d]# vim zookeeper 123456789101112#!/bin/bash#chkconfig:2345 10 90#description:service zookeeperexport JAVA_HOME=/usr/java/jdk-1.8.0_271-amd64ZOOKEEPER_HOME=/usr/local/apache-zookeeper-3.6.1-bincase \"$1\" in start) su root $&#123;ZOOKEEPER_HOME&#125;/bin/zkServer.sh start;; stop) su root $&#123;ZOOKEEPER_HOME&#125;/bin/zkServer.sh stop;; status) su root $&#123;ZOOKEEPER_HOME&#125;/bin/zkServer.sh status;; restart) su root $&#123;ZOOKEEPER_HOME&#125;/bin/zkServer.sh restart;; *) echo \"require start||stop|status|restart|\";;esac 4、 使用service zookeeper start/stop/restart命令来尝试启动关闭重启zookeeper，使用service zookeeper status查看zookeeper状态。 5、添加到开机自启 1[root@node1 init.d]# chkconfig --add zookeeper 添加完之后，我们使用chkconfig –list来查看开机自启的服务中是否已经有我们的zookeeper了，如下所示，可以看到在最后一行便是我们的zookeeper服务了。 1234[root@node1 init.d]# chkconfig --list netconsole 0:off 1:off 2:off 3:off 4:off 5:off 6:offnetwork 0:off 1:off 2:on 3:on 4:on 5:on 6:offzookeeper 0:off 1:off 2:on 3:on 4:on 5:on 6:off 2. zkCli客户端https://blog.csdn.net/dandandeshangni/article/details/80558383 2.1 基本操作 列举子节点: ls path (ls /zookeeper) 查看节点更新信息：stat path (stat /zookeeper) 创建节点 ：create path val (creat /config “test string value”) 创建临时节点 ：create -e path val 创建顺序节点：create -s path val 修改节点：set path val (set /config “another config string”) 删除节点：delete path 监视节点：stat -w path、 get -w path 2.2 ACL权限控制ZK的节点有5种操作权限：CREATE、READ、WRITE、DELETE、ADMIN 也就是 增、删、改、查、管理权限，这5种权限简写为crwda(即：每个单词的首字符缩写)。 注：这5种权限中，delete是指对子节点的删除权限，其它4种权限指对自身节点的操作权限 身份的认证有4种方式： world：默认方式，相当于全世界都能访问 auth：代表已经认证通过的用户(cli中可以通过addauth digest user:pwd 来添加当前上下文中的授权用户) digest：即用户名:密码这种方式认证，这也是业务系统中最常用的 ip：使用Ip地址认证 使用[scheme​ : id : permissions]来表示acl权限，比如-digest:username:password:cwrda getAcl:获取某个节点的acl权限信息 getAcl path 123456789#World方案权限设置setAcl /config/global world:anyone:crwa#auth方案权限设置addauth digest test:123456 setAcl /config/global auth:test:123456:cdrwa#digest方案权限设置setAcl /config/global digest:test:V28q/NynI4JI3Rk54h0r8O5kMug=:cdra#ip权限设置setAcl /niocoder/ip ip:192.168.0.68:cdrwa 超级管理员zk的权限管理表有一种ACL的模式叫做super，该模式的作用是方便管理节点。一旦我们为某一个节点设置了acl，那么其余的未授权的节点是无法访问或者操作该节点的，那么系统用久了以后，假如忘记了某一个节点的密码，那么就无法再操作这个节点了，所以需要这个super超级管理员用户权限，其作用还是很大的。 添加方式：只能在启动服务器的时候添加。 假设这个超管是：super:admin，通过代码得到其哈希值： 1String m = DigestAuthenticationProvider.generateDigest(\"super:admin\"); m是： 1super:xQJmxLMiHGwaqBvst5y6rkB6HQs= 那么打开zk目录下的/bin/zkServer.sh服务器脚本文件，找到如下一行： 1nohup $JAVA \"-Dzookeeper.log.dir=$&#123;ZOO_LOG_DIR&#125;\" \"-Dzookeeper.root.logger=$&#123;ZOO_LOG4J_PROP&#125;\" 这就是脚本中启动zk的命令，默认只有以上两个配置项，我们需要加一个超管的配置项： 1\"-Dzookeeper.DigestAuthenticationProvider.superDigest=super:xQJmxLMiHGwaqBvst5y6rkB6HQs=\" 第一个等号之后的就是刚才用户名密码的哈希值。 那么修改以后这条完整命令变成了： 12nohup $JAVA \"-Dzookeeper.log.dir=$&#123;ZOO_LOG_DIR&#125;\" \"-Dzookeeper.root.logger=$&#123;ZOO_LOG4J_PROP&#125;\" \"-Dzookeeper.DigestAuthenticationProvider.superDigest=super:xQJmxLMiHGwaqBvst5y6rkB6HQs=\"\\ -cp \"$CLASSPATH\" $JVMFLAGS $ZOOMAIN \"$ZOOCFG\" &gt; \"$_ZOO_DAEMON_OUT\" 2&gt;&amp;1 &lt; /dev/null &amp; 之后重新启动zk集群，进入zkCli输入如下命令添加权限： 1addauth digest super:admin 假如zk有一个节点/test，acl为digest方案，但是忘记了用户名和密码，正常情况下，这次登陆如果不用那个digest授权是不能访问/test的数据的。但是由于我们配置了超管，所以这次还是可以访问到的。 需要说明的是，这个超管只是在这次服务器启动期间管用，如果关闭了服务器，并修改了服务器脚本，取消了超管配置，那么下一次启动就没有这个超管了。 运维四字指令使用四字命令需要安装nc命令(yum install nc) 然后在启动脚本zkServer.sh里添加ＶＭ环境变量-Dzookeeper.4lw.commands.whitelist=*，便可以把所有四字指令添加到白名单（否则执行四字指令会报错is not executed because it is not in the whitelist），我是添加在脚本的这个位置： 123456789ZOOMAIN=\"-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=$JMXPORT -Dcom.sun.management.jmxremote.authenticate=$JMXAUTH -Dcom.sun.management.jmxremote.ssl=$JMXSSL -Dzookeeper.jmx.log4j.disable=$JMXLOG4J org.apache.zookeeper.server.quorum.QuorumPeerMain\" fielse echo \"JMX disabled by user request\" &gt;&amp;2 ZOOMAIN=\"org.apache.zookeeper.server.quorum.QuorumPeerMain\"fi# 这里就是我添加的# 如果不想添加在这里，注意位置和赋值的顺序ZOOMAIN=\"-Dzookeeper.4lw.commands.whitelist=* $&#123;ZOOMAIN&#125;\" 重启zk即可。 四字指令调用方法： 1[root@node1 ~]#echo xxxx | nc 192.168.0.68 2181 其中xxxx为： stat 查看状态信息 ruok 查看zookeeper是否启动 dump 列出没有处理的节点，临时节点 conf 查看服务器配置 cons 显示连接到服务端的信息 envi 显示环境变量信息 mntr 查看zk的健康信息 wchs 展示watch的信息 wchc和wchp 显示session的watch信息 path的watch信息","categories":[{"name":"分布式架构技术","slug":"分布式架构技术","permalink":"https://zzkenyon.github.io/categories/分布式架构技术/"}],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://zzkenyon.github.io/tags/zookeeper/"}],"keywords":[{"name":"分布式架构技术","slug":"分布式架构技术","permalink":"https://zzkenyon.github.io/categories/分布式架构技术/"}]},{"title":"zookeeper是什么以及能干什么","slug":"分布式-zookeeper是什么以及能干什么","date":"2019-05-17T16:00:00.000Z","updated":"2020-05-22T23:40:17.200Z","comments":true,"path":"2019/05/18/分布式-zookeeper是什么以及能干什么/","link":"","permalink":"https://zzkenyon.github.io/2019/05/18/分布式-zookeeper是什么以及能干什么/","excerpt":"","text":"分布式一致性问题： 1. 什么是 ZooKeeper1.1 ZooKeeper 的由来下面这段内容摘自《从Paxos到Zookeeper 》第四章第一节的某段内容，推荐大家阅读： Zookeeper最早起源于雅虎研究院的一个研究小组。在当时，研究人员发现，在雅虎内部很多大型系统基本都需要依赖一个类似的系统来进行分布式协调，但是这些系统往往都存在分布式单点问题。所以，雅虎的开发人员就试图开发一个通用的无单点问题的分布式协调框架，以便让开发人员将精力集中在处理业务逻辑上。 关于“ZooKeeper”这个项目的名字，其实也有一段趣闻。在立项初期，考虑到之前内部很多项目都是使用动物的名字来命名的（例如著名的Pig项目),雅虎的工程师希望给这个项目也取一个动物的名字。时任研究院的首席科学家RaghuRamakrishnan开玩笑地说：“在这样下去，我们这儿就变成动物园了！”此话一出，大家纷纷表示就叫动物园管理员吧一一一因为各个以动物命名的分布式组件放在一起，雅虎的整个分布式系统看上去就像一个大型的动物园了，而Zookeeper正好要用来进行分布式环境的协调一一于是，Zookeeper的名字也就由此诞生了。 1.2 ZooKeeper 概览ZooKeeper 是一个开源的分布式协调服务，ZooKeeper框架最初是在“Yahoo!”上构建的，用于以简单而稳健的方式访问他们的应用程序。 后来，Apache ZooKeeper成为Hadoop，HBase和其他分布式框架使用的有组织服务的标准。 例如，Apache HBase使用ZooKeeper跟踪分布式数据的状态。 ZooKeeper 的设计目标是将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一系列简单易用的接口提供给用户使用。 ZooKeeper 是一个典型的分布式数据一致性解决方案，分布式应用程序可以基于 ZooKeeper 实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能。 Zookeeper 一个最常用的使用场景 就是用于担任服务生产者和服务消费者的注册中心(提供发布订阅服务)。服务生产者将自己提供的服务注册到Zookeeper中心，服务的消费者在进行服务调用的时候先到Zookeeper中查找服务，获取到服务生产者的详细信息之后，再去调用服务生产者的内容与数据。如下图所示，在 Dubbo架构中 Zookeeper 就担任了注册中心这一角色。 1.2 结合使用情况的讲一下 ZooKeeper在我自己做过的项目中，主要使用到了 ZooKeeper 作为 Dubbo 的注册中心(Dubbo 官方推荐使用 ZooKeeper注册中心)。另外在搭建 solr 集群的时候，我使用 ZooKeeper 作为 solr 集群的管理工具。这时，ZooKeeper 主要提供下面几个功能：1、集群管理：容错、负载均衡。2、配置文件的集中管理。3、集群的入口。 我个人觉得在使用 ZooKeeper 的时候，最好是使用 集群版的 ZooKeeper 而不是单机版的。官网给出的架构图就描述的是一个集群版的 ZooKeeper 。通常 3 台服务器就可以构成一个 ZooKeeper 集群了。 为什么最好使用奇数台服务器构成 ZooKeeper 集群？ 所谓的zookeeper容错是指，当宕掉几个zookeeper服务器之后，剩下的个数必须大于宕掉的个数的话整个zookeeper才依然可用。假如我们的集群中有n台zookeeper服务器，那么也就是剩下的服务数必须大于n/2。先说一下结论，2n和2n-1的容忍度是一样的，都是n-1，大家可以先自己仔细想一想，这应该是一个很简单的数学问题了。 比如假如我们有3台，那么最大允许宕掉1台zookeeper服务器，如果我们有4台的的时候也同样只允许宕掉1台。 假如我们有5台，那么最大允许宕掉2台zookeeper服务器，如果我们有6台的的时候也同样只允许宕掉2台。 综上，何必增加那一个不必要的zookeeper呢？ 2. 关于 ZooKeeper 的一些重要概念2.1 重要概念总结 ZooKeeper 本身就是一个分布式程序，为了保证高可用，最好是以集群形态来部署 ZooKeeper。只要半数以上节点存活，ZooKeeper 就能正常服务。 ZooKeeper 将数据保存在内存中，这也就保证了 高吞吐量和低延迟，但是内存限制了能够存储的容量不太大，此限制也是保持znode中存储的数据量较小的进一步原因。 ZooKeeper 是在“读”多于“写”的应用程序中尤其地高性能，因为“写”会导致所有的服务器间同步状态。（“读”多于“写”是协调服务的典型场景。） ZooKeeper有临时节点的概念。 当创建临时节点的客户端会话一直保持活动，瞬时节点就一直存在。而当会话终结时，瞬时节点被删除。持久节点是指一旦这个ZNode被创建了，除非主动进行ZNode的移除操作，否则这个ZNode将一直保存在Zookeeper上。 ZooKeeper 底层其实只提供了两个功能：①管理（存储、读取）用户程序提交的数据；②为用户程序提供数据节点监听服务。 2.2 会话（Session）Session 指的是 ZooKeeper 服务器与客户端会话。在 ZooKeeper 中，一个客户端连接是指客户端和服务器之间的一个 TCP 长连接。客户端启动的时候，首先会与服务器建立一个 TCP 连接，从第一次连接建立开始，客户端会话的生命周期也开始了。通过这个连接，客户端能够通过心跳检测与服务器保持有效的会话，也能够向Zookeeper服务器发送请求并接受响应，同时还能够通过该连接接收来自服务器的Watch事件通知。 Session的sessionTimeout值用来设置一个客户端会话的超时时间。当由于服务器压力太大、网络故障或是客户端主动断开连接等各种原因导致客户端连接断开时，只要在sessionTimeout规定的时间内能够重新连接上集群中任意一台服务器，那么之前创建的会话仍然有效。 在为客户端创建会话之前，服务端首先会为每个客户端都分配一个sessionID。由于 sessionID 是 Zookeeper 会话的一个重要标识，许多与会话相关的运行机制都是基于这个 sessionID 的，因此，无论是哪台服务器为客户端分配的 sessionID，都务必保证全局唯一。 2.3 Znode在谈到分布式的时候，我们通常说的“节点”是指组成集群的每一台机器。然而，在Zookeeper中，“节点”分为两类，第一类同样是指构成集群的机器，我们称之为机器节点；第二类则是指数据模型中的数据单元，我们称之为数据节点一一ZNode。 Zookeeper将所有数据存储在内存中，数据模型是一棵树（Znode Tree)，由斜杠（/）的进行分割的路径，就是一个Znode，例如/foo/path1。每个上都会保存自己的数据内容，同时还会保存一系列属性信息。 在Zookeeper中，node可以分为持久节点和临时节点两类。所谓持久节点是指一旦这个ZNode被创建了，除非主动进行ZNode的移除操作，否则这个ZNode将一直保存在Zookeeper上。而临时节点就不一样了，它的生命周期和客户端会话绑定，一旦客户端会话失效，那么这个客户端创建的所有临时节点都会被移除。 另外，ZooKeeper还允许用户为每个节点添加一个特殊的属性：SEQUENTIAL.一旦节点被标记上这个属性，那么在这个节点被创建的时候，Zookeeper会自动在其节点名后面追加上一个整型数字，这个整型数字是一个由父节点维护的自增数字。 2.4 版本在前面我们已经提到，Zookeeper 的每个 ZNode 上都会存储数据，对应于每个ZNode，Zookeeper 都会为其维护一个叫作 Stat 的数据结构，Stat 中记录了这个 ZNode 的三个数据版本，分别是version（当前ZNode的版本）、cversion（当前ZNode子节点的版本）和 aversion（当前ZNode的ACL版本）。 2.5 WatcherWatcher（事件监听器），是Zookeeper中的一个很重要的特性。Zookeeper允许用户在指定节点上注册一些Watcher，并且在一些特定事件触发的时候，ZooKeeper服务端会将事件通知到感兴趣的客户端上去，该机制是Zookeeper实现分布式协调服务的重要特性。 2.6 ACLZookeeper采用ACL（AccessControlLists）策略来进行权限控制，类似于 UNIX 文件系统的权限控制。Zookeeper 定义了如下5种权限。 其中尤其需要注意的是，CREATE和DELETE这两种权限都是针对子节点的权限控制。 3. ZooKeeper 特点 顺序一致性： 从同一客户端发起的事务请求，最终将会严格地按照顺序被应用到 ZooKeeper 中去。 原子性： 所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么整个集群中所有的机器都成功应用了某一个事务，要么都没有应用。 单一系统映像 ： 无论客户端连到哪一个 ZooKeeper 服务器上，其看到的服务端数据模型都是一致的。 可靠性： 一旦一次更改请求被应用，更改的结果就会被持久化，直到被下一次更改覆盖。 4. ZooKeeper 设计目标4.1 简单的数据模型ZooKeeper 允许分布式进程通过共享的层次结构命名空间进行相互协调，这与标准文件系统类似。 名称空间由 ZooKeeper 中的数据寄存器组成 - 称为znode，这些类似于文件和目录。 与为存储设计的典型文件系统不同，ZooKeeper数据保存在内存中，这意味着ZooKeeper可以实现高吞吐量和低延迟。 4.2 可构建集群为了保证高可用，最好是以集群形态来部署 ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么zookeeper本身仍然是可用的。 客户端在使用 ZooKeeper 时，需要知道集群机器列表，通过与集群中的某一台机器建立 TCP 连接来使用服务，客户端使用这个TCP链接来发送请求、获取结果、获取监听事件以及发送心跳包。如果这个连接异常断开了，客户端可以连接到另外的机器上。 ZooKeeper 官方提供的架构图： 上图中每一个Server代表一个安装Zookeeper服务的服务器。组成 ZooKeeper 服务的服务器都会在内存中维护当前的服务器状态，并且每台服务器之间都互相保持着通信。集群间通过 Zab 协议（Zookeeper Atomic Broadcast）来保持数据的一致性。 4.3 顺序访问对于来自客户端的每个更新请求，ZooKeeper 都会分配一个全局唯一的递增编号，这个编号反应了所有事务操作的先后顺序，应用程序可以使用 ZooKeeper 这个特性来实现更高层次的同步原语。 这个编号也叫做时间戳——zxid（Zookeeper Transaction Id） 4.4 高性能ZooKeeper 是高性能的。 在“读”多于“写”的应用程序中尤其地高性能，因为“写”会导致所有的服务器间同步状态。（“读”多于“写”是协调服务的典型场景。） 5. ZooKeeper 集群角色介绍最典型集群模式： Master/Slave 模式（主备模式）。在这种模式中，通常 Master服务器作为主服务器提供写服务，其他的 Slave 服务器从服务器通过异步复制的方式获取 Master 服务器最新的数据提供读服务。 但是，在 ZooKeeper 中没有选择传统的 Master/Slave 概念，而是引入了Leader、Follower 和 Observer 三种角色。如下图所示 ZooKeeper 集群中的所有机器通过一个 Leader 选举过程来选定一台称为 “Leader” 的机器，Leader 既可以为客户端提供写服务又能提供读服务。除了 Leader 外，Follower 和 Observer 都只能提供读服务。Follower 和 Observer 唯一的区别在于 Observer 机器不参与 Leader 的选举过程，也不参与写操作的过半写成功策略，因此 Observer 机器可以在不影响写性能的情况下提升集群的读性能。 当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB 协议就会进人恢复模式并选举产生新的Leader服务器。这个过程大致是这样的： Leader election（选举阶段）：节点在一开始都处于选举阶段，只要有一个节点得到超半数节点的票数，它就可以当选准 leader。 Discovery（发现阶段）：在这个阶段，followers 跟准 leader 进行通信，同步 followers 最近接收的事务提议。 Synchronization（同步阶段）:同步阶段主要是利用 leader 前一阶段获得的最新提议历史，同步集群中所有的副本。同步完成之后 准 leader 才会成为真正的 leader。 Broadcast（广播阶段） 到了这个阶段，Zookeeper 集群才能正式对外提供事务服务，并且 leader 可以进行消息广播。同时如果有新的节点加入，还需要对新节点进行同步。 6. ZooKeeper &amp;ZAB 协议&amp;Paxos算法6.1 ZAB 协议&amp;Paxos算法Paxos 算法应该可以说是 ZooKeeper 的灵魂了。但是，ZooKeeper 并没有完全采用 Paxos算法 ，而是使用 ZAB 协议作为其保证数据一致性的核心算法。另外，在ZooKeeper的官方文档中也指出，ZAB协议并不像 Paxos 算法那样，是一种通用的分布式一致性算法，它是一种特别为Zookeeper设计的崩溃可恢复的原子消息广播算法。 6.2 ZAB 协议介绍ZAB（ZooKeeper Atomic Broadcast 原子广播） 协议是为分布式协调服务 ZooKeeper 专门设计的一种支持崩溃恢复的原子广播协议。 在 ZooKeeper 中，主要依赖 ZAB 协议来实现分布式数据一致性，基于该协议，ZooKeeper 实现了一种主备模式的系统架构来保持集群中各个副本之间的数据一致性。 6.3 ZAB 协议的两种基本模式ZAB协议包括两种基本的模式，分别是 崩溃恢复和消息广播。当整个服务框架在启动过程中，或是当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB 协议就会进人恢复模式并选举产生新的Leader服务器。当选举产生了新的 Leader 服务器，同时集群中已经有过半的机器与该Leader服务器完成了状态同步之后，ZAB协议就会退出恢复模式。其中，所谓的状态同步是指数据同步，用来保证集群中存在过半的机器能够和Leader服务器的数据状态保持一致。 当集群中已经有过半的Follower服务器完成了和Leader服务器的状态同步，那么整个服务框架就可以进人消息广播模式了。 当一台同样遵守ZAB协议的服务器启动后加人到集群中时，如果此时集群中已经存在一个Leader服务器在负责进行消息广播，那么新加人的服务器就会自觉地进人数据恢复模式：找到Leader所在的服务器，并与其进行数据同步，然后一起参与到消息广播流程中去。正如上文介绍中所说的，ZooKeeper设计成只允许唯一的一个Leader服务器来进行事务请求的处理。Leader服务器在接收到客户端的事务请求后，会生成对应的事务提案并发起一轮广播协议；而如果集群中的其他机器接收到客户端的事务请求，那么这些非Leader服务器会首先将这个事务请求转发给Leader服务器。 关于 ZAB 协议&amp;Paxos算法 需要讲和理解的东西太多了，推荐阅读下面两篇文章： 图解 Paxos 一致性协议 Zookeeper ZAB 协议分析","categories":[{"name":"分布式架构技术","slug":"分布式架构技术","permalink":"https://zzkenyon.github.io/categories/分布式架构技术/"}],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://zzkenyon.github.io/tags/zookeeper/"}],"keywords":[{"name":"分布式架构技术","slug":"分布式架构技术","permalink":"https://zzkenyon.github.io/categories/分布式架构技术/"}]},{"title":"dubbo-消费者服务订阅流程分析","slug":"dubbo-消费者服务订阅流程分析","date":"2019-04-30T16:00:00.000Z","updated":"2021-01-08T05:41:09.961Z","comments":true,"path":"2019/05/01/dubbo-消费者服务订阅流程分析/","link":"","permalink":"https://zzkenyon.github.io/2019/05/01/dubbo-消费者服务订阅流程分析/","excerpt":"","text":"Dubbo是以URL驱动的框架，因此本片将跟踪URL的传递以及处理来分析整个服务订阅的流程 消费者在createProxy()方法中，创建了第一个url URL-1 1registry://localhost:9090/org.apache.dubbo.registry.RegistryService?application=consumer-test&amp;dubbo=2.0.2&amp;pid=10181&amp;qos.enable=false&amp;registry=spring-cloud&amp;release=2.7.6&amp;timestamp=1610009175272 接着，在上面url上接了一个refer属性： URL-2 1registry://localhost:9090/org.apache.dubbo.registry.RegistryService?application=consumer-test&amp;dubbo=2.0.2&amp;pid=10181&amp;qos.enable=false&amp;refer=application%3Dconsumer-test%26dubbo%3D2.0.2%26init%3Dfalse%26interface%3Dcom.pd.ISayHello%26methods%3DsayHello%26pid%3D10181%26qos.enable%3Dfalse%26register.ip%3D172.30.66.2%26release%3D2.7.6%26side%3Dconsumer%26sticky%3Dfalse%26timestamp%3D1610009171036&amp;registry=spring-cloud&amp;release=2.7.6&amp;timestamp=1610009175272 %3D 是 = 号，%26 是 &amp; 符号 拼接这个refer的目的是传参 接下来创建invoker对象 1invoker = REF_PROTOCOL.refer(interfaceClass, urls.get(0)); REF_PROTOCOL是自适应扩展点，将根据url的协议 进入指定的Protocol进行处理，这里将进入 RegistyProtocol.refer 该方法中首先获取注册url 12345public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; url = getRegistryUrl(url); Registry registry = registryFactory.getRegistry(url); ...&#125; 该url为： URL-3 1spring-cloud://localhost:9090/org.apache.dubbo.registry.RegistryService?application=consumer-test&amp;dubbo=2.0.2&amp;pid=10181&amp;qos.enable=false&amp;refer=application%3Dconsumer-test%26dubbo%3D2.0.2%26init%3Dfalse%26interface%3Dcom.pd.ISayHello%26methods%3DsayHello%26pid%3D10181%26qos.enable%3Dfalse%26register.ip%3D172.30.66.2%26release%3D2.7.6%26side%3Dconsumer%26sticky%3Dfalse%26timestamp%3D1610009171036&amp;release=2.7.6&amp;timestamp=1610009175272 可以发现与上一阶段的区别就是协议换成了spring-cloud registryFactory也是自适应扩展的，将根据协议决定使用哪个registryFactory， 这里将进入SpringCloudRegistryFactory获取registry 那么获取到的肯定就是SpringCloudRegistry 继续向下进入doRefer方法 此方法中会创建一个subscribeUrl URL-4 1consumer://172.30.66.2/com.pd.ISayHello?application=consumer-test&amp;dubbo=2.0.2&amp;init=false&amp;interface=com.pd.ISayHello&amp;methods=sayHello&amp;pid=10181&amp;qos.enable=false&amp;release=2.7.6&amp;side=consumer&amp;sticky=false&amp;timestamp=1610009171036 这个url最后被添加到了AbstractRegistry一个Set类型的成员变量registered中 进一步处理这个url，添加了一个参数category=providers,configurators,routers URL-5 1consumer://172.30.66.2/com.pd.ISayHello?application=consumer-test&amp;category=providers,configurators,routers&amp;dubbo=2.0.2&amp;init=false&amp;interface=com.pd.ISayHello&amp;methods=sayHello&amp;pid=10897&amp;qos.enable=false&amp;release=2.7.6&amp;side=consumer&amp;sticky=false&amp;timestamp=1610011204472 然后开始订阅服务： 1234567//RegistryDirectorypublic void subscribe(URL url) &#123; setConsumerUrl(url); CONSUMER_CONFIGURATION_LISTENER.addNotifyListener(this); serviceConfigurationListener = new ReferenceConfigurationListener(this, url); registry.subscribe(url, this);&#125; registry是什么类型？ ListenerRegistryWrapper(SpringCloudRegistry) 因此会先调用ListenerRegistryWrapper.subscribe() 123456@Overridepublic void subscribe(URL url, NotifyListener listener) &#123; try &#123; registry.subscribe(url, listener); //这里的registry是SpringCloudRegistry &#125; finally &#123;...&#125;&#125; 再调用SpringCloudRegistry.subscribe()，而该方法继承的是父类的，所以会进入AbstractRegistry.subscribe()方法： 12345678@Override // FailbackRegistrypublic void subscribe(URL url, NotifyListener listener) &#123; super.subscribe(url, listener); // super是AbstractRegistry removeFailedSubscribed(url, listener); try &#123; doSubscribe(url, listener); //此方法在子类中定义，AbstractSpringCloudRegistry &#125; catch (Exception e) &#123;...&#125;&#125; 这里向类型为ConcurrentMap&lt;URL, Set&lt;NotifyListener&gt;&gt;的subscribed 成员中中创建一条记录，并将RegistryDirectory放到Set中，RegistryDirectory是一个NotifyListener，能够监听注册中心实例列表的变化，从而更新本地实例目录，一个服务对应一个RegistryDirectory。 123456@Override // AbstractRegistrypublic void subscribe(URL url, NotifyListener listener) &#123; ... Set&lt;NotifyListener&gt; listeners = subscribed.computeIfAbsent(url, n -&gt; new ConcurrentHashSet&lt;&gt;()); listeners.add(listener);&#125; 然后调用到了doSubscribe方法，该方法在子类AbstractSpringCloudRegistry中实现 123456789101112@Override //AbstractSpringCloudRegistrypublic final void doSubscribe(URL url, NotifyListener listener) &#123; ... //处理一些特殊场景 else &#123; // for general Dubbo Services subscribeDubboServiceURLs(url, listener); // 此时的参数url还是URL-5 &#125;&#125;protected void subscribeDubboServiceURLs(URL url, NotifyListener listener) &#123; // 干活 doSubscribeDubboServiceURLs(url, listener); registerServiceInstancesChangedEventListener(url, listener); &#125; 1234567private void doSubscribeDubboServiceURLs(URL url, NotifyListener listener) &#123; // 获取应用需要订阅的服务名称，通过配置dubbo.cloud.subscribed-services来指定 Set&lt;String&gt; subscribedServices = repository.getSubscribedServices(); // Sync 根据服务名称订阅所有服务 subscribedServices.forEach(service -&gt; subscribeDubboServiceURL(url, listener, service, this::getServiceInstances));&#125; subscribeDubboServiceURL方法的最后一个参数是一个函数引用，传入的函数参数getServiceInstances封装的是获取注册中心指定服务实例的逻辑 1234567891011121314151617181920212223242526272829303132333435363738protected void subscribeDubboServiceURL(URL url, NotifyListener listener, String serviceName, Function&lt;String, Collection&lt;ServiceInstance&gt;&gt; serviceInstancesFunction) &#123; List&lt;URL&gt; allSubscribedURLs = new LinkedList&lt;&gt;(); // 用于存放所有已订阅的实例Url //调用函数参数getServiceInstances 获取指定服务的实例 Collection&lt;ServiceInstance&gt; serviceInstances = serviceInstancesFunction .apply(serviceName); ... // 初始化服务的元信息，服务元信息里没有具体实例相关的信息 repository.initializeMetadata(serviceName); DubboMetadataService dubboMetadataService = dubboMetadataConfigServiceProxy .getProxy(serviceName); // 根据服务元信息和URL-5获取已发布的服务实例URL-6，同一个服务可能会以多种协议发布，所以这里是一个列表，通常只用dubbo的情况下，列表中只有一条记录 List&lt;URL&gt; exportedURLs = getExportedURLs(dubboMetadataService, url); for (URL exportedURL : exportedURLs) &#123; String protocol = exportedURL.getProtocol(); List&lt;URL&gt; subscribedURLs = new LinkedList&lt;&gt;(); // 获取所有的服务实例URl serviceInstances.forEach(serviceInstance -&gt; &#123; Integer port = repository.getDubboProtocolPort(serviceInstance, protocol); String host = serviceInstance.getHost(); ... // 根据serviceInstance对象和exportedURL，拼接处具体的实例url else &#123; URL subscribedURL = new URL(protocol, host, port, exportedURL.getParameters()); subscribedURLs.add(subscribedURL); &#125; &#125;); allSubscribedURLs.addAll(subscribedURLs); &#125; ... // 通知`RegistryDirectory` listener.notify(allSubscribedURLs);&#125; 根据上面的URL-5，从DubboServiceMetadataRepository中拿到符合要求的exportedUrl列表： URL-6 1dubbo://172.30.66.2:20881/com.pd.ISayHello?anyhost=true&amp;application=provider-test&amp;deprecated=false&amp;dubbo=2.0.2&amp;dynamic=true&amp;generic=false&amp;interface=com.pd.ISayHello&amp;methods=sayHello&amp;pid=818&amp;release=2.7.6&amp;side=provider&amp;timestamp=1610069264009 这个url已经可以定位到一个具体的服务实例了。 然后使用URL-6和之前获取的serviceInstances列表，生成所有的服务实例allSubscribedURLs 然后通知RegistryDirectory 1234567891011121314151617181920212223242526272829@Override//RegistryDirectorypublic synchronized void notify(List&lt;URL&gt; urls) &#123; // 过滤参数传入的实例url列表，并创建categoryUrls Map&lt;String, List&lt;URL&gt;&gt; categoryUrls = urls.stream() .filter(Objects::nonNull) .filter(this::isValidCategory) .filter(this::isNotCompatibleFor26x) .collect(Collectors.groupingBy(this::judgeCategory)); List&lt;URL&gt; configuratorURLs = categoryUrls.getOrDefault(CONFIGURATORS_CATEGORY, Collections.emptyList()); this.configurators = Configurator.toConfigurators(configuratorURLs).orElse(this.configurators); List&lt;URL&gt; routerURLs = categoryUrls.getOrDefault(ROUTERS_CATEGORY, Collections.emptyList()); toRouters(routerURLs).ifPresent(this::addRouters); // providers List&lt;URL&gt; providerURLs = categoryUrls.getOrDefault(PROVIDERS_CATEGORY, Collections.emptyList()); /** * 3.x added for extend URL address */ ExtensionLoader&lt;AddressListener&gt; addressListenerExtensionLoader = ExtensionLoader.getExtensionLoader(AddressListener.class); List&lt;AddressListener&gt; supportedListeners = addressListenerExtensionLoader.getActivateExtension(getUrl(), (String[]) null); if (supportedListeners != null &amp;&amp; !supportedListeners.isEmpty()) &#123; for (AddressListener addressListener : supportedListeners) &#123; providerURLs = addressListener.notify(providerURLs, getConsumerUrl(),this); &#125; &#125; refreshOverrideAndInvoker(providerURLs);&#125; categoryUrls是一个Map，保存category和Urls之间的映射关系： refreshOverrideAndInvoker 该方法将根据提供者的URLs，创建调用器，Invoker，每个provider创建一个Invoker，并存储到 RegistryDirectory的成员invokers这个List中。","categories":[{"name":"RPC框架Dubbo","slug":"RPC框架Dubbo","permalink":"https://zzkenyon.github.io/categories/RPC框架Dubbo/"}],"tags":[{"name":"dubbo","slug":"dubbo","permalink":"https://zzkenyon.github.io/tags/dubbo/"}],"keywords":[{"name":"RPC框架Dubbo","slug":"RPC框架Dubbo","permalink":"https://zzkenyon.github.io/categories/RPC框架Dubbo/"}]},{"title":"dubbo-服务消费者启动过程","slug":"dubbo-服务消费者启动过程","date":"2019-04-29T16:00:00.000Z","updated":"2021-01-08T13:45:29.411Z","comments":true,"path":"2019/04/30/dubbo-服务消费者启动过程/","link":"","permalink":"https://zzkenyon.github.io/2019/04/30/dubbo-服务消费者启动过程/","excerpt":"","text":"1、设计思想要实现服务消费，需要考虑以下问题： 生成远程服务的代理 获得目标服务的url地址 实现远程通信 实现负载均衡 实现集群容错 2、注解解析Dubbo的服务消费者注入也有两种方式: 通过xml形式 基于注解的方式 我来分析一下基于注解的方式的解析过程： @DubboReference 注解的解析逻辑在ReferenceAnnotationBeanPostProcessor类中，在2.7.6版本中这个类在在DubboAutoConfiguration中有显示的配置： 1234@ConditionalOnMissingBean@Bean(name = ReferenceAnnotationBeanPostProcessor.BEAN_NAME) public ReferenceAnnotationBeanPostProcessor referenceAnnotationBeanPostProcessor() &#123; return new ReferenceAnnotationBeanPostProcessor();&#125; 但其实这里出现了重复注入的情况，因为在这段代码执行之前，ReferenceAnnotationBeanPostProcessor已经在容器中了，所以2.7.8版本删除了这段代码。 那么这个类到底在哪里注入的？ 配置类DubboAutoConfiguration上注解了@EnableDubboConfig 12345678@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Inherited@Documented@Import(DubboConfigConfigurationRegistrar.class)public @interface EnableDubboConfig &#123; boolean multiple() default true;&#125; 该注解使用了@Import动态注入，进入DubboConfigConfigurationRegistrar类 123456789public class DubboConfigConfigurationRegistrar implements ImportBeanDefinitionRegistrar &#123; @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; ... // Since 2.7.6 registerCommonBeans(registry); &#125;&#125; registerCommonBeans()方法是定义在DubboBeanUtils中的一个静态方法，注释可以看到这个方法是从2.7.6版本添加的。 12345678910111213141516171819202122static void registerCommonBeans(BeanDefinitionRegistry registry) &#123; // Since 2.5.7 Register @Reference Annotation Bean Processor as an infrastructure Bean registerInfrastructureBean(registry, ReferenceAnnotationBeanPostProcessor.BEAN_NAME, ReferenceAnnotationBeanPostProcessor.class); // Since 2.7.4 [Feature] https://github.com/apache/dubbo/issues/5093 registerInfrastructureBean(registry, DubboConfigAliasPostProcessor.BEAN_NAME, DubboConfigAliasPostProcessor.class); // Since 2.7.5 Register DubboLifecycleComponentApplicationListener as an infrastructure Bean registerInfrastructureBean(registry, DubboLifecycleComponentApplicationListener.BEAN_NAME, DubboLifecycleComponentApplicationListener.class); // Since 2.7.4 Register DubboBootstrapApplicationListener as an infrastructure Bean registerInfrastructureBean(registry, DubboBootstrapApplicationListener.BEAN_NAME, DubboBootstrapApplicationListener.class); // Since 2.7.6 Register DubboConfigDefaultPropertyValueBeanPostProcessor as an infrastructure Bean registerInfrastructureBean(registry, DubboConfigDefaultPropertyValueBeanPostProcessor.BEAN_NAME, DubboConfigDefaultPropertyValueBeanPostProcessor.class);&#125; 可以看到这个方法注入了几个dubbo的基础类，其中就有ReferenceAnnotationBeanPostProcessor。当使用xml方式解析dubbo配置的时候，也会使用到这个静态方法来注入这些基础类。 3 . 消费端启动流程下面我们进入正题 springboot在实例化bean时会进入自动注入流程，之前分析过自动注入流程是在populateBean() 方法中，在此方法中有这段代码: 1234567891011121314151617for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; PropertyValues pvsToUse = ibp.postProcessProperties(pvs, bw.getWrappedInstance(), beanName); if (pvsToUse == null) &#123; if (filteredPds == null) &#123; filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); &#125; // 主要是这一句 pvsToUse = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName); if (pvsToUse == null) &#123; return; &#125; &#125; pvs = pvsToUse; &#125;&#125; 这段代码会执行BeanPostProcessor中的逻辑postProcessPropertyValues()方法， 再看ReferenceAnnotationBeanPostProcessor的类继承关系，它实现了InstantiationAwareBeanPostProcessor接口，该接口定义了postProcessPropertyValues方法 进入postProcessPropertyValues方法： 123456789101112@Override // AbstractAnnotationBeanPostProcessorpublic PropertyValues postProcessPropertyValues(PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeanCreationException &#123; // 从这里进入就是注解解析流程，这里不深究 InjectionMetadata metadata = findInjectionMetadata(beanName, bean.getClass(), pvs); try &#123; // 从这里注入 metadata.inject(bean, beanName, pvs); &#125; ... return pvs;&#125; findInjectionMetadata()方法完成了对几个指定注解的解析，返回一个InjectionMetadata对象，执行该对象的inject（）方法进行注入流程。 4. 获取远程服务实例的代理对象继续跟进inject()，这是私有内部类 AnnotatedFiledElement中的方法 123456789@Override //AbstractAnnotationBeanPostProcessor.AnnotatedFiledElementprotected void inject(Object bean, String beanName, PropertyValues pvs) throws Throwable &#123; Class&lt;?&gt; injectedType = field.getType(); //getInjectedObject方法返回需要注入的代理对象，此处开始进入正题 Object injectedObject = getInjectedObject(attributes, bean, beanName, injectedType, this); ReflectionUtils.makeAccessible(field); // 反射方式注入代理对象 field.set(bean, injectedObject);&#125; 跟进getInjectedObject方法： 1234567891011//AbstractAnnotationBeanPostProcessorprotected Object getInjectedObject(AnnotationAttributes attributes, Object bean, String beanName, Class&lt;?&gt; injectedType, InjectionMetadata.InjectedElement injectedElement) throws Exception &#123; ... if (injectedObject == null) &#123; // &gt;&gt; 干活 injectedObject = doGetInjectedBean(attributes, bean, beanName, injectedType, injectedElement); injectedObjectsCache.putIfAbsent(cacheKey, injectedObject); &#125; return injectedObject;&#125; 最终会执行到doGetInjectedBean()方法，这里使用模板模式，该方法定义在子类ReferenceAnnotationBeanPostProcessor中， 4.1 创建ReferenceBean并注册doGetInjectedBean 该方法主要做两件事： 创建了一个ReferenceBean注册到Spring IOC容器中 调用 referenceBean.get() 获取一个动态代理对象 1234567891011121314151617@Overrideprotected Object doGetInjectedBean(AnnotationAttributes attributes, Object bean, String beanName, Class&lt;?&gt; injectedType, InjectionMetadata.InjectedElement injectedElement) throws Exception &#123; // ServiceBean:com.pd.ISayHello String referencedBeanName = buildReferencedBeanName(attributes, injectedType); // @Reference(check=false,mock=com.pd.moke.ISayHelloMoke,protocol=dubbo) com.pd.ISayHello String referenceBeanName = getReferenceBeanName(attributes, injectedType); // 创建一个ReferenceBean ReferenceBean referenceBean = buildReferenceBeanIfAbsent(referenceBeanName, attributes, injectedType); boolean localServiceBean = isLocalServiceBean(referencedBeanName, referenceBean, attributes); prepareReferenceBean(referencedBeanName, referenceBean, localServiceBean); // 将referenceBean注册到ioc registerReferenceBean(referencedBeanName, referenceBean, attributes, localServiceBean, injectedType); cacheInjectedReferenceBean(referenceBean, injectedElement); // 使用ReferenceBean获取远程服务的调用对象 return referenceBean.get();&#125; 123456789public synchronized T get() &#123; if (destroyed) &#123; throw new IllegalStateException(\"The invoker of ReferenceConfig(\" + url + \") has already destroyed!\"); &#125; if (ref == null) &#123; init(); //&gt;&gt; &#125; return ref; // ref 是dubbo返回的用于远程调用的代理对象&#125; init() 方法有点类发布服务时的doExport方法，主要执行步骤如下： 1、检查配置信息 2、根据dubbo配置构建map集合 3、调用createProxy方法创建动态代理对象 本文重点分析第三步： 1ref = createProxy(map); 4.2 创建远程代理对象先思考一下，创建动态代理对象这个过程中，它可能会有哪些操作步骤?这个方法要能猜出来， 那必然需要对dubbo的使用比较熟悉。 首先我们需要注意一个点，这里是创建一个代理对象，而这个代理对象应该也和协议有关系，也就是不同的协议，使用的代理对象也应该不一样。 123456789//ReferenceConfigprivate T createProxy(Map&lt;String, String&gt; map) &#123; if (shouldJvmRefer(map)) &#123; URL url = new URL(LOCAL_PROTOCOL, LOCALHOST_VALUE, 0, interfaceClass.getName()).addParameters(map); invoker = REF_PROTOCOL.refer(interfaceClass, url); if (logger.isInfoEnabled()) &#123; logger.info(\"Using injvm service \" + interfaceClass.getName()); &#125; &#125; else &#123;...&#125; 上面代码是方法的第一部分，根据map进行判断，需要注入的服务是不是injvm的服务，主要判断依据是scope属性（scope==injvm时返回true），其次是generic属性（是泛化服务则返回false），最后的依据是getExporter(exporterMap, url) != null时，返回true，因为只有当前应用发布了该服务，getExporter才不会为空。 我们继续分析createProxy第二段代码 123456789101112131415161718192021222324252627282930//ReferenceConfigelse &#123; urls.clear(); // 点对点调用时的处理逻辑 if (url != null &amp;&amp; url.length() &gt; 0) &#123; ... &#125; else &#123; // 再次确认协议不是injvm if (!LOCAL_PROTOCOL.equalsIgnoreCase(getProtocol())) &#123; //检查注册中心配置 checkRegistry(); //返回注册中心url列表 List&lt;URL&gt; us = ConfigValidationUtils.loadRegistries(this, false); if (CollectionUtils.isNotEmpty(us)) &#123; for (URL u : us) &#123; URL monitorUrl = ConfigValidationUtils.loadMonitor(this, u); if (monitorUrl != null) &#123; map.put(MONITOR_KEY, URL.encode(monitorUrl.toFullString())); &#125; // 将url添加一个refer属性，添加到成员urls中 urls.add(u.addParameterAndEncoded(REFER_KEY, StringUtils.toQueryString(map))); &#125; &#125; if (urls.isEmpty()) &#123; ... // 抛异常 &#125; &#125; &#125; ...&#125; 代码解析： 成员变量url是没有使用注册中心，点对点调用时的硬编码url，不是本文重点不做分析 ConfigValidationUtils.loadRegistries（）返回注册中心url列表，url形状如下： 12registry://10.0.12.74:2181/org.apache.dubbo.registry.RegistryService?application=spring-boot-dubbo-consumer&amp;dubbo=2.0.2&amp;pid=1841&amp;qos.enable=false&amp;register=false&amp;registry=zookeeper&amp;release=2.7.8&amp;timestamp=1600308477956 是registry协议 每个注册中心url需要添加一个refer属性再放到urls中取，refer属性是之前的map生成的一个字符串，这样做只是为了随着url方便传参数 refer属性的形状如下： 1234refer=application=spring-boot-dubbo-consumer&amp;check=false&amp;dubbo=2.0.2&amp;init=false&amp;interface=com.pd.ISayHello&amp;metadata-type=remote&amp;methods=sayHello&amp;mock=com.pd.moke.ISayHelloMoke&amp;pid=1841&amp;protocol=dubbo&amp;qos.enable=false&amp;register.ip=172.30.66.2&amp;release=D2.7.8&amp;side=Dconsumer&amp;sticky=false &amp;timestamp=D1600308463376&amp;register=false&amp;registry=zookeeper&amp;release=2.7.8&amp;timestamp=1600308477956 createProxy()第三段： 1234567891011121314151617181920212223242526...// 接上段代码...if (urls.size() == 1) &#123; invoker = REF_PROTOCOL.refer(interfaceClass, urls.get(0)); &#125; else &#123; List&lt;Invoker&lt;?&gt;&gt; invokers = new ArrayList&lt;Invoker&lt;?&gt;&gt;(); URL registryURL = null; for (URL url : urls) &#123; // 多注册中心配置，针对每个配置中心会返回一个调用器 // url是register协议，进入RegisterProtocol.refer() invokers.add(REF_PROTOCOL.refer(interfaceClass, url)); if (UrlUtils.isRegistry(url)) &#123; registryURL = url; // use last registry url &#125; &#125; if (registryURL != null) &#123; // registry url is available // for multi-subscription scenario, use 'zone-aware' policy by default String cluster = registryURL.getParameter(CLUSTER_KEY, ZoneAwareCluster.NAME); invoker = Cluster.getCluster(cluster, false).join(new StaticDirectory(registryURL, invokers)); &#125; else &#123; // not a registry url, must be direct invoke. String cluster = CollectionUtils.isNotEmpty(invokers) ? (invokers.get(0).getUrl() != null ? invokers.get(0).getUrl().getParameter(CLUSTER_KEY, ZoneAwareCluster.NAME) : Cluster.DEFAULT) : Cluster.DEFAULT; invoker = Cluster.getCluster(cluster).join(new StaticDirectory(invokers)); &#125; &#125; 代码解析： 这段代码就是比较重要的，生成调用器（代理对象） ，可以看到此处对单注册中心 和 多注册中心 的情况做了区分： 单注册中心配置下直接调用refer方法，返回一个invoker 多注册中心配置下，针对每个注册中心，产生一个invoker，然后通过CLUSTER.join把invokers以静态的Directory形式构建一个invoker对象。 目的是实现注册中心的路由 理解此处逻辑的关键在于要清楚 Directory的概念 和 Cluster.join()的逻辑，后面我会对此分析。 此时我还是先将注意力集中在主流程上，看看invoker是怎么被创建的 1REF_PROTOCOL.refer(interfaceClass, urls.get(0)) REF_PROTOCOL是Protocol接口的自适应扩展类，这里协议类型registry，因此会执行RegistryProtocol的refer方法 4.3 创建代理对象的调用器InvokerRegistryProtocol.refer() 贴代码先 1234567891011121314151617181920212223public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; // 返回具体的注册中心协议url url = getRegistryUrl(url); // 自适应扩展点创建的是一个被ListenerRegisterWrapper包装的ZookeeperRegister Registry registry = registryFactory.getRegistry(url); if (RegistryService.class.equals(type)) &#123; return proxyFactory.getInvoker((T) registry, type, url); &#125; // group=\"a,b\" or group=\"*\" // 将refer属性解析成map Map&lt;String, String&gt; qs = StringUtils.parseQueryString(url.getParameterAndDecoded(REFER_KEY)); // 指定了group的情况 String group = qs.get(GROUP_KEY); if (group != null &amp;&amp; group.length() &gt; 0) &#123; if ((COMMA_SPLIT_PATTERN.split(group)).length &gt; 1 || \"*\".equals(group)) &#123; return doRefer(Cluster.getCluster(MergeableCluster.NAME), registry, type, url); &#125; &#125; // 没指定group，创建Cluster对象，未指定的话默认是\"failover\"(重试) Cluster cluster = Cluster.getCluster(qs.get(CLUSTER_KEY)); // type 是服务接口类型 return doRefer(cluster, registry, type, url);&#125; 主要工作有： 1、获取指定注册中心协议的url 2、根据注册中心协议创建Registry对象 3、将url参数refer解析成map 4、获取cluster对象 5、指定group和未指定，分两种情况执行dorefer操作 doRefer() 首先创建了RegistryDirectory对象，该对象作用很重要，它负责动态维护服务提供者列表。 1234567891011121314151617181920212223242526272829303132// RegistryProtocolprivate &lt;T&gt; Invoker&lt;T&gt; doRefer(Cluster cluster, Registry registry, Class&lt;T&gt; type, URL url) &#123; //初始化RegistryDirectory ，对每个注册中心会创建一个Directory RegistryDirectory&lt;T&gt; directory = new RegistryDirectory&lt;T&gt;(type, url); directory.setRegistry(registry); directory.setProtocol(protocol); // all attributes of REFER_KEY Map&lt;String, String&gt; parameters = new HashMap&lt;String, String&gt;(directory.getConsumerUrl().getParameters()); //创建consumer://协议的url URL subscribeUrl = new URL(CONSUMER_PROTOCOL, parameters.remove(REGISTER_IP_KEY), 0, type.getName(), parameters); if (directory.isShouldRegister()) &#123; //注册服务消费者的url地址 directory.setRegisteredConsumerUrl(subscribeUrl); registry.register(directory.getRegisteredConsumerUrl()); &#125; directory.buildRouterChain(subscribeUrl); // 订阅注册中心的 directory.subscribe(toSubscribeUrl(subscribeUrl)); //一个注册中心会存在多个服务提供者，所以在这里需要把多个服务提供者通过cluster.join合并成一个集群调用器 ClusterInvoker， Invoker&lt;T&gt; invoker = cluster.join(directory); // 获取监听器 List&lt;RegistryProtocolListener&gt; listeners = findRegistryProtocolListeners(url); if (CollectionUtils.isEmpty(listeners)) &#123; return invoker; // 从这里返回 &#125; RegistryInvokerWrapper&lt;T&gt; registryInvokerWrapper = new RegistryInvokerWrapper&lt;&gt;(directory, cluster, invoker); for (RegistryProtocolListener listener : listeners) &#123; listener.onRefer(this, registryInvokerWrapper); &#125; return registryInvokerWrapper;&#125; directory.subscribe方法，分析见文章《dubbo-消费者服务订阅分析》，次方法执行之后，directory的成员invokers已经装入了具体服务实例的调用器。 我们继续往下看： 4.4 合并调用器cluser.join() Cluter自适应扩展时会被包装： 12mock=org.apache.dubbo.rpc.cluster.support.wrapper.MockClusterWrapperfailover=org.apache.dubbo.rpc.cluster.support.FailoverCluster 所以默认得到的Cluster是： MockClusterWrapper（FailoverCluster） cluster.join 会先进入MockClusterWrapper： 12345@Override //MockClusterWrapperpublic &lt;T&gt; Invoker&lt;T&gt; join(Directory&lt;T&gt; directory) throws RpcException &#123; return new MockClusterInvoker&lt;T&gt;(directory, this.cluster.join(directory));&#125; 然后在执行FailoverCluster.join，然而这个类没有实现join方法而是继承了抽象父类AbstractCluster的join方法： 1234@Override //AbstractClusterpublic &lt;T&gt; Invoker&lt;T&gt; join(Directory&lt;T&gt; directory) throws RpcException &#123; return buildClusterInterceptors(doJoin(directory), directory.getUrl().getParameter(REFERENCE_INTERCEPTOR_KEY));&#125; doJoin()是模板方法，声明在抽象类，其实现在子类中： 1234@Override//FailoverClusterpublic &lt;T&gt; AbstractClusterInvoker&lt;T&gt; doJoin(Directory&lt;T&gt; directory) throws RpcException &#123; return new FailoverClusterInvoker&lt;&gt;(directory);&#125; 这里创建一个FailoverClusterInvoker返回 紧接着通过方法buildClusterInterceptors给这个Invoker添加拦截器： 123456789101112131415private &lt;T&gt; Invoker&lt;T&gt; buildClusterInterceptors(AbstractClusterInvoker&lt;T&gt; clusterInvoker, String key) &#123; // clusterInvoker = FailoverClusterInvoker // key = null AbstractClusterInvoker&lt;T&gt; last = clusterInvoker; List&lt;ClusterInterceptor&gt; interceptors = ExtensionLoader.getExtensionLoader(ClusterInterceptor.class).getActivateExtension(clusterInvoker.getUrl(), key); // 默认只有一个拦截器ConsumerContextClusterInterceptor if (!interceptors.isEmpty()) &#123; for (int i = interceptors.size() - 1; i &gt;= 0; i--) &#123; final ClusterInterceptor interceptor = interceptors.get(i); final AbstractClusterInvoker&lt;T&gt; next = last; last = new InterceptorInvokerNode&lt;&gt;(clusterInvoker, interceptor, next); &#125; &#125; return last;&#125; ClusterInterceptor使用激活扩展方式，没有指定的情况下默认激活了ConsumerContextClusterInterceptor 12context=org.apache.dubbo.rpc.cluster.interceptor.ConsumerContextClusterInterceptorzone-aware=org.apache.dubbo.rpc.cluster.interceptor.ZoneAwareClusterInterceptor 使用拦截器包装之后，得到一个拦截器链，单链表 InterceptorInvokerNode-&gt;FailoverClusterInvoker，InterceptorInvokerNode中包含了拦截器以及FailoverClusterInvoker，和指向下一个拦截器链节点的指针 1234567public InterceptorInvokerNode(AbstractClusterInvoker&lt;T&gt; clusterInvoker, ClusterInterceptor interceptor, AbstractClusterInvoker&lt;T&gt; next) &#123; this.clusterInvoker = clusterInvoker; this.interceptor = interceptor; // 当前节点的拦截器 this.next = next; // 指向下一个节点指针&#125; 因为默认只有一个激活的拦截器，所以得到的链表如下： buildClusterInterceptors方法返回的是链表头指针InterceptorInvokerNode引用，InterceptorInvokerNode继承自AbstractClusterInvoker 最后不要忘了最开始是从Cluster的包装类MockClusterWrapper中开始调用的join方法，最后还要加上一层包装 12345@Override //MockClusterWrapperpublic &lt;T&gt; Invoker&lt;T&gt; join(Directory&lt;T&gt; directory) throws RpcException &#123; return new MockClusterInvoker&lt;T&gt;(directory, this.cluster.join(directory));&#125; 最终得到的Invoker是这样的： MockClusterInvoker(InterceptorInvokerNode(FailoverClusterInvoker)) 到此是针对于一个注册中心得到的Invoker对象 多注册中心的情况 配置多个注册中心的时候，还需要调用一次cluster.join方法，将多个注册中心产生的Invoker合并成一个，以实现注册中心的负载均衡，回顾一下代码： 123// ReferenceConfigString cluster = registryURL.getParameter(CLUSTER_KEY, ZoneAwareCluster.NAME);invoker = Cluster.getCluster(cluster, false).join(new StaticDirectory(registryURL, invokers));//invokers就是多注册中心得到的Invoker集合 可以看到，会先创建一个StaticDirectory静态的目录，为什么是静态的？因为注册中心的配置是写死的，不会变，针对注册中心创建动态的目录是因为注册中心的服务提供者目录可能随时会发生变化，目录相应的也要跟着变 上面的代码 cluster = zone-aware 最终得到的Cluster是 ZoneAwareCluster类型，且不需要进行包装： join直接进入抽象类： 1234@Overridepublic &lt;T&gt; Invoker&lt;T&gt; join(Directory&lt;T&gt; directory) throws RpcException &#123; return buildClusterInterceptors(doJoin(directory), directory.getUrl().getParameter(REFERENCE_INTERCEPTOR_KEY));&#125; doJoin进入ZoneAwareCluster， 1234@Overrideprotected &lt;T&gt; AbstractClusterInvoker&lt;T&gt; doJoin(Directory&lt;T&gt; directory) throws RpcException &#123; return new ZoneAwareClusterInvoker&lt;T&gt;(directory);&#125; 再执行buildClusterInterceptors进行拦截器封装，最终得到的Invoker是这样的： InterceptorInvokerNode(FailoverClusterInvoker) 结合注册中心生成的Invoker，最终产生的Invoker是这样的 回到createProxy() 拿到最终的Invoker之后，要根据这个对象创建动态代理类，以便于消费端调用，看到createProxy方法的最后一句： 1return (T) PROXY_FACTORY.getProxy(invoker, ProtocolUtils.isGeneric(generic)); 使用JavassistProxyFactory创建一个代理对象 1234567891011121314@Override // AbstractProxyFactorypublic &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker, boolean generic) throws RpcException &#123; Set&lt;Class&lt;?&gt;&gt; interfaces = new HashSet&lt;&gt;(); String config = invoker.getUrl().getParameter(INTERFACES); if (config != null &amp;&amp; config.length() &gt; 0) &#123; ... &#125; if (generic) &#123; ... &#125; interfaces.add(invoker.getInterface()); interfaces.addAll(Arrays.asList(INTERNAL_INTERFACES)); return getProxy(invoker, interfaces.toArray(new Class&lt;?&gt;[0]));//&gt;&gt; 进入&#125; interfaces 最后包含三个接口： interface org.apache.dubbo.rpc.service.Destroyable interface com.alibaba.dubbo.rpc.service.EchoService interface com.pd.ISayHello 12345@Override@SuppressWarnings(\"unchecked\")public &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker, Class&lt;?&gt;[] interfaces) &#123; return (T) Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker));&#125; 新建实例的时候，传入了一个InvokerInvocationHandler对象，动态代理见多了肯定知道，当消费者调用远程服务时，会进入该对象的invoke方法，这里在消费流程中再分析。 到这里貌似消费端注入远程服务的流程就结束了，但是中间缺少了一个最重要的环节分析，那就是： 服务目录的订阅和监听 netty client 创建以及连接的建立 这两项内容都是在RegistryDirectory中实现的 5. RegistryDirectory在哪里创建？ 在RegistryProtocol.doRefer的时候创建，每个注册中心会创建一个RegistryDirectory对象，RegistryDirectory中保存了所有服务提供者的调用Invoker，这些invoker在RegistryDirectory.suscribe方法被调用的时候进行创建。 如何实现目录实时有效？ 并且这个对象中保存的服务提供者目录是动态可变的，可变的原因是该目录实现了NotifyListener接口，该接口就一个重要的接口方法notify。 每当注册中心的服务提供者列表发生变化的时候，例如使用的是zookeeper作为注册中心，dubbo会针对几个目录创建一些监听（subscribe时创建监听），当目录中的内容发生变化的时候会向监听的创建者（服务消费者）发送通知。 服务消费者收到通知会调用RegistryDirectory中实现的notify方法，修改消费者内存RegistryDirectory对象中保存的的服务提供者目录，以保证服务提供者目录实时有效","categories":[{"name":"RPC框架Dubbo","slug":"RPC框架Dubbo","permalink":"https://zzkenyon.github.io/categories/RPC框架Dubbo/"}],"tags":[{"name":"dubbo","slug":"dubbo","permalink":"https://zzkenyon.github.io/tags/dubbo/"}],"keywords":[{"name":"RPC框架Dubbo","slug":"RPC框架Dubbo","permalink":"https://zzkenyon.github.io/categories/RPC框架Dubbo/"}]},{"title":"dubbo-配置中心","slug":"dubbo-配置中心","date":"2019-04-22T16:00:00.000Z","updated":"2020-06-12T00:35:25.080Z","comments":true,"path":"2019/04/23/dubbo-配置中心/","link":"","permalink":"https://zzkenyon.github.io/2019/04/23/dubbo-配置中心/","excerpt":"","text":"dubbo在2.7版本之前只配备了注册中心，2.7中新增的功能-配置中心和元数据中心，因此dubbo现在拥有三大中心，指的是注册中心、元数据中心和配置中心。 注册中心：分布式环境下提供服务的注册和发现功能，服务治理的关键组件 元数据中心：元数据指的是描述数据的数据。在服务治理中的数据可以理解成provider供者提供的服务、consumer需要消费的服务，而这些服务通常都会有一些描述信息例如接口名、版本号、重试次数、容错机制等等，这些对服务的描述信息就是服务的元数据。 2.7以前，元数据一股脑的丢在注册中心，造成了一系列的问题： 推送量大大-&gt;存储数据量大-&gt;网络传输量大-&gt;延迟 生产者端注册 30+ 参数，有接近一半是不需要作为注册中心进行传递；消费者端注册 25+ 参数，只有个别需要传递给注册中心。 有了以上的理论分析，Dubbo 2.7 进行了大刀阔斧的改动，只将真正属于服务治理的数据发布到注册中心之中，大大降低了注册中心的负荷。同时，将全量的元数据发布到另外的组件中：元数据中心。元数据中心目前支持 redis（推荐），zookeeper。 Dubbo 2.6 元数据 1234567891011121314dubbo://30.5.120.185:20880/com.alibaba.dubbo.demo.DemoService?anyhost=true&amp;application=demo-provider&amp;interface=com.alibaba.dubbo.demo.DemoService&amp;methods=sayHello&amp;bean.name=com.alibaba.dubbo.demo.DemoService&amp;dubbo=2.0.2&amp;executes=4500&amp;generic=false&amp;owner=kirito&amp;pid=84228&amp;retries=7&amp;side=provider&amp;timestamp=1552965771067 从本地的 zookeeper 中取出一条服务数据，通过解码之后，可以看出，的确有很多参数是不必要。 Dubbo 2.7 元数据在 2.7 中，如果不进行额外的配置，zookeeper 中的数据格式仍然会和 Dubbo 2.6 保持一致，这主要是为了保证兼容性，让 Dubbo 2.6 的客户端可以调用 Dubbo 2.7 的服务端。如果整体迁移到 2.7，则可以为注册中心开启简化配置的参数： 1&lt;dubbo:registry address=“zookeeper://127.0.0.1:2181” simplified=“true”/&gt; Dubbo 将会只上传那些必要的服务治理数据，一个简化过后的数据如下所示： Dubbo 将会只上传那些必要的服务治理数据，一个简化过后的数据如下所示： 12345dubbo://30.5.120.185:20880/org.apache.dubbo.demo.api.DemoService?application=demo-provider&amp;dubbo=2.0.2&amp;release=2.7.0&amp;timestamp=1552975501873 对于那些非必要的服务信息，仍然全量存储在元数据中心之中 动态配置中心： 老版本中，我们要注册一个服务，需要在服务中配置注册中心地址、协议、版本号等信息，在服务集群中，每个服务都要进行一些相同内容的配置，相同配置代码在不同服务中重复率很高，为了解决这种重复配置，2.7版本的dubbo推出了外部配置功能，就是配置中心了。 我们将一些重复的配置内容配置在配置中心里面，服务只需要配置注册中心的地址就能获取这些配置。配置中心的配置有两种作用域：global级别和应用级别。 使用配置中心进行配置需要通过dubbo-admin来操作，配置完成会在zookeeper中生成一个文件：dubbo/config/dubbo/dubbo.properties 服务启动的时候，配置中心的全局配置项优先级最高，其次是应用级配置，再然后才是本地配置。 配置中心-源码解析： https://blog.csdn.net/u012881904/article/details/95891448","categories":[{"name":"RPC框架Dubbo","slug":"RPC框架Dubbo","permalink":"https://zzkenyon.github.io/categories/RPC框架Dubbo/"}],"tags":[{"name":"dubbo","slug":"dubbo","permalink":"https://zzkenyon.github.io/tags/dubbo/"}],"keywords":[{"name":"RPC框架Dubbo","slug":"RPC框架Dubbo","permalink":"https://zzkenyon.github.io/categories/RPC框架Dubbo/"}]},{"title":"dubbo-JDK的SPI原理及源码分析","slug":"dubbo-JDK的SPI原理及源码分析","date":"2019-04-20T16:00:00.000Z","updated":"2020-10-09T07:57:49.433Z","comments":true,"path":"2019/04/21/dubbo-JDK的SPI原理及源码分析/","link":"","permalink":"https://zzkenyon.github.io/2019/04/21/dubbo-JDK的SPI原理及源码分析/","excerpt":"","text":"SPI ，全称为 Service Provider Interface，是一种服务发现机制。它通过在ClassPath路径下的META-INF/services文件夹查找文件，自动加载文件里所定义的类。java语言的特性，一处编译处处运行，很大程度上是因为使用了使用spi机制。 JDK在rt.jar包中定义了很多的接口，这些接口由于各种原因没有给出实现类， 操作系统不同，实现方式不同，例如nio底层的selector实现类，不同os有自己的实现 服务商不同，实现方式不同，例如jdbc，不同的数据库服务商对jdbc都有自己的实现 统一调用接口，例如slf4j SPI是门面模式的一种应用场景，在平时的开发过程中，如果发现一个模块需要集成多个平台同一个功能，不妨考虑使用这种机制，比如支付功能、对象存储功能等等。此外dubbo为了集成多协议多平台，对spi的使用非常多 SPI如何使用 定义接口类 123public interface SPIService &#123; void execute();&#125; 然后，定义两个实现类 12345678910public class SpiImpl1 implements SPIService&#123; public void execute() &#123; System.out.println(\"SpiImpl1\"); &#125;&#125;public class SpiImpl2 implements SPIService&#123; public void execute() &#123; System.out.println(\"SpiImpl2\"); &#125;&#125; 最后呢，要在ClassPath路径下配置添加一个文件。文件名字是接口的全限定类名，内容是实现类的全限定类名，多个实现类用换行符分隔。文件路径为： resources/META_INF/services/com.pd.spi.SPIInterface 文件内容为： 12com.pd.spi.SpiImpl1com.pd.spi.SpiImpl2 在测试代码中，我们使用ServiceLoader.load或者Service.providers方法拿到实现类的实例 12345678public class Test &#123; public static void main(String[] args) &#123; ServiceLoader&lt;SPIInterface&gt; spiImpls = ServiceLoader.load(SPIInterface.class); for(SPIInterface impl : spiImpls)&#123; impl.execute(); &#125; &#125;&#125; 输出： 12SpiImpl1SpiImpl2 SPI源码分析 两种服务获取方式： Service.providers包位于sun.misc.Service， ServiceLoader.load包位于java.util.ServiceLoader 首先看一下ServiceLoader类的成员： 1234567891011121314public final class ServiceLoader&lt;S&gt; implements Iterable&lt;S&gt;&#123; //配置文件的路径前缀 private static final String PREFIX = \"META-INF/services/\"; // 需要加载的服务类接口类型对象 private final Class&lt;S&gt; service; // 类加载器 private final ClassLoader loader; // The access control context taken when the ServiceLoader is created private final AccessControlContext acc; // 已加载的服务类实现集合 private LinkedHashMap&lt;String,S&gt; providers = new LinkedHashMap&lt;&gt;(); // 真正加载逻辑所在的对象，内部类 private LazyIterator lookupIterator;&#125; 静态方法load() 1234public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) &#123; ClassLoader cl = Thread.currentThread().getContextClassLoader(); return ServiceLoader.load(service, cl);&#125; 可以看到，这里获取了线程上下文类加载器来加载实现类，双亲委派模式的破坏者。 调用了重载的load()方法 123public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service, ClassLoader loader)&#123; return new ServiceLoader&lt;&gt;(service, loader);&#125; 调用了私有的构造函数，由于实现类对象最终还是保存到了ServiceLoader的成员变量providers中，所以这里猜测，在构造方法中完成了实现类的获取和实例化： 123456private ServiceLoader(Class&lt;S&gt; svc, ClassLoader cl) &#123; service = Objects.requireNonNull(svc, \"Service interface cannot be null\"); loader = (cl == null) ? ClassLoader.getSystemClassLoader() : cl; acc = (System.getSecurityManager() != null) ? AccessController.getContext() : null; reload();&#125; 跟进reload()方法： 1234public void reload() &#123; providers.clear(); lookupIterator = new LazyIterator(service, loader);&#125; 实例化了内部类LazyIterator 1234private LazyIterator(Class&lt;S&gt; service, ClassLoader loader) &#123; this.service = service; this.loader = loader;&#125; 到此初始化流程就结束了，构造方法中并没有加载的过程啊，猜测错误。 原来这个类名称是LazyIterator，原来这里使用了懒加载，当ServiceLoader初始化的时候并不会主动去加载实现类，而是在用户代码中使用到实现类的时候再进行加载。 当用户代码执行到此： 123for(SPIInterface impl : spiImpls)&#123; impl.execute();&#125; 将会执行LazyIterator类的hasNext() 123456789101112public boolean hasNext() &#123; if (acc == null) &#123; return hasNextService(); &#125; else &#123; PrivilegedAction&lt;Boolean&gt; action = new PrivilegedAction&lt;Boolean&gt;() &#123; public Boolean run() &#123; return hasNextService(); &#125; &#125;; return AccessController.doPrivileged(action, acc); &#125;&#125; 总之会调用到hasNextService()方法 12345678910111213141516171819202122232425262728private boolean hasNextService() &#123; if (nextName != null) &#123; return true; &#125; if (configs == null) &#123; try &#123; // 拿到配置文件名 String fullName = PREFIX + service.getName(); if (loader == null) configs = ClassLoader.getSystemResources(fullName); else //使用类加载器加载文件流 configs = loader.getResources(fullName); &#125; catch (IOException x) &#123; fail(service, \"Error locating configuration files\", x); &#125; &#125; while ((pending == null) || !pending.hasNext()) &#123; if (!configs.hasMoreElements()) &#123; return false; &#125; // 解析配置文件，返回一个ArrayList的迭代器对象 pending = parse(service, configs.nextElement()); &#125; //nextName指向迭代器指向的那个对象，是实现类的全类名 nextName = pending.next(); return true;&#125; 拿到实现类的全类名，现在开始实例化： 123456789101112public S next() &#123; if (acc == null) &#123; return nextService(); &#125; else &#123; PrivilegedAction&lt;S&gt; action = new PrivilegedAction&lt;S&gt;() &#123; public S run() &#123; return nextService(); &#125; &#125;; return AccessController.doPrivileged(action, acc); &#125;&#125; 调用到nextService()方法： 1234567891011121314151617181920212223private S nextService() &#123; if (!hasNextService()) throw new NoSuchElementException(); String cn = nextName; nextName = null; Class&lt;?&gt; c = null; try &#123; c = Class.forName(cn, false, loader); &#125; catch (ClassNotFoundException x) &#123; fail(service,\"Provider \" + cn + \" not found\"); &#125; if (!service.isAssignableFrom(c)) &#123; fail(service, \"Provider \" + cn + \" not a subtype\"); &#125; try &#123; Sp = service.cast(c.newInstance()); providers.put(cn, p); return p; &#125; catch (Throwable x) &#123; fail(service, \"Provider \" + cn + \" could not be instantiated\",x); &#125; throw new Error(); // This cannot happen&#125; 使用反射的方式实例化实现类 总结： 1、 Jdk的spi 会一次性加载并实例化扩展点的所有实现，就是如果在MATA-INF/services下的文件里面加了N个实现类，那么JDK启动的时候都会一次性全部实例化，那么如果有的扩展点初始化很耗时，且运行时并没有用到，那么就会很浪费资源（堆） 2、 扩展点加载失败，会导致调用方报错，而且这个错误很难定位到时这个原因。 因此Dubbo在使用SPI时，对其做了很多的优化。","categories":[{"name":"RPC框架Dubbo","slug":"RPC框架Dubbo","permalink":"https://zzkenyon.github.io/categories/RPC框架Dubbo/"}],"tags":[{"name":"dubbo","slug":"dubbo","permalink":"https://zzkenyon.github.io/tags/dubbo/"}],"keywords":[{"name":"RPC框架Dubbo","slug":"RPC框架Dubbo","permalink":"https://zzkenyon.github.io/categories/RPC框架Dubbo/"}]},{"title":"dubbo-基于SPI的自适应扩展机制","slug":"dubbo-基于SPI的自适应扩展机制","date":"2019-04-20T16:00:00.000Z","updated":"2021-01-09T15:02:13.215Z","comments":true,"path":"2019/04/21/dubbo-基于SPI的自适应扩展机制/","link":"","permalink":"https://zzkenyon.github.io/2019/04/21/dubbo-基于SPI的自适应扩展机制/","excerpt":"","text":"复习总结： 1、 自适应扩展机制是为了能够在支持多协议的dubbo框架中根据配置灵活的加载对象，主要使用到了@SPI和@Adaptive两个注解 2、@SPI注解在扩展点接口之上，可以指定默认的实现，例如@SPI（&quot;dubbo&quot;） 3、@Adaptive用于指定扩展点接口的自适应代理类，这个代理类可以是静态的（注解在类上），也可以是代码中生成的（注解在扩展点接口方法上），注意这里代理类的生成是生成一个string类型的code源码，再通过javasisit编译成class。 4、自适应代理类中并没有真的实现接口方法，而是创建出合适的扩展点实现，将调用委托给具体的扩展点实例。 源码分析入口： 获取扩展类实例的调用语句如下 ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(&quot;myProtocol&quot;) 12345678910111213141516171819202122// ExtensionLoader.classprivate static final ConcurrentMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt; EXTENSION_LOADERS = new ConcurrentHashMap&lt;&gt;(64);public static &lt;T&gt; ExtensionLoader&lt;T&gt; getExtensionLoader(Class&lt;T&gt; type) &#123; if (type == null) &#123; //传入的接口类型为null 抛异常 throw new IllegalArgumentException(\"Extension type == null\"); &#125; if (!type.isInterface()) &#123;// 传入的类型不是接口，抛异常 throw new IllegalArgumentException(\"Extension type (\" + type + \") is not an interface!\"); &#125; if (!withExtensionAnnotation(type)) &#123;// 传入的接口没有注解@SPI，抛异常 throw new IllegalArgumentException(\"Extension type (\" + type + \") is not an extension, because it is NOT annotated with @\" + SPI.class.getSimpleName() + \"!\"); &#125; ExtensionLoader&lt;T&gt; loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); if (loader == null) &#123; EXTENSION_LOADERS.putIfAbsent(type, new ExtensionLoader&lt;T&gt;(type)); loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); &#125; return loader;&#125; 可以看到dubbo将所有的接口的ExtensionLoader都缓存到了一个hashmap中，获取Loader时先尝试从map中获取，没有获取到在创建一个存入map中并返回。 关系：每个被@SPI注解的接口都会对应一个ExtensionLoader 取到loader后，使用loader.getExtension获取指定名称的扩展： 123456789101112131415161718public T getExtension(String name) &#123; ... if (\"true\".equals(name)) &#123; return getDefaultExtension(); &#125; final Holder&lt;Object&gt; holder = getOrCreateHolder(name); Object instance = holder.get(); if (instance == null) &#123; synchronized (holder) &#123; instance = holder.get(); if (instance == null) &#123; instance = createExtension(name); // &gt;&gt; holder.set(instance); &#125; &#125; &#125; return (T) instance;&#125; 关系：每一条扩展（key-&gt;value）对应一个Holder，由于不同名称的扩展返回不同的类型的对象，所以此处用Holder封装返回的扩展对象，将具体的扩展类型泛型化，这样就可以统一返回类型。 获取扩展的逻辑： 1、 先获取缓存中的Holder，没有就创建一个空的holder放入缓存。 2、 从holder中获取扩展类型实例，没有获取到（刚创建没有实例），则创建实例，放入holder中并返回实例。 跟进创建扩展实例的方法： createExtension(name) 12345678910111213141516171819202122232425private T createExtension(String name) &#123; Class&lt;?&gt; clazz = getExtensionClasses().get(name);// 根据协议名称获取类对象 if (clazz == null) &#123; throw findException(name); &#125; try &#123; // 缓存实例 T instance = (T) EXTENSION_INSTANCES.get(clazz); if (instance == null) &#123; EXTENSION_INSTANCES.putIfAbsent(clazz, clazz.newInstance()); instance = (T) EXTENSION_INSTANCES.get(clazz); &#125; injectExtension(instance); // 依赖注入，若实例化的扩展类中有属性也是扩展点，则实例化该扩展点使用反射方式注入当前实例 Set&lt;Class&lt;?&gt;&gt; wrapperClasses = cachedWrapperClasses; if (CollectionUtils.isNotEmpty(wrapperClasses)) &#123; for (Class&lt;?&gt; wrapperClass : wrapperClasses) &#123; instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); &#125; &#125; initExtension(instance); // return instance; &#125; catch (Throwable t) &#123; throw new IllegalStateException(\"Extension instance (name: \" + name + \", class: \" + type + \") couldn't be instantiated: \" + t.getMessage(), t); &#125;&#125; 方法getExtensionClasses()获取当前ExtensionLoader的所有扩展（key-&gt;value），ExtensionLoader是和接口绑定的，比如说此时正在加载Protocol.class接口的扩展，那么该方法将获取所有的Protocol接口的扩展。见下图： 返回的是Map&lt;String,Class&lt;?&gt;&gt;类型结果，既然是Class那么这些扩展类都已加载到了虚拟机中，之前提到的JDK标准的SPI其中一点不足就是全部加载，那么dubbo这里也是全部加载啊，优化在哪里？ 这里说的加载实现类，其实指的的实例化扩展类。JDK的SPI在读取配置文件之后，将扩展类加载到虚拟机，并立即执行实例化操作。而dubbo只是将类加载进虚拟机，并且设计了一套自适应机制，在运行时实例化扩展类，也就是只有配置的扩展类才会被实例化。 在回到源码中：获取到这个map之后，根据name值myProtocal，获取到本次需要扩展点类型，是MyProtocol.class 接下来，尝试从缓存中获取扩展类型的实例，获取不到则使用clazz.newInstance()创建一个实例，放入到缓存。 到此为止，已经处出现了两处使用缓存的场景 缓存所有扩展点接口对应的ExtensionLoader 使用 ConcurrentMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt;存储，Key是扩展点接口类型 缓存所有实例化后的扩展类对象 使用ConcurrentMap&lt;Class&lt;?&gt;, Object&gt;存储，Key是具体的扩展类型 接下来是injectExtension（）这个方法，用来实现依赖注入，如果被加载的扩展类实例中，有成员属性本身也是一个扩展点，则会通过反射的方式进行注入。 注意：依赖注入是dubbo-spi的另一个优化点，突出的就是懒加载策略，包括后文将要分析的自适应扩展 最后是initExtension(instance)方法，如果扩展类型本身是一个Lifecycle类型，那么执行lifecycle.initialize()方法 至此，扩展类的实例就获取到了。 1. Dubbo的默认扩展在getExtension（name）方法中有一段代码 123if (\"true\".equals(name)) &#123; return getDefaultExtension();&#125; 当name=true时，将获取默认的扩展，默认扩展是哪个呢？ 跟进去看 1234567public T getDefaultExtension() &#123; getExtensionClasses(); if (StringUtils.isBlank(cachedDefaultName) || \"true\".equals(cachedDefaultName)) &#123; return null; &#125; return getExtension(cachedDefaultName);&#125; 根据 cachedDefaultName 默认的扩展名称获取扩展实例，那么默认的扩展名称在哪里初始化的呢？ 在代码中搜索cachedDefaultName ，找到了 cacheDefaultExtensionName()方法 123456789101112131415161718private void cacheDefaultExtensionName() &#123; final SPI defaultAnnotation = type.getAnnotation(SPI.class); if (defaultAnnotation == null) &#123; return; &#125; String value = defaultAnnotation.value(); if ((value = value.trim()).length() &gt; 0) &#123; String[] names = NAME_SEPARATOR.split(value); if (names.length &gt; 1) &#123; throw new IllegalStateException(\"More than 1 default extension name on extension \" + type.getName() + \": \" + Arrays.toString(names)); &#125; if (names.length == 1) &#123; cachedDefaultName = names[0]; &#125; &#125;&#125; 原来是从@SPI注解中获取的默认扩展名称，再看Protocol接口： 1234@SPI(\"dubbo\")public interface Protocol &#123; ...&#125; 那么Protocol接口默认的实现就是 dubbo也就是org.apache.dubbo.rpc.protocol.dubbo.DubboProtocol 总结： 扩展点接口上的注解@SPI可以写带value，这个value指定了该扩展点接口的默认扩展名称，当我们使用“true”作为名称获取扩展类对象时，获取到的就是这个指定的默认扩展类型对象。 2. 自适应扩展为什么需要自适应扩展？ 有些扩展并不想在框架启动阶段被实例化，而是希望在某些方法被调用时，根据运行时参数再决定实例化哪个具体的扩展类。 什么叫自适应扩展点？ 看一个例子： 1234public static void main(String[] args) &#123; Compiler compiler=ExtensionLoader.getExtensionLoader(Compiler.class).getAdaptiveExtension(); System.out.println(compiler.getClass().getName());&#125; 可以看到这句代码没有指定扩展名，它会返回一个AdaptiveCompiler，这个就叫做自适应。 怎么实现的呢？ 根进AdaptiveCompiler，可以看到这个类上有一个@Adaptive注解 12@Adaptivepublic class AdaptiveCompiler implements Compiler &#123;...&#125; @Adaptive这是自适应扩展类的标志，既可以修饰在类上，也可以修饰到方法上 2.1 注解@Adaptive在对自适应拓展生成过程进行深入分析之前，我们先来看一下@Adaptive 注解。该注解的定义如下： 123456@Documented@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)public @interface Adaptive &#123; String[] value() default &#123;&#125;;&#125; Adaptive 可注解在类或方法上。 当 Adaptive 注解在类上时，Dubbo 不会为该类生成Adaptive代理类，因为注解了之后的类就是代理类（静态代理类）。 当 Adaptive 注解在方法（接口方法）上时，Dubbo 则会为该方法生成代理逻辑，生成代码默认使用javasisit进行编译。 Adaptive 注解在类上的情况很少，在 Dubbo 中，仅有两个类被 Adaptive 注解了，分别是 AdaptiveCompiler 和 AdaptiveExtensionFactory。此种情况，表示拓展的加载逻辑由人工编码完成。 更多时候，Adaptive 是注解在接口方法上的，表示拓展的加载逻辑需由框架自动生成。Adaptive 注解的地方不同，相应的处理逻辑也是不同的。注解在类上时，处理逻辑比较简单。注解在接口方法上时，处理逻辑较为复杂，本文将会重点分析此块逻辑。 再回到获取自适应扩展实例的逻辑中，从getAdaptiveExtension()方法进去： 12345public T getAdaptiveExtension() &#123; ... instance = createAdaptiveExtension(); ...&#125; 1234567private T createAdaptiveExtension() &#123; try &#123; // 先获取自适应扩展类，实例化；在对其进行依赖注入 return injectExtension((T) getAdaptiveExtensionClass().newInstance()); &#125; ...&#125; 1234567private Class&lt;?&gt; getAdaptiveExtensionClass() &#123; getExtensionClasses(); // 加载所有的扩展类 if (cachedAdaptiveClass != null) &#123; return cachedAdaptiveClass; // 如果有某个扩展类注解了@Adptive，返回这个类 &#125; return cachedAdaptiveClass = createAdaptiveExtensionClass(); // 没有自适应类，那就创造一个&#125; 此处有个判断： 如果cachedAdaptiveClass!=null 返回cachedAdaptiveClass 如果为空，则创建一个AdaptiveExtensionClass 这里先说一下结论：前者是处理类上的@Adaptive注解，后者是处理方法上的，下面逐个分析 2.2 类上注解@Adaptive这里只要搞明白cachedAdaptiveClass什么时候初始化的就可以了，在代码中搜索cachedAdaptiveClass，发现了初始化的地方： 123456private void cacheAdaptiveClass(Class&lt;?&gt; clazz, boolean overridden) &#123; if (cachedAdaptiveClass == null || overridden) &#123; cachedAdaptiveClass = clazz; &#125; ...&#125; 在找cacheAdaptiveClass()方法的调用处，找到了 12345678private void loadClass(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, java.net.URL resourceURL, Class&lt;?&gt; clazz, String name, boolean overridden) throws NoSuchMethodException &#123; ... if (clazz.isAnnotationPresent(Adaptive.class)) &#123; cacheAdaptiveClass(clazz, overridden); &#125; ...&#125; 找loadClass()方法的调用处： 12345678private void loadResource(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, ClassLoader classLoader, java.net.URL resourceURL, boolean overridden, String... excludedPackages) &#123; ... if (line.length() &gt; 0 &amp;&amp; !isExcluded(line, excludedPackages)) &#123; loadClass(extensionClasses, resourceURL, Class.forName(line, true, classLoader), name, overridden); &#125; ... &#125; 继续往上找： 123456private void loadDirectory(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, String dir, String type, boolean extensionLoaderClassLoaderFirst, boolean overridden, String... excludedPackages) &#123; ... loadResource(extensionClasses, classLoader, resourceURL, overridden, excludedPackages); ...&#125; 继续： 123456789private Map&lt;String, Class&lt;?&gt;&gt; loadExtensionClasses() &#123; cacheDefaultExtensionName(); Map&lt;String, Class&lt;?&gt;&gt; extensionClasses = new HashMap&lt;&gt;(); for (LoadingStrategy strategy : strategies) &#123; loadDirectory(extensionClasses, strategy.directory(), type.getName(), strategy.preferExtensionClassLoader(), strategy.overridden(), strategy.excludedPackages()); loadDirectory(extensionClasses, strategy.directory(), type.getName().replace(\"org.apache\", \"com.alibaba\"), strategy.preferExtensionClassLoader(), strategy.overridden(), strategy.excludedPackages()); &#125; return extensionClasses;&#125; 这个方法我们很熟悉了，是用来加载配置文件中的扩展条目的（key-&gt;value）， 总结： 对每个扩展点接口，调用loadExtensionClasses加载所有扩展类的时候，会检查扩展类上是否注解了@Adaptive，如果有，则将这个类型对象赋值给cachedAdaptiveClass变量。 2.3 方法注解@Adaptive再贴一下上面的一段代码 1234private Class&lt;?&gt; getAdaptiveExtensionClass() &#123; ... return cachedAdaptiveClass = createAdaptiveExtensionClass();&#125; 通过createAdaptiveExtensionClass()方法创建一个AdaptiveExtensionClass，跟进方法： 123456private Class&lt;?&gt; createAdaptiveExtensionClass() &#123; String code = new AdaptiveClassCodeGenerator(type, cachedDefaultName).generate(); ClassLoader classLoader = findClassLoader(); org.apache.dubbo.common.compiler.Compiler compiler = ExtensionLoader.getExtensionLoader(org.apache.dubbo.common.compiler.Compiler.class).getAdaptiveExtension(); return compiler.compile(code, classLoader);&#125; 代码逻辑比较清晰，将生成一段java代码，然后获取自适应的Compiler去编译这段代码。 可以看到这里用到了自适应的Compiler，这个接口有 jdk 和 javassist 两种实现方式，@Spi注解中指定的默认实现是javassist 贴一下AdaptiveCompiler的代码 1234567891011121314151617181920212223@Adaptivepublic class AdaptiveCompiler implements Compiler &#123; private static volatile String DEFAULT_COMPILER; public static void setDefaultCompiler(String compiler) &#123; DEFAULT_COMPILER = compiler; &#125; @Override public Class&lt;?&gt; compile(String code, ClassLoader classLoader) &#123; Compiler compiler; ExtensionLoader&lt;Compiler&gt; loader = ExtensionLoader.getExtensionLoader(Compiler.class); String name = DEFAULT_COMPILER; // copy reference if (name != null &amp;&amp; name.length() &gt; 0) &#123; compiler = loader.getExtension(name); &#125; else &#123; compiler = loader.getDefaultExtension(); &#125; return compiler.compile(code, classLoader); &#125;&#125; 如果没有指定compiler，使用默认的javasissit进行编译，否则使用指定的compiler，这就是自适应Compiler的逻辑。 所以这里的重点是在java代码的生成那一块， 1String code = new AdaptiveClassCodeGenerator(type, cachedDefaultName).generate(); 首先创建了一个自适应类代码生成器，传进两个参数，接口类型type 和 默认的实现名（@SPI注解指定的名称），然后调用该生成器的generate()方法生成代码。代码自动生成的逻辑比较多，且复杂。 运行时加载，到底怎么理解呢，以Protocol接口为例，贴一段自动生成的代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package com.viewscenes.netsupervisor.adaptive;import com.alibaba.dubbo.common.URL;import com.alibaba.dubbo.common.extension.ExtensionLoader;import com.alibaba.dubbo.rpc.Exporter;import com.alibaba.dubbo.rpc.Invoker;import com.alibaba.dubbo.rpc.Protocol;import com.alibaba.dubbo.rpc.RpcException;public class Protocol$Adaptive implements Protocol &#123; public void destroy() &#123; throw new UnsupportedOperationException( \"method public abstract void Protocol.destroy() of \" + \"interface Protocol is not adaptive method!\"); &#125; public int getDefaultPort() &#123; throw new UnsupportedOperationException( \"method public abstract int Protocol.getDefaultPort()\" + \"of interface Protocol is not adaptive method!\"); &#125; /** * export 方法什么时候调用？服务发布的时候调用，服务发布肯定会指定发布服务的协议名称、 * 注册中心地址等信息 */ public Exporter export(Invoker invoker)throws RpcException &#123; if (invoker == null) &#123; throw new IllegalArgumentException(\"Invoker argument == null\"); &#125; if (invoker.getUrl() == null) &#123; throw new IllegalArgumentException(\"Invoker argument getUrl() == null\"); &#125; URL url = invoker.getUrl(); // 从调用此方法的Invoker获取url // 如果url中没有指定协议，那么使用默认“dubbo”（之前构造代码生成器的时候传进来的） String extName = (url.getProtocol() == null ? \"dubbo\" : url.getProtocol()); if (extName == null) &#123; throw new IllegalStateException(\"Fail to get extension(Protocol) name from url(\" + url.toString() + \") use keys([protocol])\"); &#125; // 使用指定的协议名或者默认协议名获取Protocol扩展实例 Protocol extension = ExtensionLoader.getExtensionLoader(Protocol.class) .getExtension(extName); // 调用具体扩展实现的export方法。 return extension.export(invoker); &#125; /** * refer 方法什么时候调用？注入远程服务时候调用，调用服务也要指定发布服务的协议名称、 * 注册中心地址等信息 */ public Invoker refer(Class clazz,URL ur)throws RpcException &#123; if (ur == null) &#123; throw new IllegalArgumentException(\"url == null\"); &#125; URL url = ur; String extName = (url.getProtocol() == null ? \"dubbo\" : url.getProtocol()); if (extName == null) &#123; throw new IllegalStateException( \"Fail to get extension(Protocol) name from url(\" + url.toString() + \") use keys([protocol])\"); &#125; // 使用指定的 或者 默认的 Protocol扩展名获取扩展实例 Protocol extension = ExtensionLoader.getExtensionLoader(Protocol.class) .getExtension(extName); // 调用具体实现类的refer方法 return extension.refer(clazz, url); &#125;&#125; 分析完对以上的代码，对自适应扩展机制应该有了一个基本的理解，自适应的Protocol$Adaptive，本身并没有具体的实现，只是根据运行时的配置，将自适应方法转发给配置的或者默认的实现类，可以算是一种代理模式的实现，这种设计非常灵活，可以借鉴。 激活扩展点自动激活扩展点，有点类似我们讲 springboot 的时候用到的 conditional，根据条件进行自动激活。但是这里设计的初衷是，对 于一个类会加载多个扩展点的实现，这个时候可以通过自动激活扩展点进行动态加载， 从而简化我们的配置工作 @Activate 提供了一些配置来允许我们配置加载条件，比如 group 过滤，比如 key 过滤。 举个例子，我们可以看看 org.apache.dubbo.Filter 这个类，它有非常多的实现，比如说 CacheFilter，这个缓存过滤器，配置信息 如下 group 表示客户端和和服务端都会加载，value 表示 url 中有 cache_key 的时候 12@Activate(group = &#123;CONSUMER, PROVIDER&#125;, value = CACHE_KEY) public class CacheFilter implements Filter &#123;...&#125; 通过下面这段代码，演示关于 Filter 的自动激活扩展点的效果。没有添加“红色部分的代码”时，list 的结果是 10，添加之后 list 的结果是 11. 会自动把 cacheFilter 加载进来 1234567public static void main(String[] args) &#123; ExtensionLoader&lt;Filter&gt; loader=ExtensionLoader.getExtensionLoader(Filter.class); URL url = new URL(\"\",\"\",0); //url=url.addParameter(\"cache\",\"cache\"); 有和没有的区别 List&lt;Filter&gt; filters=loader.getActivateExtension(url,\"cache\"); System.out.println(filters.size());&#125;","categories":[{"name":"RPC框架Dubbo","slug":"RPC框架Dubbo","permalink":"https://zzkenyon.github.io/categories/RPC框架Dubbo/"}],"tags":[{"name":"dubbo","slug":"dubbo","permalink":"https://zzkenyon.github.io/tags/dubbo/"}],"keywords":[{"name":"RPC框架Dubbo","slug":"RPC框架Dubbo","permalink":"https://zzkenyon.github.io/categories/RPC框架Dubbo/"}]},{"title":"dubbo-服务发布和注册过程","slug":"dubbo-服务发布和注册过程","date":"2019-04-20T16:00:00.000Z","updated":"2021-01-08T13:46:46.170Z","comments":true,"path":"2019/04/21/dubbo-服务发布和注册过程/","link":"","permalink":"https://zzkenyon.github.io/2019/04/21/dubbo-服务发布和注册过程/","excerpt":"","text":"1 设计思想dubbo是基于url驱动的rpc框架 所以在服务启动之后，需要针对指定的协议生成url，若指定了多协议则生成多个url。 生成url并启动本地的服务，我们称为服务发布，随后会将服务url注册到注册中心，这个过程称为服务注册 服务发布注册需要在服务启动过程中进行，启动-&gt;发布-&gt;注册 那么就需要去设计服务发布注册的时机，dubbo的做法是向springboot注册了一个事件监听器，监听ContextRefreshedEvent事件，当context刷新完成之后，该监听器会执行dubbo服务的发布注册流程。 2 执行流程@DubboComponentScan注解可以指定扫描dubbo服务的包， 12@Import(DubboComponentScanRegistrar.class)public @interface DubboComponentScan &#123; ...&#125; DubboComponentScanRegistrars是用于动态注册bean的一种方法，注册了什么呢？ 12345@Override //DubboComponentScanRegistrarspublic void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; ... registerServiceAnnotationBeanPostProcessor(packagesToScan, registry);&#125; 123456789//DubboComponentScanRegistrarsprivate void registerServiceAnnotationBeanPostProcessor(Set&lt;String&gt; packagesToScan, BeanDefinitionRegistry registry) &#123; BeanDefinitionBuilder builder = rootBeanDefinition(ServiceAnnotationBeanPostProcessor.class); builder.addConstructorArgValue(packagesToScan); builder.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); AbstractBeanDefinition beanDefinition = builder.getBeanDefinition(); BeanDefinitionReaderUtils.registerWithGeneratedName(beanDefinition, registry);&#125; 注册了一个ServiceAnnotationBeanPostProcessor，看该类的继承关系可知这是一个BeanDefinitionRegistryPostProcessor， 在ApplicationContextInitializer的标准初始化之后修改它的内部bean定义注册表。所有的beanDefinition都已加载，但还没有实例化任何bean。允许在下一个后处理阶段开始之前添加更多的bean定义 以上是BeanDefinitionRegistryPostProcessor的官方注释， 123456@Override // ServiceClassPostProcessorpublic void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException &#123; // @since 2.7.5 registerInfrastructureBean(registry, DubboBootstrapApplicationListener.BEAN_NAME, DubboBootstrapApplicationListener.class); ...&#125; 可以看到该后置处理器向ioc注册了DubboBootstrapApplicationListener 12345678@Override //DubboBootstrapApplicationListenerpublic void onApplicationContextEvent(ApplicationContextEvent event) &#123; if (event instanceof ContextRefreshedEvent) &#123; onContextRefreshedEvent((ContextRefreshedEvent) event); &#125; else if (event instanceof ContextClosedEvent) &#123; onContextClosedEvent((ContextClosedEvent) event); &#125;&#125; 12345678// DubboBootstrapApplicationListenerprivate final DubboBootstrap dubboBootstrap;public DubboBootstrapApplicationListener() &#123; this.dubboBootstrap = DubboBootstrap.getInstance();&#125;private void onContextRefreshedEvent(ContextRefreshedEvent event) &#123; dubboBootstrap.start();&#125; 跟到这里，来到了dubbo服务启动类DubboBootstrap 123456789101112131415161718192021222324private void doExportUrls() &#123; ServiceRepository repository = ApplicationModel.getServiceRepository(); ServiceDescriptor serviceDescriptor = repository.registerService(getInterfaceClass()); repository.registerProvider( getUniqueServiceName(), ref, serviceDescriptor, this, serviceMetadata ); List&lt;URL&gt; registryURLs = ConfigValidationUtils.loadRegistries(this, true); for (ProtocolConfig protocolConfig : protocols) &#123; String pathKey = URL.buildKey(getContextPath(protocolConfig) .map(p -&gt; p + \"/\" + path) .orElse(path), group, version); // In case user specified path, register service one more time to map it to path. repository.registerService(pathKey, interfaceClass); // TODO, uncomment this line once service key is unified serviceMetadata.setServiceKey(pathKey); doExportUrlsFor1Protocol(protocolConfig, registryURLs); // &gt;&gt; &#125;&#125; doExportUrlsFor1Protocol从方法名能看出这个方法的功能是使用一个协议发布服务，具体是什么协议是由用户配置的。 下图为方法的两个参数，参数protocolConfig是用户配置的协议，参数registryURLs是从用户的注册中心配置中构建的两个url，这里配置了两个 doExportUrlsFor1Protocol方法代码很多，前面主要是根据运行环境以及用户配置，初始化服务的属性，使用一个map存储这些配置属性： 然后根据这些属性生成服务url： 1URL url = new URL(name, host, port, getContextPath(protocolConfig).map(p -&gt; p + \"/\" + path).orElse(path), map); 生成的url如下： 1dubbo://172.30.66.2:20880/com.pd.ISayHello?anyhost=true&amp;application=spring-boot-dubbo-provider&amp;bind.ip=172.30.66.2&amp;bind.port=20880&amp;cluster=failover&amp;deprecated=false&amp;dubbo=2.0.2&amp;dynamic=true&amp;generic=false&amp;interface=com.pd.ISayHello&amp;loadbalance=roundrobin&amp;metadata-type=remote&amp;methods=sayHello&amp;pid=1013&amp;qos.enable=false&amp;release=2.7.8&amp;side=provider&amp;timestamp=1598924399518 dubbo默认的服务路径是接口的全类名，例如dubbo://172.30.66.2:20880/com.pd.ISayHello 实际应用中可以在配置文件中指定dubbo.provider.contextPath属性，这个是一级路径，此外在服务注解中也可以指定具体服务的二级路径，注解中的path属性指定，例如进行以下配置： 123dubbo： provider: contextpath: /panda 1234567@DubboService(registry = &#123;\"nacos\",\"zookeeper\"&#125;, path = \"sayHelloImpl\", // 指定服务二级路径 protocol = &#123;\"dubbo\"&#125;, loadbalance = \"roundrobin\", cluster = \"failover\", retries = 2)public class SayHelloImpl implements ISayHello &#123; 得到的url就是 1dubbo://172.30.66.2:20880/panda/sayHelloImpl?anyhost=true&amp;application=spring-boot-dubbo-provider&amp;bind.ip=172.30.66.2&amp;bind.port=20880&amp;cluster=failover&amp;deprecated=false&amp;dubbo=2.0.2&amp;dynamic=true&amp;generic=false&amp;interface=com.pd.ISayHello&amp;loadbalance=roundrobin&amp;metadata-type=remote&amp;methods=sayHello&amp;pid=3333&amp;qos.enable=false&amp;release=2.7.8&amp;side=provider&amp;timestamp=1600236724722 到此为止服务配置的解析就完成了，接下来就是要执行服务的发布。 2.1 服务发布还是doExportUrlsFor1Protocol方法，后半段落去非关键代码： 123456789101112131415161718192021222324252627282930313233String scope = url.getParameter(SCOPE_KEY); // 一般不指定的scope的时候 此处为nullif (!SCOPE_NONE.equalsIgnoreCase(scope)) &#123; // null != none if (!SCOPE_REMOTE.equalsIgnoreCase(scope)) &#123; // null != remote exportLocal(url); // 执行本地发布 &#125; if (!SCOPE_LOCAL.equalsIgnoreCase(scope)) &#123; //null != local if (CollectionUtils.isNotEmpty(registryURLs)) &#123; for (URL registryURL : registryURLs) &#123; // if protocol is only injvm ,not register if (LOCAL_PROTOCOL.equalsIgnoreCase(url.getProtocol())) &#123; continue; &#125; ... // 以下为发布逻辑的重点内容 String proxy = url.getParameter(PROXY_KEY); if (StringUtils.isNotEmpty(proxy)) &#123; registryURL = registryURL.addParameter(PROXY_KEY, proxy); &#125; // 生成调用器 Invoker&lt;?&gt; invoker = PROXY_FACTORY.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(EXPORT_KEY, url.toFullString())); DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this); Exporter&lt;?&gt; exporter = PROTOCOL.export(wrapperInvoker); exporters.add(exporter); &#125; &#125; else &#123; // 如果注册中心配置registryURLs为空，执行以下代码，只发布dubbo服务，不进行注册 ... Invoker&lt;?&gt; invoker = PROXY_FACTORY.getInvoker(ref, (Class) interfaceClass, url); DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this); Exporter&lt;?&gt; exporter = PROTOCOL.export(wrapperInvoker); exporters.add(exporter); &#125; PROXY_FACTORY是使用自适应扩展获得的动态代理工厂，这里获取的是javassist： 1private static final ProxyFactory PROXY_FACTORY = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension(); 2.2.1 Invoker看这个获取invoker对象的方法getInvoker： 1Invoker&lt;?&gt; invoker = PROXY_FACTORY.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(EXPORT_KEY, url.toFullString())); 参数ref： 具体的service实例对象 参数interfaceClass ：service接口 参数url : 在registryURL中添加了一个export参数，存放dubbo协议的服务url 1registry://10.0.12.76:8848/org.apache.dubbo.registry.RegistryService?application=spring-boot-dubbo-provider&amp;dubbo=2.0.2&amp;export=dubbo%3A%2F%2F172.30.66.2%3A20880%2Fcom.pd.ISayHello%3Fanyhost%3Dtrue%26application%3Dspring-boot-dubbo-provider%26bind.ip%3D172.30.66.2%26bind.port%3D20880%26cluster%3Dfailover%26deprecated%3Dfalse%26dubbo%3D2.0.2%26dynamic%3Dtrue%26generic%3Dfalse%26interface%3Dcom.pd.ISayHello%26loadbalance%3Droundrobin%26metadata-type%3Dremote%26methods%3DsayHello%26pid%3D1013%26qos.enable%3Dfalse%26release%3D2.7.8%26side%3Dprovider%26timestamp%3D1598924399518&amp;pid=1013&amp;qos.enable=false&amp;registry=nacos&amp;release=2.7.8&amp;timestamp=1598923996985 再看javassist中的getInvoker方法 123456789101112public &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) &#123; //proxy 指的是被代理的对象，也就是具体的服务类对象 // TODO Wrapper cannot handle this scenario correctly: the classname contains '$' final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf('$') &lt; 0 ? proxy.getClass() : type); return new AbstractProxyInvoker&lt;T&gt;(proxy, type, url) &#123; @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable &#123; return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments); &#125; &#125;;&#125; 在手写rpc的文章中，消费者使用动态代理将需要调用的服务名、方法名、参数等信息发送个服务提供者，服务提供者获取这些信息之后使用发射调用，获得返回值，再通过网络发送个消费者，这里存在一个性能问题，就是服务端的反射调用 如果每次处理请求，都需要去查找类查找方法，这肯定会增加服务的响应时间，dubbo提供的解决方案是除了使用静态代理的设计，在服务发布的时候就生成一个服务对象的代理类，这样在调用服务方法时直接调用代理对象响应的方法就可以。 dubbo 使用Wrapper类对服务对象进行代理，服务发布时就会生成一个Invoker对象，其成员变量wrapper就调用代理类对象，看上面的代码，消费端的请求发送到服务端之后，会进入doInvoke方法，而实际执行的是wrapper的invokeMethod方法。 wrapper对象的生成代码比较多，可以单独分析。 2.2.2 RegisterProtocol12private static final Protocol PROTOCOL = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension();Exporter&lt;?&gt; exporter = PROTOCOL.export(wrapperInvoker); 这里的PROTOCOL也是一个自适应的扩展，wrapperInvoker.getUrl()返回的是registry，因此此处将进入RegisterProtocol的export方法： 123456789101112public &lt;T&gt; Exporter&lt;T&gt; export(final Invoker&lt;T&gt; originInvoker) throws RpcException &#123; URL registryUrl = getRegistryUrl(originInvoker); // url to export locally URL providerUrl = getProviderUrl(originInvoker); final URL overrideSubscribeUrl = getSubscribedOverrideUrl(providerUrl); final OverrideListener overrideSubscribeListener = new OverrideListener(overrideSubscribeUrl, originInvoker); overrideListeners.put(overrideSubscribeUrl, overrideSubscribeListener); providerUrl = overrideUrlWithConfig(providerUrl, overrideSubscribeListener); //export invoker 启动dubbo服务，具体就是启动nettyserver final ExporterChangeableWrapper&lt;T&gt; exporter = doLocalExport(originInvoker, providerUrl); ...&#125; 12345678private &lt;T&gt; ExporterChangeableWrapper&lt;T&gt; doLocalExport(final Invoker&lt;T&gt; originInvoker, URL providerUrl) &#123; String key = getCacheKey(originInvoker); return (ExporterChangeableWrapper&lt;T&gt;) bounds.computeIfAbsent(key, s -&gt; &#123; Invoker&lt;?&gt; invokerDelegate = new InvokerDelegate&lt;&gt;(originInvoker, providerUrl); return new ExporterChangeableWrapper&lt;&gt;((Exporter&lt;T&gt;) protocol.export(invokerDelegate), originInvoker); &#125;);&#125; 重构了一个Invoker，url为dubbo协议的服务url，因此此处的Protocol.export将进入DubboProtocol 12345678910111213public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; URL url = invoker.getUrl(); // export service. String key = serviceKey(url); DubboExporter&lt;T&gt; exporter = new DubboExporter&lt;T&gt;(invoker, key, exporterMap); exporterMap.put(key, exporter); ... openServer(url); // &gt;&gt; 开启服务监听 optimizeSerialization(url); return exporter;&#125; 再往下跟就是传输层的逻辑了，dubbo使用netty4作为传输层协议，最后开启了一个netty server。 dubbo服务启动完成之后，将执行服务的注册流程 2.3 服务注册回到registryProtocol的export方法后半段： 123456789101112131415161718192021public &lt;T&gt; Exporter&lt;T&gt; export(final Invoker&lt;T&gt; originInvoker) throws RpcException &#123; ... // decide if we need to delay publish boolean register = providerUrl.getParameter(REGISTER_KEY, true); if (register) &#123; register(registryUrl, registeredProviderUrl); //&gt;&gt; &#125; // register stated url on provider model registerStatedUrl(registryUrl, registeredProviderUrl, register); exporter.setRegisterUrl(registeredProviderUrl); exporter.setSubscribeUrl(overrideSubscribeUrl); // Deprecated! Subscribe to override rules in 2.6.x or before. registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener); notifyExport(exporter); //Ensure that a new exporter instance is returned every time export return new DestroyableExporter&lt;&gt;(exporter);&#125; 进入注册流程register(registryUrl, registeredProviderUrl); //&gt;&gt; 1234private void register(URL registryUrl, URL registeredProviderUrl) &#123; Registry registry = registryFactory.getRegistry(registryUrl); registry.register(registeredProviderUrl);&#125; 看第一句先获取一个Registry，registryFactory这里也是一个自适应扩展点，扩展如下 META-INF/dubbo/internal/org.apache.dubbo.registry.RegistryFactory 123456789101112service-discovery-registry=org.apache.dubbo.registry.client.ServiceDiscoveryRegistryFactorywrapper=org.apache.dubbo.registry.RegistryFactoryWrapperdubbo=org.apache.dubbo.registry.dubbo.DubboRegistryFactorymulticast=org.apache.dubbo.registry.multicast.MulticastRegistryFactoryzookeeper=org.apache.dubbo.registry.zookeeper.ZookeeperRegistryFactoryredis=org.apache.dubbo.registry.redis.RedisRegistryFactoryconsul=org.apache.dubbo.registry.consul.ConsulRegistryFactoryetcd3=org.apache.dubbo.registry.etcd.EtcdRegistryFactorynacos=org.apache.dubbo.registry.nacos.NacosRegistryFactorysofa=org.apache.dubbo.registry.sofa.SofaRegistryFactorymultiple=org.apache.dubbo.registry.multiple.MultipleRegistryFactory debug到这里，registryUrl的值如下： 注意RegistryFactory的扩展有wapper包装器，所以创建的RegistryFactory是被RegistryFactoryWrapper包装之后的： 123456// RegistryFactoryWrapper 对饮wrapper扩展点public Registry getRegistry(URL url) &#123; return new ListenerRegistryWrapper(registryFactory.getRegistry(url), // 到这里才是创建nacos的registryFactory Collections.unmodifiableList(ExtensionLoader.getExtensionLoader(RegistryServiceListener.class) .getActivateExtension(url, \"registry.listeners\")));&#125; 因此最终获得的Registry是一个被包装的： ListenerRegistryWrapper(NacosRegistry)，外面的包装用于监听注册事件，与注册流程无关这里不进行分析。 这里是nacos协议 因此将会进入到NacosRegistryFactory来创建Registry对象，且此处使用了模板方法，NacosRegistryFactory中并没有getRegistry()方法，该方法定义在其父类AbstractRegistryFactory中，抽象父类定义了抽象方法createRegistry()，getRegistry()最终调用子类对该抽象方法的的具体实现来生成Registry对象。 下面看一下NacosRegistry的类关系图，这里也是模板模式的设计，register()方法是定义在父类中的，需要注意的是FailbackRegistry也重载了register()方法，所以register()方法的调用顺序是：ListenerRegistryWrapper–&gt;FailbackRegistry–&gt;AbstractRegistry， 12345@Override //AbstractRegistrypublic void register(URL url) &#123; ... registered.add(url); // 这里只是将url存放到一个set中&#125; 远程注册的逻辑在 FailbackRegistry中： 1234567891011121314@Overridepublic void register(URL url) &#123; if (!acceptable(url)) &#123; logger.info(\"URL \" + url + \" will not be registered to Registry. Registry \" + url + \" does not accept service of this protocol type.\"); return; &#125; super.register(url); removeFailedRegistered(url); removeFailedUnregistered(url); try &#123; // Sending a registration request to the server side &gt;&gt; 此处是执行真正的远程注册 doRegister(url); &#125; catch (Exception e) &#123;...&#125;&#125; 12345678910111213@Override // NacosRegistrypublic void doRegister(URL url) &#123; final String serviceName = getServiceName(url); final Instance instance = createInstance(url); /** * namingService.registerInstance with &#123;@link org.apache.dubbo.registry.support.AbstractRegistry#registryUrl&#125; * default &#123;@link DEFAULT_GROUP&#125; * * in https://github.com/apache/dubbo/issues/5978 */ execute(namingService -&gt; namingService.registerInstance(serviceName, getUrl().getParameter(GROUP_KEY, Constants.DEFAULT_GROUP), instance));&#125; 123456789private void execute(NamingServiceCallback callback) &#123; try &#123; callback.callback(namingService); &#125; catch (NacosException e) &#123; if (logger.isErrorEnabled()) &#123; logger.error(e.getErrMsg(), e); &#125; &#125;&#125; 此处使用lamda表达式，execute方法接收一个NamingServiceCallback类型的参数，该参数只有一个函数式接口callback(namingService)，所以在callback函数中调用了NacosNamingService来进行注册，针对不同的注册中心有不同的NamingService实现。 对服务的发布和注册就先分析到这里。 3 延伸:dubbo xml配置的解析spring中定义了一个NameSpaceHandler接口，接口注释如下： 1234/** * Base interface used by the &#123;@link DefaultBeanDefinitionDocumentReader&#125; * for handling custom namespaces in a Spring XML configuration file. */ 这个接口是用来处理spring xml配置文件中的定制的namespace，例如dubbo:service、dubbo:provider等等 Spring默认会加载jar包中的META-INF/spring.handlers文件寻找对应的NameSpaceHandler，例如dubbo实现了该接口，在dubbo-config-spring模块中，就能找到这个META-INF/spring.handlers文件: 123# dubbo-config/dubbo-config-spring/src/main/resources/META-INF/spring.handlershttp\\://dubbo.apache.org/schema/dubbo=org.apache.dubbo.config.spring.schema.DubboNamespaceHandlerhttp\\://code.alibabatech.com/schema/dubbo=org.apache.dubbo.config.spring.schema.DubboNamespaceHandler dubbo的实现类是DubboNamespaceHandler，代码如下： 12345678910111213141516171819202122232425public class DubboNamespaceHandler extends NamespaceHandlerSupport implements ConfigurableSourceBeanMetadataElement &#123; static &#123; Version.checkDuplicate(DubboNamespaceHandler.class); &#125; @Override public void init() &#123; registerBeanDefinitionParser(\"application\", new DubboBeanDefinitionParser(ApplicationConfig.class, true)); registerBeanDefinitionParser(\"module\", new DubboBeanDefinitionParser(ModuleConfig.class, true)); registerBeanDefinitionParser(\"registry\", new DubboBeanDefinitionParser(RegistryConfig.class, true)); registerBeanDefinitionParser(\"config-center\", new DubboBeanDefinitionParser(ConfigCenterBean.class, true)); registerBeanDefinitionParser(\"metadata-report\", new DubboBeanDefinitionParser(MetadataReportConfig.class, true)); registerBeanDefinitionParser(\"monitor\", new DubboBeanDefinitionParser(MonitorConfig.class, true)); registerBeanDefinitionParser(\"metrics\", new DubboBeanDefinitionParser(MetricsConfig.class, true)); registerBeanDefinitionParser(\"ssl\", new DubboBeanDefinitionParser(SslConfig.class, true)); registerBeanDefinitionParser(\"provider\", new DubboBeanDefinitionParser(ProviderConfig.class, true)); registerBeanDefinitionParser(\"consumer\", new DubboBeanDefinitionParser(ConsumerConfig.class, true)); registerBeanDefinitionParser(\"protocol\", new DubboBeanDefinitionParser(ProtocolConfig.class, true)); registerBeanDefinitionParser(\"service\", new DubboBeanDefinitionParser(ServiceBean.class, true)); registerBeanDefinitionParser(\"reference\", new DubboBeanDefinitionParser(ReferenceBean.class, false)); registerBeanDefinitionParser(\"annotation\", new AnnotationBeanDefinitionParser()); &#125; ...&#125; 可以看到注册了一堆的element解析器来解析不同的配置标签，这些标签对应的配置最终都会被解析成BeanDefinition注册到IoC容器中。最后注册的一个是注解解析器，用于处理注解配置的情况。 我们仔细看，发现涉及到服务发布和服务调用的两个配置的解析，用的是ServiceBean和referenceBean。并不是config结尾的，这两个类稍微特殊些，当然他们也继承了ServiceConfig和ReferenceConfig 。","categories":[{"name":"RPC框架Dubbo","slug":"RPC框架Dubbo","permalink":"https://zzkenyon.github.io/categories/RPC框架Dubbo/"}],"tags":[{"name":"dubbo","slug":"dubbo","permalink":"https://zzkenyon.github.io/tags/dubbo/"}],"keywords":[{"name":"RPC框架Dubbo","slug":"RPC框架Dubbo","permalink":"https://zzkenyon.github.io/categories/RPC框架Dubbo/"}]},{"title":"dubbo-基本使用和高级特性","slug":"dubbo-基本使用和高级特性","date":"2019-04-16T16:00:00.000Z","updated":"2020-08-11T10:02:39.421Z","comments":true,"path":"2019/04/17/dubbo-基本使用和高级特性/","link":"","permalink":"https://zzkenyon.github.io/2019/04/17/dubbo-基本使用和高级特性/","excerpt":"","text":"由于dubbo社区较为活跃，版本更新快，在spring-cloud-alibaba之后，spring-boot-dubbo的使用有一些改动，本文代码示例基于dubbo2.7.7版本 1. 基本使用创建项目结构：api、provider、consumer 1.1 管理项目依赖api之定义服务提供者消费者之间通信的业务接口，无需添加dubbo相关依赖。 provider 基于springboot构建添加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt; 首先添加dubbo依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.7.7&lt;/version&gt;&lt;/dependency&gt; 需要实现api的接口并将实现以服务的形式发布到注册中心，需要添加注册中心的依赖： 12345678910&lt;dependency&gt; &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-registry-nacos&lt;/artifactId&gt; &lt;version&gt;2.7.7&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-registry-zookeeper&lt;/artifactId&gt; &lt;version&gt;2.7.7&lt;/version&gt;&lt;/dependency&gt; 后面会演示多注册中心支持，因此添加两种注册中心依赖，dubbo支持很多中间件作为注册中心，除以上两种之外还有dubbo-registry-redis、dubbo-registry-multicast consumer依赖与provider一致 1.2 配置provider 配置如下： 123456789101112131415161718spring: application: name: spring-boot-dubbo-providerdubbo: application: name: $&#123;spring.application.name&#125; protocol: id: dubbo port: -1 # 表示自动生成端口号 registries: # 多注册中心 nacos: name: nacos address: nacos://10.0.12.76:8848 zookeeper: name: zookeeper address: zookeeper://10.0.12.74:2181 在需要发布的接口实现类上注解@DubboService，注解中也能进行配置，此处配置优先级高于配置文件的全局配置： 1234@DubboService(registry = &#123;\"nacos\"&#125;, // 注册到nacos，可以配置多个，必须是配置文件配置的子集 loadbalance = \"roundrobin\", // 服务端提供的负载算法，客户端不配置的话就用这个 cluster = \"failover\", // 容错机制 retries = 2) // 重试 在SpringBoot启动类上注解@DubboCompontScan(basePackages={&quot;xxx.xxx.xxx&quot;})，启动，查看nacos和zookeeper可以看到服务发布成功。 consumer配置： 1234567891011121314spring: application: name: spring-boot-dubbo-consumerdubbo: registries: nacos: name: nacos address: nacos://10.0.12.76:8848 register: false # 配置消费者不注册到注册中心 zookeeper: name: zookeeper address: zookeeper://10.0.12.74:2181 register: false # 默认是true 在需要调用远程服务的类中使用@DubboReference注解注入bean，注解中也可以进行相应的配置 123@DubboReference(protocol = \"dubbo\", // 使用dubbo协议，默认 mock = \"com.pd.moke.ISayHelloMoke\", // 服务降级，自定义的降级类 check = false) // 关闭启动检查，这样服务提供者没启动不会影响消费者的启动 配置完成启动consumer，调用远程服务的方法，调用成功返回远程结果或者调用失败返回moke中的处理结果 2. 多协议支持dubbo一个重要的特性就是支持多协议，那么有哪些协议呢： dubbo hessian thrift grpc http2.0 / protobuff rest rest rmi … 下面来演示一下使用rest和duubo两种协议来发布服务。 dubbo 中的rest协议使用restEasy提供的rest服务，在api中添加以下依赖： 12345678910&lt;dependency&gt; &lt;groupId&gt;org.jboss.resteasy&lt;/groupId&gt; &lt;artifactId&gt;resteasy-jaxrs&lt;/artifactId&gt; &lt;version&gt;3.13.0.Final&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.jboss.resteasy&lt;/groupId&gt; &lt;artifactId&gt;resteasy-client&lt;/artifactId&gt; &lt;version&gt;3.13.0.Final&lt;/version&gt;&lt;/dependency&gt; 此外rest接口需要部署到servlet容器中，这里使用jetty，api中添加依赖： 1234567891011&lt;!--jetty--&gt;&lt;dependency&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-server&lt;/artifactId&gt; &lt;version&gt;9.4.19.v20190610&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-servlet&lt;/artifactId&gt; &lt;version&gt;9.4.19.v20190610&lt;/version&gt;&lt;/dependency&gt; 使用restEasy改写api接口，令其能支持rest协议： 123456@Path(\"/\")public interface ISayHello &#123; @GET @Path(\"/say\") String sayHello(String msg);&#125; 修改provider的配置文件 123456789dubbo: protocols: dubbo: name: dubbo port: -1 # 默认生成，从20880开始往后加 rest: name: rest port: -1 # 从80开始往后加 server: jetty 启动服务，查看nacos发现该服务有两个实例，一个是dubbo协议，一个是rest协议，在浏览器访问：http://localhost/say，直接返回结果。 此外在服务实现类注解上也可以指定使用的协议类型，必须是配置文件指定的子集： 12345@DubboService(registry = &#123;\"nacos\",\"zookeeper\"&#125;, protocol = &#123;\"rest\",\"dubbo\"&#125;, // 指定协议发布 loadbalance = \"roundrobin\", cluster = \"failover\", retries = 2) 3. 客户端负载均衡当服务提供者部署了多个实例，客户端调用服务时会进行负载均衡，默认的负载均衡算法是随机算法。 3.1 Random(默认)该随机其实是加权随机算法 它的算法思想很简单。假设我们有一组服务器 servers = [A, B, C]，他们对应的权重为 weights = [5, 3, 2]，权重总和为10。现在把这些权重值平铺在一维坐标值上，[0, 5) 区间属于服务器 A，[5, 8) 区间属于 服务器 B，[8, 10) 区间属于服务器 C。接下来通过随机数生成器生成一个范围在 [0, 10) 之间的随机数， 然后计算这个随机数会落到哪个区间上。比如数字3会落到服务器 A 对应的区间上，此时返回服务器 A 即可。权重越大的机器，在坐标轴上对应的区间范围就越大，因此随机数生成器生成的数字就会有更大 的概率落到此区间内。只要随机数生成器产生的随机数分布性很好，在经过多次选择后，每个服务器被 选中的次数比例接近其权重比例。 3.2 roundrobin (轮询)所谓轮询是指将请求轮流分配给每台服务器。举个例子，我们有三台服务器 A、B、C。我们将第一个请 求分配给服务器 A，第二个请求分配给服务器 B，第三个请求分配给服务器 C，第四个请求再次分配给 服务器 A。这个过程就叫做轮询。轮询是一种无状态负载均衡算法，实现简单，适用于每台服务器性能 相近的场景下。但现实情况下，我们并不能保证每台服务器性能均相近。如果我们将等量的请求分配给 性能较差的服务器，这显然是不合理的。因此，这个时候我们需要对轮询过程进行加权，以调控每台服 务器的负载。经过加权后，每台服务器能够得到的请求数比例，接近或等于他们的权重比。比如服务器 A、B、C 权重比为 5:2:1。那么在8次请求中，服务器 A 将收到其中的5次请求，服务器 B 会收到其中的 2次请求，服务器 C 则收到其中的1次请求 3.3 一致性hash 负载dubbo， 根据参数进行hash取模。 默认是根据 {第一个参数}。 数据分片 {hash(parameter) % 3} =0,1,2 {hash(parameter) % 6} =0,1,2,3,4,5 3.4 最小活跃度根据目标集群服务器列表，处理性能最高的，权重也越高。处理性能较低的，权重也比较低 根据请求处理的吞吐量 -&gt; 发起一次请求(开始)，计数器+1、 一次请求处理完成，计数器-1 3.5 shortestreponse loadbalance最短响应时间负载均衡算法， 筛选成功调用响应时间最短的调用程序的数量，并计算这些调用程序的权重和数量。然后根据响应时间 的长短来分配目标服务的路由权重。 4. 集群容错容忍错误的能力 客户端发起了一次请求， 报错了？超时了？ 三态： 成功|失败|未知 4.1failover cluster(默认)失败自动重试(重试其他服务器)，失败自动切换 1@DubboService(cluster=&quot;failover&quot;,retires=2) 注意[幂等] ，必须要保证成功。 4.2 failfast cluster快速失败,立马报错。 4.3 failsafe cluster失败安全， 出现异常，直接吞掉。 4.4 failback cluster失败自动恢复，记录失败请求，定时重发。 4.5 forking cluster并行调用多个服务节点，只要其中一个成功返回，那么就直接返回结果。 4.6 broadcast cluster广播调用，一个请求调用所有的服务提供者。只要其中一个节点报错，那么就认为这个请求失败。 5. 服务降级客户端注解设置moke属性，上文已提到了。 6. Dubbo泛华在没有提供api的情况下消费者如何调用服务提供者提供的接口呢？这时就要用到dubbo的泛化功能了。 dubbo泛化就是使用一个GenericService接收注入的服务实例，因为此时不知道具体服务的类型呀，然后使用反射的方式调用GenericService中的方法。 演示如下： provider 12345678910public interface IDemoService &#123; String getMsg();&#125;@DubboService(protocol = &#123;\"dubbo\"&#125;)public class DemoService implements IDemoService&#123; public String getMsg()&#123; return \"泛化功能演示\"; &#125;&#125; consumer 1234567@DubboReference(interfaceName = \"com.pd.service.IDemoService\",generic = true,check = false)GenericService demoService;@GetMapping(\"/generic\")public String generic()&#123; return demoService.$invoke(\"getMsg\",new String[0],null).toString();&#125; 这样就可以通过泛化调用到远程服务了。 7. 配置的优先级在服务提供端，@DubboService注解中的配置高于配置文件 服务端配置的信息，都会装载到url上 客户端拿到url之后能够获取服务端的配置，如果客户端没有重新配置 ，那么就用服务端的配置。 客户端有配置时，覆盖服务端配置。 在客户端，注解上的配置优先级高于配置文件","categories":[{"name":"RPC框架Dubbo","slug":"RPC框架Dubbo","permalink":"https://zzkenyon.github.io/categories/RPC框架Dubbo/"}],"tags":[{"name":"dubbo","slug":"dubbo","permalink":"https://zzkenyon.github.io/tags/dubbo/"}],"keywords":[{"name":"RPC框架Dubbo","slug":"RPC框架Dubbo","permalink":"https://zzkenyon.github.io/categories/RPC框架Dubbo/"}]},{"title":"分库分表-sharding jdbc","slug":"数据库技术-sharding jdbc","date":"2019-04-06T16:00:00.000Z","updated":"2020-12-30T02:20:19.006Z","comments":true,"path":"2019/04/07/数据库技术-sharding jdbc/","link":"","permalink":"https://zzkenyon.github.io/2019/04/07/数据库技术-sharding jdbc/","excerpt":"","text":"ShardingSphere官网 1. 分片核心概念在我们用 Sharding-JDBC 之前，有一些核心概念是必须掌握的。 可以查看官网文档，很详细。 逻辑表 水平拆分的数据库（表）的相同逻辑和数据结构表的总称。例：订单数据根据主键尾数拆分为 10 张表，分别是 t_order_0 到 t_order_9，他们的逻辑表名为 t_order。 真实表（物理表） 在分片的数据库中真实存在的物理表。即上个示例中的 t_order_0 到 t_order_9。 数据节点 数据分片的最小单元。由数据源名称和数据表组成，例：ds_0.t_order_0。 绑定表（ER表） 指分片规则一致的主表和子表。例如：t_order 表和 t_order_item 表，均按照 order_id 分片，则此两张表互为绑定表关系。绑定表之间的多表关联查询不会出现笛卡尔积关联，关联查询效率将大大提升。 广播表（全局表） 指所有的分片数据源中都存在的表，表结构和表中的数据在每个数据库中均完全一致。适用于数据量不大且需要与海量数据的表进行关联查询的场景，例如：字典表。 1.1 分片算法通过分片算法将数据分片，支持通过 =、&gt;=、&lt;=、&gt;、&lt;、BETWEEN 和 IN 分片。 分片算法需要应用方开发者自行实现，可实现的灵活度非常高。 目前提供4种分片算法。 由于分片算法和业务实现紧密相关，因此并未提供内置分片算法，而是通过分片策略将各种场景提炼出来，提供更高层级的抽象，并提供接口让应用开发者自行实现分片算法。 标准分片算法 对应 StandardShardingAlgorithm，用于处理使用单一键作为分片键的 =、IN、BETWEEN AND、&gt;、&lt;、&gt;=、&lt;=进行分片的场景。需要配合 StandardShardingStrategy 使用。 复合分片算法 对应 ComplexKeysShardingAlgorithm，用于处理使用多键作为分片键进行分片的场景，包含多个分片键的逻辑较复杂，需要应用开发者自行处理其中的复杂度。需要配合 ComplexShardingStrategy 使用。 Hint分片算法 对应 HintShardingAlgorithm，用于处理使用 Hint 行分片的场景。需要配合 HintShardingStrategy 使用。 1.2 分片策略包含分片键和分片算法，由于分片算法的独立性，将其独立抽离。真正可用于分片操作的是分片键 + 分片算法，也就是分片策略。目前提供 5 种分片策略。 分片键 用于分片的数据库字段，是将数据库（表）水平拆分的关键字段。例：将订单表中的订单主键的尾数取模分片，则订单主键为分片字段。 SQL 中如果无分片字段，将执行全路由，性能较差。 除了对单分片字段的支持，Apache ShardingSphere 也支持根据多个字段进行分片。 目前提供 5 种分片策略。 标准分片策略 对应 StandardShardingStrategy。提供对 SQL语句中的 =, &gt;, &lt;, &gt;=, &lt;=, IN 和 BETWEEN AND 的分片操作支持。 StandardShardingStrategy 只支持单分片键，提供 PreciseShardingAlgorithm 和 RangeShardingAlgorithm 两个分片算法。 PreciseShardingAlgorithm 是必选的，用于处理 = 和 IN 的分片。 RangeShardingAlgorithm 是可选的，用于处理 BETWEEN AND, &gt;, &lt;, &gt;=, &lt;=分片，如果不配置 RangeShardingAlgorithm，SQL 中的 BETWEEN AND 将按照全库路由处理。 复合分片策略 对应 ComplexShardingStrategy。复合分片策略。提供对 SQL 语句中的 =, &gt;, &lt;, &gt;=, &lt;=, IN 和 BETWEEN AND 的分片操作支持。 ComplexShardingStrategy 支持多分片键，由于多分片键之间的关系复杂，因此并未进行过多的封装，而是直接将分片键值组合以及分片操作符透传至分片算法，完全由应用开发者实现，提供最大的灵活度。 Hint分片策略 对应 HintShardingStrategy。通过 Hint 指定分片值而非从 SQL 中提取分片值的方式进行分片的策略。 不分片策略 对应 NoneShardingStrategy。不分片的策略。 2. 原生API使用 2.1 数据库分片2.2 读写分离3. Spring中使用总结一下，第一，使用数据源需要使用Sharding-JDBC的数据源，而不是容器或者ORM框架定义的数据源，这样才能保证动态选择数据源的实现。 当然，流程实现由sharding-jdbc定义，在交给Druid放进池子里，在交给Mybatis，最后注入到Spring。最外层是Spring，因为代码是从Spring开始调用的。 第二，因为sharding-jdbc是在工作在客户端的，所以我们要在客户端配置分库分表的策略。跟Mycat不一样的是，sharding-jdbc没有内置各种分片策略和算法，需要我们通过表达式或者自定义的配置文件实现。 总提上需要配置的就是数据源和分片策略，配置的方式也是多样的，官网介绍很详细 配置手册 示例使用yml方式进行配置。","categories":[{"name":"数据库技术","slug":"数据库技术","permalink":"https://zzkenyon.github.io/categories/数据库技术/"}],"tags":[{"name":"shardingsphere","slug":"shardingsphere","permalink":"https://zzkenyon.github.io/tags/shardingsphere/"}],"keywords":[{"name":"数据库技术","slug":"数据库技术","permalink":"https://zzkenyon.github.io/categories/数据库技术/"}]},{"title":"Mybatis-与spring整合","slug":"数据库技术-Mybatis-源码分析之与spring整合","date":"2019-03-14T16:00:00.000Z","updated":"2020-07-17T03:30:09.031Z","comments":true,"path":"2019/03/15/数据库技术-Mybatis-源码分析之与spring整合/","link":"","permalink":"https://zzkenyon.github.io/2019/03/15/数据库技术-Mybatis-源码分析之与spring整合/","excerpt":"","text":"在Mybatis原生的API中，有三个对外提供的核心对象 SqlSessionFactory SqlSession getMapper()方法返回的代理对象（包含H对象–MapperProxy） 虽然Mybatis对Jdbc封装置后，已经大大的简化了我们对于数据库的操作，但是在我们的业务代码中不断的创建释放SqlSession也是一件很麻烦的事情。 Mybatis基于Spring的扩展接口，对原生的Api操作进一步进行了简化，所以我们在Spring中使用mybatis时没有再看到这是哪个关键对象在代码中出现的原因。我们只需要吧Mapper接口注入到需要使用的service中，调用她的方法就OK了。 mybatis与spring整合，要弄清楚的几个关键问题： 如果使用@Autowired注入一个Mapper接口，调用接口方法就能找到sql语句执行，那么这个接口在IoC容器中也是一个代理对象吗？ 如果是代理对象，还是不是SqlSession用getMapper方法获得的呢？SqlSession又是什么时候创建的？ 每个会话都要产生一个SqlSession，单例的SqlSessionFactory是什么时候创建的？ Mybatis集成到Spring里面，是为了进一步简化Mybatis的使用，所以只是对mybatis做了一些封装，并没有替换Mybatis的核心对象。也就是说：mybatis jar包中的三个核心对象都会用到，mybatis-spring.jar里面只是做了一些包装或者桥梁的工作 只要我们弄明白这三个关键对象是怎么创建的，也就理解了spring集成mybatis的原理，所以本文将分成三部分进行分析： SqlSessionFactory是在哪里创建的 SqlSession是在哪里创建的 代理Mapper对象是在哪里载入到ioc中的 1. 创建会话工厂SqlSessionFactory首先去看\u0010看Mybatis在spring-boot中的自动配置类配置了一些扫描对象： 1234567// MybatisAutoConfiguration@Bean@ConditionalOnMissingBeanpublic SqlSessionFactory sqlSessionFactory(DataSource dataSource) throws Exception &#123; SqlSessionFactoryBean factory = new SqlSessionFactoryBean(); ...&#125; SqlSessionFactoryBean这个对象看来是spring与mybatis的一个桥梁类了，看看这个类中有哪些内容呢 12public class SqlSessionFactoryBean implements FactoryBean&lt;SqlSessionFactory&gt;, InitializingBean, ApplicationListener&lt;ApplicationEvent&gt; &#123;&#125; 实现了三个接口： InitializingBean 接口，提供了一个方法afterPropertiesSet()，当这个bean的所有属性初始化完成将执行这个方法，定位过去看看： 1234public void afterPropertiesSet() throws Exception &#123; ... // 一些判断检查 this.sqlSessionFactory = buildSqlSessionFactory();&#125; 调用了buildSqlSessionFactory()方法实例化一个SqlSessionFactory对象，跟进代码能发现方法里面使用XMLConfigBuilder对全局配置文件进行解析，调用了mybatis的代码逻辑，解析并创建SqlSessionFactory，之前源码分析都分析过，不再贴代码。 FactoryBean 说明这是一个工厂bean，使用getBean方法获取到的是泛型类型的实例对象，主要是通过接口方法getObject生产实例，定位到： 1234567@Overridepublic SqlSessionFactory getObject() throws Exception &#123; if (this.sqlSessionFactory == null) &#123; afterPropertiesSet(); &#125; return this.sqlSessionFactory;&#125; getObject方法获取创建的sqlSessionFactory对象，如果还没有创建，调用afterPropertiesSet方法创建之。 ApplicationListener 接口 ，说明这个类监听了某个spring-boot的启动事件，找到事件处理方法查看： 1234567@Overridepublic void onApplicationEvent(ApplicationEvent event) &#123; if (failFast &amp;&amp; event instanceof ContextRefreshedEvent) &#123; // fail-fast -&gt; check all statements are completed this.sqlSessionFactory.getConfiguration().getMappedStatementNames(); &#125;&#125; 从事件处理中可以看出，监听的是ContextRefreshedEvent事件，当spring上下文refresh结束将发布此事件。此处调用getMappedStatementNames()之后并没有存储结果，我猜想这里只是为了触发buildAllStatements()，解析缓存中所有未处理的语句节点。建议在添加了所有映射器后调用此方法，因为它提供了快速失败的语句验证。 1234public Collection&lt;MappedStatement&gt; getMappedStatements() &#123; buildAllStatements(); return mappedStatements.values();&#125; 2. 创建会话SqlSession通过上面的配置，我们已经可以在容器中取获取一个DefaultSqlSessionFactory，按照编程式的开发过程，接下来就要使用OpenSession()方法创建一个sqlSession的实现类对象。 但是在spring中我们是不能直接使用DefaultSqlSession的，因为它是线程不安全的！ 所以在spring里面，我们要保证sqlsession实例的线程安全，必须为每一次请求创建单独的sqlSession。但是每次请求用openSqlSession去创建很麻烦。 因此在mybatis-spring的包中，提供了一个线程安全的SqlSession的包装类，用来替代SqlSession，这个类就是SqlSessionTemplate。因为他是线程安全的，所以可以在所有的Dao层共享一个实例（容器默认单例）。 SqlSessionTemplate虽然跟DefaultSqlSession一样定义了操作数据的selectOne()、selectList()、insert()、update()、delete()等所有方法，但是没有自己的实现，全部通过代理模式调用。 1234@Overridepublic &lt;T&gt; T selectOne(String statement) &#123; return this.sqlSessionProxy.selectOne(statement);&#125; 那这个代理对象是怎么来的呢 123456789public SqlSessionTemplate(SqlSessionFactory sqlSessionFactory, ExecutorType executorType, PersistenceExceptionTranslator exceptionTranslator) &#123; ... this.sqlSessionFactory = sqlSessionFactory; this.executorType = executorType; this.exceptionTranslator = exceptionTranslator; this.sqlSessionProxy = (SqlSession) newProxyInstance(SqlSessionFactory.class.getClassLoader(), new Class[] &#123; SqlSession.class &#125;, new SqlSessionInterceptor());&#125; 在构造函数中就创建了这样的一个代理对象，那既然是Jdk动态代理，调用代理方法肯定会走到第三个参数h对象的invoke方法，h对象是SqlSessionInterceptor类型实例，它是SqlSessionTemplate的一个内部类： 123456789101112131415private class SqlSessionInterceptor implements InvocationHandler &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; SqlSession sqlSession = getSqlSession(SqlSessionTemplate.this.sqlSessionFactory, SqlSessionTemplate.this.executorType, SqlSessionTemplate.this.exceptionTranslator); try &#123; Object result = method.invoke(sqlSession, args); if (!isSqlSessionTransactional(sqlSession, SqlSessionTemplate.this.sqlSessionFactory)) &#123; sqlSession.commit(true); &#125; return result; &#125; ... // 异常处理 &#125;&#125; 这里会先用getSqlSession创建一个sqlSession对象，把sqlSessionFactory、执行器类型、异常解析器传进去 总结一下：因为DefaultSqlSession自己做不到每次请求产生一个新的实例，所以 创建一个代理类也实现SqlSession，提供跟默认实现一样的方法，在任何一个方法被调用的时候都先创建一个DefaultSqlSession在调用被代理对象的响应方法。 Mybatis还再自带了一个线程安全的sqlSession实现：SqlSessionManager，实现方式与上面一样，如果不集成到spring中的情况下还要保证线程安全，那么就用SqlSessionManager。 与JdbcTemplate、RedisTemplate一样，SqlSessionTe可以简化Mybatis在spring中的使用，也是spring与mybaits整合中最关键的一个类。 2.2 如何加载一个SqlSessionTemplate到ioc容器因为SqlSessionTemplate是线程安全的，那么在Dao层如何拿到一个SqlSessionTemplate呢？ 在spring中，Mybatis中提供了一个抽象的支持类SqlSessionDaoSupport，该类中持有一个SqlSessionTemplate对象，并且提供了一个getSqlSession()方法，让我们获取SqlSessionTemplate。 那么我们让Dao层的实现类继承抽象类SqlSessionDaoSupport，就能获取到SqlSessionTemplate对象了。 在spring-boot中，自动配置类也为我们自动装配了一个SqlSessionTemplate： 12345678910@Bean // MybatisAutoConfiguration@ConditionalOnMissingBeanpublic SqlSessionTemplate sqlSessionTemplate(SqlSessionFactory sqlSessionFactory) &#123; ExecutorType executorType = this.properties.getExecutorType(); if (executorType != null) &#123; return new SqlSessionTemplate(sqlSessionFactory, executorType); &#125; else &#123; return new SqlSessionTemplate(sqlSessionFactory); &#125;&#125; 3. 接口的扫描注册自动配置代码中有这样一个配置： 1@Import(AutoConfiguredMapperScannerRegistrar.class) 导入了一个动态装载类AutoConfiguredMapperScannerRegistrar，该类实现了ImportBeanDefinitionRegistrar接口，在应用启动时会调用到接口方法registerBeanDefinitions 1234567@Override // AutoConfiguredMapperScannerRegistrarpublic void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; ... BeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(MapperScannerConfigurer.class); ... registry.registerBeanDefinition(MapperScannerConfigurer.class.getName(), builder.getBeanDefinition());&#125; 该方法向Ioc容器中注册了一个配置类MapperScannerConfigurer，这个配置类就是用来扫描Mapper接口的。 MapperScannerConfigurer实现了BeanDefinitionRegistryPostProcessor接口，该接口是BeanFactoryPostProcessor接口的子接口，定义了方法postProcessBeanDefinitionRegistry() 实现这个接口，就可以Spring创建Bean之前，修改某些BeanDefinition的属性。 那么MapperScannerConfigurer重写该方法要做什么呢？ 123456789101112131415161718192021222324@Overridepublic void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) &#123; if (this.processPropertyPlaceHolders) &#123; processPropertyPlaceHolders(); &#125; ClassPathMapperScanner scanner = new ClassPathMapperScanner(registry); scanner.setAddToConfig(this.addToConfig); scanner.setAnnotationClass(this.annotationClass); scanner.setMarkerInterface(this.markerInterface); scanner.setSqlSessionFactory(this.sqlSessionFactory); scanner.setSqlSessionTemplate(this.sqlSessionTemplate); scanner.setSqlSessionFactoryBeanName(this.sqlSessionFactoryBeanName); scanner.setSqlSessionTemplateBeanName(this.sqlSessionTemplateBeanName); scanner.setResourceLoader(this.applicationContext); scanner.setBeanNameGenerator(this.nameGenerator); scanner.setMapperFactoryBeanClass(this.mapperFactoryBeanClass); if (StringUtils.hasText(lazyInitialization)) &#123; scanner.setLazyInitialization(Boolean.valueOf(lazyInitialization)); &#125; scanner.registerFilters(); scanner.scan( StringUtils.tokenizeToStringArray(this.basePackage, ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS));&#125; 创建了一个ClassPathMapperScanner扫描器，经过一番配置之后，执行扫描器的scan操作 12345678910// `ClassPathMapperScanner`public int scan(String... basePackages) &#123; int beanCountAtScanStart = this.registry.getBeanDefinitionCount(); doScan(basePackages); // 调用重载的doscan // Register annotation config processors, if necessary. if (this.includeAnnotationConfig) &#123; AnnotationConfigUtils.registerAnnotationConfigProcessors(this.registry); &#125; return (this.registry.getBeanDefinitionCount() - beanCountAtScanStart);&#125; 首先调用的doscan是ClassPathMapperScanner重载父类的 1234567891011@Overridepublic Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) &#123; Set&lt;BeanDefinitionHolder&gt; beanDefinitions = super.doScan(basePackages); if (beanDefinitions.isEmpty()) &#123; logger.warn(\"No MyBatis mapper was found in '\" + Arrays.toString(basePackages) + \"' package. Please check your configuration.\"); &#125; else &#123; processBeanDefinitions(beanDefinitions); &#125; return beanDefinitions;&#125; 接着会调用它的父类的doscan方法： 123456789101112131415161718192021222324252627// protected Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) &#123; Assert.notEmpty(basePackages, \"At least one base package must be specified\"); Set&lt;BeanDefinitionHolder&gt; beanDefinitions = new LinkedHashSet&lt;&gt;(); for (String basePackage : basePackages) &#123; Set&lt;BeanDefinition&gt; candidates = findCandidateComponents(basePackage); for (BeanDefinition candidate : candidates) &#123; ScopeMetadata scopeMetadata = this.scopeMetadataResolver.resolveScopeMetadata(candidate); candidate.setScope(scopeMetadata.getScopeName()); String beanName = this.beanNameGenerator.generateBeanName(candidate, this.registry); if (candidate instanceof AbstractBeanDefinition) &#123; postProcessBeanDefinition((AbstractBeanDefinition) candidate, beanName); &#125; if (candidate instanceof AnnotatedBeanDefinition) &#123; AnnotationConfigUtils.processCommonDefinitionAnnotations((AnnotatedBeanDefinition) candidate); &#125; if (checkCandidate(beanName, candidate)) &#123; BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(candidate, beanName); definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, this.registry); beanDefinitions.add(definitionHolder); registerBeanDefinition(definitionHolder, this.registry); &#125; &#125; &#125; return beanDefinitions;&#125; 回到子类ClassPathMapperScanner的doscan方法，扫描完之后执行processBeanDefinitions方法，在该方法中，Mapper的beanDefinition中的BeanClass被改为了MapperFactoryean 12345678910private void processBeanDefinitions(Set&lt;BeanDefinitionHolder&gt; beanDefinitions) &#123; GenericBeanDefinition definition; for (BeanDefinitionHolder holder : beanDefinitions) &#123; definition = (GenericBeanDefinition) holder.getBeanDefinition(); ... definition.getConstructorArgumentValues() .addGenericArgumentValue(definition.getBeanClassName()); definition.setBeanClass(this.mapperFactoryBean.getClass()); ...&#125; 也就是说所有的Mapper接口，在容器里面逗比注册成了一个支持泛型的MapperFactoryBean了。为什么要这样做了，进去看看这个类： 1public class MapperFactoryBean&lt;T&gt; extends SqlSessionDaoSupport implements FactoryBean&lt;T&gt; &#123;...&#125; 这个类继承了抽象类SqlSessionDaoSupport，这不就解决了之前的问题，现在每一个注入Mapper的地方，都可以拿到SqlSessionTemplate。 分析到这里，只剩下最后一个问题，有没有用到MapperProxy？如果注册时MapperFactoryBean，难道注入使用的也是MapperFactoryBean吗，这个类并不是代理类啊 4. 接口的注入使用所以注入的到底是一个什么对象，注意看MaperactoryBean也实现了FactoryBean，我们已经见过一次，它可以在getObject方法中修改获取Bean实例的行为。 1234@Override // MapperFactoryBeanpublic T getObject() throws Exception &#123; return getSqlSession().getMapper(this.mapperInterface);&#125; 所以最终还是回到了mybatis的api中，getMapper方法获取到就是一个代理对象。MapperProxy就是该代理对象的h参数","categories":[{"name":"ORM框架","slug":"ORM框架","permalink":"https://zzkenyon.github.io/categories/ORM框架/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://zzkenyon.github.io/tags/Mybatis/"}],"keywords":[{"name":"ORM框架","slug":"ORM框架","permalink":"https://zzkenyon.github.io/categories/ORM框架/"}]},{"title":"Mybatis-源码分析之sql执行","slug":"数据库技术-Mybatis-源码分析之sql执行","date":"2019-03-13T16:00:00.000Z","updated":"2020-07-16T05:02:39.323Z","comments":true,"path":"2019/03/14/数据库技术-Mybatis-源码分析之sql执行/","link":"","permalink":"https://zzkenyon.github.io/2019/03/14/数据库技术-Mybatis-源码分析之sql执行/","excerpt":"","text":"经过解析阶段，我们获得了一个填充完整的Configuration对象，对象中有一个名为mappedStatements的Map&lt;String, MappedStatement&gt; 用于存放解析好的sql配置，还有一个MapperRegistry记录mapper接口与其代理类工厂的映射关系。 执行一条查询之前，首先要获得执行查询的SqlSession对象，在此之前要拿到工厂类SqlSessionFactory的实例。 1、 获取SqlSession使用配置对象创建出一个SqlSessionFactory，这里创建的是默认的实现类 1234//SqlSessionFactoryBuilder.classpublic SqlSessionFactory build(Configuration config) &#123; return new DefaultSqlSessionFactory(config);&#125; 用户代码获取SqlSession 1SqlSession session = sqlSessionFactory.openSession(); openSession方法最终会调用到 1234567891011121314151617//DefaultSqlSessionFactory.classprivate SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) &#123; Transaction tx = null; try &#123; final Environment environment = configuration.getEnvironment(); // 获取事务工厂 final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment( environment); // 创建事务 tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); // 根据事务工厂和默认的执行器类型，创建执行器 &gt;&gt; final Executor executor = configuration.newExecutor(tx, execType); return new DefaultSqlSession(configuration, executor, autoCommit); &#125; catch (Exception e) &#123; ... &#125;&#125; 这里我们知道根据全局配置能直到，创建的事务类型是Jdbc事务，执行器类型默认是 SIMPLE 执行器创建代码： 1234567891011121314151617181920public Executor newExecutor(Transaction transaction, ExecutorType executorType) &#123; executorType = executorType == null ? defaultExecutorType : executorType; executorType = executorType == null ? ExecutorType.SIMPLE : executorType; Executor executor; if (ExecutorType.BATCH == executorType) &#123; executor = new BatchExecutor(this, transaction); &#125; else if (ExecutorType.REUSE == executorType) &#123; executor = new ReuseExecutor(this, transaction); &#125; else &#123; // 没做配置的情况下，默认创建SimpleExecutor executor = new SimpleExecutor(this, transaction); &#125; // 二级缓存开关，settings 中的 cacheEnabled 默认是 true，缓存装饰器 if (cacheEnabled) &#123; executor = new CachingExecutor(executor); &#125; // 植入插件的逻辑，至此，四大对象已经全部拦截完毕 executor = (Executor) interceptorChain.pluginAll(executor); return executor;&#125; 植入插件的逻辑将在单独分析插件实现源码时进行展开。 回到openSqlSession方法，接下来使用创建好的执行器，创建出默认的DefaultSqlSession，这里我们可以分析出对象之间的关系：每次创建SqlSession的时候，都会创建一个新的执行器被它持有，sqlSession的查询动作最终都会由执行器来执行。 2、执行sql查询贴一段用户代码执行查询的操作： 1234567try &#123; BlogMapper mapper = session.getMapper(BlogMapper.class); Blog blog = mapper.selectBlogById(1); System.out.println(blog);&#125; finally &#123; session.close();&#125; 首先根据mapper接口，获取一个mapper对象，这里获取到的对象是mapper对应的代理类工厂生产的代理对象，跟源码看： 1234//DefaultSqlSession.classpublic &lt;T&gt; T getMapper(Class&lt;T&gt; type) &#123; return configuration.getMapper(type, this);&#125; 继续跟进 12345//Configutation.classpublic &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123; //委托给mapperRegistry return mapperRegistry.getMapper(type, sqlSession);&#125; mapperRegistry是什么，前面分析过是映射mapper接口与代理工厂的地方 12345678910111213// MapperRegistry.classpublic class MapperRegistry &#123; private final Configuration config; private final Map&lt;Class&lt;?&gt;, MapperProxyFactory&lt;?&gt;&gt; knownMappers = new HashMap&lt;&gt;(); public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123; final MapperProxyFactory&lt;T&gt; mapperProxyFactory = (MapperProxyFactory&lt;T&gt;) knownMappers.get(type); ... try &#123; return mapperProxyFactory.newInstance(sqlSession); &#125; ...&#125; MapperRegistry根据传入的mapper接口，拿到对应的代理工厂类，注意调用的过程中sqlSession一直再往里面传递，最终要在代理类的invoke方法中落地。那最终我们getmapper方法获取到一个代理对象： 123456789// MapperProxyFactorypublic T newInstance(SqlSession sqlSession) &#123; final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;&gt;(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy);&#125;protected T newInstance(MapperProxy&lt;T&gt; mapperProxy) &#123; // 1：类加载器:2：被代理类实现的接口、3：实现了 InvocationHandler 的触发管理类 return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] &#123; mapperInterface &#125;, mapperProxy);&#125; 1public class MapperProxy&lt;T&gt; implements InvocationHandler MapperProxy实现了InvocationHandler接口，所以它即为此处动态代理的h对象 这里的JDK动态代理，首先使用SQLSession创建了一个触发管理对象MapperProxy，再使用该对象创建出代理对象，因此执行mapper代理对象方法是，首先会进入到触发管理类的invoke方法： 1234567891011121314// MapperProxy.classpublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; try &#123; // toString hashCode equals getClass等方法，无需走到执行SQL的流程 if (Object.class.equals(method.getDeclaringClass())) &#123; return method.invoke(this, args); &#125; else &#123; // 提升获取 mapperMethod 的效率，到 MapperMethodInvoker（内部接口） 的 invoke // 普通方法会走到 PlainMethodInvoker（内部类） 的 invoke return cachedInvoker(method).invoke(proxy, method, args, sqlSession); &#125; &#125; ...&#125; 可以发现没有直接调用方法，为什么没有直接调用？因为代理的是接口，没有逻辑实现 1234567//MapperProxy.classprivate MapperMethodInvoker cachedInvoker(Method method) throws Throwable &#123; ... // 方法被包装成一个 MapperMethod return new PlainMethodInvoker(new MapperMethod(mapperInterface, method, sqlSession.getConfiguration())); ...&#125; 这里的处理分为两个步骤： 先对调用的接口方法进行了一次包装，包装成MapperMethod对象。 创建PlainMethodInvoker对象来执行封装后的方法。 分别进行分析：包装成MapperMethod MapperMethod有两个成员变量： sqlCommand 记录了statement id （例如：com.panda.mapper.BlogMapper.selectBlogById） 和 SQL 类型 方法签名，主要是返回值的类型 1234public MapperMethod(Class&lt;?&gt; mapperInterface, Method method, Configuration config) &#123; this.command = new SqlCommand(config, mapperInterface, method); this.method = new MethodSignature(config, mapperInterface, method);&#125; 跟进这两个构造函数： 123456789101112public SqlCommand(Configuration configuration, Class&lt;?&gt; mapperInterface, Method method) &#123; final String methodName = method.getName(); final Class&lt;?&gt; declaringClass = method.getDeclaringClass(); // 根据调用的接口类和方法名，查看配置对象中有没有对应的ms，这是mybatis的关键设计之一 MappedStatement ms = resolveMappedStatement(mapperInterface, methodName, declaringClass, configuration); ... // 找到对应的ms,利用ms给属性赋值 name = ms.getId(); type = ms.getSqlCommandType(); ...&#125; 第二步method封装完成之后是调用了PlainMethodInvoker的invoke方法执行查询，跟进代码 12345//PlainMethodInvoker.classpublic Object invoke(Object proxy, Method method, Object[] args, SqlSession sqlSession) throws Throwable &#123; // SQL执行的真正起点 return mapperMethod.execute(sqlSession, args);&#125; MapperMethod的 execute(sqlSession, args)方法就是sql执行的起点，注意只要查询还没执行，sqlsession就会一直往下传。 我们先来分析一个静态查询sql的执行： 1234567case SELECT: ... Object param = method.convertArgsToSqlCommandParam(args); // 普通 select 语句的执行入口 &gt;&gt; result = sqlSession.selectOne(command.getName(), param); ...&#125; 首先处理参数，调用convertArgsToSqlCommandParam(args)将调用传入的参数替换sql命令中的参数占位符， 在这之前，要介绍一下这里用到的参数处理器：ParamNameResolver，每次将mapper接口方法封装成一个MapperMethod的时候都生成一个此处理器，注意是一个接口方法生成一个，看构造器方法逻辑： 12345678910111213141516171819202122232425262728293031323334// ParamNameResolver构造器public ParamNameResolver(Configuration config, Method method) &#123; final Class&lt;?&gt;[] paramTypes = method.getParameterTypes(); // 获取参数类型 final Annotation[][] paramAnnotations = method.getParameterAnnotations(); // 获取参数注解 final SortedMap&lt;Integer, String&gt; map = new TreeMap&lt;&gt;(); int paramCount = paramAnnotations.length; // 该循环将从参数的@param注解中获取参数名 for (int paramIndex = 0; paramIndex &lt; paramCount; paramIndex++) &#123; if (isSpecialParameter(paramTypes[paramIndex])) &#123; // 跳过特殊参数，RowBound类型和ResultHandler类型的参数 continue; &#125; String name = null; for (Annotation annotation : paramAnnotations[paramIndex]) &#123; if (annotation instanceof Param) &#123; hasParamAnnotation = true; name = ((Param) annotation).value(); break; &#125; &#125; if (name == null) &#123; // @Param 未指定名称，则使用参数本来的名称 if (config.isUseActualParamName()) &#123; name = getActualParamName(method, paramIndex); // 获取到的名称为arg0... &#125; if (name == null) &#123; // 至此还没有名字，是用参数位置作为名称 name = String.valueOf(map.size()); &#125; &#125; map.put(paramIndex, name); &#125; names = Collections.unmodifiableSortedMap(map); // names 是一个map&#125; 总体逻辑是： 对于每个方法参数，如果注解了@Param，则将该注解中的value指定为该参数的name， 如果没有注解，判断是否配置了isUseActualParamName，配置为true的话，参数名称为”arg”+参数位置，从0开始，如第一个参数为‘arg0’ 如果该配置为false，则参数的名称为“参数位置”，如：0，1，2 最终得到一个参数位置与参数名称的map映射。 此时再来看convertArgsToSqlCommandParam方法 1234// MapperMethod.classpublic Object convertArgsToSqlCommandParam(Object[] args) &#123; return paramNameResolver.getNamedParams(args);&#125; 1234567891011121314151617181920212223//ParamNameResolver.classpublic Object getNamedParams(Object[] args) &#123; final int paramCount = names.size(); if (args == null || paramCount == 0) &#123; return null; &#125; else if (!hasParamAnnotation &amp;&amp; paramCount == 1) &#123; return args[names.firstKey()]; &#125; else &#123; final Map&lt;String, Object&gt; param = new ParamMap&lt;&gt;(); int i = 0; for (Map.Entry&lt;Integer, String&gt; entry : names.entrySet()) &#123; param.put(entry.getValue(), args[entry.getKey()]); // add generic param names (param1, param2, ...) final String genericParamName = GENERIC_NAME_PREFIX + (i + 1); // ensure not to overwrite parameter named with @Param if (!names.containsValue(genericParamName)) &#123; param.put(genericParamName, args[entry.getKey()]); &#125; i++; &#125; return param; &#125;&#125; 获取到参数之后，将调用selectOne 1result = sqlSession.selectOne(command.getName(), param); 12345678//DefaultSqlSession.classpublic &lt;T&gt; T selectOne(String statement, Object parameter) &#123; List&lt;T&gt; list = this.selectList(statement, parameter); if (list.size() == 1) &#123; return list.get(0); &#125; ...&#125; 123public &lt;E&gt; List&lt;E&gt; selectList(String statement, Object parameter) &#123; return this.selectList(statement, parameter, RowBounds.DEFAULT);&#125; 123456public &lt;E&gt; List&lt;E&gt; selectList(String statement, Object parameter, RowBounds rowBounds) &#123; try &#123; MappedStatement ms = configuration.getMappedStatement(statement); return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER); ...&#125; 12345678//CachingExecutor.classpublic &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException &#123; // 获取SQL BoundSql boundSql = ms.getBoundSql(parameterObject); // 创建CacheKey：什么样的SQL是同一条SQL？ &gt;&gt; CacheKey key = createCacheKey(ms, parameterObject, rowBounds, boundSql); return query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);&#125; 到这里关键点又来了，两点：BoundSql的获取 和 CacheKey的生成 首先讲BoundSql，这是最后执行的sql命令的包装类，无论是敬爱sql还是动态sql，在生成BoundSql之前在内存中都只是以配置对象SqlSource的形式存在，SqlSource的数据结构是有层次关系的嵌套结构，在执行查询之前，需要将SqlSource中的各个节点拼接成一条sql语句。跟进源码： 12345//MappedStatement.classpublic BoundSql getBoundSql(Object parameterObject) &#123; BoundSql boundSql = sqlSource.getBoundSql(parameterObject); ... &#125; 1234// StaticSqlSource.classpublic BoundSql getBoundSql(Object parameterObject) &#123; return new BoundSql(configuration, sql, parameterMappings, parameterObject);&#125; 可以看到对于静态的sql，sql没有凭借需求，根据sqlSource就能直接创建出BoundSql返回。 再来看CacheKey：若两个查询拥有相同的CacheKey，我们就认为这是一条查询，开启缓存的情况下会先查询缓存。 那么CacheKey是怎么构成的，或者说，什么样的查询才能确定是同一个查询？ 在BaseExecutor的createCacheKey方法中用到了六个要素： 123456789101112public CacheKey createCacheKey(MappedStatement ms, Object parameterObject, RowBounds rowBounds, BoundSql boundSql) &#123; ... cacheKey.update(ms.getId()); // msId cacheKey.update(rowBounds.getOffset()); // 翻页参数1 cacheKey.update(rowBounds.getLimit()); // 翻页参数2 cacheKey.update(boundSql.getSql());//sql语句 ... cacheKey.update(value); // 参数值 ... cacheKey.update(configuration.getEnvironment().getId());//数据源环境 return cacheKey;&#125; 也就是说，方法相同、翻页参数相同（2个）、sql语句相同、sql参数相同、数据源环境相同的情况下，才会被认为是同一个查询。 怎么比较两个CacheKey是否相同？如果一上来就比较6要素，效率不高，mybatis的做法是重写CacheKey类的hashCode方法和equel方法 让我们回到执行查询主流程上来，获取到boundSql 创建了 cacheKey 之后，调用了CacheExecutor的query方法 1234567891011121314151617181920212223242526//CacheExecutorpublic &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; Cache cache = ms.getCache(); // cache 对象是在哪里创建的？ XMLMapperBuilder类 xmlconfigurationElement() // 由 &lt;cache&gt; 标签决定 if (cache != null) &#123; // flushCache=\"true\" 清空一级二级缓存 &gt;&gt; flushCacheIfRequired(ms); if (ms.isUseCache() &amp;&amp; resultHandler == null) &#123; ensureNoOutParams(ms, boundSql); // 获取二级缓存 // 缓存通过 TransactionalCacheManager、TransactionalCache 管理 @SuppressWarnings(\"unchecked\") List&lt;E&gt; list = (List&lt;E&gt;) tcm.getObject(cache, key); if (list == null) &#123; list = delegate.query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); // 写入二级缓存 tcm.putObject(cache, key, list); // issue #578 and #116 &#125; return list; &#125; &#125; // 走到 SimpleExecutor | ReuseExecutor | BatchExecutor return delegate.query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);&#125; 尝试获取缓存，未命中的话执行装饰器上层的BaseExecutor的query方法，完成之后写入二级缓存 123456789101112131415161718192021222324252627282930//BaseExecutorpublic &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; // 异常体系之 ErrorContext ErrorContext.instance().resource(ms.getResource()).activity(\"executing a query\").object(ms.getId()); if (closed) &#123; throw new ExecutorException(\"Executor was closed.\"); &#125; if (queryStack == 0 &amp;&amp; ms.isFlushCacheRequired()) &#123; // flushCache=\"true\"时，即使是查询，也清空一级缓存 clearLocalCache(); &#125; List&lt;E&gt; list; try &#123; // 防止递归查询重复处理缓存 queryStack++; // 查询一级缓存 // ResultHandler 和 ResultSetHandler的区别 list = resultHandler == null ? (List&lt;E&gt;) localCache.getObject(key) : null; if (list != null) &#123; handleLocallyCachedOutputParameters(ms, key, parameter, boundSql); &#125; else &#123; // 真正的查询流程 list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql); &#125; &#125; finally &#123; queryStack--; &#125; ... return list;&#125; 跟进queryFromDatabase 1234567891011121314151617181920//BaseExecutorprivate &lt;E&gt; List&lt;E&gt; queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; List&lt;E&gt; list; // 先占位 localCache.putObject(key, EXECUTION_PLACEHOLDER); try &#123; // 三种 Executor 的区别，看doUpdate // 默认Simple list = doQuery(ms, parameter, rowBounds, resultHandler, boundSql); &#125; finally &#123; // 移除占位符 localCache.removeObject(key); &#125; // 写入一级缓存 localCache.putObject(key, list); if (ms.getStatementType() == StatementType.CALLABLE) &#123; localOutputParameterCache.putObject(key, parameter); &#125; return list;&#125; 看到了doQuery，终于要开始干活了 12345678910111213141516//SimpleExecutorpublic &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException &#123; Statement stmt = null; try &#123; Configuration configuration = ms.getConfiguration(); // 注意，已经来到SQL处理的关键对象 StatementHandler &gt;&gt; StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); // 获取一个 Statement对象 stmt = prepareStatement(handler, ms.getStatementLog()); // 执行查询 return handler.query(stmt, resultHandler); &#125; finally &#123; // 用完就关闭 closeStatement(stmt); &#125;&#125; 到这里出现了Mybatis四大核心对象的第二个对象StatementHandler，这是一个接口，里面定义了操作jdbc对象StateMent的诸多方法，这里使用newStatementHandler创建了一个RoutingStatementHandler，使用了委托模式，内部持有一个StatementHandler引用，根据不同的配置该引用会指向不同StatementHandler的实现，而外层逻辑只需要调用RoutingStatementHandler`的方法就能将调用委托到具体的实现类中。 默认配置下，StatementHandler的真实实现类是PreparedStatementHandler。 newStatementHandler 123456public StatementHandler newStatementHandler(Executor executor, MappedStatement mappedStatement, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) &#123; StatementHandler statementHandler = new RoutingStatementHandler(executor, mappedStatement, parameterObject, rowBounds, resultHandler, boundSql); // 植入插件逻辑（返回代理对象） statementHandler = (StatementHandler) interceptorChain.pluginAll(statementHandler); return statementHandler;&#125; 在newStatementHandler方法中创建好statementHandler之后，立即对其进行插件拦截操作。 接下来会调用prepareStatement方法创建具体的statement对象，此方法内部完成了statement对象的创建，参数的设置 看PreparedStatementHandler的构造函数： 123public PreparedStatementHandler(Executor executor, MappedStatement mappedStatement, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) &#123; super(executor, mappedStatement, parameter, rowBounds, resultHandler, boundSql);&#125; 调用了父类的构造函数： 1234567protected BaseStatementHandler(Executor executor, MappedStatement mappedStatement, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) &#123; ... // 创建了四大对象的其它两大对象 &gt;&gt; // 创建这两大对象的时候分别做了什么？ this.parameterHandler = configuration.newParameterHandler(mappedStatement, parameterObject, boundSql); this.resultSetHandler = configuration.newResultSetHandler(executor, mappedStatement, rowBounds, parameterHandler, resultHandler, boundSql);&#125; newParameterHandler 创建好parameterHandler之后立即进行插件逻辑植入。 123456public ParameterHandler newParameterHandler(MappedStatement mappedStatement, Object parameterObject, BoundSql boundSql) &#123; ParameterHandler parameterHandler = mappedStatement.getLang().createParameterHandler(mappedStatement, parameterObject, boundSql); // 植入插件逻辑（返回代理对象） parameterHandler = (ParameterHandler) interceptorChain.pluginAll(parameterHandler); return parameterHandler;&#125; newResultSetHandler 创建好resultSetHandler之后立即进行插件逻辑植入。 1234567public ResultSetHandler newResultSetHandler(Executor executor, MappedStatement mappedStatement, RowBounds rowBounds, ParameterHandler parameterHandler, ResultHandler resultHandler, BoundSql boundSql) &#123; ResultSetHandler resultSetHandler = new DefaultResultSetHandler(executor, mappedStatement, parameterHandler, resultHandler, boundSql, rowBounds); // 植入插件逻辑（返回代理对象） resultSetHandler = (ResultSetHandler) interceptorChain.pluginAll(resultSetHandler); return resultSetHandler;&#125; 四大插件适用对象都拦截完成。","categories":[{"name":"ORM框架","slug":"ORM框架","permalink":"https://zzkenyon.github.io/categories/ORM框架/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://zzkenyon.github.io/tags/Mybatis/"}],"keywords":[{"name":"ORM框架","slug":"ORM框架","permalink":"https://zzkenyon.github.io/categories/ORM框架/"}]},{"title":"Mybatis-插件源码分析","slug":"数据库技术-Mybatis-源码分析之插件原理","date":"2019-03-12T16:00:00.000Z","updated":"2020-06-22T02:10:29.004Z","comments":true,"path":"2019/03/13/数据库技术-Mybatis-源码分析之插件原理/","link":"","permalink":"https://zzkenyon.github.io/2019/03/13/数据库技术-Mybatis-源码分析之插件原理/","excerpt":"","text":"插件作用：在不修改mybatis代码和api调用方式的前提下，对调用进行拦截，增加一些特殊的需求 插件可以拦截的对象： Executor StatementHandler ParameterHandler ResultSetHandler 插件的实现原理是动态代理，使用代理解决插件的拦截需要解决四个问题： 1、 代理类什么时候创建 2、 代理类怎么被创建 3、 被代理之后调用的流程是怎样的 4、 多个插件时执行顺序是怎样的 1、自定义一个插件在分析原理之前我们要先清楚怎么使用，那我们怎么去自定义一个插件呢？ 只需要做两件事： 编写自定义的插件类 在全局文件中将该插件配置起来 1.1 编写插件类：插件类需要实现Interceptor接口，该接口有三个方法： 12345678910public interface Interceptor &#123; Object intercept(Invocation invocation) throws Throwable; default Object plugin(Object target) &#123; return Plugin.wrap(target, this); &#125; default void setProperties(Properties properties) &#123; // NOP &#125;&#125; 我们在编写自定义插件时，重点需要实现的方法是intercept(Invocation invocation)方法，该方法就是插件的核心逻辑，我们需要增加的逻辑或者流程是在这个方法中进行实现的。 plugin方法主要负责生成代理类对象，mybatis已经给出了默认的实现，没有特殊的情况一般不需要重写 setProperties方法负责设置插件的属性，有些在配置的时候会设置一些属性（在全局配置文件中），在解析配置文件的时候，需要使用该方法将xml中配置的插件属性设置到插件对象中。该方法默认是没有逻辑的，如果自定义的插件有对外可配置的属性，那么需要重写这个方法。 1.2 添加注解插件类需要添加@Intercepts注解，注解中需要指定该插件拦截的对象类型，拦截哪些方法，以分页插件为例： 1234@Intercepts(&#123; @Signature(type = Executor.class, method = \"query\", args = &#123;MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class&#125;), @Signature(type = Executor.class, method = \"query\", args = &#123;MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class, CacheKey.class, BoundSql.class&#125;),&#125;) 该分页插件拦截将拦截 Executor 类的 query 方法，由于在该类存在重载的query方法，所以这边需要提供两个@Signature。 1.3 配置插件在全局配置文件中进行以下配置： 1234567&lt;plugins&gt; &lt;plugin interceptor=\"com.pd.interceptor.SQLInterceptor\"&gt; &lt;property name=\"panda\" value=\"betterme\" /&gt; &lt;/plugin&gt; &lt;plugin interceptor=\"com.pd.interceptor.MyPageInterceptor\"&gt; &lt;/plugin&gt;&lt;/plugins&gt; 2、插件运行原理分析2.1 插件配置的解析插件配置在全局配置文件中，根据之前的源码分析我们已经清楚整个解析阶段的流程，这里我直接定位到解析逻辑，即XMLConfigBuilder类的parseConfiguration方法： 12345678private void parseConfiguration(XNode root) &#123; try &#123; ... // 插件 pluginElement(root.evalNode(\"plugins\")); ... &#125;&#125; 跟进： 1234567891011private void pluginElement(XNode parent) throws Exception &#123; if (parent != null) &#123; for (XNode child : parent.getChildren()) &#123; String interceptor = child.getStringAttribute(\"interceptor\"); Properties properties = child.getChildrenAsProperties(); Interceptor interceptorInstance = (Interceptor) resolveClass(interceptor).getDeclaredConstructor().newInstance(); interceptorInstance.setProperties(properties); // 设置插件属性 configuration.addInterceptor(interceptorInstance); &#125; &#125;&#125; 可以看到根据interceptor标签解析插件类型以及属性，实例化之后调用setProperties方法设置属性，最后将插件add到Configuration对象中，我们继续跟进，看配置对象是怎么存放插件实例的： 12345//Configurationprotected final InterceptorChain interceptorChain = new InterceptorChain();public void addInterceptor(Interceptor interceptor) &#123; interceptorChain.addInterceptor(interceptor);&#125; Configuration将插件实例放到了interceptorChain成员属性中，这个叫拦截器链的成员，内部封装了一个list用于存放插件实例。看代码： 123456789101112131415public class InterceptorChain &#123; private final List&lt;Interceptor&gt; interceptors = new ArrayList&lt;&gt;(); public Object pluginAll(Object target) &#123; for (Interceptor interceptor : interceptors) &#123; target = interceptor.plugin(target); &#125; return target; &#125; public void addInterceptor(Interceptor interceptor) &#123; interceptors.add(interceptor); &#125; public List&lt;Interceptor&gt; getInterceptors() &#123; return Collections.unmodifiableList(interceptors); &#125;&#125; 注意pluginAll方法在接下来会经常看到，它主要是通过一个for循环调用所有插件实例的plugin方法，对目标对象进行层层代理。 2.2 代理对象的创建和执行这里我还是以分页插件为例进行分析，分页插件主要是对Excutor对象的query方法进行拦截。在创建Excutor之后就要对其进行拦截生成代理对象实现加入插件的逻辑，所以先想想Excutor对象是什么时候创建的？ 之前的源码分析也分析了Excutor对象的创建是在openSession方法调用时，定位代码： 1234567891011//DefaultSqlSessionFactoryprivate SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) &#123; Transaction tx = null; try &#123; ... // 根据事务工厂和默认的执行器类型，创建执行器 &gt;&gt; final Executor executor = configuration.newExecutor(tx, execType); return new DefaultSqlSession(configuration, executor, autoCommit); &#125; ...&#125; 123456789101112//Configurationpublic Executor newExecutor(Transaction transaction, ExecutorType executorType) &#123; ... executor = new SimpleExecutor(this, transaction); // 二级缓存开关，settings 中的 cacheEnabled 默认是 true if (cacheEnabled) &#123; executor = new CachingExecutor(executor); &#125; // 植入插件的逻辑，至此，四大对象已经全部拦截完毕 executor = (Executor) interceptorChain.pluginAll(executor); return executor;&#125; 这里创建出一个SimpleExecutor之后，先对其进行缓存装饰（如果需要的话），然后调用拦截器链的pluginAll方法生成代理对象。 根据以上的分析我们知道pluginAll方法是调用拦截器连中的所有插件实例的plugin方法，而该方法的默认实现是 123default Object plugin(Object target) &#123; return Plugin.wrap(target, this); //&gt;&gt;&#125; 跟进warp方法： 12345678910111213public static Object wrap(Object target, Interceptor interceptor) &#123; // 获取插件类上的Intercepts注解信息,生成一个signatureMap Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap = getSignatureMap(interceptor); Class&lt;?&gt; type = target.getClass(); Class&lt;?&gt;[] interfaces = getAllInterfaces(type, signatureMap); if (interfaces.length &gt; 0) &#123; return Proxy.newProxyInstance( type.getClassLoader(), interfaces, new Plugin(target, interceptor, signatureMap)); &#125; return target;&#125; 该方法首先获取插件类上的@Intercepts注解信息，生成一个signatureMap，mybatis从这个map中可以知道当前的这个插件需要拦截哪些对象的哪些方法。 然后这里使用JDK动态里来生成代理对象，JDK动态代理的三个参数已经接触过很多次了，最重要的是第三个参数触发管理类对象，这边可以看到触发管理类就是Plugin类，那么Plugin肯定实现了InvocationHandler接口，我们找到它实现的invoke方法： 123456789101112public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; try &#123; // 从map中获取被拦截对象的类型对应的拦截方法集合 Set&lt;Method&gt; methods = signatureMap.get(method.getDeclaringClass()); if (methods != null &amp;&amp; methods.contains(method)) &#123; // 取到方法结合且当前方法在集合中 return interceptor.intercept(new Invocation(target, method, args)); &#125; return method.invoke(target, args); &#125; catch (Exception e) &#123; throw ExceptionUtil.unwrapThrowable(e); &#125;&#125; 首先从map中获取被拦截对象的类型对应的拦截方法集合，如果取到方法结合且当前方法在集合中，也就是说当前执行的方法需要拦截，那么调用当前拦截器的intercept方法 判断不用进行拦截，直接通过反射执行当前方法。 intercept方法需要传入一个Invocation对象，这个对象是干嘛用的呢？ 123456789101112131415public class Invocation &#123; private final Object target; private final Method method; private final Object[] args; public Invocation(Object target, Method method, Object[] args) &#123; this.target = target; this.method = method; this.args = args; &#125; public Object proceed() throws InvocationTargetException, IllegalAccessException &#123; return method.invoke(target, args); &#125;&#125; 创建Invocation需要传入被代理的对象target、当前执行的方法method、和方法执行参数 所以我们应该能猜想到，插件逻辑执行完之后，还需要继续执行目标方法的逻辑，mybatis将目标方法的执行上下文封装到Invocation中传递给intercept方法，intercept在执行完插件逻辑之后需要调用Invocation.proceed()方法执行主线逻辑。 2.3 多插件如何代理配置多插件时，代理对象的生成是一层套一层 多插件的执行顺序与配置顺序相反。 3、PageHelper原理还是老规矩，先看怎么使用，在分析原理： 123456@GetMapping(\"/page-helper-test\")public List&lt;Blog&gt; queryBlogs(@RequestParam Integer pageNum)&#123; PageHelper.startPage(pageNum,2); List&lt;Blog&gt; res = mbService.queryBlogs(); return res;&#125; 只需要在调用查询服务之前，调用PageHelper.startPage()方法将分页信息传入，拦截器就能发挥作用，这是为啥呢？跟进这个方法一探究竟： 经过多次调用重载的PageHelper.startPage()方法，最终会进入一下逻辑： 123456789101112public static &lt;E&gt; Page&lt;E&gt; startPage(int pageNum, int pageSize, boolean count, Boolean reasonable, Boolean pageSizeZero) &#123; Page&lt;E&gt; page = new Page&lt;E&gt;(pageNum, pageSize, count); page.setReasonable(reasonable); page.setPageSizeZero(pageSizeZero); //当已经执行过orderBy的时候 Page&lt;E&gt; oldPage = getLocalPage(); if (oldPage != null &amp;&amp; oldPage.isOrderByOnly()) &#123; page.setOrderBy(oldPage.getOrderBy()); &#125; setLocalPage(page); //&gt;&gt; return page;&#125; 将controller传入的分页信息封装成一个Page对象，然后调用setLocalPage方法： 1234protected static final ThreadLocal&lt;Page&gt; LOCAL_PAGE = new ThreadLocal&lt;Page&gt;();protected static void setLocalPage(Page page) &#123; LOCAL_PAGE.set(page);&#125; 原来分页信息存放到了一个ThreadLocal变量中，那么可以猜想，intercept方法肯定会去这个线程私有变量中去取出这个信息，再根据使用的数据库类型做相应的拦截处理，拼接sql语句。 4、应用场景分析4.1 水平分表场景描述：假如一张费用表按照月度拆分为12张表，当查询条件出现月份时，把select语句中的逻辑表明修改为对应月份的费用表名。 实现方式：对query、update方法进行拦截，修改sql语句 4.2 菜单权限控制场景描述：不同角色的用户登录，查询菜单时获取到的菜单结果不同，在前段展示不同的菜单 实现方式：对query方法进行拦截，修改sql语句，加上权限过滤条件 4.3 数据脱敏场景描述：对查询返回的敏感信息进行屏蔽，例如使用XXXX替换掉手机号的中间四位 实现方式：拦截ResultSet，对结果集脱敏","categories":[{"name":"ORM框架","slug":"ORM框架","permalink":"https://zzkenyon.github.io/categories/ORM框架/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://zzkenyon.github.io/tags/Mybatis/"}],"keywords":[{"name":"ORM框架","slug":"ORM框架","permalink":"https://zzkenyon.github.io/categories/ORM框架/"}]},{"title":"Mybatis-源码分析之配置解析","slug":"数据库技术-Mybatis-源码分析之配置解析","date":"2019-03-11T16:00:00.000Z","updated":"2020-07-16T01:49:42.563Z","comments":true,"path":"2019/03/12/数据库技术-Mybatis-源码分析之配置解析/","link":"","permalink":"https://zzkenyon.github.io/2019/03/12/数据库技术-Mybatis-源码分析之配置解析/","excerpt":"","text":"复习总结： mybatis通过sqlSession调用方法来执行sql查询，sqlSession是由单例对象sqlSessionFactory创建的 单例对象sqlSessionFactory的创建需要解析全局配置文件，根据配置对象创建出DefaultSqlSessionFactory 全局配置的解析重点在于mapper的解析，根据mapper配置方式不同分为xml解析和接口解析，每一个解析完成的mapper最终都会调用addMapper方法存储到Configuration.MapperRegistry对象中，该对象维护了每个mapper接口到代理生成对象的映射 mapper中的每一个statement最终都会被解析成一个MappedStatement对象，解析的重点在于SqlSource的创建，动态的、静态的有所区别，最终MappedStatement对象会被添加到Configuration.mappedStatements对象中，这是另一个map，用于维护statementId到MappedStatement对象的映射。 statementId 就是mapper接口对应的查询方法的全限定名，也是mapper映射器中namespace+”.”+sqlId，二者保持绝对的一致。 之前的文章提到使用mybatis的两种方式： 使用statementId硬编码方式调用 123456789public void testStatement() throws IOException &#123; SqlSession session = sqlSessionFactory.openSession(); try &#123; Blog blog = (Blog) session.selectOne(\"com.panda.mybatis.mapper.BlogMapper.selectBlogById\", 1); System.out.println(blog); &#125; finally &#123; session.close(); &#125;&#125; 使用mapper接口调用 12345678910public void testSelect() throws IOException &#123; SqlSession session = sqlSessionFactory.openSession(); // ExecutorType.BATCH try &#123; BlogMapper mapper = session.getMapper(BlogMapper.class); Blog blog = mapper.selectBlogById(1); System.out.println(blog); &#125; finally &#123; session.close(); &#125;&#125; 这两种方式只是在确定statementId的方式上有些不同，最终都是通过SqlSession来执行sql查询的，所以sqlSession就是本文的分析入口。 mybatis中每个SqlSession都会持有一个jdbc连接，SqlSession的接口方法经过层层调用最终都会调用到jdbc的方法，那么我们怎么获取一个SqlSession呢？mybatis为我们提供了一个SqlSessionFactory来获取SqlSession，下面的讲述从SqlSessionFactory的创建开始。 sqlSessionFactory创建代码如下，该对象在应用中以单例形式存在，生命周期与应用相同，一旦创建，就会一直存在。 123String resource = \"mybatis-config.xml\";InputStream inputStream = Resources.getResourceAsStream(resource);sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); 将全局配置文件的文件流传入build方法，创建出一个SqlSessionFactory对象。 1、全局配置的解析进入SqlSessionFactoryBuilder.build方法（贴出核心代码，忽略部分）： 12345678910public SqlSessionFactory build(InputStream inputStream, String environment, Properties properties) &#123; try &#123; // 用于解析 mybatis-config.xml，同时创建了 Configuration 对象 &gt;&gt; XMLConfigBuilder parser = new XMLConfigBuilder(inputStream, environment, properties); // 解析XML，最终返回一个 DefaultSqlSessionFactory &gt;&gt; return build(parser.parse()); &#125; catch (Exception e) &#123; ... &#125;&#125; 主要流程分为： 创建XMLConfigBuilder对象作为全局配置解析器 解析全局配置文件，解析完成获得全局的Configuration对象（核心） 使用Configuration对象创建一个SqlSessionFactory 具体xml文件的解析过程不做展开，主要关心解析出了哪些东西，解析器XMLConfigBuilder继承自BaseConfigBuilder，父类中声明了一个Configuration成员对象，进入parse()方法： 12345678// XMLConfigBuilderpublic Configuration parse() &#123; ... parsed = true; // XPathParser，dom 和 SAX 都有用到 &gt;&gt; parseConfiguration(parser.evalNode(\"/configuration\")); return configuration;&#125; 首先找到”/configuration”标签，继续跟 123456789101112131415161718192021222324252627282930private void parseConfiguration(XNode root) &#123; try &#123; // 对于全局配置文件各种标签的解析 propertiesElement(root.evalNode(\"properties\")); // 解析 settings 标签 Properties settings = settingsAsProperties(root.evalNode(\"settings\")); loadCustomVfs(settings); loadCustomLogImpl(settings); // 类型别名 typeAliasesElement(root.evalNode(\"typeAliases\")); // 插件 pluginElement(root.evalNode(\"plugins\")); // 用于创建对象 objectFactoryElement(root.evalNode(\"objectFactory\")); // 用于对对象进行加工 objectWrapperFactoryElement(root.evalNode(\"objectWrapperFactory\")); // 反射工具箱 reflectorFactoryElement(root.evalNode(\"reflectorFactory\")); // settings 子标签赋值，默认值就是在这里提供的 &gt;&gt; settingsElement(settings); // 创建了数据源 &gt;&gt; environmentsElement(root.evalNode(\"environments\")); databaseIdProviderElement(root.evalNode(\"databaseIdProvider\")); typeHandlerElement(root.evalNode(\"typeHandlers\")); // 解析引用的Mapper映射器 mapperElement(root.evalNode(\"mappers\")); &#125; catch (Exception e) &#123; throw new BuilderException(\"Error parsing SQL Mapper Configuration. Cause: \" + e, e); &#125;&#125; 解析各种子标签： 1.1 properties用来配置参数信息，比如最常见的数据库连接信息，为了避免直接把参数写死在xml中，我们可以把这些参数单独放在properties文件中，用标签引用进来，在xml配置中就可以使用”${}”的形式进行引用。 123456789101112&lt;properties resource=\"db.properties\"&gt;&lt;/properties&gt;&lt;environments default=\"development\"&gt; &lt;environment id=\"development\"&gt; &lt;transactionManager type=\"JDBC\"/&gt;&lt;!-- 单独使用时配置成MANAGED没有事务 --&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"$&#123;jdbc.driver&#125;\"/&gt; &lt;property name=\"url\" value=\"$&#123;jdbc.url&#125;\"/&gt; &lt;property name=\"username\" value=\"$&#123;jdbc.username&#125;\"/&gt; &lt;property name=\"password\" value=\"$&#123;jdbc.password&#125;\"/&gt; &lt;/dataSource&gt; &lt;/environment&gt;&lt;/environments&gt; 可以使用resource引用应用里的相对路劲，也可以是用url指定本地服务器或者网络的绝对路径 1.2 settings里面是mybatis内部的一些核心配置 1.3 typeAliases该标签配置的是类型别名，主要用来简化配置中的全类名。如果每个地方都配置全类名的话，内容会比较多，所以我们可以为自己的Bean创建别名，既可以指定单个类，也可以指定一个package，自动转换 1234&lt;typeAliases&gt; &lt;typeAlias alias=\"blog\" type=\"com.panda.domain.Blog\" /&gt; &lt;package name=\"com.panda.domain\"/&gt;&lt;/typeAliases&gt; 配置别名之后，在映射器配置文件中只需要写别名就行了，例如： 123&lt;select id=\"selectBlogByBean\" parameterType=\"blog\" resultType=\"blog\" &gt; select bid, name, author_id authorId from blog where name = '$&#123;name&#125;'&lt;/select&gt; 1.4 typeHandlers配置java类型与jdbc类型相互转换的处理器，mybatis对于常见的类型已经注册好了一批Handler，对于用户自定义类型，需要自定义编写handler进行转换，例如json对象转换成varchar 1.5 objectFactory数据库返回结果集之后需要转换成java对象，此时需要创建对象实例，由于我们不知道需要处理的类型是什么，有哪些属性，所以不能使用new的方式去创建，只能通过反射。 在mybatis中提供了一个工厂类的接口，叫ObjectFactory专门用来创建对象的实例，里面定义了4个方法： 1234567public interface ObjectFactory &#123; default void setProperties(Properties properties) &#123;// NOP &#125; &lt;T&gt; T create(Class&lt;T&gt; type); &lt;T&gt; T create(Class&lt;T&gt; type, List&lt;Class&lt;?&gt;&gt; constructorArgTypes, List&lt;Object&gt; constructorArgs); &lt;T&gt; boolean isCollection(Class&lt;T&gt; type);&#125; 有一个默认实现类DefaultObjectFactory，创建对象始终都调用了instantiateClass方法，方法中使用反射。默认情况下所有对象都是由该对象创建。 扩展：如果想要修改对象工厂在初始化实体类时候的行为，可以通过继承DefaultObjectFactory自定义对象工厂，并在objectFactory注册，创建对象时会调用到自定义的对象工厂 1.6 plugin插件是Mybatis很强大的机制，更很多其他框架一样，mybatis预留了插件的接口，让mybatis更容易扩展，后面专门分析 1.7 environments此标签用来管理数据库环境，比如我们可以有开发环境测试环境生产环境的数据库，可以再不同环境中使用不同的数据源 一个标签代表一个数据源，这里面有两个关键的子标签，一个是事务管理器标签，一个是数据源标签 如果配置的是“JDBC” 则会使用Connection对象的commit、rollback、close 来管理事务 如果配置的是“MANAGED”，mybatis会把事务交给容器管理，比如Jboss、Weblogic 1.8 mappermappers标签配置的是mybatis中可能会执行到的sql语句半成品，全局配置中的mappers有两种配置方式： 12345678&lt;mappers&gt; &lt;package name=\"com.panda.mybatis.mapper\"/&gt;&lt;/mappers&gt;&lt;mappers&gt; &lt;mapper resource=\"BlogMapper.xml\"/&gt; &lt;mapper url=\"e://....//BlogMapperExt.xml\"/&gt; &lt;mapper mapperClass=\"com.panda.mybatis.mapper.BlogMapper\"/&gt;&lt;/mappers&gt; 2、Mapper映射器的解析1mapperElement(root.evalNode(\"mappers\")); 跟进去 123456789101112131415161718192021222324252627282930313233//XMLConfigBuilder.classprivate void mapperElement(XNode parent) throws Exception &#123; if (parent != null) &#123; for (XNode child : parent.getChildren()) &#123; // 不同的mapper配置方式解析方式也有点区别，但最终都是调用 addMapper()方法（添加到 MapperRegistry）。这个方法和 getMapper() 对应 if (\"package\".equals(child.getName())) &#123; String mapperPackage = child.getStringAttribute(\"name\"); configuration.addMappers(mapperPackage); &#125; else &#123; String resource = child.getStringAttribute(\"resource\"); String url = child.getStringAttribute(\"url\"); String mapperClass = child.getStringAttribute(\"class\"); if (resource != null &amp;&amp; url == null &amp;&amp; mapperClass == null) &#123; // resource 相对路径 ErrorContext.instance().resource(resource); InputStream inputStream = Resources.getResourceAsStream(resource); XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, resource, configuration.getSqlFragments()); // 解析 Mapper.xml，总体上做了两件事情 &gt;&gt; mapperParser.parse(); &#125; else if (resource == null &amp;&amp; url != null &amp;&amp; mapperClass == null) &#123; // url 绝对路径, 与相对路径流程大差不差 ... &#125; else if (resource == null &amp;&amp; url == null &amp;&amp; mapperClass != null) &#123; // class 单个接口 Class&lt;?&gt; mapperInterface = Resources.classForName(mapperClass); configuration.addMapper(mapperInterface); &#125; else &#123; ... &#125; &#125; &#125; &#125;&#125; 对mapper的解析主要分为两种： mapper.xml的解析—使用XMLMapperBuilder类进行解析 mapper接口的解析—调用addMapper(...)方法将mapper添加到MapperRegistry中。 2.1 MapperRegistry这个类用于存放被解析出来的mapper接口 12345public class MapperRegistry &#123; private final Configuration config; // 全局配置对象 private final Map&lt;Class&lt;?&gt;, MapperProxyFactory&lt;?&gt;&gt; knownMappers = new HashMap&lt;&gt;(); ...&#125; 可以看到该类中维护了一个map，存放mapper接口到代理工厂类的映射，此处设计动态代理将在分析执行阶段时进行详细的分析。目前只需要了解被解析过的mapper会被添加到这个类的实例中。 2.2 XMLMapperBuilderXMLMapperBuilder用于对xml映射器进行解析，跟进XMLMapperBuilder的parse方法，它解析的就是xml映射器文件了。 123456789101112131415//XMLMapperBuilder.classpublic void parse() &#123; // 总体上做了两件事情，对于语句的注册和接口的注册 if (!configuration.isResourceLoaded(resource)) &#123; // 1、具体增删改查标签的解析。 一个查询标签被解析成一个MappedStatement。 &gt;&gt; configurationElement(parser.evalNode(\"/mapper\")); configuration.addLoadedResource(resource); // 2、把namespace（接口类型）映射到一个工厂类MapperProxyFactory &gt;&gt; bindMapperForNamespace(); &#125; parsePendingResultMaps(); parsePendingCacheRefs(); parsePendingStatements();&#125; 解析mapper映射器主要做两件事： 解析具体的增删改查标签，每个标签被解析成一个MappedStatement 吧namespace标签映射到一个工厂类MapperProxyFactory，就是MapperRegistry中的map中 2.2.1 configurationElement12345678910111213141516171819202122232425262728293031//XMLMapperBuilder.classprivate void configurationElement(XNode context) &#123; // 添加缓存对象 cacheRefElement(context.evalNode(\"cache-ref\")); // 解析 cache 属性，添加缓存对象 cacheElement(context.evalNode(\"cache\")); // 创建 ParameterMapping 对象 parameterMapElement(context.evalNodes(\"/mapper/parameterMap\")); // 创建 List&lt;ResultMapping&gt; resultMapElements(context.evalNodes(\"/mapper/resultMap\")); // 解析可以复用的SQL sqlElement(context.evalNodes(\"/mapper/sql\")); // 解析增删改查标签，得到 MappedStatement &gt;&gt; buildStatementFromContext(context.evalNodes(\"select|insert|update|delete\")); ...&#125;private void buildStatementFromContext(List&lt;XNode&gt; list) &#123; ... // 解析 Statement &gt;&gt; buildStatementFromContext(list, null);&#125;private void buildStatementFromContext(List&lt;XNode&gt; list, String requiredDatabaseId) &#123; for (XNode context : list) &#123; // 用来解析增删改查标签的 XMLStatementBuilder final XMLStatementBuilder statementParser = new XMLStatementBuilder(configuration, builderAssistant, context, requiredDatabaseId); // 解析 Statement，添加 MappedStatement 对象 &gt;&gt; statementParser.parseStatementNode(); &#125;&#125; 123456//XMLStatementBuilder.classpublic void parseStatementNode() &#123; ... SqlSource sqlSource = langDriver.createSqlSource(configuration, context, parameterTypeClass); ...&#125; 这里就开始将xml中的sql语句进行解析，一条查询语句解析成一个MappedStatement对象，我们主要关注MS的成员变量sqlSource。sqlSource是对xml映射文件中的配置查询的抽象，每条查询配置对应一个sqlSource。 跟进createSqlSource 1234567//XMLLanguageDriver.classpublic SqlSource createSqlSource(Configuration configuration, XNode script, Class&lt;?&gt; parameterType) &#123; //创建sql脚本解析器 XMLScriptBuilder builder = new XMLScriptBuilder(configuration, script, parameterType); //解析脚本 &gt;&gt; return builder.parseScriptNode();&#125; XMLScriptBuilder是用于解析单条sql配置脚本的类 1234567891011//XMLScriptBuilder.classpublic SqlSource parseScriptNode() &#123; MixedSqlNode rootSqlNode = parseDynamicTags(context); SqlSource sqlSource; if (isDynamic) &#123; sqlSource = new DynamicSqlSource(configuration, rootSqlNode); &#125; else &#123; sqlSource = new RawSqlSource(configuration, rootSqlNode, parameterType); &#125; return sqlSource;&#125; 通常我们写的sql配置解析成的类型有StaticSqlSource和DynamicSqlSource两种，很明显这两种类型的对应了静态sql和动态sql，其实对于静态sql，mybatis更常用的是RawSqlSource，因为它在启动的时候就已经计算好了mapping，性能好一些。 parseDynamicTags（） 首先创建MixedSqlNode作为root节点，然后遍历所有子标签 如果子标签是静态文本的话，查看文本中有没有“${}”占位符，有的话用文本创建子节点TextSqlNode,并将当前的 isDynamic= true，这种情况属于sql拼接，有sql注入的风险 若没有该占位符，则用静态文本创建子节点StaticTextSqlNode 如果子标签是动态标签（9个动态标签之一），使用指定标签的Handler创建相应类型的子节点，并将isDynamic= true 创建的所有子节点将add到root节点的contents中 然后XMLScriptBuilder根据isDynamic的值来创建sqlSource对象：如果isDynamic= true则创建DynamicSqlSource，否则创建RawSqlSource Raw是生的，未加工的意思，RawSqlSource是还没加工好的StaticSqlSource，它持有一个SqlSource引用，实例化的时候会创建一个StaticSqlSource并赋值给该引用，创建StaticSqlSource时已经将#{}占位符替换成了？占位，替换#{}时，每处理一个占位符就会生成一个ParameterMapping，最终得到一个名为`ParameterMappings的List 这样设计的原因：静态sql语句不受运行时参数影响，因此在解析阶段就可以将sql、parameterMapping等创建出来，提高静态查询的性能。 让我们回到XMLStatementBuilder代码 1234567891011//XMLStatementBuilder.classpublic void parseStatementNode() &#123; ... SqlSource sqlSource = langDriver.createSqlSource(configuration, context, parameterTypeClass); ... // &gt;&gt; 关键的一步： MappedStatement 的创建 builderAssistant.addMappedStatement(id, sqlSource, statementType, sqlCommandType, fetchSize, timeout, parameterMap, parameterTypeClass, resultMap, resultTypeClass, resultSetTypeEnum, flushCache, useCache, resultOrdered, keyGenerator, keyProperty, keyColumn, databaseId, langDriver, resultSets);&#125; addMappedStatement方法参数非常多，导致方法体很长，但是逻辑确很清晰，这里不贴代码，简单描述一下流程： 首先使用传入的众多参数，初始化了一个MappedStatement.Builder，显然是建造者模式； 然后使用Builder建造一个MappedStatement，并将这个MS加入到Configuration对象的mappedStatements中 Map&lt;String, MappedStatement&gt; mappedStatements 这是Configuration对象用于存储MappedStatement的地方，key是ms的id，就是sql配置文件的 namespace + “.” + sqlid ms解析完成之后我们再回到XMLMapperBuilder.parse()方法，继续看第二步。 123456789101112//XMLMapperBuilder.classpublic void parse() &#123; // 总体上做了两件事情，对于语句的注册和接口的注册 if (!configuration.isResourceLoaded(resource)) &#123; // 1、具体增删改查标签的解析。 一个查询标签被解析成一个MappedStatement。 &gt;&gt; configurationElement(parser.evalNode(\"/mapper\")); configuration.addLoadedResource(resource); // 2、把namespace（接口类型）映射到一个工厂类MapperProxyFactory &gt;&gt; bindMapperForNamespace(); &#125; ...&#125; 2.2.2 bindMapperForNamespace()该方法主要负责把namespace（接口类型）映射到一个工厂类MapperProxyFactory 1234567891011121314151617//XMLMapperBuilder.classprivate void bindMapperForNamespace() &#123; String namespace = builderAssistant.getCurrentNamespace(); if (namespace != null) &#123; Class&lt;?&gt; boundType = null; ... boundType = Resources.classForName(namespace); ... if (boundType != null) &#123; if (!configuration.hasMapper(boundType)) &#123; configuration.addLoadedResource(\"namespace:\" + namespace); // 添加到 MapperRegistry，本质是一个 map，里面也有 Configuration &gt;&gt; configuration.addMapper(boundType); &#125; &#125; &#125;&#125; 判断configuration中有没有注册该接口，没有的添加到 1234//Configuration.classpublic &lt;T&gt; void addMapper(Class&lt;T&gt; type) &#123; mapperRegistry.addMapper(type); // &gt;&gt;&#125; 12345678910111213141516171819//MapperRegistry.classpublic &lt;T&gt; void addMapper(Class&lt;T&gt; type) &#123; if (type.isInterface()) &#123; ... boolean loadCompleted = false; try &#123; // ！Map&lt;Class&lt;?&gt;, MapperProxyFactory&lt;?&gt;&gt; 存放的是接口类型，和对应的工厂类的关系 knownMappers.put(type, new MapperProxyFactory&lt;&gt;(type)); // 注册了接口之后，根据接口，开始解析所有方法上的注解，例如 @Select &gt;&gt; MapperAnnotationBuilder parser = new MapperAnnotationBuilder(config, type); parser.parse(); loadCompleted = true; &#125; finally &#123; if (!loadCompleted) &#123; knownMappers.remove(type); &#125; &#125; &#125;&#125; configuration持有的MapperRegistry对象，用来管理所有的mapper接口与其代理类工厂的映射，从这段代码我们了解到，代理类工厂的类型是MapperProxyFactory，这是一个很重要的类，类中提供了创建mapper代理对象的方法 MapperProxyFactory 本文先简单的介绍一下MapperProxyFactory，后续在分析执行阶段在详细分析动态代理在这里的执行过程。 12345678910111213141516171819202122232425262728public class MapperProxyFactory&lt;T&gt; &#123; private final Class&lt;T&gt; mapperInterface; private final Map&lt;Method, MapperMethodInvoker&gt; methodCache = new ConcurrentHashMap&lt;&gt;(); public MapperProxyFactory(Class&lt;T&gt; mapperInterface) &#123; this.mapperInterface = mapperInterface; &#125; public Class&lt;T&gt; getMapperInterface() &#123; return mapperInterface; &#125; public Map&lt;Method, MapperMethodInvoker&gt; getMethodCache() &#123; return methodCache; &#125; @SuppressWarnings(\"unchecked\") protected T newInstance(MapperProxy&lt;T&gt; mapperProxy) &#123; // 1：类加载器:2：被代理类实现的接口、3：实现了 InvocationHandler 的触发管理类 return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] &#123; mapperInterface &#125;, mapperProxy); &#125; public T newInstance(SqlSession sqlSession) &#123; final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;&gt;(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy); &#125;&#125; 因为这里使用的是JDK动态代理，所以创建代理对象需要一个实现了InvocationHandler接口的触发管理类，调用代理对象的方法都会进入到该管理类的invoke方法。 sql的执行是有sqlSession发起的，所以触发管理类需要获取执行当前sql的sqlsession对象，这样执行代理对象的查询方法才会进入到sqlSession中。 解析阶段的主要流程大致如上，很多细节没有扣，留待以后慢慢学习 总结： 解析主要是全局解析和映射器解析两块，全局解析主要是一些关键配置，映射器解析主要是解析得到MS对象 Ms对象是mybatis中很重要的对象，尤其是其成员sqlSource 解析阶段还为每个mapper接口生成了代理类工厂，这块是mybatis的重要设计","categories":[{"name":"ORM框架","slug":"ORM框架","permalink":"https://zzkenyon.github.io/categories/ORM框架/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://zzkenyon.github.io/tags/Mybatis/"}],"keywords":[{"name":"ORM框架","slug":"ORM框架","permalink":"https://zzkenyon.github.io/categories/ORM框架/"}]},{"title":"SpringBoot启动之上下文刷新(二)","slug":"SpringBoot启动之上下文刷新(二)","date":"2019-03-05T16:00:00.000Z","updated":"2020-08-25T01:40:14.249Z","comments":true,"path":"2019/03/06/SpringBoot启动之上下文刷新(二)/","link":"","permalink":"https://zzkenyon.github.io/2019/03/06/SpringBoot启动之上下文刷新(二)/","excerpt":"","text":"上下文刷新阶段主要做什么事呢？ 注册beanDefinition。 beanDefinition来自哪里？ 引用的spring-boot-starter jar包 用户业务代码中的Component类包括Configuration、Service、Controller等等 了解了主要目标后，我们来分析源码。 12345678910//SpringApplicationprivate void refreshContext(ConfigurableApplicationContext context) &#123; refresh(context); if (this.registerShutdownHook) &#123; try &#123; context.registerShutdownHook(); &#125; ... &#125;&#125; 跟进： 1234protected void refresh(ApplicationContext applicationContext) &#123; Assert.isInstanceOf(AbstractApplicationContext.class, applicationContext); ((AbstractApplicationContext) applicationContext).refresh();&#125; 调用到抽象上下文AbstractApplicationContext中的refresh方法，跟进去： 12345678910111213141516171819202122232425262728293031@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // 准备刷新 prepareRefresh(); // 获取容器 ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // 容器做刷新前准备 prepareBeanFactory(beanFactory); try &#123; // 执行上下文的beanFactory后置处理器方法，这是一个钩子方法，子类中实现 postProcessBeanFactory(beanFactory); // 执行所有的beanFactory后置处理器 invokeBeanFactoryPostProcessors(beanFactory); // 注册bean后置处理器 registerBeanPostProcessors(beanFactory); // 初始化消息源 initMessageSource(); // 初始化事件广播 initApplicationEventMulticaster(); // 供之类实现的，初始化特殊的Bean onRefresh(); // 注册监听器 registerListeners(); // 实例化所有的(non-lazy-init)单例Bean finishBeanFactoryInitialization(beanFactory); // 发布刷新完毕事件 finishRefresh(); &#125; ...&#125; 我们的关注点，beanDefinition的注册，在invokeBeanFactoryPostProcessors方法中，跟进： 1234protected void invokeBeanFactoryPostProcessors(ConfigurableListableBeanFactory beanFactory) &#123; PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(beanFactory, getBeanFactoryPostProcessors()); ...&#125; 继续跟，这个方法的源码非常长，但是逻辑很清晰，首先分析一下入参： beanFactory 就是我么要刷新的容器 beanFactoryPostProcessors 到目前为止上下文中注册的beanFactory后处理器，里面的东西我们在此处不关心。 看这段代码前我们要先明确目标，我们要分析的是bean注册的过程，其他边角逻辑不要去钻牛角尖。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135public static void invokeBeanFactoryPostProcessors(ConfigurableListableBeanFactory beanFactory, List&lt;BeanFactoryPostProcessor&gt; beanFactoryPostProcessors) &#123; // 创建了一个HashSet存放已经执行完的后处理器的beanName Set&lt;String&gt; processedBeans = new HashSet&lt;&gt;(); if (beanFactory instanceof BeanDefinitionRegistry) &#123; // 强转得到注册器 BeanDefinitionRegistry registry = (BeanDefinitionRegistry) beanFactory; // 创建列表存放常规的BeanFactoryPostProcessor List&lt;BeanFactoryPostProcessor&gt; regularPostProcessors = new ArrayList&lt;&gt;(); //创建列表存放BeanDefinitionRegistryPostProcessor List&lt;BeanDefinitionRegistryPostProcessor&gt; registryProcessors = new ArrayList&lt;&gt;(); // 下面一个for循环执行的是参数传入的后处理器，不关心，直接跳过 for (BeanFactoryPostProcessor postProcessor : beanFactoryPostProcessors) &#123; if (postProcessor instanceof BeanDefinitionRegistryPostProcessor) &#123; BeanDefinitionRegistryPostProcessor registryProcessor = (BeanDefinitionRegistryPostProcessor) postProcessor; registryProcessor.postProcessBeanDefinitionRegistry(registry); registryProcessors.add(registryProcessor); &#125; else &#123; regularPostProcessors.add(postProcessor); &#125; &#125; // 创建一个列表 List&lt;BeanDefinitionRegistryPostProcessor&gt; currentRegistryProcessors = new ArrayList&lt;&gt;(); // 关键点来了，从容器中获取BeanDefinitionRegistryPostProcessor // 到目前为止还没有进行过注册，所有的后处理器都是上下文传过来的，容器中怎么会有后处理器呢？ // 答案就是上篇文章提到的root bean，spring boot启动的是会注册的内部启动类 // 其中就有一个bean是BeanDefinitionRegistry后处理器，那就是ConfigurationClassPostProcessor String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); for (String ppName : postProcessorNames) &#123; if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; // 主角被放入了currentRegistryProcessors列表中 currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); processedBeans.add(ppName); &#125; &#125; sortPostProcessors(currentRegistryProcessors, beanFactory); registryProcessors.addAll(currentRegistryProcessors); //调用主角的方法 invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry); currentRegistryProcessors.clear(); // Next, invoke the BeanDefinitionRegistryPostProcessors that implement Ordered. postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); for (String ppName : postProcessorNames) &#123; if (!processedBeans.contains(ppName) &amp;&amp; beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); processedBeans.add(ppName); &#125; &#125; sortPostProcessors(currentRegistryProcessors, beanFactory); registryProcessors.addAll(currentRegistryProcessors); invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry); currentRegistryProcessors.clear(); // Finally, invoke all other BeanDefinitionRegistryPostProcessors until no further ones appear. boolean reiterate = true; while (reiterate) &#123; reiterate = false; postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); for (String ppName : postProcessorNames) &#123; if (!processedBeans.contains(ppName)) &#123; currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); processedBeans.add(ppName); reiterate = true; &#125; &#125; sortPostProcessors(currentRegistryProcessors, beanFactory); registryProcessors.addAll(currentRegistryProcessors); invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry); currentRegistryProcessors.clear(); &#125; // Now, invoke the postProcessBeanFactory callback of all processors handled so far. invokeBeanFactoryPostProcessors(registryProcessors, beanFactory); invokeBeanFactoryPostProcessors(regularPostProcessors, beanFactory); &#125; else &#123; // Invoke factory processors registered with the context instance. invokeBeanFactoryPostProcessors(beanFactoryPostProcessors, beanFactory); &#125; // Do not initialize FactoryBeans here: We need to leave all regular beans // uninitialized to let the bean factory post-processors apply to them! String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanFactoryPostProcessor.class, true, false); // Separate between BeanFactoryPostProcessors that implement PriorityOrdered, // Ordered, and the rest. List&lt;BeanFactoryPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;&gt;(); List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;&gt;(); List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;&gt;(); for (String ppName : postProcessorNames) &#123; if (processedBeans.contains(ppName)) &#123; // skip - already processed in first phase above &#125; else if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; priorityOrderedPostProcessors.add(beanFactory.getBean(ppName, BeanFactoryPostProcessor.class)); &#125; else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; orderedPostProcessorNames.add(ppName); &#125; else &#123; nonOrderedPostProcessorNames.add(ppName); &#125; &#125; // First, invoke the BeanFactoryPostProcessors that implement PriorityOrdered. sortPostProcessors(priorityOrderedPostProcessors, beanFactory); invokeBeanFactoryPostProcessors(priorityOrderedPostProcessors, beanFactory); // Next, invoke the BeanFactoryPostProcessors that implement Ordered. List&lt;BeanFactoryPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;&gt;(orderedPostProcessorNames.size()); for (String postProcessorName : orderedPostProcessorNames) &#123; orderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class)); &#125; sortPostProcessors(orderedPostProcessors, beanFactory); invokeBeanFactoryPostProcessors(orderedPostProcessors, beanFactory); // Finally, invoke all other BeanFactoryPostProcessors. List&lt;BeanFactoryPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;&gt;(nonOrderedPostProcessorNames.size()); for (String postProcessorName : nonOrderedPostProcessorNames) &#123; nonOrderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class)); &#125; invokeBeanFactoryPostProcessors(nonOrderedPostProcessors, beanFactory); // Clear cached merged bean definitions since the post-processors might have // modified the original metadata, e.g. replacing placeholders in values... beanFactory.clearMetadataCache();&#125; 上一篇文章中，讲到将主类注册到容器中时，容器中已经有了5个root bean： 其中的第一个名为org.springframework.context.annotation.internalConfigurationAnnotationProcessor的bean，它的类型是ConfigurationClassPostProcessor 首先调用到的是ConfigurationClassPostProcessor的此方法： 12345@Overridepublic void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) &#123; ... processConfigBeanDefinitions(registry);&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public void processConfigBeanDefinitions(BeanDefinitionRegistry registry) &#123; List&lt;BeanDefinitionHolder&gt; configCandidates = new ArrayList&lt;&gt;(); //获取已注册的beanName，此处获取到 5+1 组合 即5个rootbean 和 1个主类 String[] candidateNames = registry.getBeanDefinitionNames(); for (String beanName : candidateNames) &#123; BeanDefinition beanDef = registry.getBeanDefinition(beanName); ... // 此处检查该类是否为配置类，是否有@Configuration注解 else if (ConfigurationClassUtils.checkConfigurationClassCandidate(beanDef, this.metadataReaderFactory)) &#123; //将主类bd包装成BeanDefinitionHolder添加到候选名单 configCandidates.add(new BeanDefinitionHolder(beanDef, beanName)); &#125; &#125; ... // 配置类解析器 ConfigurationClassParser parser = new ConfigurationClassParser( this.metadataReaderFactory, this.problemReporter, this.environment, this.resourceLoader, this.componentScanBeanNameGenerator, registry); Set&lt;BeanDefinitionHolder&gt; candidates = new LinkedHashSet&lt;&gt;(configCandidates); Set&lt;ConfigurationClass&gt; alreadyParsed = new HashSet&lt;&gt;(configCandidates.size()); do &#123; parser.parse(candidates); parser.validate(); Set&lt;ConfigurationClass&gt; configClasses = new LinkedHashSet&lt;&gt;(parser.getConfigurationClasses()); configClasses.removeAll(alreadyParsed); // Read the model and create bean definitions based on its content if (this.reader == null) &#123; this.reader = new ConfigurationClassBeanDefinitionReader( registry, this.sourceExtractor, this.resourceLoader, this.environment, this.importBeanNameGenerator, parser.getImportRegistry()); &#125; this.reader.loadBeanDefinitions(configClasses); alreadyParsed.addAll(configClasses); candidates.clear(); if (registry.getBeanDefinitionCount() &gt; candidateNames.length) &#123; String[] newCandidateNames = registry.getBeanDefinitionNames(); Set&lt;String&gt; oldCandidateNames = new HashSet&lt;&gt;(Arrays.asList(candidateNames)); Set&lt;String&gt; alreadyParsedClasses = new HashSet&lt;&gt;(); for (ConfigurationClass configurationClass : alreadyParsed) &#123; alreadyParsedClasses.add(configurationClass.getMetadata().getClassName()); &#125; for (String candidateName : newCandidateNames) &#123; if (!oldCandidateNames.contains(candidateName)) &#123; BeanDefinition bd = registry.getBeanDefinition(candidateName); if (ConfigurationClassUtils.checkConfigurationClassCandidate(bd, this.metadataReaderFactory) &amp;&amp; !alreadyParsedClasses.contains(bd.getBeanClassName())) &#123; candidates.add(new BeanDefinitionHolder(bd, candidateName)); &#125; &#125; &#125; candidateNames = newCandidateNames; &#125; &#125; while (!candidates.isEmpty()); ...&#125; 4.4 扩展点4.4.1 ApplicationContextInitializer只定义了一个方法： 1234567public interface ApplicationContextInitializer&lt;C extends ConfigurableApplicationContext&gt; &#123; /** * 在refersh阶段执行 * 可以修改当前applicationContext的属性，例如扩展各种后置处理器 */ void initialize(C applicationContext);&#125; DelegatingApplicationContextInitializer 执行环境属性“context.initializer.classes”中指定的初始化程序，SpringBoot应用程序通过这种方式给用户提供了实现自定义Initializer的机会 ContextIdApplicationContextInitializer 从Environment中获取“spring.application.name”属性生成ContextId对象，将id 设置到上下文中，并在容器里注册ContextId单例对象 ConfigurationWarningsApplicationContextInitializer 在上下文中添加一个BeanFactory后处理器，用来warning因配置错误导致的异常 RSocketPortInfoApplicationContextInitializer 在上下文中增加一个监听器，用于监听RSocketServerInitializedEvent事件，该事件在contextRefresh完成且RSocketServer准备就绪时发布 4.4.2 BeanFactoryPostProcessor只定义了一个方法 在IoC初始化之后执行，用于对已注册的BeanDefinition执行一些自定义操作 12345678@FunctionalInterfacepublic interface BeanFactoryPostProcessor &#123; /** * 在所有的ApplicationContextInitializer执行完之后，所有的beanDefinition都已加载，但还没有实例化之前执行 * 可以对该beanFactory进行任何可执行的操作（具体操作要看具体的beanFactory提供哪些操作） */ void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException;&#125; 4.4.3 BeanDefinitionRegistryPostProcesser自身只定义了一个方法，当然也继承了父接口的方法，在refresh阶段BeanFactoryPostProcessor之前执行 用于在IoC初始化阶段，对IoC的初始化进行一些自定义操作 12345678public interface BeanDefinitionRegistryPostProcessor extends BeanFactoryPostProcessor &#123; /** * 在ApplicationContextInitializer的标准初始化之后修改它的内部bean定义注册表。所有的beanDefinition都已加载，但还没有实例化任何bean。 * 允许在下一个后处理阶段开始之前添加更多的bean定义 */ void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException;&#125; spring boot 内置的ConfigurationClassPostProcessor，是比较重要的后置处理器，用于在refresh阶段进行BeanDefinition的扫描和注册 5、ApplicationContext - DI 阶段5.1 BeanPostProcesser在容器实例化bean之后可以使用BeanPostProcesser对bean对象执行一些操作 因此可以猜测：应该是属于DI阶段的后处理器 参考资料： springboot启动流程（目录） context.refresh","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/categories/SpringBoot/"}],"tags":[{"name":"源码分析","slug":"源码分析","permalink":"https://zzkenyon.github.io/tags/源码分析/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/categories/SpringBoot/"}]},{"title":"ORM框架-发展历史","slug":"数据库技术-Mybatis-ORM框架发展历史","date":"2019-03-04T16:00:00.000Z","updated":"2020-07-16T00:23:29.515Z","comments":true,"path":"2019/03/05/数据库技术-Mybatis-ORM框架发展历史/","link":"","permalink":"https://zzkenyon.github.io/2019/03/05/数据库技术-Mybatis-ORM框架发展历史/","excerpt":"","text":"贴一段最常见的传统Jdbc数据访问代码： 1234567891011121314151617181920212223242526public class JdbcDemo &#123; public static void main(String[] args) &#123; ResultSet re = null; try &#123; Class.forName(\"com.mysql.cj.jdbc.Driver\"); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; try &#123; Connection connection = DriverManager.getConnection( \"jdbc:mysql://10.0.12.72:3306/mybatis-demo\",\"root\",\"C!Fr0ShoW9Nu\"); Statement statement = connection.createStatement(); String sql = \"SELECT * FROM blog\"; re = statement.executeQuery(sql); while(re.next())&#123; Blog blog = new Blog(); blog.setBid(re.getInt(\"bid\")); blog.setName(re.getString(\"name\")); blog.setAuthorId(re.getInt(\"author_id\")); System.out.println(blog); &#125; &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 分析这段代码能发现这种连接数据库获取对象的方式有四大弊端： 1、 造成代码重复 2、 资源管理问题，像Connection、StateMent、ResultSet这些资源需要用户去管理，很可能造成资源泄露 3、 结果集的处理，执行结果ResultSet需要用户代码转换成java对象 4、Sql耦合，查询语句耦合在业务代码中，不好管理。 那么解决思路是什么？写一个工具类，将重复操作和资源管理代码封装进去，查询时只要传入sql语句就行了。 于是 Apache在2003年发布了一个叫Commons DbUtils工具类，可以简化对数据库的操作。 DbUtils使用核心类QueryRunner进行操作。 此外，spring也对原生的JDBC做了封装 1、对于代码重复问题—-sping提供了一个模板方法JdbcTemplate，里面封装了各种各样的exectue、query、update方法 注释： 它是JDBC的核心包的中心类。简化了jdbc的使用，可以避免常见的异常。它封装了jdbc的核心流程，应用只需要提供sql，提取结果集就行了，它是线程安全的。初始话的时候可以设置数据源，所以资源管理的问题也可以解决 2、对于结果集转换 根据不同dto类型实现RowMapper接口，同一类型的对象数据集转换代码只需要写一份 可以使用反射的方式进行优化，这样就只要写一份数据映射代码。 DbUtils和JdbcTemplate，这两个工具类对jdbc做了轻量级的封装，帮我们解决的问题有： 对操作数据的增删改查方法进行了封装 无论是QueryRunner 还是JdbcTemplate 都可以传入一个数据源进行时初始化，也就是资源管理这一部分的事情可以交给专门的数据源组件去做 可以帮助我们映射结果集，无论是映射成List、Map还是POJO 这种轻量化的工具类已经帮助我们解决了很大的问题，但还是存在以下几点不足 Sql语句是写死在代码里的，依旧存在硬编码问题 参数只能按照固定位置的顺序传入，它是通过占位符去替换的，不能传入对象和Map，没有自动映射 在方法里，可以把结果集映射成实体类，但是不能直接把实体类映射成数据库记录，没有自动生成Sql功能 查询没有缓存，性能还不够好 面对这些新的需求，轻量化的工具类是不够用了，ORM框架应运而生。 1、HibernateHibernate是一个很流行的ORM框架，2001年的时候就出现了第一个版本，在使用Hibernate时，我们需要为实体类建立一些hbm的xml映射文件 然后通过Hibernate提供的session的增删改查方法来操作对象。 使用Hibernate操作对象就像是操作数据库的数据一样，Hibernate会自动帮我们生成sql语句，可以屏蔽数据库的差异。自动进行映射。这样业务代码变得更加简洁。程序的可读性更高 映射的配置文件也可以使用注解代替。 session方法也可以通过继承JpaRepository获得，无需手动创建 总结Hibernate特性： 根据数据库方言生成sql语句，代码移植性好 自动管理连接资源 实现了对象和关系型数据库的完全映射，操作对象就像在操作数据库 提供缓存机制 存在的一些问题： 使用get、update、save，操作是所有字段，没有办法指定部分字段，不够灵活 自动生成sql方式，如果要基于sql做一些优化的话，是很困难的，可能会存在性能问题 不支持动态sql 总结起来就是：操作真的很方便，可是还不够灵活，我们需要一个更灵活的框架 2、mybatis与Hibernate相比，mybatis是半自动的Orm框架，恰恰是半自动化解决了Hibernate遗留的问题。mybatis的封装成本没有Hibernate那么高，不会自动生成全部的sql语句，它主要解决的是sql和对象的映射问题。 两种方式使用： 通过传入statementId的方式调用，但这种方式存在硬编码，且id错误在编译时不能发现 通过定义mapper接口，调用接口方法的方式。 总结出mybatis的核心特性： 使用连接池管理连接 Sql与代码分离集中管理 结果集映射 参数映射和动态sql 彩虹昂福sql的提取 缓存（虽然已不常用了） 插件机制（很强大很灵活）","categories":[{"name":"ORM框架","slug":"ORM框架","permalink":"https://zzkenyon.github.io/categories/ORM框架/"}],"tags":[{"name":"ORM","slug":"ORM","permalink":"https://zzkenyon.github.io/tags/ORM/"}],"keywords":[{"name":"ORM框架","slug":"ORM框架","permalink":"https://zzkenyon.github.io/categories/ORM框架/"}]},{"title":"SpringBoot启动之上下文刷新(一)","slug":"SpringBoot启动之上下文刷新(一)","date":"2019-03-04T16:00:00.000Z","updated":"2020-05-29T08:27:58.231Z","comments":true,"path":"2019/03/05/SpringBoot启动之上下文刷新(一)/","link":"","permalink":"https://zzkenyon.github.io/2019/03/05/SpringBoot启动之上下文刷新(一)/","excerpt":"","text":"在学习Context之前我们得先区分一下ApplicationContext和BeanFactory两者之间的关系。 在我们的理解中，容器应该是一个空间的概念，用于存放事物的东西。在spring中，存放的是Bean。而BeanFactory提供了这么一个空间用于存放Bean，所以BeanFactory才是Bean所在的主要容器，而不是我们一直说的ApplicationContext。 既然ApplicationContext不是容器，那它又是啥呢？我们称之为”上下文”。”上下文”的概念我们也许不见得那么熟，但是”场景”，”场所”这样的概念我们应该就比较熟悉了。比如说”拍摄场景”，”交易场所”等。它们的共同点都是事件发生的地方。所以ApplicationContext正是spring定义的应用程序的事件发生场所，也就是所谓的应用上下文。 上面，我了解了BeanFactory作为Bean容器，而ApplicationContext作为上下文。那么Bean容器和上下文之间是什么关系呢？我们可以看一个代码片段： 123456// 通用的应用上下文实现public class GenericApplicationContext extends AbstractApplicationContext implements BeanDefinitionRegistry &#123; // 默认BeanFactory的实现 private final DefaultListableBeanFactory beanFactory; ...&#125; 我们看到BeanFactory是被组合在ApplicationContext当中的，所以它们的其中一种关系就是组合关系。也就是说应用上下文中包含着Bean工厂。 接着，我们再看ApplicationContext的类图 我们看到ApplicationContext和BeanFactory还存在着继承关系，这意味着ApplicationContext可以对外被当做BeanFactory来使用，这也是为什么我们总是把ApplicationContext当做容器来看的主要原因，因为对外来看两者是一体的。 结合上面的组合关系，我们可以知道对内的话ApplicationContext的BeanFactory相关实现会由内部组合的BeanFactory的实现类来完成具体工作，其本质就是静态代理。 后文我将称呼ApplicationContext为上下文，而BeanFactory为Bean容器，进行区分。 举例：AbstractApplicationContext是Context的第一个实现类，虽然是抽象的，但是context的复杂继承结构里定义的接口方法在该抽象类中都有实现。 1 基础-Bean管理spring boot初始化ioc容器的流程：读取xml配置或注解配置文件，对需要管理的Bean构建BeanDefinition对象，并注册到“容器”中，容器根据这些BeanDefinition创建Bean。 annotation或者xml中Bean的配置 –&gt; 生成BeanDefinition –&gt; 创建Bean 1.1 BeanDefinition描述Bean属性的对象，bean的定义。 1.2 BeanDefinitionRegistry该接口中定义了注册BeanDefinition的相关方法，接口中方法： 123456789101112131415161718public interface BeanDefinitionRegistry extends AliasRegistry &#123; // 注册beanDefition void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException; // 移除指定的beanDefinition void removeBeanDefinition(String beanName) throws NoSuchBeanDefinitionException; // 获取指定名称的beanDefinition BeanDefinition getBeanDefinition(String beanName) throws NoSuchBeanDefinitionException; // 判断是否存在指定名称的beanDefinition boolean containsBeanDefinition(String beanName); // 获取容器中所有beanDefinion的名称 String[] getBeanDefinitionNames(); // 获取容器中beanDefinion的数量 int getBeanDefinitionCount(); // 判断指定的beanDefinion在该注册中心是否被使用 boolean isBeanNameInUse(String beanName);&#125; 上下文中组合的容器DefaultListableBeanFactory实现了该接口，因此容器本身也是一个注册器，并且所有的BeanDefitintion注册后都放到了容器中，使用一个ConcurrentHashMap来存放解析到的BeanDefinition 123456public class DefaultListableBeanFactory extends AbstractAutowireCapableBeanFactory implements ConfigurableListableBeanFactory, BeanDefinitionRegistry, Serializable &#123; // 存放beanDefinition的数据结构是一个ConcurrentHashMap private final Map&lt;String, BeanDefinition&gt; beanDefinitionMap = new ConcurrentHashMap&lt;&gt;(256); // …………&#125; GenericApplicationContext实现也实现了注册器接口，所以上下文本身也是一个注册器，但是对于接口方法的具体实现还是直接调用了成员容器的的实现。 1234567891011121314public class GenericApplicationContext extends AbstractApplicationContext implements BeanDefinitionRegistry &#123; @Override public void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException &#123; this.beanFactory.registerBeanDefinition(beanName, beanDefinition); &#125; @Override public void removeBeanDefinition(String beanName) throws NoSuchBeanDefinitionException &#123; this.beanFactory.removeBeanDefinition(beanName); &#125; // ……&#125; 1.3 BeanDefinitionLoaderBeanDefinition加载器，将需要注册的bean资源（Class&lt;?&gt;、Resource、Package、CharSequence）使用给定的注册器进行注册。 加载器的构造方法需要指定BeanDefinition注册器和BeanDefinition资源（可能是类、包、配置文件路径等等）： 1234567891011BeanDefinitionLoader(BeanDefinitionRegistry registry, Object... sources) &#123; ... this.sources = sources; this.annotatedReader = new AnnotatedBeanDefinitionReader(registry); this.xmlReader = new XmlBeanDefinitionReader(registry); if (isGroovyPresent()) &#123; this.groovyReader = new GroovyBeanDefinitionReader(registry); &#125; this.scanner = new ClassPathBeanDefinitionScanner(registry); this.scanner.addExcludeFilter(new ClassExcludeFilter(sources));&#125; 2 创建-准备-刷新现在回到启动过程，看源码： 12345678910public ConfigurableApplicationContext run(String... args) &#123; ... context = createApplicationContext(); //创建 exceptionReporters = getSpringFactoriesInstances(SpringBootExceptionReporter.class, new Class[] &#123; ConfigurableApplicationContext.class &#125;, context); prepareContext(context, environment, listeners, applicationArguments, printedBanner);//准备 refreshContext(context);//刷新 afterRefresh(context, applicationArguments); ...&#125; 首先创建上下文，根据应用的类型创建相应的上下文： 123456switch (this.webApplicationType) &#123;case SERVLET: // 使用反射创建指定的context实现类对象 contextClass = Class.forName(DEFAULT_SERVLET_WEB_CONTEXT_CLASS); ...&#125; servlet web 应用创建的是AnnotationConfigServletWebServerApplicationContext。 实例化之后，实例化工厂中配置的 FailureAnalyzers，这是一个异常分析类，放在这里实例化，我想是因为这个异常分析器主要是针对的是上下文配置和刷新阶段的错误。 准备上下文prepareContext() 梳理一下该方法的参数： context 就是上一步创建的context实例 environment 运行环境，指定profile的所有属性源（默认7个属性源）配置的属性都已经放到了该对象中 listeners 是管理事件发布的，启动时实例化的所有事件监听器都被他管理着 applicationArguments 命令行参数包装对象，默认是没有配置的 printedBanner 不重要不care 123456789101112131415161718192021222324252627private void prepareContext(ConfigurableApplicationContext context, ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) &#123; context.setEnvironment(environment); // 1 context中保存了运行环境 postProcessApplicationContext(context); //2 对context进行后处理 applyInitializers(context); // 3 执行之前实例化的initializers listeners.contextPrepared(context); // 4 广播准备就绪事件 ... // 5 设置是否可以覆盖beanDefinition if (beanFactory instanceof DefaultListableBeanFactory) &#123; ((DefaultListableBeanFactory) beanFactory) .setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding); &#125; // 6 处理延迟加载的配置 if (this.lazyInitialization) &#123; context.addBeanFactoryPostProcessor(new LazyInitializationBeanFactoryPostProcessor()); &#125; // 7、加载当前可以拿到的bena资源 Set&lt;Object&gt; sources = getAllSources(); Assert.notEmpty(sources, \"Sources must not be empty\"); // 8 解析资源 load(context, sources.toArray(new Object[0])); //9 广播事件 listeners.contextLoaded(context);&#125; 1、context中保存了运行环境 2、对context进行后处理： 若SpringApplication 成员beanNameGenerator不为 null ，设置容器的beanName生成器。 若成员 resourceLoader 不为 null ，设置资源加载器 设置容器的转换服务类 1234567891011121314151617protected void postProcessApplicationContext(ConfigurableApplicationContext context) &#123; if (this.beanNameGenerator != null) &#123; context.getBeanFactory().registerSingleton(AnnotationConfigUtils.CONFIGURATION_BEAN_NAME_GENERATOR, this.beanNameGenerator); &#125; if (this.resourceLoader != null) &#123; if (context instanceof GenericApplicationContext) &#123; ((GenericApplicationContext) context).setResourceLoader(this.resourceLoader); &#125; if (context instanceof DefaultResourceLoader) &#123; ((DefaultResourceLoader) context).setClassLoader(this.resourceLoader.getClassLoader()); &#125; &#125; if (this.addConversionService) &#123; context.getBeanFactory().setConversionService(ApplicationConversionService.getSharedInstance()); &#125;&#125; 3、执行之前实例化的initializers: 使用泛型处理器GenericTypeResolver 获取 初始化类的 泛型变量，若当前上下文是该泛型变量的实例，则执行initializer.initialize(context)方法。 12345678protected void applyInitializers(ConfigurableApplicationContext context) &#123; for (ApplicationContextInitializer initializer : getInitializers()) &#123; Class&lt;?&gt; requiredType = GenericTypeResolver.resolveTypeArgument(initializer.getClass(), ApplicationContextInitializer.class); Assert.isInstanceOf(requiredType, context, \"Unable to call initializer.\"); initializer.initialize(context); &#125;&#125; 有哪些初始化类呢？他们的初始化做了些什么？ 4、广播上下文准备就绪事件ApplicationContextInitializedEvent，可以看一下有哪几个监听器坚听了该事件，分别又做了什么呢？ 123456789101112131415161718192021// 工厂配置中的所有监听器以及他们监听的事件org.springframework.context.ApplicationListener=\\ //ContextRefreshedEventorg.springframework.boot.ClearCachesApplicationListener,\\ //ParentContextAvailableEventorg.springframework.boot.builder.ParentContextCloserApplicationListener,\\ //ApplicationEnvironmentPreparedEventorg.springframework.boot.context.FileEncodingApplicationListener,\\ //ApplicationEnvironmentPreparedEventorg.springframework.boot.context.config.AnsiOutputApplicationListener,\\ //ApplicationEnvironmentPreparedEvent ApplicationPreparedEventorg.springframework.boot.context.config.ConfigFileApplicationListener,\\ //ApplicationEnvironmentPreparedEventorg.springframework.boot.context.config.DelegatingApplicationListener,\\ //ApplicationEnvironmentPreparedEvent ApplicationFailedEventorg.springframework.boot.context.logging.ClasspathLoggingApplicationListener,\\ //ApplicationStartingEvent ApplicationEnvironmentPreparedEvent //ApplicationPreparedEvent ContextClosedEvent ApplicationFailedEventorg.springframework.boot.context.logging.LoggingApplicationListener,\\ //ApplicationStartingEventorg.springframework.boot.liquibase.LiquibaseServiceLocatorApplicationListener 这里没有符合的监听器，没有做任何处理， 注意：虽然没有内置的监听器来处理该事件，但是可以留给程序员去扩展 5、设置是否可以覆盖beanDefinition 6、处理延迟加载的配置 这里的处理是如果配置了延迟加载（默认是true），向上下文添加一个后置处理器LazyInitializationBeanFactoryPostProcessor，该处理器的执行逻辑就是注册beanDefinition时，将beanDefinition 中的延迟加载标志设置为true。这样所有的bean都会延迟加载。 7、加载当前可以拿到的bena资源 这里能拿到的资源默认只有启动方法中传入的springboot启动类 8、加载获取到的资源类，调用链很长，但是任务很明确–&gt;将主类注册到容器中 9、发布上下文加载完成的事件 ApplicationPreparedEvent 那些监听器会响应呢？ ConfigFileApplicationListener，LoggingApplicationListener， ConfigFileApplicationListener我们在加载环境对象的时候就接触过了，这里又出来是做了什么呢 ： 12345678// ConfigFileApplicationListenerprivate void onApplicationPreparedEvent(ApplicationEvent event) &#123; this.logger.switchTo(ConfigFileApplicationListener.class); addPostProcessors(((ApplicationPreparedEvent) event).getApplicationContext());&#125;protected void addPostProcessors(ConfigurableApplicationContext context) &#123; context.addBeanFactoryPostProcessor(new PropertySourceOrderingPostProcessor(context));&#125; 添加了一个后处理器PropertySourceOrderingPostProcessor，处理逻辑很简单，如果属性源MutablePropertySources中有一个叫”defaultProperties“的属性源，将他放到List的最后面 再看LoggingApplicationListener此时做了什么 12345678910111213//`LoggingApplicationListener`private void onApplicationPreparedEvent(ApplicationPreparedEvent event) &#123; ConfigurableListableBeanFactory beanFactory = event.getApplicationContext().getBeanFactory(); if (!beanFactory.containsBean(LOGGING_SYSTEM_BEAN_NAME)) &#123; beanFactory.registerSingleton(LOGGING_SYSTEM_BEAN_NAME, this.loggingSystem); &#125; if (this.logFile != null &amp;&amp; !beanFactory.containsBean(LOG_FILE_BEAN_NAME)) &#123; beanFactory.registerSingleton(LOG_FILE_BEAN_NAME, this.logFile); &#125; if (this.loggerGroups != null &amp;&amp; !beanFactory.containsBean(LOGGER_GROUPS_BEAN_NAME)) &#123; beanFactory.registerSingleton(LOGGER_GROUPS_BEAN_NAME, this.loggerGroups); &#125;&#125; 判断容器中是否存在名为springBootLoggingSystem的bean，不存在则将本对象的成员loggingSystem注册进去，然后注册日志文件logFile、注册loggerGroups 上下文准备阶段先整理这么些内容，下一篇继续讲上下文刷新。","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/categories/SpringBoot/"}],"tags":[{"name":"源码分析","slug":"源码分析","permalink":"https://zzkenyon.github.io/tags/源码分析/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/categories/SpringBoot/"}]},{"title":"SpringBoot启动之环境准备阶段","slug":"SpringBoot启动之环境准备阶段","date":"2019-02-28T16:00:00.000Z","updated":"2020-05-28T09:22:38.534Z","comments":true,"path":"2019/03/01/SpringBoot启动之环境准备阶段/","link":"","permalink":"https://zzkenyon.github.io/2019/03/01/SpringBoot启动之环境准备阶段/","excerpt":"","text":"环境对象用来干什么的？ 环境对象用来收集项目的各种配置，并且可以做到在不同环境（开发环境、测试环境、生产环境）中，这些配置可以很方便的切换。 在数据结构的设计上，环境包括两块内容：profiles 和 properties profiles 就是环境名称，比如测试环境test、开发环境dev、生产环境pro、默认的default等。 properties 是环境属性，由一对对的 key:value 组成 在底层实现上，properties 是从许多不同的属性源获取的 接口设计Environment的接口设计将profile和property操作进行了隔离，如下图所示：PropertyResolver接口定义了properties的相关操作，Environment接口定义了获取profile的的操作。ConfigurablePropertyResolver接口在父接口基础上增加了用于属性类型转换的ConversionService ConfigurableEnvironment接口在以上所有接口基础上，增加设置profile、获取属性源等操作 数据结构数据结构的定义在抽象类AbstractEnvironment中 123456789101112public abstract class AbstractEnvironment implements ConfigurableEnvironment &#123; private final Set&lt;String&gt; activeProfiles = new LinkedHashSet&lt;&gt;(); private final Set&lt;String&gt; defaultProfiles = new LinkedHashSet&lt;&gt;(getReservedDefaultProfiles()); private final MutablePropertySources propertySources = new MutablePropertySources(); //构造函数，调用属性源定制方法 public AbstractEnvironment() &#123; customizePropertySources(this.propertySources); &#125; //属性源定制方法，抽象类中无定制，子类需要定制属性源重载此方法即可 protected void customizePropertySources(MutablePropertySources propertySources) &#123; &#125;&#125; 可以看到 profile的数据结构就是两个String set，单纯的profile就是String对象表示环境的名称，defaultProfiles中只有一个元素“default”，在创建环境对象的时候就初始化了。 上文提到过property键值对，是通过不同的来源获取，比如main函数的args参数、应用的配置文件application.yml、系统的属性、jvm的属性、servelet的属性等等 创建环境对象时属性源的定制放到子类中进行，抽象类中无定制，举例说明：实现类StandardEnvironment 重载了customizePropertySources方法，添加了两个属性源“systemEnvironment”和“systemProperties” ；其子类StandardServletEnvironment 又进行了重载，又添加了两个属性源“servletContextInitParams”和“servletConfigInitParams” 。所以当Servlet环境对象创建出来的时候，已经有4个属性源被添加了进去，在后续执行阶段中还会添加多种属性源。 环境抽象类中的成员MutablePropertySources就是用来管理这些属性源的，看代码： 12345public class MutablePropertySources implements PropertySources &#123; private final List&lt;PropertySource&lt;?&gt;&gt; propertySourceList = new CopyOnWriteArrayList&lt;&gt;(); ...//operator&#125; MutablePropertySources组合了一个List用来存放众多的属性源，继承了管理属性源的PropertySources接口 12345678public interface PropertySources extends Iterable&lt;PropertySource&lt;?&gt;&gt; &#123; ... //根据名称判断是否存在属性源 boolean contains(String name); // 返回指定名称的属性源 @Nullable PropertySource&lt;?&gt; get(String name);&#125; 可以看到PropertySources接口继承了Iterable接口，所以MutablePropertySources肯定也定义了迭代器方式访问List属性源。 属性源接着我们看属性源的实现，从抽象类开始说起： 12345public abstract class PropertySource&lt;T&gt; &#123; protected final String name; protected final T source; //...&#125; 抽象属性源内部有两个成员，属性源名称和泛型属性源对象。这里为什么要用泛型？因为不同属性源的源对象类型不同，有的源对象时Map&lt;&gt;类型，servelet源对象是SelveletContext和SelveleConfig类型，还有组合源对象（源对象是多个属性源源组成的list）等等。 此外，抽象内部还声明了两个内部类：StubPropertySource 和 CompairsonPrppertySource ： StubPropertySource 是用于占位的属性源，在已知属性源名称却还没拿到源对象的时候，会创建一个占位属性源放到list中，等拿到原对象再进行替换。 CompairsonPrppertySource 是仅用于比较的属性源。由于属性源的equals方法是根据属性源名称进行判断的，所以比较属性源只有名称。 启动过程中会出现的属性源： systemEnvironment 源类型是SystemEnvironmentPropertySource 源对象是Map类型 systemProperties 源类型是PropertiesPropertySource 构造函数接受properties对象，源对象是Map类型 servletContextInitParams 源类型是ServletContextPropertySource，源对象是SelveleContext类型 servletConfigInitParams 源类型是ServletConfigPropertySource，源对象是SelveleConfig类型 commandLineArgs 源类型是SimpleCommandLinePropertySource，源对象是CommandLineArgs类型 application:[classpath:/application.yml] 源类型是OriginTrackedMapPropertySource 源对象是Map类型 random 源类型是RandomValuePropertySource，源对象是Random类型 启动代码分析12345678public ConfigurableApplicationContext run(String... args) &#123; ... try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); ... &#125;&#125; 以上代码是run()方法中创建并配置Environment对象的过程，首先把args参数封装成了一个DefaultApplicationArguments，因为args也是springboot程序配置的方式之一，所以环境创建需要将其作为属性源。 调用prepareEnvironment()方法创建运行环境，传入两个参数，一个是目前为止注册的事件监听器，另一个是包装好的命令行配置。跟进代码 12345678910111213private ConfigurableEnvironment prepareEnvironment(SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments) &#123; // 创建对象 ConfigurableEnvironment environment = getOrCreateEnvironment(); // 使用SpringApplication对象的成员配置对象，一般不会做配置 configureEnvironment(environment, applicationArguments.getSourceArgs()); ConfigurationPropertySources.attach(environment); // 发布事件，读取配置文件就是在这里 listeners.environmentPrepared(environment); // 绑定环境 bindToSpringApplication(environment); ...&#125; 首先是创建环境对象，根据当前项目类型，创建不同的环境实例，web应用创建StandardServletEnvironment实例 12345678private ConfigurableEnvironment getOrCreateEnvironment() &#123; ... switch (this.webApplicationType) &#123; case SERVLET: return new StandardServletEnvironment(); ... &#125;&#125; StandardServletEnvironment代码层次较多，这里不再贴代码，简单描述一下： StandardServletEnvironment继承自StandardEnvironment，在往上继承了AbstractEnvironment，AbstractEnvironment构造器只调用了一个方法 1protected void customizePropertySources(MutablePropertySources propertySources); 该方法AbstractEnvironment并没有给出具体实现，这是一个钩子，具体实现交给不同的环境类自己去实现 比如StandardEnvironment的实现，添加了两个属性源systemEnvironment和systemProperties： 12345678// StandardEnvironment@Overrideprotected void customizePropertySources(MutablePropertySources propertySources) &#123; propertySources.addLast( new PropertiesPropertySource(SYSTEM_PROPERTIES_PROPERTY_SOURCE_NAME, getSystemProperties())); propertySources.addLast( new SystemEnvironmentPropertySource(SYSTEM_ENVIRONMENT_PROPERTY_SOURCE_NAME, getSystemEnvironment()));&#125; 再比如：StandardServletEnvironment的实现中添加了servletContextInitParams 和 servletConfigInitParams 12345678910//StandardServletEnvironment@Overrideprotected void customizePropertySources(MutablePropertySources propertySources) &#123; propertySources.addLast(new StubPropertySource(SERVLET_CONFIG_PROPERTY_SOURCE_NAME)); propertySources.addLast(new StubPropertySource(SERVLET_CONTEXT_PROPERTY_SOURCE_NAME)); if (JndiLocatorDelegate.isDefaultJndiEnvironmentAvailable()) &#123; propertySources.addLast(new JndiPropertySource(JNDI_PROPERTY_SOURCE_NAME)); &#125; super.customizePropertySources(propertySources);&#125; StubPropertySource 表示这是占位属性源，因为此时还没有初始化servlet容器，还没有拿到servlet的配置。 因此，我们的环境类StandardServletEnvironment构造函数调用完成之后就已经添加了4个属性源。 让我们回到prepareEnvironment() 创建好对象之后，就是配置环境对象，首先将之前传入的命令行配置包装对象添加到属性源中，此时属性源数量达到5个。 接下来会向监听器发布一个ApplicationEnvironmentPrepared事件，表示环境准备好了，然后ConfigFileApplicationListener监听了此事件， 123456789//`ConfigFileApplicationListener`private void onApplicationEnvironmentPreparedEvent(ApplicationEnvironmentPreparedEvent event) &#123; List&lt;EnvironmentPostProcessor&gt; postProcessors = loadPostProcessors(); postProcessors.add(this); AnnotationAwareOrderComparator.sort(postProcessors); for (EnvironmentPostProcessor postProcessor : postProcessors) &#123; postProcessor.postProcessEnvironment(event.getEnvironment(), event.getSpringApplication()); &#125;&#125; 然而在事件处理逻辑中并没有马上去读取配置文件，而是将自己添加到了Environment的后处理器列表中，因为ConfigFileApplicationListener同时也实现了EnvironmentPostProcessor接口。 然后开始逐个调用后处理器逻辑，调用到自己时： 1234@Overridepublic void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application) &#123; addPropertySources(environment, application.getResourceLoader());&#125; 1234protected void addPropertySources(ConfigurableEnvironment environment, ResourceLoader resourceLoader) &#123; RandomValuePropertySource.addToEnvironment(environment); new Loader(environment, resourceLoader).load();&#125; 此处先添加了第6个属性源 RandomValuePropertySource ，然后加载配置文件，成为第7个属性源 配置文件加载结束后会称为OriginTrackedMapPropertiesSource ，配置信息会解析成map存储在属性源中，如图","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/categories/SpringBoot/"}],"tags":[{"name":"源码分析","slug":"源码分析","permalink":"https://zzkenyon.github.io/tags/源码分析/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/categories/SpringBoot/"}]},{"title":"SpringBoot启动之事件机制","slug":"SpringBoot启动之事件机制","date":"2019-02-27T16:00:00.000Z","updated":"2020-05-28T09:22:00.702Z","comments":true,"path":"2019/02/28/SpringBoot启动之事件机制/","link":"","permalink":"https://zzkenyon.github.io/2019/02/28/SpringBoot启动之事件机制/","excerpt":"","text":"springboot启动过程分为几个步骤，准备环境-准备上下文-上下文刷新（ioc容器初始化），在每个步骤前后，主流程会触发一些事件的发布，启动初期注册好的一系列监听器监听到感兴趣的事件后，去执行一些特定的初始化任务。 这种设计，可以很好地将不同阶段初始化的内容从主流程中解耦出来，减少主流程的复杂性。所以要学习springboot启动过程，首先要了解事件的发布和监听机制。 首先我们看一下EventObject，这个类定义了一个事件，该类中的source属性可以用来表示事件源，即哪个对象触发的事件。 1234567891011121314151617package java.util;public class EventObject implements java.io.Serializable &#123; private static final long serialVersionUID = 5516075349620653480L; /** * 触发事件时将触发对象传进来 */ protected transient Object source; public EventObject(Object source) &#123; if (source == null) throw new IllegalArgumentException(\"null source\"); this.source = source; &#125; ...// getSource &amp; toString&#125; 其次我们需要了解一下关于事件监听的接口EventListener: 1234package java.util;public interface EventListener &#123;&#125; 这个接口没有任何方法，但是JDK文档已经明确告诉我们：所有事件的监听必须继承此接口。 接下来我们来看spring中是怎么使用的，Spring中也给我们提供了一套事件处理机制，其中几个较为关键的接口和类分别是: ApplicationEvent 事件 ApplicationListener 事件监听器 ApplicationEventPublisher 事件发布者 ApplicationEventMulticaster 下面我们依次看一下这几个类与接口： 123456789101112131415161718package org.springframework.context;import java.util.EventObject;public abstract class ApplicationEvent extends EventObject &#123; private static final long serialVersionUID = 7099057708183571937L; /*事件发生时间 */ private final long timestamp; public ApplicationEvent(Object source) &#123; super(source); this.timestamp = System.currentTimeMillis(); &#125; public final long getTimestamp() &#123; return this.timestamp; &#125;&#125; ApplicationEvent直接继承了EventObject，增加了一个时间戳字段。 1234567package org.springframework.context;import java.util.EventListener;/*泛型是监听的具体时间类型*/public interface ApplicationListener&lt;E extends ApplicationEvent&gt; extends EventListener &#123; // 处理事件的函数 void onApplicationEvent(E event);&#125; 我们可以看到该接口继承EventListener，多了一个方法，用于处理事件。 12345678910package org.springframework.context;public interface ApplicationEventPublisher &#123; /** * 发布具体事件 */ void publishEvent(ApplicationEvent event); void publishEvent(Object event);&#125; 这个接口比较重要,它是用来触发一个事件的(虽然方法的名称为发布事件)，调用方法publishEvent过后，事件对应的listener将会执行相应的内容。 ApplicationEventMulticaster接口管理ApplicationListener的同时可以执行listener监听事件的方法： 12345678910111213141516171819202122232425package org.springframework.context.event;import org.springframework.context.ApplicationEvent;import org.springframework.context.ApplicationListener;import org.springframework.core.ResolvableType;/** * 管理一系列的监听者，负责把事件发布给他们 */public interface ApplicationEventMulticaster &#123; // 添加监听器 void addApplicationListener(ApplicationListener&lt;?&gt; listener); // 添加一个侦听器bean来通知所有事件。 void addApplicationListenerBean(String listenerBeanName); // 移除监听器 void removeApplicationListener(ApplicationListener&lt;?&gt; listener); // 移除监听器bean void removeApplicationListenerBean(String listenerBeanName); // 移除所有监听器 void removeAllListeners(); // 向指定事件的监听器广播事件 void multicastEvent(ApplicationEvent event); // 重载方法 void multicastEvent(ApplicationEvent event, ResolvableType eventType);&#125; ApplicationEventMulticaster的子类SimpleApplicationEventMulticaster ，是SpringApplication.run()方法中用到的事件处理类 springboot启动入口SpringBoot应用启动时，首先会创建出一个SpringBootApplication实例，之后执行该对象的run方法启动应用。先来看看创建实例的构造函数做了什么： 123456789public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123; this.resourceLoader = resourceLoader; Assert.notNull(primarySources, \"PrimarySources must not be null\"); this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources)); this.webApplicationType = WebApplicationType.deduceFromClasspath(); setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass();&#125; 参数一：resourceLoader - 资源加载器，默认情况下启动该参数为 null 参数二：primarySources - 主资源，可以接受多个配置类对象，默认情况下该参数为main函数所在的类(注解了@SpringBootApplication的类)，例如：DemoApplication.class 初始化类成员： 初始化this.resourceLoader - 将参数一直接赋值给该成员 初始化this.primarySources - 将参数二转换成LinkedHashSet类型，并赋值给该成员 初始化this.webApplicationType - 这是一个枚举类型成员，根据类路径中是否存在相关类型来判断此应用的类型赋值给该成员，有三种应用类型SERVLET / REACTIVE / NONE 初始化this.initializers - 读取META/spring.factories文件中注册的ApplicationContextInitializer类信息，创建若干个ApplicationContextInitializer bean，组成List赋值给该成员 初始化this.listeners - 读取META/spring.factories文件中注册的ApplicationListener类信息，创建若干个ApplicationListener bean，组成List赋值给该成员 初始化this.mainApplicationClass - 通过new出一个RuntimeException，并获取该异常的栈追踪信息，然后从中获取main方法所在的类对象，赋值给该成员 我们主要关注setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class))这一句 在org/springframework/boot/spring-boot/2.2.0.RELEASE/spring-boot-2.2.0.RELEASE.jar!/META-INF/spring.factories配置文件中只指定了一个Listener 1234567891011# Application Listenersorg.springframework.context.ApplicationListener=\\org.springframework.boot.ClearCachesApplicationListener,\\org.springframework.boot.builder.ParentContextCloserApplicationListener,\\org.springframework.boot.context.FileEncodingApplicationListener,\\org.springframework.boot.context.config.AnsiOutputApplicationListener,\\org.springframework.boot.context.config.ConfigFileApplicationListener,\\org.springframework.boot.context.config.DelegatingApplicationListener,\\org.springframework.boot.context.logging.ClasspathLoggingApplicationListener,\\org.springframework.boot.context.logging.LoggingApplicationListener,\\org.springframework.boot.liquibase.LiquibaseServiceLocatorApplicationListener 先将这些ApplicationListener实例化存在SpringApplication中 构造结束后，我们来到run方法： 1234567891011public ConfigurableApplicationContext run(String... args) &#123; ... SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); ...&#125;private SpringApplicationRunListeners getRunListeners(String[] args) &#123; Class&lt;?&gt;[] types = new Class&lt;?&gt;[] &#123; SpringApplication.class, String[].class &#125;; return new SpringApplicationRunListeners(logger, getSpringFactoriesInstances(SpringApplicationRunListener.class, types, this, args));&#125; 这里将实例化SpringApplicationRunListener对象，看spring.factories文件 12org.springframework.boot.SpringApplicationRunListener=\\org.springframework.boot.context.event.EventPublishingRunListener 创建了EventPublishingRunListener实例 123456789101112131415161718//EventPublishingRunListenerpublic class EventPublishingRunListener implements SpringApplicationRunListener, Ordered &#123; private final SpringApplication application; private final String[] args; // 核心对象S private final SimpleApplicationEventMulticaster initialMulticaster; public EventPublishingRunListener(SpringApplication application, String[] args) &#123; this.application = application; this.args = args; this.initialMulticaster = new SimpleApplicationEventMulticaster(); for (ApplicationListener&lt;?&gt; listener : application.getListeners()) &#123; // 这里将之前实例化的ApplicationListener全部交给了SimpleApplicationEventMulticaster this.initialMulticaster.addApplicationListener(listener); &#125; &#125;&#125; 它持有的 SimpleApplicationEventMulticaster就是负责spring启动事件广播的类，可以这样理解：spring产生的事件都丢给这个类，而这个类内部维护了所有的事件监听器，SimpleApplicationEventMulticaster收到事件就将事件广播给所有的监听者。 run 函数就是调用这些方法传入事件 然后这些方法会将事件对SimpleApplicationEventMulticaster持有的ApplicationListener尽心广播，触发事件处理逻辑。 下一篇文章重点关注ConfigFileApplicationListener，这个监听器在环境对象准备好之后就会加载application配置文件。","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/categories/SpringBoot/"}],"tags":[{"name":"源码分析","slug":"源码分析","permalink":"https://zzkenyon.github.io/tags/源码分析/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/categories/SpringBoot/"}]},{"title":"虚拟机-vagrant&virtualBox使用说明","slug":"分布式-vagrant&virtualBox使用说明","date":"2019-01-21T16:00:00.000Z","updated":"2020-06-12T00:41:35.630Z","comments":true,"path":"2019/01/22/分布式-vagrant&virtualBox使用说明/","link":"","permalink":"https://zzkenyon.github.io/2019/01/22/分布式-vagrant&virtualBox使用说明/","excerpt":"","text":"vagrant是一个工具，用于创建和部署虚拟化开发环境的，能与virtualVM、virtualBox等虚拟机软件搭配使用。 拿VirtualBox举例，VirtualBox会开放一个创建虚拟机的接口，Vagrant会利用这个接口创建虚拟机，并且通过Vagrant来管理，配置和自动安装虚拟机。 安装最新版virtualBox 安装最新版vagrant 1、创建虚拟机首先下载镜像，我们使用vagrant box add 命令进行下载 Vagrant 的 box，是一个打包好的单一文件，其中包含了一个完整系统的虚拟机相关数据。 123456# 添加virtualBox，名字可自定义，使用官方的命名不需要url，下载速度慢，建议使用国内镜像源下载vagrant box add &#123;name&#125; &#123;url&#125;# 列出已下载所有的virtualBoxvagrant box list# 移除指定的virtualBoxvagrant box remove &#123;name&#125; 本文使用中国科技大学的centos7镜像源，在cmd任意目录下执行： 1vagrant box add centos7 http://mirrors.ustc.edu.cn/centos-cloud/centos/7/vagrant/x86_64/images/CentOS-7-x86_64-Vagrant-1708_01.VirtualBox.box 在用户目录下新建文件夹 如：E:/vagrant/，在目录下执行 1vgrant init 会生成一个vagrantfile文件，该文件是将要创建的虚拟机属性配置文件，如下修改文件： 123456789101112131415161718192021222324Vagrant.configure(&quot;2&quot;) do |config| (1..3).each do |i| config.vm.define &quot;node#&#123;i&#125;&quot; do |node| # 设置虚拟机的Box node.vm.box = &quot;centos7&quot; # 设置虚拟机的主机名 node.vm.hostname=&quot;node#&#123;i&#125;&quot; # 设置虚拟机的IP node.vm.network &quot;public_network&quot;, ip: &quot;192.168.2.#&#123;200+i&#125;&quot; # VirtaulBox相关配置 node.vm.provider &quot;virtualbox&quot; do |v| # 设置虚拟机的名称 v.name = &quot;node#&#123;i&#125;&quot; # 设置虚拟机的内存大小 v.memory = 2048 # 设置虚拟机的CPU个数 v.cpus = 1 end end endend 保存后，在当前目录执行 1vagrant up vagrant会根据vagrantfile创建3台虚拟机并启动，本文将采用桥接网卡的网络模型，因此在virtualBox中将虚拟机关闭之后，对网络进行设置，取消默认勾选的NAT网络，只剩下桥接网卡。 2、网络模型选择2.1 网络选型原则​ 第一：每个网络只负载一种业务类型的数据流量，功能单一化。例如连接外网用一个网络、虚拟机之间互通用一个网络、虚拟机与主机之间互通又是一个网络。这样的话可使每种网络上的数据流量比较纯净，同时也可以避免因为网络故障而影响到全部的业务。 ​ 第二：在保证网络功能的前提下，单一的网络要保证最小的连通性、最大的隔离性。比如用于连接外网的网络，最好禁止掉连通宿主机，其它虚拟机这种额外的功能，可最大程序的提高效率。 ​ 第三：网络的独立性。当有多种技术可以达成某种网络功能时，选型时应选择对外部环境依赖程度最小、独立性最高的实现方式，避免因外宿主机换了一个无线网络环境，而影响到在宿主机上虚拟出来的网络。 ​ 第四：最后一条就是效率。当有多种选择时，数据流动路径最短的那一种，往住是效率最高的一种。 2.2 四种网络模式连通性汇总列表“o”表示连接，“x”表示不通。前提条件是用VirtualBox创建出网络后，没有进行额外的配置，NAT网络没有进行端口映射、仅主机网络没有进行连接共享等。理论上，通过一定的技术手段，所有的模式对所有的网络都是可以连通的。 2.3 VirtualBox四种网络模式独立性独立性即对外部环境依赖性，分成高、中，低三档，越高说明越依赖于外部环境。 2.4 四种网络模式的典型应用例如想用VirtualBox创建虚拟机，以安装部署OpenStack,那么应该用VirtualBox创建四个网络，每个网络都有单独的目的，每种网络各司其职，同时对外部的依赖性降到最低。 3、远程登录本文选用的桥接网卡，虚拟机将与宿主机共享网络，在一个网络之中的设备（宿主机以及同一路由器下的设备）都能使用桥接网卡的ip地址远程登录到虚拟机中，端口默认22，可以自行修改。 在登陆之前需要修改虚拟机sshd配置 123456vim /etc/ssh/sshd_config# 修改项如下PasswordAuthentication=yes#重启sshd服务service sshd restart 笔者宿主机ip为192.168.2.110 查看node1虚拟机桥接网卡ip为 192.168.2.112，因此执行 1ssh -p 22 root@192.168.2.112 输入密码完成登录。 参考： VirtualBox四种网络模式及典型配置","categories":[{"name":"分布式架构技术","slug":"分布式架构技术","permalink":"https://zzkenyon.github.io/categories/分布式架构技术/"}],"tags":[{"name":"vagrant","slug":"vagrant","permalink":"https://zzkenyon.github.io/tags/vagrant/"}],"keywords":[{"name":"分布式架构技术","slug":"分布式架构技术","permalink":"https://zzkenyon.github.io/categories/分布式架构技术/"}]},{"title":"虚拟机-vagrantfile简析","slug":"分布式-vagrantfile简析","date":"2019-01-21T16:00:00.000Z","updated":"2020-06-12T00:41:47.214Z","comments":true,"path":"2019/01/22/分布式-vagrantfile简析/","link":"","permalink":"https://zzkenyon.github.io/2019/01/22/分布式-vagrantfile简析/","excerpt":"","text":"参考： Vagrant的配置文件Vagrantfile详解 1、box设置1config.vm.box = &quot;centos7&quot; 该名称是再使用 vagrant init 中后面跟的名字。 2、hostname设置1config.vm.hostname = &quot;node1&quot; 设置hostname非常重要，因为当我们有很多台虚拟服务器的时候，都是依靠hostname來做识别的。比如，我安装了centos1,centos2 两台虚拟机，再启动时，我可以通过vagrant up centos1来指定只启动哪一台。 3、虚拟机网络设置12345//Host-only模式config.vm.network &quot;private_network&quot;, ip: &quot;192.168.10.11&quot;//Bridge模式config.vm.network &quot;public_network&quot;, ip: &quot;10.1.2.61&quot; Vagrant的网络连接方式有三种： NAT : 缺省创建，用于让vm可以通过host转发访问局域网甚至互联网。 host-only : 只有主机可以访问vm，其他机器无法访问它。 bridge : 此模式下vm就像局域网中的一台独立的机器，可以被其他机器访问。 123config.vm.network :private_network, ip: &quot;192.168.33.10&quot;配置当前vm的host-only网络的IP地址为192.168.33.10 host-only 模式的IP可以不指定，而是采用dhcp自动生成的方式，如 : 1config.vm.network &quot;private_network&quot;, type: &quot;dhcp” 123456#创建一个bridge桥接网络，指定IPconfig.vm.network &quot;public_network&quot;, ip: &quot;192.168.0.17&quot;#创建一个bridge桥接网络，指定桥接适配器config.vm.network &quot;public_network&quot;, bridge: &quot;en1: Wi-Fi (AirPort)&quot;#创建一个bridge桥接网络，不指定桥接适配器config.vm.network &quot;public_network&quot; 4、同步目录设置1config.vm.synced_folder &quot;D:/xxx/code&quot;, &quot;/home/www/&quot; 前面的路径(D:/xxx/code)是本机代码的地址，后面的地址就是虚拟机的目录。虚拟机的/vagrant目录默认挂载宿主机的开发目录(可以在进入虚拟机机后，使用df -h 查看)，这是在虚拟机启动时自动挂载的。我们还可以设置额外的共享目录，上面这个设定，第一个参数是宿主机的目录，第二个参数是虚拟机挂载的目录。 5、端口转发设置1config.vm.network :forwarded_port, guest: 80, host: 8080 上面的配置把宿主机上的8080端口映射到客户虚拟机的80端口，例如你在虚拟机上使用nginx跑了一个Go应用，那么你在host上的浏览器中打开http://localhost:8080时，Vagrant就会把这个请求转发到虚拟机里跑在80端口的nginx服务上。不建议使用该方法，因为涉及端口占用问题，常常导致应用之间不能正常通信，建议使用Host-only和Bridge方式进行设置。 guest和host是必须的，还有几个可选属性： guest_ip：字符串，vm指定绑定的Ip，缺省为0.0.0.0 host_ip：字符串，host指定绑定的Ip，缺省为0.0.0.0 protocol：字符串，可选TCP或UDP，缺省为TCP 6、定义vm的configure配置节点(一个节点就是一个虚拟机)123config.vm.define :mysql do |mysql_config|...end 表示在config配置中，定义一个名为mysql的vm配置，该节点下的配置信息命名为mysql_config； 如果该Vagrantfile配置文件只定义了一个vm，这个配置节点层次可忽略。 还可以在一个Vagrantfile文件里建立多个虚拟机，一般情况下，你可以用多主机功能完成以下任务： 分布式的服务，例如网站服务器和数据库服务器 分发系统 测试接口 灾难测试 12345678Vagrant.configure(&quot;2&quot;) do |config| config.vm.define &quot;web&quot; do |web| web.vm.box = &quot;apache&quot; end config.vm.define &quot;db&quot; do |db| db.vm.box = &quot;mysql&quot; endend 当定义了多主机之后，在使用vagrant命令的时候，就需要加上主机名，例如vagrant ssh web；也有一些命令，如果你不指定特定的主机，那么将会对所有的主机起作用，比如vagrant up；你也可以使用表达式指定特定的主机名，例如vagrant up /follower[0-9]/。 7、通用数据 设置一些基础数据，供配置信息中调用。1234app_servers = &#123; :service1 =&gt; &apos;192.168.33.20&apos;, :service2 =&gt; &apos;192.168.33.21&apos;&#125; 这里是定义一个hashmap，以key-value方式来存储vm主机名和ip地址。 8、配置信息12345ENV[&quot;LC_ALL&quot;] = &quot;en_US.UTF-8&quot;指定vm的语言环境，缺省地，会继承host的locale配置Vagrant.configure(&quot;2&quot;) do |config| # ...end 参数2，表示的是当前配置文件使用的vagrant configure版本号为Vagrant 1.1+,如果取值为1，表示为Vagrant 1.0.x Vagrantfiles，旧版本暂不考虑，记住就写2即可。 do … end 为配置的开始结束符，所有配置信息都写在这两段代码之间。 config是为当前配置命名，你可以指定任意名称，如myvmconfig，在后面引用的时候，改为自己的名字即可。 9、vm提供者配置123config.vm.provider :virtualbox do |vb| # ...end 10 vm provider通用配置虚机容器提供者配置，对于不同的provider，特有的一些配置，此处配置信息是针对virtualbox定义一个提供者，命名为vb，跟前面一样，这个名字随意取，只要节点内部调用一致即可。 配置信息又分为通用配置和个性化配置，通用配置对于不同provider是通用的，常用的通用配置如下： 123456789101112131415vb.name = &quot;centos7&quot;指定vm-name，也就是virtualbox管理控制台中的虚机名称。如果不指定该选项会生成一个随机的名字，不容易区分。vb.gui = truevagrant up启动时，是否自动打开virtual box的窗口，缺省为falsevb.memory = &quot;1024&quot;指定vm内存，单位为MBvb.cpus = 2设置CPU个数 11 vm provider个性化配置(virtualbox)上面的provider配置是通用的配置，针对不同的虚拟机，还有一些的个性的配置，通过vb.customize配置来定制。 对virtual box的个性化配置，可以参考：VBoxManage modifyvm 命令的使用方法。详细的功能接口和使用说明，可以参考virtualbox官方文档。 1234567891011121314151617181920修改vb.name的值v.customize [&quot;modifyvm&quot;, :id, &quot;--name&quot;, &quot;mfsmaster2&quot;]如修改显存，缺省为8M，如果启动桌面，至少需要10M，如下修改为16M：vb.customize [&quot;modifyvm&quot;, :id, &quot;--vram&quot;, &quot;16&quot;]调整虚拟机的内存vb.customize [&quot;modifyvm&quot;, :id, &quot;--memory&quot;, &quot;1024&quot;]指定虚拟CPU个数vb.customize [&quot;modifyvm&quot;, :id, &quot;--cpus&quot;, &quot;2&quot;]增加光驱：vb.customize [&quot;storageattach&quot;,:id,&quot;--storagectl&quot;, &quot;IDE Controller&quot;,&quot;--port&quot;,&quot;0&quot;,&quot;--device&quot;,&quot;0&quot;,&quot;--type&quot;,&quot;dvddrive&quot;,&quot;--medium&quot;,&quot;/Applications/VirtualBox.app/Contents/MacOS/VBoxGuestAdditions.iso&quot;]注：meduim参数不可以为空，如果只挂载驱动器不挂在iso，指定为“emptydrive”。如果要卸载光驱，medium传入none即可。从这个指令可以看出，customize方法传入一个json数组，按照顺序传入参数即可。json数组传入多个参数v.customize [&quot;modifyvm&quot;, :id, &quot;--name&quot;, “mfsserver3&quot;, &quot;--memory&quot;, “2048&quot;] 12 一组相同配置的vm前面配置了一组vm的hash map，定义一组vm时，使用如下节点遍历。 1234567#遍历app_servers map，将key和value分别赋值给app_server_name和app_server_ipapp_servers.each do |app_server_name, app_server_ip| #针对每一个app_server_name，来配置config.vm.define配置节点，命名为app_config config.vm.define app_server_name do |app_config| #此处配置，参考config.vm.define endend 如果不想定义app_servers，下面也是一种方案: 12345678(1..3).each do |i| config.vm.define &quot;app-#&#123;i&#125;&quot; do |node| app_config.vm.hostname = &quot;app-#&#123;i&#125;.vagrant.internal&quot; app_config.vm.provider &quot;virtualbox&quot; do |vb| vb.name = app-#&#123;i&#125; end endend 13 provision任务你可以编写一些命令，让vagrant在启动虚拟机的时候自动执行，这样你就可以省去手动配置环境的时间了。 脚本何时会被执行 第一次执行vagrant up命令 执行vagrant provision命令 执行vagrant reload –provision或者vagrant up –provision命令 你也可以在启动虚拟机的时候添加–no-provision参数以阻止脚本被执行 provision任务是什么？ provision任务是预先设置的一些操作指令，格式： 1234config.vm.provision 命令字 json格式参数config.vm.provion 命令字 do |s| s.参数名 = 参数值end 每一个 config.vm.provision 命令字 代码段，我们称之为一个provisioner。根据任务操作的对象，provisioner可以分为： Shell File Ansible CFEngine Chef Docker Puppet Salt 根据vagrantfile的层次，分为： configure级：它定义在 Vagrant.configure(“2”) 的下一层次，形如： config.vm.provision … vm级：它定义在 config.vm.define “web” do |web| 的下一层次，web.vm.provision … 执行的顺序是先执行configure级任务，再执行vm级任务，即便configure级任务在vm定义的下面才定义。例如： 123456789Vagrant.configure(&quot;2&quot;) do |config| config.vm.provision &quot;shell&quot;, inline: &quot;echo 1&quot; config.vm.define &quot;web&quot; do |web| web.vm.provision &quot;shell&quot;, inline: &quot;echo 2&quot; end config.vm.provision &quot;shell&quot;, inline: &quot;echo 3&quot;end 输出结果： 123==&gt; default: &quot;1&quot;==&gt; default: &quot;2&quot;==&gt; default: &quot;3&quot; 如何使用 单行脚本 helloword只是一个开始，对于inline模式，命令只能在写在一行中。 单行脚本使用的基本格式： 1config.vm.provision &quot;shell&quot;, inline: &quot;echo fendo&quot; shell命令的参数还可以写入do … end代码块中，如下： 123config.vm.provision &quot;shell&quot; do |s| s.inline = &quot;echo hello provision.&quot;end 内联脚本 如果要执行脚本较多，可以在Vagrantfile中指定内联脚本，在Vagrant.configure节点外面，写入命名内联脚本： 1234$script = &lt;&lt;SCRIPTecho I am provisioning...echo hello provision.SCRIPT 然后，inline调用如下： 1config.vm.provision &quot;shell&quot;, inline: $script 外部脚本 也可以把代码写入代码文件，并保存在一个shell里，进行调用： 1config.vm.provision &quot;shell&quot;, path: &quot;script.sh&quot; script.sh的内容： 1echo hello provision. ####","categories":[{"name":"分布式架构技术","slug":"分布式架构技术","permalink":"https://zzkenyon.github.io/categories/分布式架构技术/"}],"tags":[{"name":"vagrant","slug":"vagrant","permalink":"https://zzkenyon.github.io/tags/vagrant/"}],"keywords":[{"name":"分布式架构技术","slug":"分布式架构技术","permalink":"https://zzkenyon.github.io/categories/分布式架构技术/"}]},{"title":"SpringCloud-服务降级组件Hystrix","slug":"SpringCloud-Hystrix使用及原理","date":"2019-01-06T16:00:00.000Z","updated":"2020-12-01T06:17:55.541Z","comments":true,"path":"2019/01/07/SpringCloud-Hystrix使用及原理/","link":"","permalink":"https://zzkenyon.github.io/2019/01/07/SpringCloud-Hystrix使用及原理/","excerpt":"","text":"目标： 为了避免单点服务故障造成服务雪崩，需要引入服务熔断功能 Hystrix是在服务调用者中使用，所以调用链最底层的服务无需使用 虽然Eureka-client包中貌似已经依赖了netflix-hystrix，但是要正常使用断路器功能还需单独引入依赖 Feign 默认是关闭服务熔断功能的，需要在yml中修改配置 feign.hystrix.enable: true 1. 使用服务调用服务，在微服务系统内部一般使用ribbon和feign两种负载方式调用，针对这两种调用方式，开启服务熔断的方式也不相同。 无论使用哪种方式调用底层服务，需要使用断路器都需要增加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 1.1 restTemplate 在主类上注解@EnableCircuitBreaker开启熔断器 在需要熔断的服务接口方法上注解@HystrixCommand，该注解只能用于方法。如下所示 123456@HystrixCommand(fallbackMethod = \"getUserFallback\")public User getUser(Long id) &#123; //调用远程服务 http请求 String url = URL_PREFIX+\"/user/\"+id; return restTemplate.getForObject(url,User.class);&#125; 该注解中指明了服务不可用时该调用的方法名称，因此在该服务类中，还需要添加fallback方法： 123public User getUserFallback(Long id)&#123; return new User(0L,\"null\",\"null\");&#125; 所以当底层服务不可用时，底层服务会返回一个字段都为空的User对象。 1.2 feign 使用Feign作为负载调用，主类无需注解@EnableCircuitBreaker 下面是feign的配置类，当我们在yml文件中对 feign.hystrix.enabled 配置为true时，feign将自动为我们引入断路器功能。 12345678910111213//源码路径：org.springframework.cloud.openfeign.FeignClientsConfiguration@Configuration(proxyBeanMethods = false)@ConditionalOnClass(&#123; HystrixCommand.class, HystrixFeign.class &#125;)protected static class HystrixFeignConfiguration &#123; @Bean @Scope(\"prototype\") @ConditionalOnMissingBean @ConditionalOnProperty(name = \"feign.hystrix.enabled\") public Feign.Builder feignHystrixBuilder() &#123; return HystrixFeign.builder(); &#125;&#125; feign不使用service方法调用底层服务，所以@HystrixCommand也无法使用。 @FeignClient注解中加一个属性，如下: 123456@FeignClient(value = \"user-provider\",fallback = UserServiceFallBack.class)public interface UserServiceFeignClient &#123; @GetMapping(value = \"/user/&#123;id&#125;\") User getUser(@PathVariable(\"id\")Long id);&#125; 此外还需要创建UserServiceFallBack类(要实现上面的接口)，写入接口中所有方法的fallBack方法 12345678@Service@Slf4jpublic class UserServiceFallBack implements UserServiceFeignClient &#123; @Override public User getUser(Long id) &#123; return new User(0L,\"null\",\"null\"); &#125;&#125; 以上就是在feign调用中使用断路器的方法，一定要手动开启： 123feign: hystrix: enable: true 2、Hystrix三种服务降级方案2.1 熔断触发降级熔断的目的是为了起到保护作用 熔断降级又分为： 主动降级。例如大促的时候关闭非核心服务 被动降级。熔断降级、限流降级 1234567891011121314151617@HystrixCommand(commandProperties = &#123; @HystrixProperty(name=\"circuitBreaker.enabled\",value =\"true\"), // 开启熔断器 @HystrixProperty(name=\"circuitBreaker.requestVolumeThreshold\",value= \"5\"), //最小请求次数 @HystrixProperty(name=\"circuitBreaker.sleepWindowInMilliseconds\",value =\"5000\"),//熔断时间 @HystrixProperty(name=\"circuitBreaker.errorThresholdPercentage\",value = \"50\") //错误百分比 &#125;,fallbackMethod = \"fallback\")@GetMapping(\"/hystrix/order/&#123;num&#125;\")public String queryOrder(@PathVariable(\"num\")int num)&#123; if(num%2==0)&#123; return \"正常访问\"; &#125; //restTemplate默认有一个请求超时时间 return restTemplate.getForObject(\"http://localhost:8082/orders\",String.class);&#125;public String fallback(int num)&#123; //兜底可以在这里完成 return \"系统繁忙 \";&#125; 注意： 熔断开启之后，后续的正常请求也无法发送过去. 如何触发熔断?”判断阈值” 10s钟之内，发起了20次请求，失败率超过50%。 熔断的恢复时间(熔断5s)，从熔断开启到后续5s之内的请求，都不会发起到远程服务端. 熔断会有一个自动恢复。 2.2 超时触发降级可以配置超时时间，Hystrix能够配置的属性见类HystrixCommandProperties 1234567@HystrixCommand(fallbackMethod =\"timeoutFallback\",commandProperties = &#123; @HystrixProperty(name=\"execution.isolation.thread.timeoutInMilliseconds\",value = \"3000\"),&#125;)@GetMapping(\"/hystrix/timeout\")public String queryOrderTimeout()&#123; return restTemplate.getForObject(\"http://localhost:8082/orders\",String.class); &#125; 2.3 资源隔离触发降级资源隔离主要指对线程的隔离。Hystrix提供了两种线程隔离方式：线程池和信号量。 线程隔离-线程池线程隔离是hystrix默认的资源隔离方案。 Hystrix通过命令模式对发送请求的对象和执行请求的对象进行解耦，将不同类型的业务请求封装为对应的命令请求。如订单服务查询商品，查询商品请求-&gt;商品Command；商品服务查询库存，查询库存请求-&gt;库存Command。并且为每个类型的Command配置一个线程池，当第一次创建Command时，根据配置创建一个线程池，并放入ConcurrentHashMap，如商品Command： 12345final static ConcurrentHashMap&lt;String, HystrixThreadPool&gt; threadPools = new ConcurrentHashMap&lt;String, HystrixThreadPool&gt;();...if (!threadPools.containsKey(key)) &#123; threadPools.put(key, new HystrixThreadPoolDefault(threadPoolKey, propertiesBuilder));&#125; 后续查询商品的请求创建Command时，将会重用已创建的线程池。 优点： 保护应用程序以免受来自依赖故障的影响，指定依赖线程池饱和不会影响应用程序的其余部分。 当引入新客户端lib时，即使发生问题，也是在本lib中，并不会影响到其他内容。 当依赖从故障恢复正常时，应用程序会立即恢复正常的性能。 当应用程序一些配置参数错误时，线程池的运行状况会很快检测到这一点（通过增加错误，延迟，超时，拒绝等），同时可以通过动态属性进行实时纠正错误的参数配置。 如果服务的性能有变化，需要实时调整，比如增加或者减少超时时间，更改重试次数，可以通过线程池指标动态属性修改，而且不会影响到其他调用请求。 除了隔离优势外，hystrix拥有专门的线程池可提供内置的并发功能，使得可以在同步调用之上构建异步门面（外观模式），为异步编程提供了支持（Hystrix引入了Rxjava异步框架）。 注意：尽管线程池提供了线程隔离，我们的客户端底层代码也必须要有超时设置或响应线程中断，不能无限制的阻塞以致线程池一直饱和。 缺点： 线程池的主要缺点是增加了计算开销。每个命令的执行都在单独的线程完成，增加了排队、调度和上下文切换的开销。因此，要使用Hystrix，就必须接受它带来的开销，以换取它所提供的好处。 通常情况下，线程池引入的开销足够小，不会有重大的成本或性能影响。但对于一些访问延迟极低的服务，如只依赖内存缓存，线程池引入的开销就比较明显了，这时候使用线程池隔离技术就不适合了，我们需要考虑更轻量级的方式，如信号量隔离。 线程隔离-信号量上面提到了线程池隔离的缺点，当依赖了响应延迟极低的服务时，线程池隔离技术引入的开销超过了它所带来的好处。这时候可以使用信号量隔离技术来代替，通过设置信号量来限制对任何给定依赖的并发调用量。下图说明了线程池隔离和信号量隔离的主要区别： 使用线程池时，发送请求的线程和执行依赖服务的线程不是同一个，而使用信号量时，发送请求的线程和执行依赖服务的线程是同一个，都是发起请求的线程。先看一个使用信号量隔离线程的示例： 1234567891011121314151617181920212223242526272829public class QueryByOrderIdCommandSemaphore extends HystrixCommand&lt;Integer&gt; &#123; private final static Logger logger = LoggerFactory.getLogger(QueryByOrderIdCommandSemaphore.class); private OrderServiceProvider orderServiceProvider; public QueryByOrderIdCommandSemaphore(OrderServiceProvider orderServiceProvider) &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"orderService\")) .andCommandKey(HystrixCommandKey.Factory.asKey(\"queryByOrderId\")) .andCommandPropertiesDefaults(HystrixCommandProperties.Setter() //至少有10个请求，熔断器才进行错误率的计算 .withCircuitBreakerRequestVolumeThreshold(10) //熔断器中断请求5秒后会进入半打开状态,放部分流量过去重试 .withCircuitBreakerSleepWindowInMilliseconds(5000) //错误率达到50开启熔断保护 .withCircuitBreakerErrorThresholdPercentage(50) .withExecutionIsolationStrategy(HystrixCommandProperties.ExecutionIsolationStrategy.SEMAPHORE) //最大并发请求量 .withExecutionIsolationSemaphoreMaxConcurrentRequests(10))); this.orderServiceProvider = orderServiceProvider; &#125; @Override protected Integer run() &#123; return orderServiceProvider.queryByOrderId(); &#125; @Override protected Integer getFallback() &#123; return -1; &#125;&#125; 由于Hystrix默认使用线程池做线程隔离，使用信号量隔离需要显示地将属性execution.isolation.strategy设置为ExecutionIsolationStrategy.SEMAPHORE，同时配置信号量个数，默认为10。客户端需向依赖服务发起请求时，首先要获取一个信号量才能真正发起调用，由于信号量的数量有限，当并发请求量超过信号量个数时，后续的请求都会直接拒绝，进入fallback流程。 信号量隔离主要是通过控制并发请求量，防止请求线程大面积阻塞，从而达到限流和防止雪崩的目的。 总结： 线程池和信号量都支持熔断和限流。相比线程池，信号量不需要线程切换，因此避免了不必要的开销。但是信号量不支持异步，也不支持超时，也就是说当所请求的服务不可用时，信号量会控制超过限制的请求立即返回，但是已经持有信号量的线程只能等待服务响应或从超时中返回，即可能出现长时间等待。线程池模式下，当超过指定时间未响应的服务，Hystrix会通过响应中断的方式通知线程立即结束并返回。 3 熔断器Circuit Breaker 主要有6个参数： circuitBreaker.enabled 表示是否启用熔断器 circuitBreaker.forceOpen 熔断器是否强制打开，并始终保持打开状态，不关注熔断开关的实际状态，默认false circuitBreaker.forceClose 熔断器是否强制关闭，并始终保持关闭状态，不关注熔断开关的实际状态，默认false circuitBreaker.errorThresholdPercentage 错误率达到设定值会开启熔断开关，默认50% circuitBreaker.requestVolumeThreshold 一段时间内至少有设定值个请求才进行计算错误率，默认20 circuitBreaker.sleepWindowInMilliseconds 熔断器搬开状态试探睡眠事件，默认5000ms 工作原理： 熔断器工作的详细过程如下： 第一步，调用allowRequest()判断是否允许将请求提交到线程池 如果熔断器强制打开，circuitBreaker.forceOpen为true，不允许放行，返回。 如果熔断器强制关闭，circuitBreaker.forceClosed为true，允许放行。此外不必关注熔断器实际状态，也就是说熔断器仍然会维护统计数据和开关状态，只是不生效而已。 第二步，调用isOpen()判断熔断器开关是否打开 如果熔断器开关打开，进入第三步，否则继续； 如果一个周期内总的请求数小于circuitBreaker.requestVolumeThreshold的值，允许请求放行，否则继续； 如果一个周期内错误率小于circuitBreaker.errorThresholdPercentage的值，允许请求放行。否则，打开熔断器开关，进入第三步。 第三步，调用allowSingleTest()判断是否允许单个请求通行，检查依赖服务是否恢复 如果熔断器打开，且距离熔断器打开的时间或上一次试探请求放行的时间超过circuitBreaker.sleepWindowInMilliseconds的值时，熔断器器进入半开状态，允许放行一个试探请求；否则，不允许放行。 此外，为了提供决策依据，每个熔断器默认维护了10个bucket，每秒一个bucket，当新的bucket被创建时，最旧的bucket会被抛弃。其中每个blucket维护了请求成功、失败、超时、拒绝的计数器，Hystrix负责收集并统计这些计数器。 4. 降级回退方式 Fail Fast 快速失败 快速失败是最普通的命令执行方法，命令没有重写降级逻辑。 如果命令执行发生任何类型的故障，它将直接抛出异常。 Fail Silent 无声失败 指在降级方法中通过返回null，空Map，空List或其他类似的响应来完成。 Fallback: Static 指在降级方法中返回静态的默认值。这不会导致请求以无声失败的方式被删除，而是导致默认行为的发生。 Fallback: Stubbed 当命令返回一个包含多个字段的符合对象时，适合以stubbed方式回退 123protected MissionInfo getFallback() &#123; return new MissionInfo(\"missionName\",\"error\");&#125; Fallback: Cache via Network 有时，如果调用依赖服务失败，可以从缓存服务（如redis）中查询旧数据版本。由于又会发起远程调用，所以建议重新封装一个Command，使用不同的ThreadPoolKey，与主线程池进行隔离。 123protected Integer getFallback() &#123; return new RedisServiceCommand(redisService).execute();&#125; Primary + Secondary with Fallback 3. hystrix仪表盘3.1 配置dashboard工程 创建单独的工程hystrix-dashboard 123456server: port: 12345spring: application: name: hystrix-dashboard 依赖如下，只有一个： 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 主类如下： 1234567@SpringBootApplication@EnableHystrixDashboard //开启dashboardpublic class DashBoardApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DashBoardApplication.class,args); &#125;&#125; 3.2 配置熔断器所在工程 由于调用者的底层服务调用信息是通过actuator获取，所以需要添加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 修改配置，暴露hystrix自定义的 actuator-endpoint 12345management: endpoints: web: exposure: include: \"*,hystrix.stream\" 3.3 启动 启动eureka-sever 启动底层服务 启动服务调用者（断路器） 启动hystrix-dashboard 访问：localhost:12345/hyxtrix 页面中输入：http://localhost:9002/actuator/hystrix.stream, 点击Monitor stream，进入单机监控页面 注意：此处不能使用https，因为在本地没有证书，会导致连接不上9002端口的服务 请求9002端口的服务，就会产生相应的仪表数据","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/tags/SpringCloud/"}],"keywords":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}]},{"title":"SpringCloud-服务网关zuul","slug":"SpringCloud-网关过滤器zuul","date":"2019-01-02T16:00:00.000Z","updated":"2020-05-28T11:20:22.596Z","comments":true,"path":"2019/01/03/SpringCloud-网关过滤器zuul/","link":"","permalink":"https://zzkenyon.github.io/2019/01/03/SpringCloud-网关过滤器zuul/","excerpt":"","text":"Zuul是Netflix开源的微服务网关，可以和Eureka、Ribbon、Hystrix等组件配合使用，Spring Cloud对Zuul进行了整合与增强。 Zuul的主要功能是路由转发和过滤器。 zuul默认和Ribbon结合实现了负载均衡的功能。 Zuul默认使用的HTTP客户端是Apache HTTPClient，也可以使用RestClient或okhttp3.OkHttpClient。 zuul原理及可用功能zuul的核心是一系列的filters, 其作用类比Servlet框架的Filter，或者AOP。zuul把请求路由到用户处理逻辑的过程中，这些filter参与一些过滤处理，比如Authentication，Load Shedding等。 Zuul使用一系列不同类型的过滤器，使我们能够快速灵活地将功能应用于我们的边缘服务。这些过滤器可帮助我们执行以下功能： 身份验证和安全性 - 确定每个资源的身份验证要求并拒绝不满足这些要求的请求 洞察和监控 - 在边缘跟踪有意义的数据和统计数据，以便为我们提供准确的生产视图 动态路由 - 根据需要动态地将请求路由到不同的后端群集 压力测试 - 逐渐增加群集的流量以衡量性能。 Load Shedding - 为每种类型的请求分配容量并删除超过限制的请求 静态响应处理 - 直接在边缘构建一些响应，而不是将它们转发到内部集群 zuul使用入门新建springboot项目，引入依赖： 123456789101112131415161718&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 编写主类： 12345678@SpringBootApplication@EnableEurekaClient@EnableZuulProxypublic class ZuulApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ZuulApplication.class,args); &#125;&#125; 配置： 1234567891011121314151617181920212223server: port: 7001spring: application: name: zuul-serviceeureka: client: service-url: defaultZone: http://localhost:8761/eureka/ instance: prefer-ip-address: true #显示客户端真实ipzuul: routes: user-provider_1: path: /user/** serviceId: user-provider user-provider1_2: path: /user/** url: http://xxx.xxx.xxx.xxx:8080/ 运行项目， 启动了eureka的时候使用serviceid方式访问：http://localhost:7001/serviceId/。 若不使用eureka可以使用url方式访问：http://localhost:7001/path，但是要注意的是url方式访问没有 Hystrix、Ribbon 特性。 Zuul过滤器为了让api网关组件可以被更方便的使用，它在http请求生命周期的各个阶段默认实现了一批核心过滤器，它们会在api网关服务启动的时候被自动加载和启动。我们可以在源码中查看和了解它们，它们定义与spring-cloud-netflix-core模块的org.springframework.cloud.netflix.zuul.filters包下。在默认启动的过滤器中包含三种不同生命周期的过滤器，这些过滤器都非常重要，可以帮我们理解zuul对外部请求处理的过程，以及帮助我们在此基础上扩展过滤器去完成自身系统需要的功能 1、pre过滤器ServletDetectionFilter ServletDetectionFilter：它的执行顺序为-3，是最先被执行的过滤器。该过滤器总是会被执行，主要用来检测当前请求是通过Spring的DispatcherServlet处理运行的，还是通过ZuulServlet来处理运行的。它的检测结果会以布尔类型保存在当前请求上下文的isDispatcherServletRequest参数中，这样后续的过滤器中，我们就可以通过RequestUtils.isDispatcherServletRequest()和RequestUtils.isZuulServletRequest()方法来判断请求处理的源头，以实现后续不同的处理机制。一般情况下，发送到api网关的外部请求都会被Spring的DispatcherServlet处理，除了通过/zuul/路径访问的请求会绕过DispatcherServlet（比如之前我们说的大文件上传），被ZuulServlet处理，主要用来应对大文件上传的情况。另外，对于ZuulServlet的访问路径/zuul/，我们可以通过zuul.servletPath参数进行修改。 Servlet30WrapperFilter 它的执行顺序为-2，是第二个执行的过滤器，目前的实现会对所有请求生效，主要为了将原始的HttpServletRequest包装成Servlet30RequestWrapper对象。 FormBodyWrapperFilter 它的执行顺序为-1，是第三个执行的过滤器。该过滤器仅对两类请求生效，第一类是Context-Type为application/x-www-form-urlencoded的请求，第二类是Context-Type为multipart/form-data并且是由String的DispatcherServlet处理的请求（用到了ServletDetectionFilter的处理结果）。而该过滤器的主要目的是将符合要求的请求体包装成FormBodyRequestWrapper对象 DebugFilter 它的执行顺序为1，是第四个执行的过滤器，该过滤器会根据配置参数zuul.debug.request和请求中的debug参数来决定是否执行过滤器中的操作。而它的具体操作内容是将当前请求上下文中的debugRouting和debugRequest参数设置为true。由于在同一个请求的不同生命周期都可以访问到这二个值，所以我们在后续的各个过滤器中可以利用这二个值来定义一些debug信息，这样当线上环境出现问题的时候，可以通过参数的方式来激活这些debug信息以帮助分析问题，另外，对于请求参数中的debug参数，我们可以通过zuul.debug.parameter来进行自定义 PreDecorationFilter 执行顺序是5，是pre阶段最后被执行的过滤器，该过滤器会判断当前请求上下文中是否存在forward.do和serviceId参数，如果都不存在，那么它就会执行具体过滤器的操作（如果有一个存在的话，说明当前请求已经被处理过了，因为这二个信息就是根据当前请求的路由信息加载进来的）。而当它的具体操作内容就是为当前请求做一些预处理，比如说，进行路由规则的匹配，在请求上下文中设置该请求的基本信息以及将路由匹配结果等一些设置信息等，这些信息将是后续过滤器进行处理的重要依据，我们可以通过RequestContext.getCurrentContext()来访问这些信息。另外，我们还可以在该实现中找到对HTTP头请求进行处理的逻辑，其中包含了一些耳熟能详的头域，比如X-Forwarded-Host,X-Forwarded-Port。另外，对于这些头域是通过zuul.addProxyHeaders参数进行控制的，而这个参数默认值是true，所以zuul在请求跳转时默认会为请求增加X-Forwarded-*头域，包括X-Forwarded-Host,X-Forwarded-Port，X-Forwarded-For，X-Forwarded-Prefix,X-Forwarded-Proto。也可以通过设置zuul.addProxyHeaders=false关闭对这些头域的添加动作 2、route过滤器RibbonRoutingFilter 它的执行顺序为10，是route阶段的第一个执行的过滤器。该过滤器只对请求上下文中存在serviceId参数的请求进行处理，即只对通过serviceId配置路由规则的请求生效。而该过滤器的执行逻辑就是面向服务路由的核心，它通过使用ribbon和hystrix来向服务实例发起请求，并将服务实例的请求结果返回 SimpleHostRoutingFilter 它的执行顺序为100，是route阶段的第二个执行的过滤器。该过滤器只对请求上下文存在routeHost参数的请求进行处理，即只对通过url配置路由规则的请求生效。而该过滤器的执行逻辑就是直接向routeHost参数的物理地址发起请求，从源码中我们可以知道该请求是直接通过httpclient包实现的，而没有使用Hystrix命令进行包装，所以这类请求并没有线程隔离和断路器的保护 SendForwardFilter 它的执行顺序是500，是route阶段第三个执行的过滤器。该过滤器只对请求上下文中存在的forward.do参数进行处理请求，即用来处理路由规则中的forward本地跳转装配 3、post过滤器SendErrorFilter 它的执行顺序是0，是post阶段的第一个执行的过滤器。该过滤器仅在请求上下文中包含error.status_code参数（由之前执行的过滤器设置的错误编码）并且还没有被该过滤器处理过的时候执行。而该过滤器的具体逻辑就是利用上下文中的错误信息来组成一个forward到api网关/error错误端点的请求来产生错误响应 SendResponseFilter 它的执行顺序为1000，是post阶段最后执行的过滤器，该过滤器会检查请求上下文中是否包含请求响应相关的头信息，响应数据流或是响应体，只有在包含它们其中一个的时候执行处理逻辑。而该过滤器的处理逻辑就是利用上下文的响应信息来组织需要发送回客户端的响应内容 高级用法spring cloud zuul SpringBoot之Zuul使用","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/tags/SpringCloud/"}],"keywords":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}]},{"title":"协议-http和https","slug":"分布式-http和https","date":"2018-12-30T16:00:00.000Z","updated":"2020-06-12T00:40:30.964Z","comments":true,"path":"2018/12/31/分布式-http和https/","link":"","permalink":"https://zzkenyon.github.io/2018/12/31/分布式-http和https/","excerpt":"","text":"http特点： 无连接 每次连接只处理一个请求 无状态 每次处理的都是单独的请求，没有上下文概念 可以传输多种数据类型 支持BS/CS http关键点1、URL规则 协议 + 域名 + 端口号 + 虚拟目录部分 + 文件名部分 + 参数部分（非必须） + 锚部分（非必须） 虚拟目录部分： 从域名后的第一个“/”开始到最后一个“/”为止 文件名部分：最后一个“/”开始到“？”为止 参数部分： 从“？”开始到“#”为止之间的部分为参数部分 锚部分： “#”开始到最后，都是锚部分 url 和uri 的区别： URI，是uniform resource identifier，统一资源标识符，用来唯一的标识一个资源。 URL是uniform resource locator，统一资源定位器，它是一种具体的URI，即URL可以用来标识一个资源，而且还指明了如何locate这个资源。 URI是以一种抽象的，高层次概念定义统一资源标识，而URL则是具体的资源标识的方式。URL是一种URI。笼统地说，每个 URL 都是 URI，但不一定每个 URI 都是 URL。这是因为 URI 还包括一个子类，即统一资源名称 (URN)，它命名资源但不指定如何定位资源。 在Java类库中，URI类不包含任何访问资源的方法，它唯一的作用就是解析。相反的是，URL类可以打开一个到达资源的流。 2、根据MIME TYPE解析文件 3、 状态码 4、请求意图（GET/POST/PUT/DELETE） http请求报文请求行（request line）、请求头部（header）、空行和请求数据四个部分组成。 Get请求例子，使用Charles抓取的request：1234567GET /562f25980001b1b106000338.jpg HTTP/1.1Host img.mukewang.comUser-Agent Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.106 Safari/537.36Accept image/webp,image/*,*/*;q=0.8Referer http://www.imooc.com/Accept-Encoding gzip, deflate, sdchAccept-Language zh-CN,zh;q=0.8 POST请求例子，使用Charles抓取的request：12345678POST / HTTP1.1Host:www.wrox.comUser-Agent:Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 2.0.50727; .NET CLR 3.0.04506.648; .NET CLR 3.5.21022)Content-Type:application/x-www-form-urlencodedContent-Length:40Connection: Keep-Alivename=Professional%20Ajax&amp;publisher=Wiley 响应报文HTTP响应也由四个部分组成，分别是：状态行、消息报头、空行和响应正文。 例子 12345678910HTTP/1.1 200 OKDate: Fri, 22 May 2009 06:07:21 GMTContent-Type: text/html; charset=UTF-8&lt;html&gt; &lt;head&gt;&lt;/head&gt; &lt;body&gt; &lt;!--body goes here--&gt; &lt;/body&gt;&lt;/html&gt; HTTP状态码状态代码有三位数字组成，第一个数字定义了响应的类别，共分五种类别: 1234567891xx：指示信息--表示请求已接收，继续处理2xx：成功--表示请求已被成功接收、理解、接受3xx：重定向--要完成请求必须进行更进一步的操作4xx：客户端错误--请求有语法错误或请求无法实现5xx：服务器端错误--服务器未能实现合法的请求 常见状态码： 1234567200 OK //客户端请求成功400 Bad Request //客户端请求有语法错误，不能被服务器所理解401 Unauthorized //请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用 403 Forbidden //服务器收到请求，但是拒绝提供服务404 Not Found //请求资源不存在，eg：输入了错误的URL500 Internal Server Error //服务器发生不可预期的错误503 Server Unavailable //服务器当前不能处理客户端的请求，一段时间后可能恢复正常 HTTP请求方法根据HTTP标准，HTTP请求可以使用多种请求方法。HTTP1.0定义了三种请求方法： GET, POST 和 HEAD方法。HTTP1.1新增了五种请求方法：OPTIONS, PUT, DELETE, TRACE 和 CONNECT 方法。 12345678GET 请求指定的页面信息，并返回实体主体。HEAD 类似于get请求，只不过返回的响应中没有具体的内容，用于获取报头POST 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改。PUT 从客户端向服务器传送的数据取代指定的文档的内容。DELETE 请求服务器删除指定的页面。CONNECT HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器。OPTIONS 允许客户端查看服务器的性能。TRACE 回显服务器收到的请求，主要用于测试或诊断。 GET和POST请求的区别1、请求参数提交方式不同 GET提交，请求的数据会附在URL之后（就是把数据放置在HTTP协议头中），以?分割URL和传输数据，多个参数用&amp;连接；如果数据是英文字母/数字，原样发送，如果是空格，转换为+，如果是中文/其他字符，则直接把字符串用BASE64加密，得出如： %E4%BD%A0%E5%A5%BD，其中％XX中的XX为该符号以16进制表示的ASCII。 POST提交：把提交的数据放置在是HTTP包的包体中。上文示例中红色字体标明的就是实际的传输数据 因此，GET提交的数据会在地址栏中显示出来，而POST提交，地址栏不会改变 2、传输数据的大小：首先声明：HTTP协议没有对传输的数据大小进行限制，HTTP协议规范也没有对URL长度进行限制。 而在实际开发中存在的限制主要有： GET：特定浏览器和服务器对URL长度有限制，例如 IE对URL长度的限制是2083字节(2K+35)。对于其他浏览器，如Netscape、FireFox等，理论上没有长度限制，其限制取决于操作系 统的支持。 因此对于GET提交时，传输数据就会受到URL长度的 限制。 POST：由于不是通过URL传值，理论上数据不受 限。但实际各个WEB服务器会规定对post提交数据大小进行限制，Apache、IIS6都有各自的配置。 3、安全性 POST的安全性要比GET的安全性高。比如：通过GET提交数据，用户名和密码将明文出现在URL上，因为(1)登录页面有可能被浏览器缓存；(2)其他人查看浏览器的历史纪录，那么别人就可以拿到你的账号和密码了，除此之外，使用GET提交数据还可能会造成Cross-site request forgery攻击。 https多了ssl/tls层，在数据加密的流程中用到了 数字摘要(MD5,SHA256) —–证书防篡改用到了签名 非对称加密 （公钥/私钥）—-协商过程使用非对称加密 对称加密 —-会话过程使用对称加密 https加密流程如下所示： client向server发送请求https://baidu.com，然后连接到server的443端口，发送的信息主要是随机值1和客户端支持的加密算法。 server接收到信息之后给予client响应握手信息，包括随机值2和匹配好的协商加密算法，这个加密算法一定是client发送给server加密算法的子集。 随即server给client发送第二个响应报文是数字证书。服务端必须要有一套数字证书，可以自己制作，也可以向组织申请。区别就是自己颁发的证书需要客户端验证通过，才可以继续访问，而使用受信任的公司申请的证书则不会弹出提示页面，这套证书其实就是一对公钥和私钥。传送证书，这个证书其实就是公钥，只是包含了很多信息，如证书的颁发机构，过期时间、服务端的公钥，第三方证书认证机构(CA)的签名，服务端的域名信息等内容。 客户端解析证书，这部分工作是由客户端的TLS来完成的，首先会验证公钥是否有效，比如颁发机构，过期时间等等，如果发现异常，则会弹出一个警告框，提示证书存在问题。如果证书没有问题，那么就生成一个随即值（预主秘钥）。 客户端认证证书通过之后，接下来是通过随机值1、随机值2和预主秘钥组装会话秘钥。然后通过证书的公钥加密会话秘钥。 传送加密信息，这部分传送的是用证书加密后的会话秘钥，目的就是让服务端使用秘钥解密得到随机值1、随机值2和预主秘钥。 服务端解密得到随机值1、随机值2和预主秘钥，然后组装会话秘钥，跟客户端会话秘钥相同。 客户端通过会话秘钥加密一条消息发送给服务端，主要验证服务端是否正常接受客户端加密的消息。 同样服务端也会通过会话秘钥加密一条消息回传给客户端，如果客户端能够正常接受的话表明SSL层连接建立完成了。","categories":[{"name":"分布式架构技术","slug":"分布式架构技术","permalink":"https://zzkenyon.github.io/categories/分布式架构技术/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://zzkenyon.github.io/tags/网络/"}],"keywords":[{"name":"分布式架构技术","slug":"分布式架构技术","permalink":"https://zzkenyon.github.io/categories/分布式架构技术/"}]},{"title":"为什么用和什么时候用Mq（转）","slug":"MQ-为什么用和什么时候用","date":"2018-12-19T16:00:00.000Z","updated":"2020-05-22T12:17:26.930Z","comments":true,"path":"2018/12/20/MQ-为什么用和什么时候用/","link":"","permalink":"https://zzkenyon.github.io/2018/12/20/MQ-为什么用和什么时候用/","excerpt":"","text":"原文地址 1、缘起一切脱离业务的架构设计与新技术引入都是耍流氓。 引入一个技术之前，首先应该解答的问题是，这个技术解决什么问题。 就像微服务分层架构之前，应该首先回答，为什么要引入微服务，微服务究竟解决什么问题（详见《互联网架构为什么要做微服务？》）。 最近分享了几篇MQ相关的文章： 《MQ如何实现延时消息》 《MQ如何实现消息必达》 《MQ如何实现幂等性》 不少网友询问，究竟什么时候使用MQ，MQ究竟适合什么场景，故有了此文。 2、MQ是干嘛的消息总线（Message Queue），后文称MQ，是一种跨进程的通信机制，用于上下游传递消息。 在互联网架构中，MQ是一种非常常见的上下游“逻辑解耦+物理解耦”的消息通信服务。 使用了MQ之后，消息发送上游只需要依赖MQ，逻辑上和物理上都不用依赖其他服务。 3、什么时候不使用MQ既然MQ是互联网分层架构中的解耦利器，那所有通讯都使用MQ岂不是很好？这是一个严重的误区，调用与被调用的关系，是无法被MQ取代的。 MQ的不足是： 1）系统更复杂，多了一个MQ组件 2）消息传递路径更长，延时会增加 3）消息可靠性和重复性互为矛盾，消息不丢不重难以同时保证 4）上游无法知道下游的执行结果，这一点是很致命的 举个栗子：用户登录场景，登录页面调用passport服务，passport服务的执行结果直接影响登录结果，此处的“登录页面”与“passport服务”就必须使用调用关系，而不能使用MQ通信。 无论如何，记住这个结论：调用方实时依赖执行结果的业务场景，请使用调用，而不是MQ。 4、什么时候使用MQ4.1 典型场景一：数据驱动的任务依赖 什么是任务依赖，举个栗子，互联网公司经常在凌晨进行一些数据统计任务，这些任务之间有一定的依赖关系，比如： 1）task3需要使用task2的输出作为输入 2）task2需要使用task1的输出作为输入 这样的话，tast1, task2, task3之间就有任务依赖关系，必须task1先执行，再task2执行，载task3执行。 对于这类需求，常见的实现方式是，使用cron人工排执行时间表： 1）task1，0:00执行，经验执行时间为50分钟 2）task2，1:00执行（为task1预留10分钟buffer），经验执行时间也是50分钟 3）task3，2:00执行（为task2预留10分钟buffer） 这种方法的坏处是： 1）如果有一个任务执行时间超过了预留buffer的时间，将会得到错误的结果，因为后置任务不清楚前置任务是否执行成功，此时要手动重跑任务，还有可能要调整排班表 2）总任务的执行时间很长，总是要预留很多buffer，如果前置任务提前完成，后置任务不会提前开始 3）如果一个任务被多个任务依赖，这个任务将会称为关键路径，排班表很难体现依赖关系，容易出错 4）如果有一个任务的执行时间要调整，将会有多个任务的执行时间要调整 无论如何，采用“cron排班表”的方法，各任务耦合，谁用过谁痛谁知道 优化方案是，采用MQ解耦： 1）task1准时开始，结束后发一个“task1 done”的消息 2）task2订阅“task1 done”的消息，收到消息后第一时间启动执行，结束后发一个“task2 done”的消息 3）task3同理 采用MQ的优点是： 1）不需要预留buffer，上游任务执行完，下游任务总会在第一时间被执行 2）依赖多个任务，被多个任务依赖都很好处理，只需要订阅相关消息即可 3）有任务执行时间变化，下游任务都不需要调整执行时间 需要特别说明的是，MQ只用来传递上游任务执行完成的消息，并不用于传递真正的输入输出数据。 4.2 典型场景二：上游不关心执行结果上游需要关注执行结果时要用“调用”，上游不关注执行结果时，就可以使用MQ了。 举个栗子，58同城的很多下游需要关注“用户发布帖子”这个事件，比如招聘用户发布帖子后，招聘业务要奖励58豆，房产用户发布帖子后，房产业务要送2个置顶，二手用户发布帖子后，二手业务要修改用户统计数据。 对于这类需求，常见的实现方式是，使用调用关系： 帖子发布服务执行完成之后，调用下游招聘业务、房产业务、二手业务，来完成消息的通知，但事实上，这个通知是否正常正确的执行，帖子发布服务根本不关注。 这种方法的坏处是： 1）帖子发布流程的执行时间增加了 2）下游服务当机，可能导致帖子发布服务受影响，上下游逻辑+物理依赖严重 3）每当增加一个需要知道“帖子发布成功”信息的下游，修改代码的是帖子发布服务，这一点是最恶心的，属于架构设计中典型的依赖倒转，谁用过谁痛谁知道 优化方案是，采用MQ解耦： 1）帖子发布成功后，向MQ发一个消息 2）哪个下游关注“帖子发布成功”的消息，主动去MQ订阅 采用MQ的优点是： 1）上游执行时间短 2）上下游逻辑+物理解耦，除了与MQ有物理连接，模块之间都不相互依赖 3）新增一个下游消息关注方，上游不需要修改任何代码 4.3 典型场景三：上游关注执行结果，但执行时间很长 有时候上游需要关注执行结果，但执行结果时间很长（典型的是调用离线处理，或者跨公网调用），也经常使用回调网关+MQ来解耦。 举个栗子，微信支付，跨公网调用微信的接口，执行时间会比较长，但调用方又非常关注执行结果，此时一般怎么玩呢？ 一般采用“回调网关+MQ”方案来解耦： 1）调用方直接跨公网调用微信接口 2）微信返回调用成功，此时并不代表返回成功 3）微信执行完成后，回调统一网关 4）网关将返回结果通知MQ 5）请求方收到结果通知 这里需要注意的是，不应该由回调网关来调用上游来通知结果，如果是这样的话，每次新增调用方，回调网关都需要修改代码，仍然会反向依赖，使用回调网关+MQ的方案，新增任何对微信支付的调用，都不需要修改代码啦。","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://zzkenyon.github.io/categories/消息中间件/"}],"tags":[],"keywords":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://zzkenyon.github.io/categories/消息中间件/"}]},{"title":"jvm-元空间","slug":"jvm-元空间","date":"2018-11-05T16:00:00.000Z","updated":"2021-01-18T01:29:29.958Z","comments":true,"path":"2018/11/06/jvm-元空间/","link":"","permalink":"https://zzkenyon.github.io/2018/11/06/jvm-元空间/","excerpt":"","text":"基础概念： 方法区：jvm规范中的定义，指一片内存区域，用于存放加载到内存中的类信息、常量池等。 永久代：JDK1.7（含）之前方法区的实现方式，使用永久代实现主要是为了把GC分代收集扩展至方法区，省去了专门为方法区编写内存管理代码的工作。 元空间：JDK1.8（含）之后的方法区实现。 instanceKlass ：java类的运行时结构数据，就是常说的类的元数据，由于jvm底层C++实现，java应用程序不能直接访问该对象，而是通过java.lang.Class类的实例间接访问该部分信息。xx.class对象是java程序访问xx类instanceKlass 数据的接口，且xx.class对象其实是存在堆里的。 指针压缩 64位平台上默认打开 设置-XX:+UseCompressedOops压缩对象指针， oops指的是普通对象指针(ordinary object pointers)， 会被压缩成32位。 设置-XX:+UseCompressedClassPointers压缩类指针，会被压缩成32位。 类指针压缩空间（Compressed Class Pointer Space）：对于64位平台，为了压缩JVM对象中的_klass指针的大小，引入了类指针压缩空间。 只有是64位平台上启用了类指针压缩才会存在这个区域。 类指针压缩空间会有一个基地址 一个64位的地址，只取后32位，那么前32位固定不变的前提下，地址空间的大小是2的32次方 1. 永久代被取代Permanent Generation space是指内存的永久保存区域，用于存放Class和Meta的信息，类在被加载的时候被放入PermGen space区域，它和存放对象的堆区域不同，所以应用程序会加载很多类的话，就很可能出现永久代溢出错误，这种错误常见在web服务器对jsp进行预编译的时候。 1.1 为什么移除持久代 永久代空间大小是在启动时固定好的——运行时很难进行调优。-XX:MaxPermSize，设置成多少好呢？ HotSpot的内部类型也是Java对象：它可能会在Full GC中被移动，同时它对应用不透明，且是非强类型的，难以跟踪调试，还需要存储元数据的元数据信息（meta-metadata）。 简化Full GC：每一个回收器有专门的元数据迭代器。 可以在GC不进行暂停的情况下并发地释放类数据。 使得原来受限于持久代的一些改进未来有可能实现 根据上面的各种原因，永久代最终被移除，方法区移至Metaspace，字符串常量移至Java Heap。 1.2 移除持久代后，PermGen空间的状况 这部分内存空间将全部移除。 JVM的参数：-XX:PermSize 和-XX:MaxPermSize 会被忽略并给出警告（如果在启用时设置了这两个参数）。 2. 元空间随着JDK1.8的到来，JVM不再有PermGen。但类的元数据信息还在，只不过不再是存储在连续的堆空间上，而是移动到叫做“Metaspace”的本地内存（Native memory）中。 2.1 Metaspace的组成 Klass Metaspace 这块内存最多只会存在一块，用来存 instanceKlass 这部分默认放在类指针压缩空间中，是一块连续的内存区域，和之前的perm一样紧接着Heap。通过-XX:CompressedClassSpaceSize来控制这块内存的大小，默认是1 G。 但是这块内存不是必须的，如果设置了-XX:-UseCompressedClassPointers，或者-Xmx设置大于32 G，就不会有这块内存，这种情况下instanceKlass都会存在NoKlass Metaspace里。 NoKlass Metaspace: 用来存instanceKlass相关的其他的内容，比如method，constantPool等，这块内存是由多块内存组合起来的，所以可以认为是不连续的内存块组成的。 这块内存是必须的，虽然叫做NoKlass Metaspace，但是也其实可以存instanceKlass的内容，上面已经提到了对应场景。 NoKlass Metaspace在本地内存中分配。 Klass Metaspace和NoKlass Metaspace 都是所有class-loader共享的，所以类加载器们要分配内存，但是每个类加载器都有一个SpaceManager，来管理属于这个类加载的内存小块。如果Klass Metaspace用完了，那就会报OOM异常，不过一般情况下不会，NoKlass Metaspace是由一块块内存慢慢组合起来的，在没有达到限制条件的情况下，会不断加长这条链，让它可以持续工作。 2.2 Metaspace的几个参数如果我们要改变Metaspace的一些行为，我们一般会对其相关的一些参数做调整，因为Metaspace的参数本身不是很多，所以我这里将涉及到的所有参数都做一个介绍。 MetaspaceSize ：初始空间大小，达到该值就会触发垃圾收集进行类型卸载，同时GC会对该值进行调整：如果释放了大量的空间，就适当降低该值；如果释放了很少的空间，那么在不超过MaxMetaspaceSize时，适当提高该值。 MaxMetaspaceSize ：最大空间，默认是没有限制的。 MinMetaspaceFreeRatio ：在GC之后，最小的Metaspace剩余空间容量的百分比，减少为分配空间所导致的垃圾收集 MaxMetaspaceFreeRatio ：在GC之后，最大的Metaspace剩余空间容量的百分比，减少为释放空间所导致的垃圾收集 CompressedClassSpaceSize ：默认1 G，这个参数主要是设置Klass Metaspace的大小，不过这个参数设置了也不一定起作用，前提是能开启压缩指针，假如-Xmx超过了32 G，压缩指针是开启不来的。如果有Klass Metaspace，那这块内存是和Heap连着的。 MinMetaspaceExpansion ：MinMetaspaceExpansion和MaxMetaspaceExpansion这两个参数或许和大家认识的并不一样，也许很多人会认为这两个参数不就是内存不够的时候，然后扩容的最小大小吗？其实不然 这两个参数和扩容其实并没有直接的关系，也就是并不是为了增大committed的内存，而是为了增大触发metaspace GC的阈值 这两个参数主要是在比较特殊的场景下救急使用，比如gcLocker或者should_concurrent_collect的一些场景，因为这些场景下接下来会做一次GC，相信在接下来的GC中可能会释放一些metaspace的内存，于是先临时扩大下metaspace触发GC的阈值，而有些内存分配失败其实正好是因为这个阈值触顶导致的，于是可以通过增大阈值暂时绕过去 默认332.8K，增大触发metaspace GC阈值的最小要求。假如我们要救急分配的内存很小，没有达到MinMetaspaceExpansion，但是我们会将这次触发metaspace GC的阈值提升MinMetaspaceExpansion，之所以要大于这次要分配的内存大小主要是为了防止别的线程也有类似的请求而频繁触发相关的操作，不过如果要分配的内存超过了MaxMetaspaceExpansion，那MinMetaspaceExpansion将会是要分配的内存大小基础上的一个增量 MaxMetaspaceExpansion ：默认5.2M，增大触发metaspace GC阈值的最大要求。假如说我们要分配的内存超过了MinMetaspaceExpansion但是低于MaxMetaspaceExpansion，那增量是MaxMetaspaceExpansion，如果超过了MaxMetaspaceExpansion，那增量是MinMetaspaceExpansion加上要分配的内存大小 注：每次分配只会给对应的线程一次扩展触发metaspace GC阈值的机会，如果扩展了，但是还不能分配，那就只能等着做GC了 UseLargePagesInMetaspace ：默认false，这个参数是说是否在metaspace里使用LargePage，一般情况下我们使用4 KB的page size，这个参数依赖于UseLargePages这个参数开启，不过这个参数我们一般不开。 InitialBootClassLoaderMetaspaceSize ：64位下默认4M，32位下默认2200K，metasapce前面已经提到主要分了两大块，Klass Metaspace以及NoKlass Metaspace，而NoKlass Metaspace是由一块块内存组合起来的，这个参数决定了NoKlass Metaspace的第一个内存Block的大小，即2*InitialBootClassLoaderMetaspaceSize，同时为bootstrapClassLoader的第一块内存chunk分配了InitialBootClassLoaderMetaspaceSize的大小 2.3 Metaspace内存管理 在metaspace中，类和其元数据的生命周期与其对应的类加载器相同，只要类的类加载器是存活的，在Metaspace中的类元数据也是存活的，不能被回收。 每个加载器有单独的存储空间。 省掉了GC扫描及压缩的时间。 当GC发现某个类加载器不再存活了，会把对应的空间整个回收。 参考文档： Metaspace 之一：Metaspace整体介绍（永久代被替换原因、元空间特点、元空间内存查看分析方法 JVM源码分析之Metaspace解密 JDK8 的FullGC 之 metaspace JVM学习——元空间（Metaspace）","categories":[{"name":"深入理解java虚拟机","slug":"深入理解java虚拟机","permalink":"https://zzkenyon.github.io/categories/深入理解java虚拟机/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://zzkenyon.github.io/tags/jvm/"}],"keywords":[{"name":"深入理解java虚拟机","slug":"深入理解java虚拟机","permalink":"https://zzkenyon.github.io/categories/深入理解java虚拟机/"}]},{"title":"SpringCloud-微服务使用入门","slug":"SpringCloud-服务注册、调用以及负载均衡","date":"2018-10-31T16:00:00.000Z","updated":"2020-07-20T02:24:50.657Z","comments":true,"path":"2018/11/01/SpringCloud-服务注册、调用以及负载均衡/","link":"","permalink":"https://zzkenyon.github.io/2018/11/01/SpringCloud-服务注册、调用以及负载均衡/","excerpt":"","text":"传统java编程中如果想要在程序中发起http请求有哪些做法？开源的http工具包有很多，OkHttp、HttpClient、jdk自带的等等，使用这些工具并不方便，需要程序员手动封装一些请求参数，构造请求，手动调用发送请求，处理响应。。。 因此在spring对这些工具类进行了封装，对外只提供RestTemplate类，开发人员使用RestTemplate可以很方便的发送http请求，只需要指定http请求的服务器地址及端口号。 父项目依赖配置：父项目pom配置： 1234567891011121314151617181920212223&lt;properties&gt; &lt;spring.boot.version&gt;2.2.0.RELEASE&lt;/spring.boot.version&gt; &lt;spring.cloud.version&gt;Hoxton.RELEASE&lt;/spring.cloud.version&gt; ...&lt;/properties&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.boot.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.cloud.version&#125;&lt;/version&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; boot版本号 2.2.x.RELEASE 应当使用的cloud版本序列为Hoxton.RELEASE 父pom中这样配置，子模块中引入boot和cloud的依赖不再需要填写版本号信息，统一了系统的依赖版本 服务器配置：主类上注解@EnableEurekaServer，表示是服务器 1234567891011spring: application: name: eureka-servereureka: instance: hostname: localhost client: registerWithEureka: false #是否要注册到eureka fetchRegistry: false #表示是否从Eureka Server获取注册信息 serviceUrl: defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ #单机配置 eureka服务器不需要注册注册中心让别人发线，所以配置registerWithEureka为false 也不需要获取其他服务的注册信息所以registerWithEureka 也为false 安全访问 eureka服务器可以配置安全访问，需要引入依赖spring-boot-stater-security，并配置user和password 12345spring: security: user: name: admin password: 123456 所有的客户端对的client.serviceUrl.defaultZone 都需要使用user:passwod@host 的形式进行配置 eg: http://admin:123456@localhost:8761/erueka/ 注册服务主类注解@EnableEurekaClient，表示是客户端 基本配置： 1234567891011spring: application: name: user-providereureka: client: healthcheck: enabled: true #开启健康检查，需要引入actuator依赖 service-url: defaultZone: http://localhost:8761/eureka/ #告诉服务提供者要把服务注册到哪儿 instance: prefer-ip-address: true #显示客户端真实ip 如果是eureka服务器集群，defaultZone可以写个url，用“,”隔开 若同一个服务需要部署多个实例，配置文件中服务名称srping.application.name需要一致 调用服务服务调用方也需要引入eureka-client依赖，但需设置不注册到服务中心 123eureka: client: register-with-eureka: false 服务调用可以使用ribbon或者feign进行负载均衡 使用ribbon： eureka-client包中已经引入了netflix-ribbon，所以不用单独添加依赖。 注册一个RestTemplate Bean 12345678910111213@SpringBootApplication@EnableEurekaClientpublic class ConsumerApp&#123; public static void main(String[] args)&#123; SpringApplication.run(ConsumerApp.class); &#125; @Bean @LoadBalanced public RestTemplater restTemplate()&#123; return new RestTemplate(); &#125;&#125; 根据服务名称调用服务： 12345678910111213141516@RestControllerpublic class UserController &#123; public static final String URL_PREFIX = \"http://USER-PROVIDER\"; private RestTemplate restTemplate; @Autowired public void setRestTemplate(RestTemplate template)&#123; this.restTemplate = template; &#125; @GetMapping(\"/user/&#123;id&#125;\") public User getUser(@PathVariable(\"id\")Long id)&#123; //调用远程服务 http请求 String url = URL_PREFIX+\"/provider/user/\"+id; return restTemplate.getForObject(url,User.class); &#125;&#125; 缺点是需要拼接字符串。 使用feign feign底层也是使用的ribbon 主类添加注解@EnableEurekaClient表示服务消费者是Eurrka客户端 主类添加注解@EnableFeignClients表示使用Fegin进行负载 首先定义fegint访问接口： 123456@FeignClient(value=\"user-provider\")//需要调用的服务名称public interface UserServiceFeignClient&#123; //此处为服务提供者提供的url @GetMapping(\"provider/user/&#123;id&#125;\") public User getUser(@PathVariable(\"id\")Long id);&#125; 在Controller中访问 12345678910@RestControllerpublic class UserController&#123; @Autowired private UserServiceFeignClient client; //此处为服务消费者提供的url @GetMapping(\"/user/&#123;id&#125;\") public User getUser(@PathVariable(\"id\") Long id)&#123; return client.getUser(id); &#125;&#125; 比直接使用ribbon优雅多了 这样使用Feign还有一个问题，开发者需要了解服务提供者提供的所有rest接口并编写FeignClient接口来调用服务，还是会产生一些模块间的耦合问题，有什么方法可以解决这个问题吗？ 如果FeignClient接口由服务提供者来编写，并打成jar包发布到仓库中，服务调用者只需要依赖提供者提供的api jar包，就能直接调用远程服务了。 下面演示一下具体用法：","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/tags/SpringCloud/"}],"keywords":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zzkenyon.github.io/categories/SpringCloud/"}]},{"title":"jvm-对象的内存布局","slug":"jvm-对象的内存布局","date":"2018-10-30T16:00:00.000Z","updated":"2020-05-28T00:56:52.536Z","comments":true,"path":"2018/10/31/jvm-对象的内存布局/","link":"","permalink":"https://zzkenyon.github.io/2018/10/31/jvm-对象的内存布局/","excerpt":"","text":"对象内的布局是：最前面是对象头，有两个VM内部字段：_mark 和 _klass。 后面紧跟着就是对象的所有实例字段，紧凑排布，规则如下： 继承深度越浅的类所声明的字段越靠前，继承深度越深的类所声明的字段越靠后。 在同一个类中声明的字段按字段的类型宽度来重排序，对普通Java类默认的排序是：long/double - 8字节、int/float - 4字节、short/char - 2字节、byte/boolean - 1字节，最后是引用类型字段（4或8字节）。 每个字段按照其宽度来对齐；最终对象默认再做一次8字节对齐。在类继承的边界上如果有因对齐而带来的空隙的话，可以把子类的字段拉到空隙里。 这种排布方式可以让原始类型字段最大限度地紧凑排布在一起，减少字段间因为对齐而带来的空隙；同时又让引用类型字段尽可能排布在一起，减少OopMap的开销。 12345678910111213141516class A &#123; boolean b; Object o1;&#125;class B extends A &#123; int i; long l; float f; Object o2;&#125;class C extends B &#123; boolean b;&#125; 它的实例对象布局就是：（假定是64位HotSpot VM，默认开启压缩指针的话） 1234567891011--&gt; +0 [ _mark ] (64-bit header word) +8 [ _klass ] (32-bit header word, compressed klass pointer) +12 [ A.b ] (boolean, 1 byte) +13 [ (padding) ] (padding for alignment, 3 bytes) +16 [ A.o1 ] (reference, compressed pointer, 4 bytes) +20 [ B.i ] (int, 4 bytes) +24 [ B.l ] (long, 8 bytes) +32 [ B.f ] (float, 4 bytes) +36 [ B.o2 ] (reference, compressed pointer, 4 bytes) +40 [ C.b ] (boolean, 1 byte) +41 [ (padding) ] (padding for object alignment, 7 bytes) 所以C类的对象实例大小，在这个设定下是48字节，其中有10字节是为对齐而浪费掉的padding，12字节是对象头，剩下的26字节是用户自己代码声明的实例字段。 留意到C类里字段的排布是按照这个顺序的：对象头 - Object声明的字段（无） - A声明的字段 - B声明的字段 - C声明的字段——按继承深度从浅到深排布。而每个类里面的字段排布顺序则按前面说的规则，按宽度来重排序。同时，如果类继承边界上有空隙（例如这里A和B之间其实本来会有一个4字节的空隙，但B里正好声明了一些不宽于空隙4字节的字段，就可以把第一个不宽于4字节的字段拉到该空隙里，也就是 B.i 的位置）。 同时也请留意到A类和C类都声明了名字为b的字段。它们之间有什么关系？——没关系。Java里，字段是不参与多态的。 派生类如果声明了跟基类同名的字段，则两个字段在最终的实例中都会存在；派生类的版本只会在名字上遮盖（shadow / hide）掉基类字段的名字，而不会与基类字段合并或令其消失。上面例子特意演示了一下A.b 与 C.b 同时存在的这个情况。","categories":[{"name":"深入理解java虚拟机","slug":"深入理解java虚拟机","permalink":"https://zzkenyon.github.io/categories/深入理解java虚拟机/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://zzkenyon.github.io/tags/jvm/"}],"keywords":[{"name":"深入理解java虚拟机","slug":"深入理解java虚拟机","permalink":"https://zzkenyon.github.io/categories/深入理解java虚拟机/"}]},{"title":"SpringBoot-注解@ConfigurationProperties的正确使用姿势","slug":"SpringBoot-注解@ConfigurationProperties的正确使用姿势","date":"2018-10-23T16:00:00.000Z","updated":"2020-05-28T11:23:20.738Z","comments":true,"path":"2018/10/24/SpringBoot-注解@ConfigurationProperties的正确使用姿势/","link":"","permalink":"https://zzkenyon.github.io/2018/10/24/SpringBoot-注解@ConfigurationProperties的正确使用姿势/","excerpt":"","text":"1. 前言在编写项目代码时，我们要求更灵活的配置，更好的模块化整合。在 Spring Boot 项目中，为满足以上要求，我们将大量的参数配置在 application.properties 或 application.yml 文件中，通过 @ConfigurationProperties 注解，我们可以方便的获取这些参数值 2. 使用 @ConfigurationProperties 配置模块假设我们正在搭建一个发送邮件的模块。在本地测试，我们不想该模块真的发送邮件，所以我们需要一个参数来「开关」 disable 这个功能。另外，我们希望为这些邮件配置一个默认的主题，这样，当我们查看邮件收件箱，通过邮件主题可以快速判断出这是测试邮件 在 application.yml文件中创建这些参数: 1234app: mail: enable: true default-subject: This is a Test 我们可以使用 @Value 注解或着使用 Spring Environment bean 访问这些属性，是这种注入配置方式有时显得很笨重。我们将使用更安全的方式(@ConfigurationProperties )来获取这些属性 12345678910@ConfigurationProperties(prefix = \"app.mail\")@Datapublic class MailProperties &#123; private Boolean enable = Boolean.TRUE; private String defaultSubject; /** * 获取列表类型属性 */ private List&lt;String&gt; smtpServer;&#125; @ConfigurationProperties 的基本用法非常简单:我们为每个要捕获的外部属性提供一个带有字段的类。请注意以下几点: 前缀定义了哪些外部属性将绑定到类的字段上 根据 Spring Boot 宽松的绑定规则，类的属性名称必须与外部属性的名称匹配 我们可以简单地用一个值初始化一个字段来定义一个默认值 类本身可以是包私有的 类的字段必须有公共 setter 方法 Spring 宽松绑定规则 (relaxed binding)： Spring使用一些宽松的绑定属性规则。因此，以下变体都将绑定到 hostName 属性上: 123456app: mail: hostName: localhost host-name: localhost host_name: localhost HOST_NAME: localhost 如果我们将 MailProperties 类型的 bean 注入到另一个 bean 中，这个 bean 现在可以以类型安全的方式访问那些外部配置参数的值。 但是，我们仍然需要让 Spring 知道我们的 @ConfigurationProperties 类存在，以便将其加载到应用程序上下文中。 3. 激活 @ConfigurationProperties对于 Spring Boot，创建一个 MailProperties 类型的 bean，我们可以通过下面几种方式将其添加到应用上下文中 3.1 方式一首先，我们可以通过添加 @Component 注解让 Component Scan 扫描到 12345@ConfigurationProperties(prefix = \"app.mail\")@Componentpublic class MailProperties &#123; ...&#125; 很显然，只有当类所在的包被 Spring @ComponentScan 注解扫描到才会生效，默认情况下，该注解会扫描在主应用类下的所有包结构 3.2 方式二我们也可以通过 Spring 的 Java Configuration 特性实现同样的效果: 1234567@Configurationpublic class MailConfiguration &#123; @Bean public MailProperties mailProperties()&#123; return new MailProperties(); &#125;&#125; 只要 MailConfiguration 类被 Spring Boot 应用扫描到，我们就可以在应用上下文中访问 MailProperties bean 3.3 方式三我们还可以使用 @EnableConfigurationProperties 注解让我们的类被 Spring Boot 所知道，在该注解中其实是用了@Import(EnableConfigurationPropertiesImportSelector.class) 实现，大家可以看一下 12345@Configuration@EnableConfigurationProperties(MailProperties.class)public class Properties&#123; &#125; 3.4 最佳方式是什么所有上述方法都同样有效。然而，我建议模块化你的应用程序，并让每个模块提供自己的@ConfigurationProperties 类，只提供它需要的属性，就像我们在上面的代码中对邮件模块所做的那样。这使得在不影响其他模块的情况下重构一个模块中的属性变得容易。 因此，我不建议在应用程序类本身上使用 @EnableConfigurationProperties，如许多其他教程中所示，是在特定于模块的 @Configuration 类上使用@EnableConfigurationProperties，该类也可以利用包私有的可见性对应用程序的其余部分隐藏属性。 所以是第二种。 4. 特殊情况操作4.1 类型不匹配的属性如果我们在 application.properties 属性上定义的属性不能被正确的解析会发生什么？假如我们为原本应该为布尔值的属性提供的值为 ‘foo’: 123app: mail: enable: foo 默认情况下，Spring Boot 将会启动失败，并抛出异常: 123456Failed to bind properties under &apos;myapp.mail.enabled&apos; to java.lang.Boolean: Property: myapp.mail.enabled Value: foo Origin: class path resource [application.properties]:1:20 Reason: failed to convert java.lang.String to java.lang.Boolean 当我们为属性配置错误的值时，而又不希望 Spring Boot 应用启动失败，我们可以设置 ignoreInvalidFields 属性为 true (默认为 false)，like this： 12345@ConfigurationProperties(prefix = \"app.mail\",ignoreInvalidFields = true)@Datapublic class MailProperties &#123; ...&#125; 这样，Spring Boot 将会设置 enabled 字段为我们在 Java 代码里设定好的默认值。如果我们没有设置默认值，enabled 将为 null，因为这里定义的是 boolean 的包装类 Boolean 4.2 未知的属性如果我们在 application.yml文件提供了 MailProperties 类中没有字段的属性会发生什么？ 12345app: mail: enable: true default-subject: adaf unknow-property: unknow 默认情况下，Spring Boot 会忽略那些不能绑定到 @ConfigurationProperties 类字段的属性 然而，当配置文件中有一个属性实际上没有绑定到 @ConfigurationProperties 类时，我们可能希望启动失败。也许我们以前使用过这个配置属性，但是它已经被删除了，这种情况我们希望被触发告知手动从 application.properties 删除这个属性 为了实现上述情况，我们仅需要将 ignoreUnknownFields 属性设置为 false (默认是 true) 12345@ConfigurationProperties(prefix = \"app.mail\",ignoreUnknownFields = false)@Datapublic class MailProperties &#123; ...&#125; 现在，应用启动时，控制台会反馈我们异常信息 123456Binding to target [Bindable@cf65451 type = com.example.configurationproperties.properties.MailModuleProperties, value = ‘provided‘, annotations = array&lt;Annotation&gt;[@org.springframework.boot.context.properties.ConfigurationProperties(value=myapp.mail, prefix=myapp.mail, ignoreInvalidFields=false, ignoreUnknownFields=false)]] failed: Property: myapp.mail.unknown-property Value: foo Origin: class path resource [application.properties]:3:29 Reason: The elements [myapp.mail.unknown-property] were left unbound. 弃用警告??(Deprecation Warning)ignoreUnknownFields 在未来 Spring Boot 的版本中会被标记为 deprecated，因为我们可能有两个带有 @ConfigurationProperties 的类，同时绑定到了同一个命名空间 (namespace) 上，其中一个类可能知道某个属性，另一个类却不知道某个属性，这样就会导致启动失败 4.3 启动时校验属性值如果我们希望配置参数在传入到应用中时有效的，我们可以通过在字段上添加 bean validation 注解，同时在类上添加 @Validated 注解 123456789@ConfigurationProperties(prefix = \"app.mail\",ignoreInvalidFields = true)@Data@Validatedpublic class MailProperties &#123; private Boolean enable = Boolean.TRUE; @NotEmpty private String defaultSubject; ...&#125; 如果我们忘记在 application.yml设置 defaultSubject 为空： 123app: mail: default-subject: 应用启动时，我们将会得到 BindValidationException 123456789Binding to target org.springframework.boot.context.properties.bind.BindException: Failed to bind properties under ‘myapp.mail‘ to com.example.configurationproperties.properties.MailModuleProperties failed: Property: myapp.mail.enabled Value: null Reason: must not be null Property: myapp.mail.defaultSubject Value: null Reason: must not be empty 当然这些默认的验证注解不能满足你的验证要求，我们也可以自定义注解 4.4 复杂属性类型4.4.1 List 和 Set假如，我们为邮件模块提供了一个 SMTP 服务的列表，我们可以添加该属性到 MailModuleProperties 类中 123456789@ConfigurationProperties(prefix = \"app.mail\")@Datapublic class MailProperties &#123; ... /** * 获取列表类型属性 */ private List&lt;String&gt; smtpServer;&#125; 我们应该在application.yml文件中这样配置： 123456app: mail: smtp-server: - 10.0.23.12 - 10.0.23.61 - 10.0.23.89 set 集合也是这种方式的配置方式，不再重复书写。另外YAML 是更好的阅读方式，层次分明，所以在实际应用中更推荐大家使用该种方式做数据配置 4.4.2 DurationSpring Boot 内置支持从配置参数中解析 durations (持续时间)，官网文档 给出了明确的说明 1234567@ConfigurationProperties(prefix = \"app.mail\")@Datapublic class MailProperties &#123; ... private DataSize size; private Duration time;&#125; 我们既可以配置毫秒数数值，也可配置带有单位的文本: 12345678910app: mail: enable: false default-subject: This is dev env smtp-server: - 10.0.23.12 - 10.0.23.61 - 10.0.23.89 size: 20KB time: 2s 官网上已明确说明，配置 duration 不写单位，默认按照毫秒来指定，我们也可已通过 @DurationUnit 来指定单位: 1234567@ConfigurationProperties(prefix = \"app.mail\")@Datapublic class MailProperties &#123; ... @DurationUnit(chronoUnit.SECONDS) private Duration time;&#125; 常用单位如下: ns for nanoseconds (纳秒) us for microseconds (微秒) ms for milliseconds (毫秒) s for seconds (秒) m for minutes (分) h for hours (时) d for days (天) 4.4.3 DataSize与 Duration 的用法一毛一样，默认单位是 byte (字节)，可以通过 @DataSizeUnit 单位指定: 1234567@ConfigurationProperties(prefix = \"app.mail\")@Datapublic class MailProperties &#123; ... @DataSizeUnit(DataUnit.MEGABYTE) private DataSize size; &#125; 但是，我测试的时候打印出来结果都是以 B (bytes) 来显示 常见单位如下: B for bytes KB for kilobytes MB for megabytes GB for gigabytes TB for terabytes 4.5 自定义类型有些情况，我们想解析配置参数到我们自定义的对象类型上，假设，我们我们设置最大包裹重量: 123app: mail: max-weight: 1KG 在 MailProperties 中添加 Weight 属性 123456@ConfigurationProperties(prefix = \"app.mail\")@Datapublic class MailProperties &#123; ... private Weight maxWeight; &#125; 我们可以模仿 DataSize 和 Duration 创造自己的 converter (转换器) 123456789public class WeightConvert implements Converter&lt;String, Weight&gt; &#123; @Override public Weight convert(String s) &#123; /* ... */ return null; &#125;&#125; 将其注册到 Spring Boot 上下文中 12345678@Configurationpublic class MailConfiguration &#123; @Bean @ConfigurationPropertiesBinding public WeightConvert weightConvert()&#123; return new WeightConvert(); &#125;&#125; @ConfigurationPropertiesBinding 注解是让 Spring Boot 知道使用该转换器做数据绑定 5. 使用 Spring Boot Configuration Processor 完成自动补全我们向项目中添加依赖: 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; 重新 build 项目之后，configuration processor 会为我们创建一个 JSON 文件： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354文件路径：target/classes/META-INF/spring-configuration-metadata.json&#123; \"groups\": [ &#123; \"name\": \"app.mail\", \"type\": \"com.pd.properties.properties.MailProperties\", \"sourceType\": \"com.pd.properties.properties.MailProperties\" &#125;, &#123; \"name\": \"app.message\", \"type\": \"com.pd.properties.properties.MessageProperties\", \"sourceType\": \"com.pd.properties.properties.MessageProperties\" &#125; ], \"properties\": [ &#123; \"name\": \"app.mail.default-subject\", \"type\": \"java.lang.String\", \"description\": \"默认主题.\", \"sourceType\": \"com.pd.properties.properties.MailProperties\" &#125;, &#123; \"name\": \"app.mail.enable\", \"type\": \"java.lang.Boolean\", \"description\": \"邮件功能开关.\", \"sourceType\": \"com.pd.properties.properties.MailProperties\", \"defaultValue\": true &#125;, &#123; \"name\": \"app.mail.smtp-server\", \"type\": \"java.util.List&lt;java.lang.String&gt;\", \"description\": \"获取列表类型属性\", \"sourceType\": \"com.pd.properties.properties.MailProperties\" &#125;, &#123; \"name\": \"app.message.from\", \"type\": \"java.lang.String\", \"description\": \"发送方.\", \"sourceType\": \"com.pd.properties.properties.MessageProperties\" &#125;, &#123; \"name\": \"app.message.size\", \"type\": \"org.springframework.util.unit.DataSize\", \"description\": \"信息最大大小.\", \"sourceType\": \"com.pd.properties.properties.MessageProperties\" &#125;, &#123; \"name\": \"app.message.time\", \"type\": \"java.time.Duration\", \"sourceType\": \"com.pd.properties.properties.MessageProperties\" &#125; ], \"hints\": []&#125; 这样，当我们在 application.properties 和 application.yml 中写配置的时候会有自动提醒 自动生成的peoperty信息有两种获取途径 spring从properties bean中自动搜集，description对应字段注释，type对应字段类型，有默认值的字段生成default-vaule等等 程序员手动编写src\\main\\resources\\META-INF\\additional-spring-configuration-metadata.json文件 程序build的时候，spring将结合上面两种方式生成target/classes/META-INF/spring-configuration-metadata.json文件","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/tags/SpringBoot/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/categories/SpringBoot/"}]},{"title":"Mybatis-动态sql","slug":"数据库技术-Mybatis-动态sql","date":"2018-09-19T16:00:00.000Z","updated":"2020-06-22T02:14:10.539Z","comments":true,"path":"2018/09/20/数据库技术-Mybatis-动态sql/","link":"","permalink":"https://zzkenyon.github.io/2018/09/20/数据库技术-Mybatis-动态sql/","excerpt":"","text":"为什么需要动态sql？ 我们通常会把多种条件查询放在一个接口中，后端接口不知道前端回会传什么参数，所以要将所有的参数类型考虑在内，执行之前根据传入参数类型动态的生成查询语句。 Mybatis的动态sql是基于ognl表达式的。 动态标签按照官网的分类，Mybatis的动态标签主要有四类：if，choose（when,otherwise）,trim(where,set),foreach if–用在需要判断的时候，条件写在test中： 1234567891011121314&lt;select id=\"selectBlogListIf\" parameterType=\"blog\" resultMap=\"BaseResultMap\" &gt; select bid, name, author_id authorId from blog &lt;where&gt; &lt;if test=\"bid != null\"&gt; AND bid = #&#123;bid&#125; &lt;/if&gt; &lt;if test=\"name != null and name != ''\"&gt; AND name LIKE '%$&#123;name&#125;%' &lt;/if&gt; &lt;if test=\"authorId != null\"&gt; AND author_id = #&#123;authorId&#125; &lt;/if&gt; &lt;/where&gt;&lt;/select&gt; choose(when,otherwise) —需要选择一个条件的时候 123456789101112131415161718&lt;select id=\"selectBlogListChoose\" parameterType=\"blog\" resultMap=\"BaseResultMap\" &gt; select bid, name, author_id authorId from blog &lt;where&gt; &lt;choose&gt; &lt;when test=\"bid !=null\"&gt; bid = #&#123;bid, jdbcType=INTEGER&#125; &lt;/when&gt; &lt;when test=\"name != null and name != ''\"&gt; AND name LIKE CONCAT(CONCAT('%', #&#123;name, jdbcType=VARCHAR&#125;),'%') &lt;/when&gt; &lt;when test=\"authorId != null \"&gt; AND author_id = #&#123;authorId, jdbcType=INTEGER&#125; &lt;/when&gt; &lt;otherwise&gt; &lt;/otherwise&gt; &lt;/choose&gt; &lt;/where&gt;&lt;/select&gt; set—专注于更新 123456789101112&lt;update id=\"updateByPrimaryKey\" parameterType=\"blog\"&gt; update blog &lt;set&gt; &lt;if test=\"name != null\"&gt; name = #&#123;name,jdbcType=VARCHAR&#125;, &lt;/if&gt; &lt;if test=\"authorId != null\"&gt; author_id = #&#123;authorId,jdbcType=CHAR&#125;, &lt;/if&gt; &lt;/set&gt; where bid = #&#123;bid,jdbcType=INTEGER&#125;&lt;/update&gt; trim标签用于将动态参数前后的sql语句拎出来，prefix属性是动态参数前缀内容，suffix属性是动态参数后缀内容，suffixOverrides属性指后缀内容前需要去掉的部分，如下代码 1234567891011121314151617181920212223242526&lt;insert id=\"insertBlog\" parameterType=\"blog\"&gt;insert into blog &lt;trim prefix=\"(\" suffix=\")\" suffixOverrides=\",\"&gt; &lt;if test=\"bid != null\"&gt; bid, &lt;/if&gt; &lt;if test=\"name != null\"&gt; name, &lt;/if&gt; &lt;if test=\"authorId != null\"&gt; author_id, &lt;!--suffixOverrides 去掉的就是这个逗号 --&gt; &lt;/if&gt; &lt;/trim&gt; &lt;trim prefix=\"values (\" suffix=\")\" suffixOverrides=\",\"&gt; &lt;if test=\"bid != null\"&gt; #&#123;bid,jdbcType=INTEGER&#125;, &lt;/if&gt; &lt;if test=\"name != null\"&gt; #&#123;name,jdbcType=VARCHAR&#125;, &lt;!-- #&#123;name,jdbcType=VARCHAR,typeHandler=com.gupaoedu.type.MyTypeHandler&#125;, --&gt; &lt;/if&gt; &lt;if test=\"authorId != null\"&gt; #&#123;authorId,jdbcType=INTEGER&#125;, &lt;/if&gt; &lt;/trim&gt;&lt;/insert&gt; 批量插入 1234567&lt;insert id=\"insertBlogList\" parameterType=\"java.util.List\"&gt; insert into blog (bid, name, author_id) values &lt;foreach collection=\"list\" item=\"blog\" index=\"index\" separator=\",\"&gt; ( #&#123;blog.bid&#125;,#&#123;blog.name&#125;,#&#123;blog.authorId&#125; ) &lt;/foreach&gt;&lt;/insert&gt; 批量删除 123456&lt;delete id=\"deleteByList\" parameterType=\"java.util.List\"&gt; delete from blog where bid in &lt;foreach collection=\"list\" item=\"item\" open=\"(\" separator=\",\" close=\")\"&gt; #&#123;item.bid,jdbcType=INTEGER&#125; &lt;/foreach&gt;&lt;/delete&gt; 批量更新 123456789101112131415&lt;update id=\"updateBlogList\"&gt; update blog set name = &lt;foreach collection=\"list\" item=\"blogs\" index=\"index\" separator=\" \" open=\"case bid\" close=\"end\"&gt; when #&#123;blogs.bid&#125; then #&#123;blogs.name&#125; &lt;/foreach&gt; ,author_id = &lt;foreach collection=\"list\" item=\"blogs\" index=\"index\" separator=\" \" open=\"case bid\" close=\"end\"&gt; when #&#123;blogs.bid&#125; then #&#123;blogs.authorId&#125; &lt;/foreach&gt; where bid in &lt;foreach collection=\"list\" item=\"item\" open=\"(\" separator=\",\" close=\")\"&gt; #&#123;item.bid,jdbcType=INTEGER&#125; &lt;/foreach&gt;&lt;/update&gt;","categories":[{"name":"ORM框架","slug":"ORM框架","permalink":"https://zzkenyon.github.io/categories/ORM框架/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://zzkenyon.github.io/tags/Mybatis/"}],"keywords":[{"name":"ORM框架","slug":"ORM框架","permalink":"https://zzkenyon.github.io/categories/ORM框架/"}]},{"title":"设计模式之装饰器模式","slug":"设计模式之装饰器模式","date":"2018-08-02T16:00:00.000Z","updated":"2020-05-28T01:22:18.719Z","comments":true,"path":"2018/08/03/设计模式之装饰器模式/","link":"","permalink":"https://zzkenyon.github.io/2018/08/03/设计模式之装饰器模式/","excerpt":"","text":"结构型—-装饰器模式也叫包装模式，是指再不改变原有对象的基础上将新功能附加到对象上，提供了比继承更有弹性的替代方案（扩展原对象功能） 优点： 完全符合开闭原则 装饰功能即插即用 多种装饰排列组合，能获得多种效果 缺点： 会增加更多的代码文件 动态装饰、多层次装饰模型会很复杂 源码案例： 1、 jdk的BIO源码中，InputStream OutputStream Reader Writer接口的实现，就是使用了装饰器模式，针对不同类型的资源的输入输出，可以根据业务场景添加功能 2、 Mybatis源码中，二级缓存的实现就是用的装饰器迷失，对基本执行器BaseExecutor 进行装饰，执行器就拥有了缓存功能： 1new CacheExecutor(new BaseExecutor()); 应用关键点： 首先要有一个接口 然后要有一个实现类的基本款 装饰类亦实现接口，并持有一个此接口实现类对象，首次装饰构造时传入基本款，可以嵌套装饰 装饰类实现接口方法可以调用基本款，并对其加强（装饰） 案例：代码中日志接口用的很熟悉了，有一天有一个需求，写日志时要将string类型的日志换成json格式 装饰器模式实现： 首先要一个接口：现成的Logger接口 然后需要一个基本款： 1LoggerFactory.getLogger(clazz); 装饰器类： 12345678public class LoggerDecorator implements Logger &#123; protected Logger logger ; public LoggerDecorator(Logger logger)&#123; this.logger = logger; &#125; //以下为接口方法 ...&#125; 子装饰类 1234567891011public class JsonLogger extends LoggerDecorator &#123; public JsonLogger(Logger logger) &#123; super(logger); &#125; @Override public void info(String s) &#123; JSONObject res = new JSONObject(); res.put(\"message\",s); logger.info(res.toJSONString()); &#125;&#125; 12345public class JsonLoggerFactory &#123; public static Logger getLogger(Class clazz)&#123; return new JsonLogger(LoggerFactory.getLogger(clazz)); &#125;&#125; 12345678public class Test &#123; private static final Logger LOGGER_1 = LoggerFactory.getLogger(Test.class); private static final Logger LOGGER = JsonLoggerFactory.getLogger(Test.class); public static void main(String[] args)&#123; LOGGER_1.info(\"测试错误\"); LOGGER.info(\"测试错误\"); &#125;&#125; 输出： 1216:07:47.704 [main] INFO com.panda.decorator.jsonlogger.Test - 测试错误16:07:47.794 [main] INFO com.panda.decorator.jsonlogger.Test - &#123;&quot;message&quot;:&quot;测试错误&quot;&#125;","categories":[{"name":"源码中的设计模式","slug":"源码中的设计模式","permalink":"https://zzkenyon.github.io/categories/源码中的设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://zzkenyon.github.io/tags/设计模式/"}],"keywords":[{"name":"源码中的设计模式","slug":"源码中的设计模式","permalink":"https://zzkenyon.github.io/categories/源码中的设计模式/"}]},{"title":"微信支付-异步回调通知","slug":"业务-微信支付异步回调通知","date":"2018-08-01T16:00:00.000Z","updated":"2021-01-25T09:25:13.497Z","comments":true,"path":"2018/08/02/业务-微信支付异步回调通知/","link":"","permalink":"https://zzkenyon.github.io/2018/08/02/业务-微信支付异步回调通知/","excerpt":"","text":"应用后台调用统一下单接口时需要指定回调的notify_url，微信支付平台执行统一下单后，会调用该url，发送一个异步通知给应用后台，同时后台需要调用查询微信后台这笔订单的支付结果以及金额，这是一个并行操作，需要注意的是微信后台收到的金额和订单金额需要进行比对，为了防止钓鱼，所以这个查询是有必要的，必须匹配：收到的到账金额 &gt;= 订单金额，具体细节参考微信支付开发者文档 好吧，来看一下代码，异步通知地址需要自己配置好，在生成预付单的时候就得传过去，这个地址就是自己的应用后台中的某个rest-controller，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@RequestMapping(\"/notice\")public void notice(HttpServletRequest request, HttpServletResponse response) throws IOException &#123; InputStream inStream = request.getInputStream(); ByteArrayOutputStream outSteam = new ByteArrayOutputStream(); byte[] buffer = new byte[1024]; int len = 0; while ((len = inStream.read(buffer)) != -1) &#123; outSteam.write(buffer, 0, len); &#125; outSteam.close(); inStream.close(); String result = new String(outSteam.toByteArray(), \"utf-8\"); Map&lt;String, String&gt; map = null; try &#123; map = XMLUtil.doXMLParse(result); &#125; catch (JDOMException e) &#123; e.printStackTrace(); &#125; // 此处调用订单查询接口验证是否交易成功 WXOrderQuery wxpayResult = reqOrderQueryResult(map); boolean isSucc = wxpayResult.isSuccess(); // 支付成功，商户处理后同步返回给微信参数 PrintWriter writer = response.getWriter(); if (!isSucc) &#123; // 支付失败， 记录流水失败 System.out.println(\"===============支付失败==============\"); &#125; else &#123; orderService.doWXPayNotice(wxpayResult); System.out.println(\"===============付款成功，业务处理完毕==============\"); // 通知微信已经收到消息，不要再给我发消息了，否则微信会8连击调用本接口 String noticeStr = setXML(\"SUCCESS\", \"\"); writer.write(noticeStr); writer.flush(); &#125; String noticeStr = setXML(\"FAIL\", \"\"); writer.write(noticeStr); writer.flush();&#125;public static String setXML(String return_code, String return_msg) &#123; return \"&lt;xml&gt;&lt;return_code&gt;&lt;![CDATA[\" + return_code + \"]]&gt;&lt;/return_code&gt;&lt;return_msg&gt;&lt;![CDATA[\" + return_msg + \"]]&gt;&lt;/return_msg&gt;&lt;/xml&gt;\";&#125; XMLUtil.java是用于解析支付结果通知信息的工具类，用到了 compile group: &#39;jdom&#39;, name: &#39;jdom&#39;, version: &#39;1.0&#39; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970/** * XMLUtil * 用于解析微信的异步通知信息 * @author zhaozhengkang@cetiti.com */public class XMLUtil &#123; /** * 解析xml,返回第一级元素键值对。如果第一级元素有子节点，则此节点的值是子节点的xml数据。 * @param strxml * @return * @throws JDOMException * @throws IOException */ public static Map doXMLParse(String strxml) throws JDOMException, IOException &#123; strxml = strxml.replaceFirst(\"encoding=\\\".*\\\"\", \"encoding=\\\"UTF-8\\\"\"); if(null == strxml || \"\".equals(strxml)) &#123; return null; &#125; Map m = new HashMap(); InputStream in = new ByteArrayInputStream(strxml.getBytes(\"UTF-8\")); SAXBuilder builder = new SAXBuilder(); Document doc = builder.build(in); Element root = doc.getRootElement(); List list = root.getChildren(); Iterator it = list.iterator(); while(it.hasNext()) &#123; Element e = (Element) it.next(); String k = e.getName(); String v = \"\"; List children = e.getChildren(); if(children.isEmpty()) &#123; v = e.getTextNormalize(); &#125; else &#123; v = XMLUtil.getChildrenText(children); &#125; m.put(k, v); &#125; //关闭流 in.close(); log.error(\"doXMLParse m===\"+m.toString()); return m; &#125; /** * 获取子结点的xml * @param children * @return String */ public static String getChildrenText(List children) &#123; StringBuffer sb = new StringBuffer(); if(!children.isEmpty()) &#123; Iterator it = children.iterator(); while(it.hasNext()) &#123; Element e = (Element) it.next(); String name = e.getName(); String value = e.getTextNormalize(); List list = e.getChildren(); sb.append(\"&lt;\" + name + \"&gt;\"); if(!list.isEmpty()) &#123; sb.append(XMLUtil.getChildrenText(list)); &#125; sb.append(value); sb.append(\"&lt;/\" + name + \"&gt;\"); &#125; &#125; log.error(\"getChildrenText sb====\"+sb.toString()); return sb.toString(); &#125;&#125; 123456789101112131415161718192021222324252627282930313233public WXOrderQuery reqOrderQueryResult(Map&lt;String, String&gt; map) &#123; WXOrderQuery orderQuery = new WXOrderQuery(); orderQuery.setAppid(map.get(\"appid\")); orderQuery.setMch_id(map.get(\"mch_id\")); orderQuery.setTransaction_id(map.get(\"transaction_id\")); orderQuery.setOut_trade_no(map.get(\"out_trade_no\")); orderQuery.setNonce_str(map.get(\"nonce_str\")); String payFlowId = map.get(\"attach\"); orderQuery.setAttach(payFlowId); //此处需要密钥PartnerKey，此处直接写死，自己的业务需要从持久化中获取此密钥，否则会报签名错误 orderQuery.setPartnerKey(WXPayContants.partnerKey); Map&lt;String, String&gt; orderMap = orderQuery.reqOrderquery(); //此处添加支付成功后，支付金额和实际订单金额是否等价，防止钓鱼 if (orderMap.get(\"return_code\") != null &amp;&amp; orderMap.get(\"return_code\").equalsIgnoreCase(\"SUCCESS\")) &#123; if (orderMap.get(\"trade_state\") != null &amp;&amp; orderMap.get(\"trade_state\").equalsIgnoreCase(\"SUCCESS\")) &#123; // 查询订单（交易流水的实际金额），判断微信收到的钱和订单中的钱是否等额 SpPayFlowCargoSource payFlow = spPayFlowCargoSourceService.getPayFlowById(payFlowId); String total_fee = map.get(\"total_fee\"); orderQuery.setPayFlow(payFlow); Integer db_fee = payFlow.getFee().multiply(new BigDecimal(100)).intValue(); if (Integer.parseInt(total_fee) == db_fee) &#123; orderQuery.setSuccess(true); return orderQuery; &#125; &#125; &#125; orderQuery.setSuccess(false); return orderQuery;&#125; 到这一步，就能判断金额到底对不对，对了那么久成功支付，订单进行下一步流程~ 再次强调，一定要防止钓鱼，另外异步调用的时候需要去查看你的订单或者交易流水是否已经成功了，成功就没有必要继续走，直接return就行 在高并发场景下，收到的支付结果通知应该发布到MQ，后台另起一线程订阅MQ并做相应处理，如下图：","categories":[{"name":"随便写写","slug":"随便写写","permalink":"https://zzkenyon.github.io/categories/随便写写/"}],"tags":[{"name":"支付","slug":"支付","permalink":"https://zzkenyon.github.io/tags/支付/"}],"keywords":[{"name":"随便写写","slug":"随便写写","permalink":"https://zzkenyon.github.io/categories/随便写写/"}]},{"title":"java-会用HashMap","slug":"java-会用HashMap","date":"2018-07-20T16:00:00.000Z","updated":"2021-01-12T07:25:08.140Z","comments":true,"path":"2018/07/21/java-会用HashMap/","link":"","permalink":"https://zzkenyon.github.io/2018/07/21/java-会用HashMap/","excerpt":"","text":"一个问题引发的思考如果确定只装载100个元素，new HashMap(?)多少是最佳的，why？要解答这个问题，第一要知道HashMap的数据结构，第二再弄明白存取数据的逻辑。 1.首先，我是一个数组HashMap本质上是一个数组，数组的每个元素是一个单链表或者红黑树，由0个或多个节点组成。java源码中的定义如下： 1transient Node&lt;K,V&gt;[] table; 1.1节点类Node&lt;K,V&gt;Node类是HashMap的一个静态内部类，可以将其看成是一个独立的类，只是声明在HashMap类内部而已。下面是源码： 123456789101112131415161718192021222324252627282930313233343536373839static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123;//Entry是Map接口中的一个内部接口 final int hash;//此节点的哈希值，同一个链表上的哈希值不一定相同 final K key;//键，不能修改 V value;//值 Node&lt;K,V&gt; next;//指向下一个节点 Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + \"=\" + value; &#125; public final int hashCode() &#123;//此Node类的hashCode方法 return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123;//重新设置节点Value，返回旧Value V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123;//判断节点相等的方法， if (o == this)//同一个对象，返回true return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true;//键和值都相等则返回true &#125; return false; &#125;&#125; 1.2为啥有链表还有树为了提高查询效率，当链表的长度达到阈值的时候会自动将链表树形化，源码中的三个阈值常量如下： 123static final int TREEIFY_THRESHOLD = 8;static final int UNTREEIFY_THRESHOLD = 6;static final int MIN_TREEIFY_CAPACITY = 64; TREEIFY_THRESHOLD 树形化阈值：当链表长度超过这个值的时候，将链表进行树形化改造 UNTREEIFY_THRESHOLD 链表化阈值：当节点数低于这个阈值，将红黑树改造成链表。这个值必须必树形化阈值小，避免频繁的转换。 MIN_TREEIFY_CAPACITY 最小树形化容量：当数组table的长度低于这个值，即使元素链表的长度超过树形化阈值，也不会进行树形化改造，而是对table进行扩容。这个值不能小于4*TREEIFY_THRESHOLD 2.怎么进行数据的存取呢2.1hash方法拿到一个&lt;Key,Value&gt;，要存在table的哪个位置呢，这就需要用hash方法来决定了。。。从代码说起： 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; key.hashCode()函数调用的是key键值类型自带的哈希函数（与HashMap的hashCode()函数不是同一个），它返回一个32位int类型的散列值。 考虑到hash值得取值范围太大，不可能创建一个如此大的hash table，因此定位到table的位置只使用hash值的后几位（具体位数与table长度有关）。 如果只取后几位，碰撞会比较严重，因此就有了扰动函数，将hash值右移16位（高16位移到低16位），再与自身亦或，得到的结果混合了原hash值得高位和低位，以此来加大低位的随机性。 2.2定位最终得到的hash值，将由低位进行定位，定位操作如下：12n = tab.lengthtab[(n - 1) &amp; hash] 数组长度必为2的整数次幂，因此(n-1)相当于低位掩码，与h进行与操作，保留h低位，掩盖高位。 这里不做取余，是因为取余可能为负数（hashCode为负数的时候） 不对取余进行模运算，是因为最大的整数Math.abs()会返回负值 由此可知，对于HashMap的同一个链表的各个节点key值得hash值不一定相同（只是低位相同） 2.3扩容(resize)默认容量是1616是2的整数次幂的原因，在小数据量的情况下16比15或20更能减少key之间的碰撞，而加快查询的效率。 容量是15会怎样？当数组长度为15的时候，hashcode的值会与14（1110）进行“与”，那么最后一位永远是0，而0001，0011，0101，1001，1011，0111，1101这几个位置永远都不能存放元素了，空间浪费相当大，更糟的是这种情况中，数组可以使用的位置比数组长度小了很多，这意味着进一步增加了碰撞的几率（hash不均匀），降低了查询的效率！ 所以，在存储大容量数据的时候，最好预先指定hashmap的size为2的整数次幂次方。就算不指定的话，也会以大于且最接近指定值大小的2次幂来初始化的，代码如下(HashMap的构造方法中)： 123int capacity = 1; while (capacity &lt; initialCapacity) capacity &lt;&lt;= 1; //乘以2 什么时候扩容&amp;怎么扩容当hashmap中的元素越来越多的时候，碰撞的几率也就越来越高（因为数组的长度是固定的），所以为了提高查询的效率，就要对hashmap的数组进行扩容，数组扩容这个操作也会出现在ArrayList中，所以这是一个通用的操作，很多人对它的性能表示过怀疑，不过想想我们的“均摊”原理，就释然了，而在hashmap数组扩容之后，最消耗性能的点就出现了：原数组中的数据必须重新计算其在新数组中的位置，并放进去，这就是resize。那么hashmap什么时候进行扩容呢？当hashmap中的元素个数超过数组大小length x loadFactor时，就会进行数组扩容，==loadFactor的默认值为0.75==，也就是说，默认情况下，数组大小为16，那么当hashmap中元素个数超过16x0.75=12的时候，就把数组的大小扩展为2*16=32，即扩大一倍，然后重新计算每个元素在数组中的位置，而这是一个非常消耗性能的操作，所以++如果我们已经预知hashmap中元素的个数，那么预设元素的个数能够有效的提高hashmap的性能++。 回到开篇的问题当有100个元素new HashMap(100), 但是理论上来讲new HashMap(128)更合适，不过上面已经说过，即使是100，hashmap也自动会将其设置为128。 但是new HashMap(128)还不是更合适的，因为0.75x100 &lt; 100, 也就是说为了让0.75 x size &gt; 100, 我们必须这样new HashMap(256)才最合适，既考虑了&amp;的问题，也避免了resize的问题。 3.可以使用自定义的类作为key的类型吗可以，但是必须改写key类型的hashcode与equals方法 首先计算key的hashcode，找到数组中对应位置的某一元素，然后通过key的equals方法在对应位置的链表中找到需要的元素。所以，hashcode与equals方法对于找到对应元素是两个关键方法。 Hashmap的key可以是任何类型的对象，例如User这种对象，为了保证两个具有相同属性的user的hashcode相同，我们就需要改写hashcode方法，比方把hashcode值的计算与User对象的id关联起来，那么只要user对象拥有相同id，那么他们的hashcode也能保持一致了，这样就可以找到在hashmap数组中的位置了。如果这个位置上有多个元素，还需要用key的equals方法在对应位置的链表中找到需要的元素，所以只改写了hashcode方法是不够的，equals方法也是需要改写滴~当然啦，按正常思维逻辑，equals方法一般都会根据实际的业务内容来定义，例如根据user对象的id来判断两个user是否相等。 总结： put操作时，根据key的hashcode()方法计算散列值，算法为高16位与低16位抑或之后，取table长度的后几位。因此，同一个table单位下，存储的元素key值可能不同。 get操作时，由于上述原因，需要根据key的equals()方法在链表或红黑树中进行查找。 自定义类型作为key，需要重写hashcode方法和equals方法。","categories":[{"name":"不知如何分类","slug":"不知如何分类","permalink":"https://zzkenyon.github.io/categories/不知如何分类/"}],"tags":[{"name":"java","slug":"java","permalink":"https://zzkenyon.github.io/tags/java/"}],"keywords":[{"name":"不知如何分类","slug":"不知如何分类","permalink":"https://zzkenyon.github.io/categories/不知如何分类/"}]},{"title":"SpringBoot-事务没有生效","slug":"SpringBoot-事务没有生效","date":"2018-07-11T16:00:00.000Z","updated":"2020-06-22T06:48:45.377Z","comments":true,"path":"2018/07/12/SpringBoot-事务没有生效/","link":"","permalink":"https://zzkenyon.github.io/2018/07/12/SpringBoot-事务没有生效/","excerpt":"","text":"@Transactional 注解什么情况下会失效？ 数据库引擎不支持事务 @Transactional注解的方法，在类内部被调用 @Transactional 应用在非 public 修饰的方法上 @Transactional 注解属性 propagation 设置错误 @Transactional 注解属性 rollbackFor 设置错误 异常被你的 catch“吃了”导致@Transactional失效 本文从以上问题为切入点，简要的描述spring事务的使用方法，lets begin。 存储引擎不支持事务我们常用的mysql数据库，提供了很多的存储引擎，可以解决不同业务场景的数据存储需求，常用的innodb是支持事务的引擎，而Myisam不支持事务。spring事务模块本身不提供事务的实现，究其原理其实是对数据库事务的封装，当数据库存储引擎没有提供事务实现，spring的事务可定也不会生效了。 在类内部调用事务方法事务方法内部调用不生效，是动态代理的锅。注解方式配置注解，实现原理是spring aop，而spring aop 在类内部调用的时候是不进行拦截的。aop的原理是动态代理，当外部类调用切面方法时，会调用到生成的动态代理类中的增强过的方法，而类内部调用，是通过this指针调用本实例的方法。 假如方法A没有注解事务，那么在生成aop动态代理类的时候将不会对A方法进行增强。这时在A方法内部调用了事务方法B，此时会通过this指针去调用B方法，而由于A方法不是切面，调用A方法的实例是原生类的对象，this指针指向的并不是代理类，所以this中的B方法并没有被增强，因此事务不会生效。 此处需要结合spring aop的实现原理来理解，跳转 非public方法上添加事务非public方法添加事务注解之所以会失效是因为在Spring AOP 代理时，TransactionInterceptor （事务拦截器）在目标方法执行前后进行拦截，DynamicAdvisedInterceptor（CglibAopProxy 的内部类）的 intercept 方法或 JdkDynamicAopProxy 的 invoke 方法会间接调用AbstractFallbackTransactionAttributeSource的computeTransactionAttribute 方法，获取Transactional 注解的事务配置信息。 123456protected TransactionAttribute computeTransactionAttribute(Method method, Class&lt;?&gt; targetClass) &#123; // Don't allow no-public methods as required. if (allowPublicMethodsOnly() &amp;&amp; !Modifier.isPublic(method.getModifiers())) &#123; return null;&#125; 此方法会检查目标方法的修饰符是否为 public，不是 public则不会获取@Transactional 的属性配置信息。 注意：protected、private 修饰的方法上使用 @Transactional 注解，虽然事务无效，但不会有任何报错，这是我们很容犯错的一点。 事务的传播级别-propagationpropagation 代表事务的传播行为，默认值为 Propagation.REQUIRED，其他的属性信息如下： Propagation.NESTED ：和 Propagation.REQUIRED 效果一样。 Propagation.REQUIRED：如果当前存在事务，则加入该事务，如果当前不存在事务，则创建一个新的事务。( 也就是说如果A方法和B方法都添加了注解，在默认传播模式下，A方法内部调用B方法，会把两个方法的事务合并为一个事务 ） Propagation.SUPPORTS：如果当前存在事务，则加入该事务；如果当前不存在事务，则以非事务的方式继续运行。 Propagation.MANDATORY：如果当前存在事务，则加入该事务；如果当前不存在事务，则抛出异常。 Propagation.REQUIRES_NEW：重新创建一个新的事务，如果当前存在事务，暂停当前的事务。( 当类A中的 a 方法用默认Propagation.REQUIRED模式，类B中的 b方法加上采用 Propagation.REQUIRES_NEW模式，然后在 a 方法中调用 b方法操作数据库，然而 a方法抛出异常后，b方法并没有进行回滚（因为此时b方法已提交），Propagation.REQUIRES_NEW会暂停 a方法的事务) Propagation.NOT_SUPPORTED：以非事务的方式运行，如果当前存在事务，暂停当前的事务。 Propagation.NEVER：以非事务的方式运行，如果当前存在事务，则抛出异常。 若是错误的配置以下三种 propagation，事务将不会发生回滚。 TransactionDefinition.PROPAGATION_SUPPORTS：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。 TransactionDefinition.PROPAGATION_NOT_SUPPORTED：以非事务方式运行，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_NEVER：以非事务方式运行，如果当前存在事务，则抛出异常。 事务的隔离级别-isolationisolation ：事务的隔离级别，默认值为 Isolation.DEFAULT。 Isolation.DEFAULT：使用底层数据库默认的隔离级别。 数据库的事务并发会带来一些问题： 脏读（读到未提交的数据）：事务A执行一条查询，事务B修改了这部分数据但没提交，导致A读取到事务B没有提交的数据，事务B可能回滚导致事务A读取到的数据是脏数据。 不可重复读：事务A执行一条查询后，事务B对这部分数据执行了update/delete并提交了，导致事务A再次查询时与上一次的查询结果不一致，称为不可重复度。 幻读：事务A执行一条范围查询后，事务B在此范围insert了若干条数据，导致事务A再次执行该查询是记录数增多，产生幻读。 注意：幻读和不可重复度的区别是事务B对数据进行的操作不同，幻读是insert操作，不可重复读是update和delete操作 以上三个问题称为数据库的读一致性问题，必须由数据库自己提供一定的事务隔离机制来解决 Isolation.READ_UNCOMMITTED 读未提交 ，没有解决以上任何问题 Isolation.READ_COMMITTED 读已提交 解决了脏读 Isolation.REPEATABLE_READ 可重复度 解决了不可重复度 innodb也解决了幻读 Isolation.SERIALIZABLE 串行化 性能巨差 事务的其他属性timeout 属性timeout ：事务的超时时间，单位为秒，默认值为 -1（没有超时回滚）。如果超过该时间限制但事务还没有完成，则自动回滚事务。 readOnly 属性readOnly ：指定事务是否为只读事务，默认值为 false；为了忽略那些不需要事务的方法，比如读取数据，可以设置 read-only 为 true。 这里要解释一下只读事务 概念：从设置事务的时间点开始（时间点a）到这个事务结束的过程中，其他事务所提交的数据，该事务将看不见！ 如果执行的单条查询语句，则没有必要启用事务支持，数据库默认支持SQL执行期间的读一致性（基于MVCC） 如果你一次执行多条查询语句，例如统计查询，报表查询，在这种场景下，多条查询SQL必须保证整体的读一致性，否则，在前条SQL查询之后，后条SQL查询之前，数据被其他用户改变，则该次整体的统计查询将会出现读数据不一致的状态，此时，应该启用事务支持。（spring不启用事务控制，数据库将默认为每条查询开启一个事务） 注意：在将事务设置成只读后，相当于将数据库设置成只读数据库，此时若要进行写的操作，会出现错误 rollbackFor 属性rollbackFor ：用于指定能够触发事务回滚的异常类型，可以指定多个异常类型。 rollbackFor 可以指定能够触发事务回滚的异常类型。Spring默认抛出了未检查unchecked异常（继承自 RuntimeException 的异常）或者 Error才回滚事务；其他异常不会触发回滚事务。如果在事务中抛出其他类型的异常，但却期望 Spring 能够回滚事务，就需要指定rollbackFor属性。 12// 希望自定义的异常可以进行回滚@Transactional(propagation= Propagation.REQUIRED,rollbackFor= MyException.class) 若在目标方法中抛出的异常是 rollbackFor 指定的异常的子类，事务同样会回滚。Spring源码如下： 123456789private int getDepth(Class&lt;?&gt; exceptionClass, int depth) &#123; if (exceptionClass.getName().contains(this.exceptionName)) &#123; return depth; &#125; if (exceptionClass == Throwable.class) &#123; return -1; &#125; return getDepth(exceptionClass.getSuperclass(), depth + 1);&#125; 如果异常被你的 catch“吃了”，会导致@Transactional失效，这种情况是最常见的一种@Transactional注解失效场景， 123456789101112131415@Transactionalprivate Integer A() throws Exception &#123; int insert = 0; try &#123; CityInfoDict cityInfoDict = new CityInfoDict(); cityInfoDict.setCityName(\"2\"); cityInfoDict.setParentCityId(2); // A 插入字段为 2的数据 insert = cityInfoDictMapper.insert(cityInfoDict); // B 插入字段为 3的数据 b.insertB(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; 如果B方法内部抛了异常，而A方法此时try catch了B方法的异常，那这个事务还能正常回滚吗？ 答案：不能！ 会抛出异常： 1org.springframework.transaction.UnexpectedRollbackException: Transaction rolled back because it has been marked as rollback-only 因为当ServiceB中抛出了一个异常以后，ServiceB标识当前事务需要rollback。但是ServiceA中由于你手动的捕获这个异常并进行处理，ServiceA认为当前事务应该正常commit。此时就出现了前后不一致，也就是因为这样，抛出了UnexpectedRollbackException异常。 spring的事务是在调用业务方法之前开始的，业务方法执行完毕之后才执行commit or rollback，事务是否执行取决于是否抛出runtime异常。如果抛出runtime exception 并在你的业务方法中没有catch到的话，事务会回滚。 在业务方法中一般不需要catch异常，如果非要catch一定要抛出throw new RuntimeException()，或者注解中指定抛异常类型@Transactional(rollbackFor=Exception.class)，否则会导致事务失效，数据commit造成数据不一致，所以有些时候try catch反倒会画蛇添足。 noRollbackFor属性noRollbackFor：抛出指定的异常类型，不回滚事务，也可以指定多个异常类型。","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/tags/SpringBoot/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/categories/SpringBoot/"}]},{"title":"鉴权模块-shiro过滤器与案例分析","slug":"shiro-过滤器原理分析","date":"2018-06-09T16:00:00.000Z","updated":"2020-06-18T02:26:23.744Z","comments":true,"path":"2018/06/10/shiro-过滤器原理分析/","link":"","permalink":"https://zzkenyon.github.io/2018/06/10/shiro-过滤器原理分析/","excerpt":"","text":"ShiroFilter的实现原理： Shiro对servlet容器的FilterChain进行了代理，在执行Servlet容器的Filter链之前，通过ProxiedFilterChain对Servlet容器的Filter链进行了代理，先执行Shiro自己的Filter体系，然后才会委托给Servlet容器的Filter链进行Servlet容器级别的过滤。 在应用启动阶段，shiro会初始化一些对象： 创建一个PathMatchingFilterChainResolver对象用来解析请求的url匹配到哪个Filter，方式是将url逐一的与Filter的url模式进行匹配，直到匹配到正确的filter，就生成ProxiedFilterChain。 1234public PathMatchingFilterChainResolver() &#123; this.pathMatcher = new AntPathMatcher(); this.filterChainManager = new DefaultFilterChainManager();&#125; 创建PathMatchingFilterChainResolver时会创建一个DefaultFilterChainManager对象，这个对象将管理所有的shiro默认Filter以及用户自定义的Filter。 12345public DefaultFilterChainManager() &#123; this.filters = new LinkedHashMap&lt;String, Filter&gt;(); this.filterChains = new LinkedHashMap&lt;String, NamedFilterList&gt;(); addDefaultFilters(false); // 添加defaultFilter，&#125; 12345678910111213public enum DefaultFilter &#123; anon(AnonymousFilter.class), authc(FormAuthenticationFilter.class), authcBasic(BasicHttpAuthenticationFilter.class), logout(LogoutFilter.class), noSessionCreation(NoSessionCreationFilter.class), perms(PermissionsAuthorizationFilter.class), port(PortFilter.class), rest(HttpMethodPermissionFilter.class), roles(RolesAuthorizationFilter.class), ssl(SslFilter.class), user(UserFilter.class);&#125; 那么用户自定义的Filter在哪里添加进去。 接下来我们看Shiro与Spring的集成，首先看一下这个类： 123456public class ShiroFilterFactoryBean implements FactoryBean, BeanPostProcessor &#123; private Map&lt;String, Filter&gt; filters; private Map&lt;String, String&gt; filterChainDefinitionMap; private AbstractShiroFilter instance; ...&#125; ShiroFilterFactoryBean实现了FactoryBean接口，表明这是一个工厂bean，在spring中通过getBean()方法获取该bean时将调用它的getObject()方法返回实例对象： 123456public Object getObject() throws Exception &#123; if (instance == null) &#123; instance = createInstance(); &#125; return instance;&#125; instance就是这个FactoryBean要返回的具体的bean对象。 继续跟： 12345678910protected AbstractShiroFilter createInstance() throws Exception &#123; ... SecurityManager securityManager = getSecurityManager(); ... // 主要看这边 &gt;&gt; FilterChainManager manager = createFilterChainManager(); PathMatchingFilterChainResolver chainResolver = new PathMatchingFilterChainResolver(); chainResolver.setFilterChainManager(manager); return new SpringShiroFilter((WebSecurityManager) securityManager, chainResolver);&#125; 可以看到，这里实例化了上文提到的两个关键类，在创建DefaultFilterChainManager时，将用户自定义的filter也放了进去： 123456789101112131415161718192021222324252627282930313233343536protected FilterChainManager createFilterChainManager() &#123; // 实例化 ，默认的filter已经放进去了 DefaultFilterChainManager manager = new DefaultFilterChainManager(); Map&lt;String, Filter&gt; defaultFilters = manager.getFilters(); //apply global settings if necessary: for (Filter filter : defaultFilters.values()) &#123; applyGlobalPropertiesIfNecessary(filter); &#125; //getFilters获取的是用户自定义的filter，在配置中设置的 //在shiro配置类中我们会这样配置 filterMap.put(\"tokenLogin\", new AccessTokenLoginFilter()); Map&lt;String, Filter&gt; filters = getFilters(); if (!CollectionUtils.isEmpty(filters)) &#123; for (Map.Entry&lt;String, Filter&gt; entry : filters.entrySet()) &#123; String name = entry.getKey(); Filter filter = entry.getValue(); applyGlobalPropertiesIfNecessary(filter); if (filter instanceof Nameable) &#123; ((Nameable) filter).setName(name); &#125; // 将自定义filter逐个放入`DefaultFilterChainManager`中 manager.addFilter(name, filter, false); &#125; &#125; // getFilterChainDefinitionMap 获取的是用户配置的所以url模式 // 在配置类中我么会这样配置 filterRuleMap.put(\"/**\",\"tokenLogin\"); Map&lt;String, String&gt; chains = getFilterChainDefinitionMap(); if (!CollectionUtils.isEmpty(chains)) &#123; for (Map.Entry&lt;String, String&gt; entry : chains.entrySet()) &#123; String url = entry.getKey(); String chainDefinition = entry.getValue(); // 根据每条配置，创建Chain &gt;&gt; manager.createChain(url, chainDefinition); &#125; &#125; return manager;&#125; 进入createChain方法： 123456789101112131415// chainName 就是url模式public void createChain(String chainName, String chainDefinition) &#123; ...//一些检查和日志操作 // 根据配置解析chainDefinition // 比如一条过滤定义是：\"authc, roles[admin,user], perms[file:edit]\" // 解析出来就是这样&#123; \"authc\", \"roles[admin,user]\", \"perms[file:edit]\" &#125; String[] filterTokens = splitChainDefinition(chainDefinition); for (String token : filterTokens) &#123; String[] nameConfigPair = toNameConfigPair(token); // 按照解析出来的规则，逐个添加过滤器 addToChain(chainName, nameConfigPair[0], nameConfigPair[1]); &#125;&#125; 读到这里我们可以知道，对于一条请求我们是可以添加多个过滤器的，之前开发中遇到的及安全问题也就迎刃而解了。 注意：一个请求只可以匹配到一个url模式，但是url模式对应的过滤规则可以添加多个过滤器，所以一个请求是可以执行多个shiroFilter的 每个url模式执行createChain方法都会生成一个SimpleNamedFilterList，里面存放了该模式对应的filter。 应用启动阶段的处理到此结束，以下是请求到达后才会执行的部分 请求处理阶段 请求到达之后，会通过PathMatchingFilterChainResolver匹配到请求uri对应到的url模式，那么就能获取到对应模式的SimpleNamedFilterList，然后调用ProxiedFilterChain方法生成ProxiedFilterChain PathMatchingFilterChainResolver中的方法，获取ProxiedFilterChain 1234567891011121314public FilterChain getChain(ServletRequest request, ServletResponse response, FilterChain originalChain) &#123; FilterChainManager filterChainManager = getFilterChainManager(); if (!filterChainManager.hasChains()) &#123; return null; &#125; String requestURI = getPathWithinApplication(request); for (String pathPattern : filterChainManager.getChainNames()) &#123; if (pathMatches(pathPattern, requestURI)) &#123; ...//日志操作 return filterChainManager.proxy(originalChain, pathPattern); &#125; &#125; return null;&#125; 代理chain执行时，将先执行Shiro的Filter，再执行Servlet的Filter，贴代码： 123456789101112131415161718192021222324252627public class ProxiedFilterChain implements FilterChain &#123; private static final Logger log = LoggerFactory.getLogger(ProxiedFilterChain.class); private FilterChain orig; // Servlet的filter private List&lt;Filter&gt; filters; // shiro的filter private int index = 0; public ProxiedFilterChain(FilterChain orig, List&lt;Filter&gt; filters) &#123; if (orig == null) &#123; throw new NullPointerException(\"original FilterChain cannot be null.\"); &#125; this.orig = orig; this.filters = filters; this.index = 0; &#125; public void doFilter(ServletRequest request, ServletResponse response) throws IOException, ServletException &#123; if (this.filters == null || this.filters.size() == this.index) &#123; ... this.orig.doFilter(request, response); &#125; else &#123; ... this.filters.get(this.index++).doFilter(request, response, this); &#125; &#125;&#125; 执行逻辑清晰，不多说。 shiro过滤器默认过滤器分类 （1）认证过滤器：anon、authcBasic、auchc、user、logout （2）授权过滤器：perms、roles、ssl、rest、port 过滤器名称 对应类型 anom org.apache.shior.web.filter.authc.AnonymousFilter authc org.apache.shior.web.filter.authc.FormAuthenticationFilter authcBasic org.apache.shior.web.filter.authc.BasicHttpAuthenticationFilter user org.apache.shior.web.filter.authc.UserFilter logout org.apache.shior.web.filter.authc.LogoutFilter perms org.apache.shior.web.filter.authz.PermissionsAuthorizationFilter roles org.apache.shior.web.filter.authz.RolesAuthorizationFilter ssl org.apache.shior.web.filter.authz.SslFilter rest org.apache.shior.web.filter.authz.HttpMethodPermissionFilter port org.apache.shior.web.filter.authz.PortFilter anon：匿名过滤器，表示通过了url配置的资源都可以访问，例：“/statics/**=anon”表示statics目录下所有资源都能访问 authc：基于表单的过滤器，表示通过了url配置的资源需要登录验证，否则跳转到登录，例：“/unauthor.jsp=authc”如果用户没有登录访问unauthor.jsp则直接跳转到登录 authcBasic：Basic的身份验证过滤器，表示通过了url配置的资源会提示身份验证，例：“/welcom.jsp=authcBasic”访问welcom.jsp时会弹出身份验证框 user：用户过滤器，表示可以使用登录验证/记住我的方式访问通过了url配置的资源，例：“/welcom.jsp=user”表示访问welcom.jsp页面可以通过登录验证或使用记住我后访问，否则直接跳转到登录 logout：退出拦截器，表示执行logout方法后，跳转到通过了url配置的资源，例：“/logout.jsp=logout”表示执行了logout方法后直接跳转到logout.jsp页面 perms：权限过滤器，表示访问通过了url配置的资源会检查相应权限，例：“/statics/*=perms[“user:add:,user:modify:*”]“表示访问statics目录下的资源时只有新增和修改的权限 port：端口过滤器，表示会验证通过了url配置的资源的请求的端口号，例：“/port.jsp=port[8088]”访问port.jsp时端口号不是8088会提示错误 rest：restful类型过滤器，表示会对通过了url配置的资源进行restful风格检查，例：“/welcom=rest[user:create]”表示通过restful访问welcom资源时只有新增权限 roles：角色过滤器，表示访问通过了url配置的资源会检查是否拥有该角色，例：“/welcom.jsp=roles[admin]”表示访问welcom.jsp页面时会检查是否拥有admin角色 ssl：ssl过滤器，表示通过了url配置的资源只能通过https协议访问，例：“/welcom.jsp=ssl”表示访问welcom.jsp页面如果请求协议不是https会提示错误 自定义Filter通过自定义自己的拦截器可以扩展一些功能，比如 动态 url -角色/权限访问控制的实现、 根据 Subject 身份信息获取用户信息绑定到 Request（即设置通用数据）、 验证码验证、 在线用户信息的保存等等","categories":[{"name":"业务","slug":"业务","permalink":"https://zzkenyon.github.io/categories/业务/"}],"tags":[{"name":"shrio","slug":"shrio","permalink":"https://zzkenyon.github.io/tags/shrio/"}],"keywords":[{"name":"业务","slug":"业务","permalink":"https://zzkenyon.github.io/categories/业务/"}]},{"title":"鉴权模块-密码的散列存储","slug":"shiro-密码的散列存储","date":"2018-06-02T16:00:00.000Z","updated":"2020-06-18T02:25:51.105Z","comments":true,"path":"2018/06/03/shiro-密码的散列存储/","link":"","permalink":"https://zzkenyon.github.io/2018/06/03/shiro-密码的散列存储/","excerpt":"","text":"在涉及到密码存储问题上，应该加密 / 生成密码摘要存储，而不是存储明文密码。比如之前的 600w csdn 账号泄露对用户可能造成很大损失，因此应加密 / 生成不可逆的摘要方式存储。 散列算法散列算法一般用于生成数据的摘要信息，是一种不可逆的算法，一般适合存储密码之类的数据，常见的散列算法如 MD5、SHA 等。一般进行散列时最好提供一个 salt（盐） 比如加密密码 “admin”，产生的散列值是 “21232f297a57a5a743894a0e4a801fc3”，可以到一些 md5 解密网站很容易的通过散列值得到密码 “admin”，即如果直接对密码进行散列相对来说破解更容易，此时我们可以加一些只有系统知道的干扰数据，如用户名和 ID（即盐）；这样散列的对象是 “密码 + 用户名 +ID”，这样生成的散列值相对来说更难破解。 Shiro 还提供了通用的散列支持： 1234String str = \"hello\";String salt = \"123\";//内部使用MessageDigestString simpleHash = new SimpleHash(\"SHA-1\", str, salt).toString(); 通过调用 SimpleHash 时指定散列算法，其内部使用了 Java 的 MessageDigest 实现。 为了方便使用，Shiro 提供了 HashService，默认提供了 DefaultHashService 实现。 12345678910111213DefaultHashService hashService = new DefaultHashService(); //默认算法SHA-512hashService.setHashAlgorithmName(\"SHA-512\");hashService.setPrivateSalt(new SimpleByteSource(\"123\")); //私盐，默认无hashService.setGeneratePublicSalt(true);//是否生成公盐，默认falsehashService.setRandomNumberGenerator(new SecureRandomNumberGenerator());//用于生成公盐。默认就这个hashService.setHashIterations(1); //生成Hash值的迭代次数HashRequest request = new HashRequest.Builder() .setAlgorithmName(\"MD5\") .setSource(ByteSource.Util.bytes(\"hello\")) .setSalt(ByteSource.Util.bytes(\"123\")) .setIterations(2) .build();String hex = hashService.computeHash(request).toHex(); SecureRandomNumberGenerator 用于生成一个随机数： 123SecureRandomNumberGenerator randomNumberGenerator = new SecureRandomNumberGenerator();randomNumberGenerator.setSeed(\"123\".getBytes());String hex = randomNumberGenerator.nextBytes().toHex(); 加密 / 解密Shiro 还提供对称式加密 / 解密算法的支持，如 AES、Blowfish 等；当前还没有提供对非对称加密 / 解密算法支持，未来版本可能提供。 AES 算法实现： 1234567891011AesCipherService aesCipherService = new AesCipherService();aesCipherService.setKeySize(128); //设置key长度//生成keyKey key = aesCipherService.generateNewKey();String text = \"hello\";//加密String encrptText = aesCipherService.encrypt(text.getBytes(), key.getEncoded()).toHex();//解密String text2 = new String(aesCipherService.decrypt(Hex.decode(encrptText),key.getEncoded()).getBytes());Assert.assertEquals(text, text2); PasswordService/CredentialsMatcher简单介绍Shiro 提供了 PasswordService 及 CredentialsMatcher 用于提供加密密码及验证密码服务。 123456789public interface PasswordService &#123; //输入明文密码得到密文密码 String encryptPassword(Object plaintextPassword) throws IllegalArgumentException;&#125;public interface CredentialsMatcher &#123; //匹配用户输入的token的凭证（未加密）与系统提供的凭证（已加密） boolean doCredentialsMatch(AuthenticationToken token, AuthenticationInfo info);&#125; Shiro 默认提供了 PasswordService的实现 DefaultPasswordService和CredentialsMatcher 的实现 PasswordMatcher 及 HashedCredentialsMatcher（更强大）。 DefaultPasswordService 配合 PasswordMatcher 实现简单的密码加密与验证服务 1、定义 Realm（com.github.zhangkaitao.shiro.chapter5.hash.realm.MyRealm） 12345678910111213public class MyRealm extends AuthorizingRealm &#123; private PasswordService passwordService; public void setPasswordService(PasswordService passwordService) &#123; this.passwordService = passwordService; &#125; //省略doGetAuthorizationInfo，具体看代码 @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; return new SimpleAuthenticationInfo(\"wu\", passwordService.encryptPassword(\"123\"),getName()); &#125;&#125; 这里为了演示方便，直接注入一个 passwordService 来加密密码，实际使用时需要在 Service 层使用 passwordService 加密密码并存到数据库。 HashedCredentialsMatcher 实现密码验证服务 Shiro 提供了 CredentialsMatcher 的散列实现 HashedCredentialsMatcher，和PasswordMatcher 不同的是，它只用于密码验证，且可以提供自己的盐，而不是随机生成盐，且生成密码散列值的算法需要自己 写，因为能提供自己的盐。 HashedCredentialsMatcher需要进行全局配置，加密算法、迭代次数、私盐等 项目中的实现PasswordHelper 类用于在UserService中对密码生成数字签名，代替PasswordService PasswordHelper 指定了hash算法，迭代次数，私盐 123456789101112131415161718192021@Componentpublic class PasswordHelper &#123; // 公盐生成器 private final RandomNumberGenerator randomNumberGenerator = new SecureRandomNumberGenerator(); public final static String PRIVATE_SALT = ByteSource.Util.bytes(\"jungomama\").toHex(); //私盐 private static final String algorithmName = \"md5\"; private static final int hashIterations = 2; /** * 加密密码 在添加用户、充值密码的时候调用 * @param user */ public void encryptPassword(User user) &#123; user.setPublicSalt(randomNumberGenerator.nextBytes().toHex()); // 设置公盐 String newPassword = new SimpleHash( algorithmName, user.getPassword(), ByteSource.Util.bytes(user.getPublicSalt() + PRIVATE_SALT), hashIterations).toHex(); user.setPassword(newPassword); &#125; 自定义类RetryLimitHashedCredentialsMatcher继承了HashedCredentialsMatcher，扩展除了重试次数限制的功能。 123456789101112131415161718192021222324252627282930313233public class RetryLimitHashedCredentialsMatcher extends HashedCredentialsMatcher &#123; private RedisTemplate&lt;String,Object&gt; redisService; @Autowired public void setRedisService(RedisTemplate&lt;String, Object&gt; redisService) &#123; this.redisService = redisService; &#125; /** * 缓存无需删除，设置1小时失效。 * @param token * @param info * @return */ @Override public boolean doCredentialsMatch(AuthenticationToken token, AuthenticationInfo info) &#123; if (super.doCredentialsMatch(token, info)) &#123; return true; &#125; else &#123; String username = (String) token.getPrincipal(); AtomicInteger retryCount = (AtomicInteger) redisService.opsForValue().get(username); if (retryCount == null) &#123; redisService.opsForValue().set(username, new AtomicInteger(0)); &#125; assert retryCount != null; if (retryCount.incrementAndGet() &gt; 5) &#123; throw new ExcessiveAttemptsException(); &#125; else &#123; redisService.opsForValue().set(username,retryCount); &#125; return false; &#125; &#125;&#125; 在ShiroConfig中要进行bean的配置： 123456789101112131415161718192021@Bean(\"retryLimitHashedCredentialsMatcher\")public RetryLimitHashedCredentialsMatcher retryLimitHashedCredentialsMatcher()&#123; RetryLimitHashedCredentialsMatcher matcher = new RetryLimitHashedCredentialsMatcher(); matcher.setHashAlgorithmName(\"MD5\"); matcher.setHashIterations(2); return matcher;&#125;/** * 将自定义的校验规格放入Realm * @param matcher * @return */@Bean(\"sqlDatabaseRealm\")public SqlDatabaseRealm sqlDatabaseRealm( @Qualifier(\"retryLimitHashedCredentialsMatcher\") RetryLimitHashedCredentialsMatcher matcher)&#123; SqlDatabaseRealm sqlDatabaseRealm = new SqlDatabaseRealm(); //信息放入缓存 sqlDatabaseRealm.setCacheManager(new MemoryConstrainedCacheManager()); sqlDatabaseRealm.setCredentialsMatcher(matcher); return sqlDatabaseRealm;&#125; 以上就实现了密码签名存储、hash密码验证、重试次数限制的功能","categories":[{"name":"业务","slug":"业务","permalink":"https://zzkenyon.github.io/categories/业务/"}],"tags":[{"name":"shrio","slug":"shrio","permalink":"https://zzkenyon.github.io/tags/shrio/"}],"keywords":[{"name":"业务","slug":"业务","permalink":"https://zzkenyon.github.io/categories/业务/"}]},{"title":"鉴权模块-登录鉴权设计","slug":"shiro-zuul鉴权网关设计","date":"2018-06-01T16:00:00.000Z","updated":"2020-11-04T01:10:17.181Z","comments":true,"path":"2018/06/02/shiro-zuul鉴权网关设计/","link":"","permalink":"https://zzkenyon.github.io/2018/06/02/shiro-zuul鉴权网关设计/","excerpt":"","text":"场景：用户的角色不同，有不同的接口访问权限。 支持多种登录方式（用户名登录、手机号登录、ldap登录） 支持密码散列存储 支持黑名单 防暴力破解 api限流 支持高并发 需求分析： 接口权限 用户的角色属于用户属性 1对多 –&gt; 数据库存储 角色的权限属于角色的属性 1对多 –&gt; 数据库存储 权限对应的接口调用属于业务范围 1对多 –&gt; 项目中进行配置 多登录方式意味着多数据源 用户名登录 需要存储用户名密码 –&gt; 关系型数据库 手机号登录 需要短信服务 –&gt;付费开通短信服务 Ldap登录 需要接入Ldap数据库 黑名单：指定用户不予登录， 黑名单的存储（缓存） 黑名单有效期 防暴力破解 登录验证失败超过一定次数进入黑名单 api限流 在单位时间内同一个用户调用同一个接口的次数是有限的 要避免单位时间交界处的超频访问 技术选型： 关系型数据库及orm框架 -&gt; mysql + mybatis 黑名单缓存使用redis -&gt; 可配置自动过期 鉴权框架–&gt; apache shiro ，轻量，支持多数据源 网关 netflix.zuul 方案设计：登录设计1、 首次访问需要登陆，客户端需提供用户名密码，由shiro进行用户名/密码认证，shiro获取当前用户信息，并生成token令牌设置到response的cookie中返回给客户端（具体实现上走controller），客户端保存cookie 2、 token令牌中携带uid信息，并进行数字签名防止被篡改，在TCP连接keeplive期间再次请求，服务器能从携带的token中获取到uid，不再需要登录，token需要设置有效期。 3、TCP断开后，再次访问同域名下的API，客户端会带上之前发放的Token，shiro会进行token认证，此次认证不需要客户端提供用户名密码，自动登录。认证成功，shiro会获取到当前的用户信息（token中有用户名）–具体实现上走Filter 鉴权设计传统的三表结构 User表 用户有1到多种role Role表 role有1到多个permission Permission表 具体方案关于用户系统对于一个简单的用户系统（不考虑复杂的权限控制，只考虑最单一的“合法用户”的鉴定），其功能其实可以被拆的很简单：注册、登录、鉴权。 注册：用户将用户名和密码交给服务器，并由服务器存储的过程。 登录：用户将用户名和密码交给服务器，服务器鉴定是否正确的过程（在 Token鉴权系统中，这一步如果通过，会生成并返回 Token）。 鉴权：用户将 Token 发送给服务器，服务器校验该 Token 是否合法的过程（不考虑复杂鉴权）。 安全问题流程清楚了，我们就来分析一下问题。不考虑前端可能出现的网络抓包等问题，仅从服务器角度考虑，我们可能遇到的安全问题有以下几个： 密码泄漏 生成 Token 的 Secret Key（Salt）泄漏 Token 泄漏 / 伪造 归纳一下：我们要解决的最重要的安全问题，就是用户最机密的安全信息被泄漏或伪造。 鉴权设计实践在我最近完成的产品上，为了规避这些问题，我们在关键步骤上进行了一些处理。整个鉴权系统依赖 Apache Shiro 框架；同时，在密码处理，Token 认证上，我们结合了一些自己的解决方案。 整个流程大致是这样的：（流程图软件到期了 TAT） 注册 登录 鉴权 关于密码加密存储与验证密码是一定要进行加密存储的。用户系统最核心的数据表，就是包含用户名（ID）、加密后的密码、Salt 的表。Salt 的生成，我们使用了 Shiro 提供的随机字符串生成工具，与用户名连接后，再进行 MD5。然后使用 Salt 加密密码，然后同时保存 Salt 和加密后的密码。 当用户登录时，我们使用 Salt 对用户输入的密码进行加密，再尝试与存储的密码进行匹配。 关于 Token 方案（JWT Token）使用 JWT Token 作为我们的 Token 方案。 1. JWT TokenJWT Token 的全称是 JSON Web Token。一个 JWT Token 由三部分构成：Header，Payload，Signature。Header 规定了 Token 使用的加密方式与 Token 的类型，Payload 是 Token 中包含的用户信息（用户名，过期时间等），Signature 是 Header 的 Base64 值 + Payload 的 Base64 值 + Secret Key 生成的字符串，再对该字符串使用 Header 中规定的散列方式（HS256 或 RS256）取散列值后得到的字符串。一个典型的 JWT Token 是这个样子的： 1eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ 1234567891011121314151617// HEADER&#123; \"alg\": \"HS256\", \"typ\": \"JWT\"&#125;// PAYLOAD&#123; \"sub\": \"1234567890\", \"name\": \"John Doe\", \"admin\": true&#125;// SIGNATUREHMACSHA256( base64UrlEncode(header) + \".\" + base64UrlEncode(payload), secret) Header、Payload 和 Signature 用 . 分隔。 验证 Token 的时候，我们只需要将前两段（即 Header 和 Payload 的 Base64）加上 Secret Key，然后按照 Header 规定的加密方式进行加密，将生成的字符串与第三段（Signature）比对即可。当然，Token 验证的实践上，不同的项目存在一些分歧：有些人会将生成的 Token 直接存在数据库（比如 Redis）里，然后通过 Query 的方式验证是否合法。这一点我们随后讨论。 一个 JWT Token 唯一不可见的部分，就是 Secret Key。它是保证这个 Token 合法且安全的唯一字段。拿不到 Secret Key ，就无法生成 Token，也无法验证 Token。这种 Token 机制很常见（HTTPS 的握手过程就类似这样，SSH 连接也是 - 私钥只有一方持有），难点在于，如何生成并管理 Secret Key。 2. Secret Key首先，所有用户使用相同的 Secret Key 一定是不合理的。所以我们要解决的第一个问题是，如何为每一个用户生成唯一的 Secret Key ？ 还记得刚才的 Salt 么？每个用户的 Salt 都是唯一的，我们使用 Salt ，但不直接使用 Salt 作为 Secret Key。我们使用 Salt + 加密后的密码，再取 MD5 值作为该用户的 Secret Key。每次鉴权前，我们通过这个方式生成 Secret Key，再使用 Secret Key 进行鉴权。 3. 在项目中使用12345&lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;0.9.1&lt;/version&gt;&lt;/dependency&gt; 安全性分析整套系统的安全之处在于，我们没有将任何敏感信息本地化。假设一种最坏的情况：攻击者拿到了我们数据库的全部数据，他能做什么？ 获取密码：密码被加密了，而且每个用户使用不同的 Salt 进行加密，加密方法是自定义的，不知道加密方法的话难以破解。 获取 Token：我们没有保存任何的 Token。 获取 Secret Key：Secret Key 是算出来的，即便拿到了 Salt，不知道算法也无法直接得到 Secret Key。 我们避免了直接保存任何安全信息。攻击者拿到的数据，都无法被直接利用。即便尝试破解，代价也是巨大的。 关于 Redis在我看到的一些实践中，有些项目喜欢使用 Redis 存储生成的 Token，从而简化鉴权流程，提升鉴权效率。这样做可以吗？ 我咨询了一位业界专家，同时查阅了相关资料，我给出的答案是：可以，但是不合理，不推荐。 避免用 Redis 直接存储 Token还记得我们安全性分析的前提么：如果攻击者拿到了我们数据库的全部数据，他能做什么？ 将 Token 保存在 Redis 中，一定是有风险的。如果服务器被攻破，用户 Token 泄漏的话，在规定的过期时间内，这些被泄漏的 Token 将会使用户账户变得非常危险。 当然，如果系统运行在内网环境，或者系统本身对用户安全的要求不高，这种方案从某种程度上讲，确实可以提升鉴权效率，简化鉴权流程。但是鉴于其可能存在的安全问题，不推荐。 可以用 Redis 缓存 Salt在我们的产品设计中，我们使用 Salt 计算 Secret Key，然后再进行 Token 认证。我们可以在用户登录时把 Salt 缓存到 Redis 中以提升查询效率。 进一步优化使用 Payload 生成 Secret Key现在，整个系统的安全性基本可靠了。但是，仔细分析系统的设计，还是有一点问题：每次鉴权都需要去查询 Salt，I/O 开销比较大。这恰恰也是有些人使用 Redis 的原因之一 —— 提升查询速度。 仔细分析一下，我们用 Salt 当做了生成 Secret Key 的 Seed ，目的在于保证 Secret Key 唯一，同时不直接存储 Secret Key 。但其实，保持 Secret Key 唯一的方式有很多，不一定要通过 Salt 。实际上只有登录操作必须依赖 Salt，鉴权操作完全可以使用别的机制。 我们可以使用 JWT 的 Payload 中的某些字段，通过特定算法生成 Secret Key。比如：有效期时间戳 + 用户名，再取 SHA256 散列值（当然可以更复杂，不过要注意性能开销）。因为生成 Secret Key 的算法是不透明的，所以 Secret Key 也是相对安全的。 如果对把生成 Token 的信息放在 Payload 中心存顾虑的话，我们可以在服务器上通过静态配置文件的方式设置固定的 Secret Salt ，配合 Payload 生成 Secret Key。 通过这样的方式，我们可以避免在鉴权阶段对数据库进行访问，提升响应效率。我们也可以利用 Secret Salt 进行细粒度的权限角色划分，在此就不赘述了。 更标准的密码加密模式关于密码加密等方式，我的老师给了我一些建议：可以使用 Blowfish 算法进行对称加密。这样的加密更标准，更安全。 JWT Token 与前端JWT Token 应该放在哪官方建议使用 Bearer 的模式，即： 1Authorization: Bearer &lt;token&gt; 合理使用 Payload，避免 Token 过长JWT Token 是有 Payload 的，这从一定程度上会造成 Payload 滥用。我在 Chrome 上遇到一个奇怪的 Bug：如果 Authorization 过长，Chrome 传递这个字段的时候会发生截断。我们的产品刚开始研发的时候，过度依赖 JWT 的 Payload 传递用户基本信息（用户名、所属用户组、邮箱等），造成 Token 长度非常长。后来对 Token 进行了几次瘦身，才避免了 Chrome 上的 Bug。 前端真的需要依赖 Payload 吗？答案是否定的。前端并不关心，也不应该关心 Token 的 Payload 是什么，真正使用 Payload 的应该是后端。前端获取用户信息的方式，应当是在用户登录的时候，由服务器作为 HTTP Response 回传，并使用 Cookie / Local Storage / Session Storage 进行持久化存储，而不是通过解析 Token 的 Payload 获得。 开发遇到的问题问题描述： 在网关中实现鉴权，考虑到分布式环境可能不止部署一台网关服务器，因此服务器不记录会话信息（为了实现高可用）。因此首次登录之后发放accessToken，再次请求网关会携带这个token 问题是，再次请求网关时，网关并不知道该请求的客户端已经登录了，因此无法获取权限信息，通过url过滤实现鉴权时，会直接跳转到登录页面 这个问题的主要原因是一个url不能经过两个过滤器，然后我将token登录过滤器的逻辑集成到鉴权过滤器中，在鉴权之前先使用token登录 新问题：token登录之后principal关联到accessTokenRealm，鉴权时，shiro还是会去sqlRealm中拿权限信息，然后当然拿不到，报异常。 异常原因：sqlRealm中获取user的语句是这样写的： 1User user = (User) principals.fromRealm(this.getClass().getName()).iterator().next(); fromRealm方法返回一个集合，当集合为空时，获取迭代器执行next操作就会报错，编码不严谨造成的低级错误，正确的做法是应该先对集合判空 1234567User user;Collection users = principalCollection.fromRealm(this.getClass().getName());if(users.isEmpty())&#123; return null ;&#125; else&#123; user = (User)users.iterator().next();&#125; 在作出以上两点修改之后，分布式网关的鉴权功能基本实现了，接下来进行优化。 shrio默认使用的是PermissionsAuthorizationFilter来进行鉴权，我上面的做法是 123456789101112public class AccessTokenAuthorizedFilter extends PermissionsAuthorizationFilter &#123; private String[] perms; private final AccessTokenLoginFilter accessTokenLoginFilter = new AccessTokenLoginFilter(); public AccessTokenAuthorizedFilter(String[] perms)&#123; this.perms = perms; &#125; @Override public boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) throws IOException &#123; accessTokenLoginFilter.executeLogin(request,response); return super.isAccessAllowed(request,response,perms); &#125;&#125; 这样带来的缺点是不能像PermissionsAuthorizationFilter那样优雅的配置过滤器了。 12345678910ShiroFilterFactoryBean factoryBean = new ShiroFilterFactoryBean();Map&lt;String, Filter&gt; filterMap = new HashMap&lt;&gt;(16);filterMap.put(\"permedit\",new AccessTokenAuthorizedFilter(new String[]&#123;\"edit\"&#125;));factoryBean.setFilters(filterMap);factoryBean.setSecurityManager(manager);LinkedHashMap&lt;String,String&gt; filterRuleMap = new LinkedHashMap&lt;String, String&gt;();//拥有edit权限filterRuleMap.put(\"/user-provider/user/edit\",\"permedit\");factoryBean.setFilterChainDefinitionMap(filterRuleMap);return factoryBean; 接下来的优化就是看能不能有更好的设计方式，能像原生的shiro那样优雅的配置 1filterRuleMap.put(\"/user-provider/user/edit\",\"perms[edit]\"); 以上问题，在我阅读shiroFilter部分的源码之后迎刃而解，详细见下一篇","categories":[{"name":"业务","slug":"业务","permalink":"https://zzkenyon.github.io/categories/业务/"}],"tags":[{"name":"shrio","slug":"shrio","permalink":"https://zzkenyon.github.io/tags/shrio/"}],"keywords":[{"name":"业务","slug":"业务","permalink":"https://zzkenyon.github.io/categories/业务/"}]},{"title":"并发编程-执行异步任务","slug":"并发编程-执行异步任务","date":"2018-05-29T16:00:00.000Z","updated":"2020-10-29T13:26:18.513Z","comments":true,"path":"2018/05/30/并发编程-执行异步任务/","link":"","permalink":"https://zzkenyon.github.io/2018/05/30/并发编程-执行异步任务/","excerpt":"","text":"异步编程的目标是：提交一个任务给线程池，在任务执行期间，提交者可以执行其他的逻辑，当提交的任务执行完成，通知提交者来获取执行结果 jdk并发包中的异步编程是通过Future 接口实现的： 12345678public interface Future&lt;V&gt; &#123; boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; 泛型V是任务执行结果的类型。 我们通过如下方式提交任务给线程池： 123ThreadPool.submit(new Callable&lt;String&gt;()-&gt;&#123; return \"zpd\";&#125;); submit接收一个Callable类型的任务，但是我们知道，线程池一般都是通过execut方法来执行任务，且execute只接受Runnable类型的任务，Callable任务又是怎么执行的？ 那我们来看一下submit方法的源码： 1234567//AbstractExecutorServicepublic &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task); execute(ftask); return ftask;&#125; 可以看到Callable又被封装成了FutureTask对象再执行，FutureTask实现了RunnableFuture接口 123public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123; void run();&#125; 原来FutureTask就是Runnable和Future的合体，意味着Callable被封装成RunnableFuture之后，即可以直接丢给execut方法执行，又能使用Future接口的方法实现异步功能。 12345678public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; &#123; private volatile int state; // 执行过程 private Callable&lt;V&gt; callable; // 执行结果或者异常 private Object outcome; ...&#125; FutureTask类的两个关键对象，其中一个就是对提交的Callable对象的引用。 这里我整理一下：最终被线程池执行的对象是FutureTask，它本身是一个Runnable，且持有一个Callable对象，因此线程池执行它的时候，一定是执行它的run方法，而run方法内部肯定调用了Callable对象的call方法，因为提交的任务逻辑就是call方法。 submit方法对Runnable类型的任务也做了适配。看源码： 1234567//AbstractExecutorServicepublic &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task, result); execute(ftask); return ftask;&#125; 我们在传入Runnable型任务的时候，由于其执行体没有返回值，因此还需要传入另一个参数来代表执行完成的返回结果，这样在将Runnable封装成FutureTask时，可以使用适配器将Runnable任务和 result 转换成一个Callable，再去构建 FutureTask对象 贴出两个newTaskFor方法： 1234567//AbstractExecutorServiceprotected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; return new FutureTask&lt;T&gt;(runnable, value);&#125;protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; return new FutureTask&lt;T&gt;(callable);&#125; 我看到网上一些资料对比callable与runnable的区别： 1、callable 有返回值，runnable不支持返回值 2、callable 可以抛出异常，runnable则不支持 我认为这样对比的意义不大，因为这两个接口本来既不是一个层级的，Runnable是可以直接被线程执行的，而Callable需要通过再封装成Runnable，并在封装层的run方法调用中才能执行，call方法可以有返回值，可以抛异常也只是针对封装层的FutureTask对象而言，返回的结果给了FutureTask，异常也抛给了FutureTask，用户想要获取返回值或者异常，需要主动的写代码获取。 因此Future异步任务的执行过程，并不是真正的异步，最主要的问题是没有实现回调，只能称为同步非阻塞。所以在java8中又新增了一个真正的异步函数，CompletableFuture Java 8 中新增加了一个类：CompletableFuture，它提供了非常强大的 Future 的扩展功能，最重要的是实现了回调的功能。 使用示例： 123456789101112131415161718192021222324public class CallableFutureTest &#123; public static void main(String[] args) &#123; System.out.println(\"start\"); /** * 异步非阻塞 */ CompletableFuture.runAsync(() -&gt; &#123; try &#123; Thread.sleep(3000); System.out.println(\"sleep done\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); try &#123; Thread.sleep(4000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"done\"); &#125;&#125; CompletableFuture.runAsync()方法提供了异步执行无返回值任务的功能。 123456ExecutorService executorService = Executors.newFixedThreadPool(100);CompletableFuture&lt;String&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123; // do something return \"result\";&#125;, executorService); CompletableFuture.supplyAsync()方法提供了异步执行有返回值任务的功能。 CompletableFuture源码中有四个静态方法用来执行异步任务： 12345678public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier)&#123;..&#125;public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier,Executor executor)&#123;..&#125;public static CompletableFuture&lt;Void&gt; runAsync(Runnable runnable)&#123;..&#125;public static CompletableFuture&lt;Void&gt; runAsync(Runnable runnable,Executor executor)&#123;..&#125; 前面两个可以看到是带返回值的方法，后面两个是不带返回值的方法。同时支持传入自定义的线程池，如果不传入线程池的话默认是使用 ForkJoinPool.commonPool()作为它的线程池执行异步代码。 合并两个异步任务 如果有两个任务需要异步执行，且后面需要对这两个任务的结果进行合并处理，CompletableFuture 也支持这种处理： 1234567891011ExecutorService executorService = Executors.newFixedThreadPool(100);CompletableFuture&lt;String&gt; future1 = CompletableFuture.supplyAsync(() -&gt; &#123; return \"Task1\";&#125;, executorService);CompletableFuture&lt;String&gt; future2 = CompletableFuture.supplyAsync(() -&gt; &#123; return \"Task2\";&#125;, executorService);CompletableFuture&lt;String&gt; future = future1.thenCombineAsync(future2, (task1, task2) -&gt; &#123; return task1 + task2; // return \"Task1Task2\" String&#125;); 通过 CompletableFuture.thenCombineAsync()方法获取两个任务的结果然后进行相应的操作。 下一个依赖上一个的结果 如果第二个任务依赖第一个任务的结果： 12345678910ExecutorService executorService = Executors.newFixedThreadPool(100);CompletableFuture&lt;String&gt; future1 = CompletableFuture.supplyAsync(() -&gt; &#123; return \"Task1\";&#125;, executorService);CompletableFuture&lt;String&gt; future = future1.thenComposeAsync(task1 -&gt; &#123; return CompletableFuture.supplyAsync(() -&gt; &#123; return task1 + \"Task2\"; // return \"Task1Task2\" String &#125;);&#125;, executorService); CompletableFuture.thenComposeAsync()支持将第一个任务的结果传入第二个任务中。 常用 API 介绍 拿到上一个任务的结果做后续操作，上一个任务完成后的动作 1234public CompletableFuture&lt;T&gt; whenComplete(BiConsumer&lt;? super T,? super Throwable&gt; action)public CompletableFuture&lt;T&gt; whenCompleteAsync(BiConsumer&lt;? super T,? super Throwable&gt; action)public CompletableFuture&lt;T&gt; whenCompleteAsync(BiConsumer&lt;? super T,? super Throwable&gt; action, Executor executor)public CompletableFuture&lt;T&gt; exceptionally(Function&lt;Throwable,? extends T&gt; fn) 上面四个方法表示在当前阶段任务完成之后下一步要做什么。whenComplete 表示在当前线程内继续做下一步，带 Async 后缀的表示使用新线程去执行。 拿到上一个任务的结果做后续操作，使用 handler 来处理逻辑，可以返回与第一阶段处理的返回类型不一样的返回类型。 123public &lt;U&gt; CompletableFuture&lt;U&gt; handle(BiFunction&lt;? super T,Throwable,? extends U&gt; fn)public &lt;U&gt; CompletableFuture&lt;U&gt; handleAsync(BiFunction&lt;? super T,Throwable,? extends U&gt; fn)public &lt;U&gt; CompletableFuture&lt;U&gt; handleAsync(BiFunction&lt;? super T,Throwable,? extends U&gt; fn, Executor executor) Handler 与 whenComplete 的区别是 handler 是可以返回一个新的 CompletableFuture 类型的。 12345CompletableFuture&lt;Integer&gt; f1 = CompletableFuture.supplyAsync(() -&gt; &#123; return \"hahaha\";&#125;).handle((r, e) -&gt; &#123; return 1;&#125;); 拿到上一个任务的结果做后续操作， thenApply方法 123public &lt;U&gt; CompletableFuture&lt;U&gt; thenApply(Function&lt;? super T,? extends U&gt; fn)public &lt;U&gt; CompletableFuture&lt;U&gt; thenApplyAsync(Function&lt;? super T,? extends U&gt; fn)public &lt;U&gt; CompletableFuture&lt;U&gt; thenApplyAsync(Function&lt;? super T,? extends U&gt; fn, Executor executor) 注意到 thenApply 方法的参数中是没有 Throwable，这就意味着如有有异常就会立即失败，不能在处理逻辑内处理。且 thenApply 返回的也是新的 CompletableFuture。 这就是它与前面两个的区别。 拿到上一个任务的结果做后续操作，可以不返回任何值，thenAccept方法 123public CompletableFuture&lt;Void&gt; thenAccept(Consumer&lt;? super T&gt; action)public CompletableFuture&lt;Void&gt; thenAcceptAsync(Consumer&lt;? super T&gt; action)public CompletableFuture&lt;Void&gt; thenAcceptAsync(Consumer&lt;? super T&gt; action, Executor executor) 看这里的示例： 1234567CompletableFuture.supplyAsync(() -&gt; &#123; return \"result\";&#125;).thenAccept(r -&gt; &#123; System.out.println(r);&#125;).thenAccept(r -&gt; &#123; System.out.println(r);&#125;); 执行完毕是不会返回任何值的。 CompletableFuture 的特性提现在执行完 runAsync 或者 supplyAsync 之后的操作上。CompletableFuture 能够将回调放到与任务不同的线程中执行，也能将回调作为继续执行的同步函数，在与任务相同的线程中执行。它避免了传统回调最大的问题，那就是能够将控制流分离到不同的事件处理器中。 另外当你依赖 CompletableFuture 的计算结果才能进行下一步的时候，无需手动判断当前计算是否完成，可以通过 CompletableFuture 的事件监听自动去完成。","categories":[{"name":"并发编程的艺术","slug":"并发编程的艺术","permalink":"https://zzkenyon.github.io/categories/并发编程的艺术/"}],"tags":[{"name":"JDK","slug":"JDK","permalink":"https://zzkenyon.github.io/tags/JDK/"}],"keywords":[{"name":"并发编程的艺术","slug":"并发编程的艺术","permalink":"https://zzkenyon.github.io/categories/并发编程的艺术/"}]},{"title":"jvm(5)垃圾回收","slug":"jvm(5)垃圾回收","date":"2018-05-24T16:00:00.000Z","updated":"2021-01-18T09:29:58.838Z","comments":true,"path":"2018/05/25/jvm(5)垃圾回收/","link":"","permalink":"https://zzkenyon.github.io/2018/05/25/jvm(5)垃圾回收/","excerpt":"","text":"垃圾对象检测： 引用计数 可达性分析 GC root由哪些对象组成 本地方法栈中引用的对象 虚拟机栈中引用的对象 方法区中类变量引用的对象 方法区中的常量引用的对象 1. 垃圾收集算法和收集器垃圾收集算法有哪些： 标记-清除 产生内存碎片、效率不高 标记-整理 效率低 复制 空间利用率低 新生代（Young区）对象朝生夕死，GC时存活概率小，所以适合复制算法 老年代（old区）对象，GC频率低，涉及空间较大，因此适合使用标记清除或者标记整理 垃圾收集器有哪些 评价一个垃圾收集器优劣的指标是 吞吐量 和 停顿时间 一、新生代收集器 Serial 收集器 历史悠久的收集器，单线程运行，运行时会阻塞其他线程，使用复制算法，因此适用于新生代垃圾回收 ParNew 收集器 Serial收集器的并行版，同样采用复制算法，适用于新生代，单CPU性能比Serial差 运行在server模式下的虚拟中首选的新生代收集器 Parallel Scavenge 收集器 注重吞吐量， 吞吐量 = 程序运行时间/(程序运行时间+垃圾回收时间) 二、老年代收集器 Serial old 复制算法的实现，单线程运行 Paraller Old 最关注的点事吞吐量 CMS 并发收集器 Concurrent Mark Sweep—并发标记清理 并发：用户线程和垃圾回收线程一起执行 并行：多条垃圾回收线程同时执行 CMS 最关注的点是GC停顿时间，所以优点是低停顿时间（因为并发收集） 缺点就是会产生大量的内存碎片（因为采用标记-清理算法），且并发阶段会吞吐量降低 流程：初始标记-&gt;并发标记-&gt;重新标记-&gt; 并发清理 初始标记，stw，标记的事GCroot 并发标记，与用户线程一起执行，执行可达性分析，标记不可达对象 重新标记，stw，标记并发标记阶段产生的新垃圾 并发清理，用户线程一起执行，回收标记的对象 使用 -XX:+UseConcMarkSweepGC 开启CMS 搭配使用： 三、G1 Garbage-First 整体上属于标记-整理算法的实现，不会产生内存碎片 比CMS先进的地方在于用户可以设置停顿时间的大小，G1会按照用户的设置的停顿时间制定回收计划 G1可同时用于新生代和老年代的垃圾回收，核心在于对堆内存的重新划分，不同的内存区域对于G1来说只是逻辑上的区分，在物理层面，G1将内存划分成一个个的region统一进行管理。 G1收集器会先收集存活对象少的区域，也就是垃圾对象多的区域，这样可以有大量的空间可以释放出来，这就 是Garbage First的由来 执行流程为：初始标记–&gt; 并发标记 –&gt; 最终标记 –&gt; 筛选回收 初始标记：stw，标记GC ROOT 并发标记：与用户线程并发执行，执行可达性分析 最终标记：stw，标记并发标记阶段用户线程产生的新垃圾 筛选回收：stw，对各个Region的回收价值和回收成本进行排序，根据用户设定的停顿时间指定回收计划 总结： Serial 和Serial Old 为串行收集器，适用于内存较小的嵌入式设备 Parallel 和 Parallel Old 为并行收集器，吞吐量优先的收集器组合，适用于科学计算、后台处理等应用场景 CMS 和 G1 为并发收集器，停顿时间优先，CMS适用于老年代收集（标记-清除），G1适用于整个堆内存垃圾回收（标记-整理），适用与对响应时间要求较高的场景，比如Web 使用不同的收集器 123456789（1）串行 -XX：+UseSerialGC -XX：+UseSerialOldGC （2）并行(吞吐量优先)： -XX：+UseParallelGC -XX：+UseParallelOldGC （3）并发收集器(响应时间优先) -XX：+UseConcMarkSweepGC -XX：+UseG1GC 2、GC分类Minor GC触发条件：当Eden区满时，触发Minor GC。 Full GC触发条件：（1）调用System.gc时，系统建议执行Full GC，但是不必然执行（2）老年代空间不足（3）方法区空间不足（4）通过Minor GC后进入老年代的平均大小大于老年代的可用内存（5）由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小。 3、调优JVM调优参数简介 jvm调优一般适用非标准化参数，即-XX参数。除此之外还有标准化参数-、-X参数，此处不表 boolean 类型参数：用+/-表示是否开启，例如-XX:+UseG1GC，开启G1收集器 值类型参数：例如-XX:MaxGCPauseMillis=500，表示GC最大允许停顿时间500ms 其他参数 -Xms100M 等价于 -XX:InitialHeapSize = 100M -Xmx200M 等价于 -XX:MaxHeapSize = 200M -Xss20K 等价于 -XX:ThreadStackSize = 20k 展示常用的jvm参数： -XX:+PrintFlagsFinal 启动时打印所有JVM参数 参数怎么修改 ide中进行配置 java -XX:+UseG1GC tomcat –bin–xxxxx.sh/catalina.sh — jvm参数 实时修改 jinfo，只能修改一部分 启动时打印的参数 = 表示默认参数 :=表示用户修改的参数 常用参数 内存分配相关 -Xms100M 初始堆大小 -Xmx200M 堆最大size -Xss20K 方法栈大小 经验值3000~5000字节 -XX:NewSize=20M 设置Young区大小 -XX:MaxNewSize=50M 年轻代最大size -XX:OldSize=50M 设置Old区大小 -XX:MetaspaceSize=100M 设置元空间大小 -XX:MaxMetaspaceSize=200M 元空间最大size -XX:NewRatio=4 老生代占堆比值 4 表示—新生代：老年代 = 1：4 -XX:SurviviorRatio=8 Eden区占Young区的比例 8表示Eden:s0:s1=8:1:1 GC相关 -XX:+UseSerialGC -XX:+UseSerialOldGC -XX:+UseParallelGC -XX:+UseParallelOldGC -XX:+UseConcMarkSweepGC -XX:+UseG1GC -XX:MaxGCPauseMillis=200ms 设置允许的最大GC停顿时间 -XX:G1HeapWastePercent 设置允许G1收集器浪费的堆空间占比 XX:ConcGCThreads=n 设置并行的GC线程数量 -XX:InitiatingHeapOccupancyPercent 启动并发GC周期时，dui -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps Xloggc:$CATALINA_HOME/logs/gc.log 设置GC日志打印选项 -XX:MaxTenuringThreshold =6 对象提升到老年代的年龄阈值 -XX:G1OldCSetRegionThresholdPercent=1 -XX:G1MixedGCCountTarget=8 -XX:G1MixedGCLiveThresholdPercent=65 其他参数 -XX:CICompilerCount=3 -XX:+HeapDumpOnOutOfMemoryError oom的时候dump内存快照 -XX:HeapDumpPath=heap.hprof 内存快照输出路径 常用命令： jps 查看当前jvm中的所有java进程号 jinfo 查看和调整指定进程的jvm参数 查看指定名称参数的指令：jinfo -flag 查看所有指令：jinfo -flags 修改参数： jinfo -flag &lt;+/-&gt; jinfo -flag = jstat class/gc jstack 查看某进程的线程，可用于排查死锁 jmap: 生成堆内存快照 jmap -heap PID 干嘛要看堆内寸信息呢 生产环境OOM—-&gt;在发生oom的时候能把内存的信息导出来进行分析 手动 dump文件： jmap -dump:format=b,file=heap.hprof PID 配置自动dump -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumoPath=dump.hprof 常用工具 jdk自带 jconsole jvisualvm 连接远端的java 使用jmx连接 第三方 arthas mat GC调优： GC 发生的timing eden区满 old区满 方法区满 System.gc() 获取GC日志 配置参数 -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -Xloggc:gc.log 若想要获取tomcat的Gc日志，编辑catalina.bat,在第一行加上参数： 1set JAVA_OPTS=%JAVA_OPTS% -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -Xloggc:gc.log 启动tomcat后能在当前目录拿到gc.log文件 GC日志文件分析工具 gceasy GCViewer G1调优指南（官方） 不要手动设置新生代和老年代的大小，只要设置整个堆的大小 G1收集器在运行过程中，会自己调整新生代和老年代的大小 其实是通过adapt代的大小来调整对象晋升的速度和年龄，从而达到为收集器设置的暂停时间目标 如果手动设置了大小就意味着放弃了G1的自动调优 不断调优暂停时间目标 一般情况下这个值设置到100ms或者200ms都是可以的(不同情况下会不一样)，但如果设置成50ms就 不太合理。暂停时间设置的太短，就会导致出现G1跟不上垃圾产生的速度。最终退化成Full GC。所以 对这个参数的调优是一个持续的过程，逐步调整到最佳状态。暂停时间只是一个目标，并不能总是得到 满足。 使用-XX:ConcGCThreads=n来增加标记线程的数量 IHOP如果阀值设置过高，可能会遇到转移失败的风险，比如对象进行转移时空间不足。如果阀值设置过 低，就会使标记周期运行过于频繁，并且有可能混合收集期回收不到空间。 IHOP值如果设置合理，但是在并发周期时间过长时，可以尝试增加并发线程数，调高 ConcGCThreads。 MixedGC调优 1234-XX:InitiatingHeapOccupancyPercent -XX:G1MixedGCLiveThresholdPercent -XX:G1MixedGCCountTarger -XX:G1OldCSetRegionThresholdPercent 适当增加堆内存大小 常见问题： 1、内存泄漏与内存溢出的区别 内存泄漏是指不再使用的对象无法得到及时的回收，持续占用内存空间，从而造成内存空间的浪费。内存泄漏很容易导致内存溢出，但内存溢出不一定是内存泄漏导致的。 2、young gc会有stw吗？ 不管什么 GC，都会发送 stop-the-world，区别是发生的时间长短。而这个时间跟垃圾收集器又有关系，Serial、PartNew、Parallel Scavenge 收集器无论是串行还是并行，都会挂起用户线程，而 CMS和 G1 在并发标记时，是不会挂起用户线程的，但其它时候一样会挂起用户线程，stop the world 的时间相对来说就小很多了。 3、major gc和full gc的区别 Major Gc 在很多参考资料中是等价于 Full GC 的，我们也可以发现很多性能监测工具中只有 Minor GC和 Full GC。一般情况下，一次 Full GC 将会对年轻代、老年代、元空间以及堆外内存进行垃圾回收。触发 Full GC 的原因有很多：当年轻代晋升到老年代的对象大小，并比目前老年代剩余的空间大小还要大时，会触发 Full GC；当老年代的空间使用率超过某阈值时，会触发 Full GC；当元空间不足时（JDK1.7永久代不足），也会触发 Full GC；当调用 System.gc() 也会安排一次 Full GC。 4、G1与CMS的区别是什么 CMS 主要集中在老年代的回收，而 G1 集中在分代回收，包括了年轻代的 Young GC 以及老年代的 MixGC；G1 使用了 Region 方式对堆内存进行了划分，且基于标记整理算法实现，整体减少了垃圾碎片的产生；在初始化标记阶段，搜索可达对象使用到的 Card Table，其实现方式不一样。 5、什么是直接内存 Java的NIO库允许Java程序使用直接内存。直接内存是在java堆外的、直接向系统申请的内存空间。通常访问直接内存的速度会优于Java堆。因此出于性能的考虑，读写频繁的场合可能会考虑使用直接内存。由于直接内存在java堆外，因此它的大小不会直接受限于Xmx指定的最大堆大小，但是系统内存是有限的，Java堆和直接内存的总和依然受限于操作系统能给出的最大内存。 6、垃圾判断的方式 引用计数法：指的是如果某个地方引用了这个对象就+1，如果失效了就-1，当为0就会回收但是JVM没有用这种方式，因为无法判定相互循环引用（A引用B,B引用A）的情况引用链法： 通过一种GC ROOT的对象（方法区中静态变量引用的对象等-static变量）来判断，如果有一条链能够到达GC ROOT就说明，不能到达GC ROOT就说明可以回收 7、不可达的对象一定要被回收吗？ 即使在可达性分析法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑阶段”，要真正宣告一个对象死亡，至少要经历两次标记过程；可达性分析法中不可达的对象被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行 fifinalize 方法。当对象没有覆盖 fifinalize 方法，或fifinalize 方法已经被虚拟机调用过时，虚拟机将这两种情况视为没有必要执行。被判定为需要执行的对象将会被放在一个队列中进行第二次标记，除非这个对象与引用链上的任何一个对象建立关联，否则就会被真的回收。 8、方法区中的无用类回收 方法区主要回收的是无用的类，那么如何判断一个类是无用的类的呢？判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。类需要同时满足下面 3 个条件才能算是无用的类： 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 虚拟机可以对满足上述 3 个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。 9、为什么要区分新生代和老年代 当前虚拟机的垃圾收集都采用分代收集算法，这种算法没有什么新的思想，只是根据对象存活周期的不同将内存分为几块。一般将 java 堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。 比如在新生代中，每次收集都会有大量对象死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。","categories":[{"name":"深入理解java虚拟机","slug":"深入理解java虚拟机","permalink":"https://zzkenyon.github.io/categories/深入理解java虚拟机/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://zzkenyon.github.io/tags/jvm/"}],"keywords":[{"name":"深入理解java虚拟机","slug":"深入理解java虚拟机","permalink":"https://zzkenyon.github.io/categories/深入理解java虚拟机/"}]},{"title":"jvm(4)类加载机制以及类加载器","slug":"jvm(4)类加载机制以及类加载器","date":"2018-05-19T16:00:00.000Z","updated":"2021-01-27T10:43:59.999Z","comments":true,"path":"2018/05/20/jvm(4)类加载机制以及类加载器/","link":"","permalink":"https://zzkenyon.github.io/2018/05/20/jvm(4)类加载机制以及类加载器/","excerpt":"","text":"1、类加载器的分类 Bootstrap ClassLoader 负责加载$JAVA_HOME中的 jre/lib/rt.jar里面所有的class 或者 Xbootclassoath选项指定的jar包，由C++实现，不是ClassLoader的子类 Extenson ClassLoader 负责加载java平台中扩展功能的一些jar包，包括$JAVA_HOME中的jre/lib/*.jar或者-Djava.ext.dirs指定目录下的jar包。 App ClassLoader 负责加载classpath中指定的jar包以及 -Djava.class.path 所指定目录下的类和jar包 Custom ClassLoader 通过java.lang.ClassLoader的子类自定义加载器。属于应用程序根据自身需要自定义的classLader。如Tomcat，Jboss都会根据J2EE规范自行实现ClassLoader 2、类加载原则：检查某个类是否已经加载，顺序是自底而上，从custom classloader 到 Bootstrap classloader 逐层检查，只要某个classloader已加载就是为已加载此类，保证此类之加载一次。 加载的顺序是自顶向下，也就是先由上层尝试加载此类，这就是双亲委派机制 双亲委派定义：如果一个类加载器在接到加载棋类的请求时，它首先不会自己藏市区加载这个类，而是把这个请求任务委托给父类加载器去完成，依次递归。如果父类加载器可以完成加载任务，就成功返回，只有父类加载器不能完成此加载任务是，自己才去加载。 双亲委派优势：java类随着加载它的类加载器一起具备了一种带有优先级的层次关系。比如java中的Object类，它存放在rt.jar中，无论哪个类加载器要加载这个类，最终都是委派给处于模型顶端的驱动类加载器进行加载。因此Object类在各种类加载环境中都是同一个类。如果不采用这种模式，那么由各个类自己加载的话，系统中会存在多种不同的Object类。 3、类加载器重要方法分析： 可以看到顶层的类加载器是classLoader类，它是一个抽象类，几乎所有的类加载器都继承自classloader（不包括启动类加载器），下面介绍一下classloader中比较重要的方法 loadClass(String) 该方法用来加载指定名称的字节码文件，不建议用户重写但可以直接调用该方法。此方法是ClassLoader类自己实现的，方法逻辑就是双亲委派的实现。 loadClass实现也可以知道如果不想重新定义加载类的规则，也没有复杂的逻辑，只想在运行时加载自己指定的类，那么我们可以直接使用this.getClass().getClassLoder.loadClass(&quot;className&quot;)，这样就可以直接调用ClassLoader的loadClass方法获取到class对象。 findClass(String) 自定义加载器时需要重写的方法。该方法是在loadClass方法中被调用的，当loadClass方法中父加载器加载失败后，则会调用自己的findClass()方法来完成类加载。将向上委托和自己加载两块逻辑分开，可以保证自定义的加载器也符合双亲委派模型 需要注意的是ClassLoader类中并没有实现findClass()方法的具体代码逻辑，取而代之的是抛出ClassNotFoundException异常，同时应该知道的是findClass方法通常是和defineClass方法一起使用的(稍后会分析)，ClassLoader类中findClass()方法源码如下： defineClass(byte[] b, int off, int len) 此方法用于将字节流解析成Jvm能够使别的Class对象，此方法由ClassLoader类实现，通过这个方法不仅能够通过class文件实例化class对象，也可以通过其他方式实例化class对象，比如通过网络接收字节流等 此方法通常与findClass方法一起使用，一般情况下在自定义类加载器时，会直接覆盖findClass方法去获取字节码文件，转换成字节流之后交给defineClass方法去实例化Class对象 12345678910protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; // 获取类的字节数组 byte[] classData = getClassData(name); if (classData == null) &#123; throw new ClassNotFoundException(); &#125; else &#123; //使用defineClass生成class对象 return defineClass(name, classData, 0, classData.length); &#125;&#125; 4、自定义类加载器1、 类与类加载器 在jvm中表示两个class对象是否为同一个对象需要满足两个必要条件 全类名必须一致 加载这个类的classLoader必须相同 也就是说，在jvm中即使两个类来自同一个字节码文件，被同一个虚拟机加载，但是只要加载它们的加载器不是同一个，那么这两个类对象也是不相等的，这是因为不同的加载器实例对象拥有不同的独立的类名称空间。 2、显示加载和隐式加载 显示加载：显示的使用代码加载一个类，如Class.forName()以及 getClassLoader().loadClass(string) 隐式加载：虚拟机自动加载，加载某个类时，需要加载其依赖的其他类 3、编写类加载器 当需要加载的类不在classpath上时 当字节码文件是通过网络传输并且可能被加密的时候 当需要实现热部署功能，即一个字节码文件通过不同的类加载器产生不同的class对象 当项目依赖多版本jar包时 自定义File类加载器： 12345678910111213141516171819202122232425262728293031public class FileClassLoader extends ClassLoader&#123; private String rootDir ; public FileClassLoader(String rootDir) &#123; this.rootDir = rootDir; &#125; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; Class&lt;?&gt; clazz = null; String clazzLocation = rootDir + name + \".class\"; try &#123; InputStream in = new BufferedInputStream(new FileInputStream(clazzLocation)); byte[] buffer = new byte[1024]; int len = in.read(buffer); clazz = defineClass(name,buffer,0,len); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return clazz; &#125; public static void main(String[] args) throws Exception&#123; String rootDir = \"/Users/zhaozhengkang/Documents/\"; FileClassLoader classLoader = new FileClassLoader(rootDir); Class&lt;?&gt; clazz = classLoader.loadClass(\"DemoClass\"); System.out.println(clazz.getName()); Method method = clazz.getMethod(\"pringHello\"); method.invoke(clazz.newInstance()); &#125;&#125; 关键是重写findClass方法，方法中读取指定路径上的指定名称的字节码文件，获取到字节数组，在调用defineClass实例化Class对象。main方法中使用反射的方式调用了DemoClass中的方法。 抽象类ClassLoader构造方法中已经制定了 parent 为AppClassLoader 因此，只要我们使用继承ClassLoader的方式编写自定义的CL，那么这个加载器就是遵循双亲委派机制的加载器。 这里是为了演示自定义加载器的方法，实际自定义文件类加载器最好的方式是继承FileUrlClassLoader类 5、破坏双亲委派java的SPI机制，指的是java定义一套接口，这套接口允许第三方提供实现。常见的如JDBC。 java的SPI接口属于java的核心库，一般存在与rt.jar包中，由Bootstrap类加载器加载。 SPI的实现代码则是作为java应用所依赖的jar包被存放在classpath下，启动类加载器加载不到 同时由于双亲委派机制的存在，启动类加载器也无法委托具体的AppClassLoader去加载 鉴于以上原因，我们需要一种特殊的类加载器来加载这种情形，那就是线程上下文类加载器。 我们可以通过java.lang.Thread类中的getContextClassLoader()和 setContextClassLoader(ClassLoader cl)方法来获取和设置线程的上下文类加载器。 线程上下文类加载器的加载方式破坏了“双亲委派模型”，它在执行过程中抛弃双亲委派加载链模式，使程序可以逆向使用类加载器，当然这也使得Java类加载器变得更加灵活。 线程上下文类加载器默认情况下就是AppClassLoader，那为什么不直接通过getSystemClassLoader()获取类加载器来加载classpath路径下的类的呢？其实是可行的，但这种直接使用getSystemClassLoader()方法获取AppClassLoader加载类有一个缺点，那就是代码部署到不同服务时会出现问题，如把代码部署到Java Web应用服务或者EJB之类的服务将会出问题，因为这些服务使用的线程上下文类加载器并非AppClassLoader，而是Java Web应用服自家的类加载器，类加载器不同。所以我们应用该少用getSystemClassLoader()。总之不同的服务使用的可能默认ClassLoader是不同的，但使用线程上下文类加载器总能获取到与当前程序执行相同的ClassLoader，从而避免不必要的问题。 https://blog.csdn.net/t894690230/article/details/73252331 参考文章： 深入理解Java类加载器(ClassLoader) 真正理解线程上下文类加载器（多案例分析）","categories":[{"name":"深入理解java虚拟机","slug":"深入理解java虚拟机","permalink":"https://zzkenyon.github.io/categories/深入理解java虚拟机/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://zzkenyon.github.io/tags/jvm/"}],"keywords":[{"name":"深入理解java虚拟机","slug":"深入理解java虚拟机","permalink":"https://zzkenyon.github.io/categories/深入理解java虚拟机/"}]},{"title":"并发编程-并发工具类","slug":"并发编程-并发工具类","date":"2018-05-17T12:36:12.000Z","updated":"2020-05-22T11:40:35.732Z","comments":true,"path":"2018/05/17/并发编程-并发工具类/","link":"","permalink":"https://zzkenyon.github.io/2018/05/17/并发编程-并发工具类/","excerpt":"","text":"在JDK的并发包中提供了几个非常有用的并发工具类。CountDownLatch、CyclicBarrier和Semaphore提供了并发流程控制手段，Exchanger提供了两个线程之间交换数据的手段，本文将配合应用场景介绍该如何使用这几个工具类。 1. CountDownLatchCountDownLatch是JDK 5+里面闭锁的一个实现，他允许一个或多个线程等待其他线程完成各自的工作后再执行。 闭锁（Latch）：一种同步方法，可以延迟线程的进度直到线程到达某个终点状态。 与CountDownLatch第一次交互是主线程等待其它的线程，主线程必须在启动其它线程后立即调用await方法，这样主线程的操作就会在这个方法上阻塞，直到其他线程完成各自的任务。 其他的N个线程必须引用闭锁对象，因为他们需要通知CountDownLatch对象，他们已经完成了各自的任务，这种机制就是通过调用countDown()方法来完成的。每调用一次这个方法，在构造函数中初始化的count值就减1，所以当N个线程都调用了这个方法count的值等于0，然后主线程就能通过await方法，恢复自己的任务。 与Join的区别：调用join方法需要等待thread执行完毕才能继续向下执行,而CountDownLatch只需要检查计数器的值为零就可以继续向下执行，相比之下，CountDownLatch更加灵活一些，可以实现一些更加复杂的业务场景。 1.1 使用场景 开启多个线程分块下载一个大文件，每个线程只下载固定的一截，最后由另外一个线程来拼接所有的分段。 应用程序的主线程希望在负责启动框架服务的线程已经启动所有的框架服务之后再执行。 确保一个计算不会执行，直到所需要的资源被初始化。 1.2 主要方法12345678910//初始化计数的次数，不能重置public CountDownLatch(int count); //调用此方法则计数减1public void countDown(); //得到当前的计数Public Long getCount(); //调用此方法会一直阻塞当前线程，直到计时器的值为0，除非线程被中断。public void await() throws InterruptedException //调用此方法会一直阻塞当前线程，直到计时器的值为0，除非线程被中断或者计数器超时，返回false代表计数器超时。Public boolean await(long timeout, TimeUnit unit) 1.3 使用案例 latch.countDown(); 建议放到finally语句里。 对这个计数器的操作都是原子操作，同时只能有一个线程去操作这个计数器。 12345678910111213141516171819202122232425262728293031public class CountDownLatchTest &#123; private final CountDownLatch latch = new CountDownLatch(3); private final ReentrantLock lock = new ReentrantLock(); private int count; public int getCount()&#123; return this.count; &#125; public class RunnableTask implements Runnable&#123; @Override public void run() &#123; try &#123; lock.lock(); count += 100; &#125;finally &#123; latch.countDown(); lock.unlock(); &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException&#123; CountDownLatchTest demo = new CountDownLatchTest(); int i = 3; while(i-- &gt; 0)&#123; new Thread(demo.new RunnableTask()).start(); &#125; demo.latch.await(); System.out.println(demo.getCount()); &#125;&#125; 三个线程分别对count加100，等三个线程执行完后，主线程输出count的值。输出300 2. CyclicBarrier字面意思是可以循环使用的屏障。他要做的事情是让一组线程到达一个同步点时被阻塞，直到最后一个线程到达同步点，才会打开屏障，所有线程继续运行。 默认的构造方法 CyclicBarrier(int parties) ，参数代表屏障拦截的线程数量，每个线程调用await方法告诉CyclicBarrier已经到达屏障，然后被阻塞。 1.1 使用场景可用于多线程计算数据，最后合并计算结果 1.2 主要方法123456789101112131415//初始化public CyclicBarrier(int parties)//barrierAction表示被拦住的线程需要执行的任务public CyclicBarrier(int parties, Runnable barrierAction)//被拦住的线程调用次函数进入阻塞状态public int await()//被拦住的线程调用次函数进入阻塞状态，超时唤醒public int await(long timeout, TimeUnit unit)public void reset() //返回需要被拦住的线程数量public int getParties() //查询此屏障是否处于断开状态public boolean isBroken()//返回已被拦住的线程数量public int getNumberWaiting() 1.3 使用案例初始化线程数为2，加上主线程调用await()3次，所以得出结论主线程调用不计入await次数之内。123456789101112131415161718192021222324252627public class CyclicBarrierTest &#123; private static CyclicBarrier cb = new CyclicBarrier(2); private static ReentrantLock lock = new ReentrantLock(); private static int count; public static class RunnableTask implements Runnable&#123; @Override public void run() &#123; try &#123; lock.lock(); count += 100; cb.await(); &#125;catch (Throwable e)&#123; &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; public static void main(String[] args) throws Exception&#123; for(int i = 0; i &lt; 2; i++) &#123; new Thread(new RunnableTask()).start(); &#125; cb.await(); System.out.println(count); &#125;&#125; 输出200 1.4 与CountDownLatch的区别 CountDownLatch的计数器只能使用一次，而CyclicBarrier的计数器可以使用reset()方法重置，可以使用多次，所以CyclicBarrier能够处理更为复杂的场景； CyclicBarrier还提供了一些其他有用的方法，比如getNumberWaiting()方法可以获得CyclicBarrier阻塞的线程数量，isBroken()方法用来了解阻塞的线程是否被中断； CountDownLatch允许一个或多个线程等待一组事件的产生，而CyclicBarrier用于等待其他线程运行到栅栏位置。 3. SemaphoreSemaphore是用来控制同事访问特定资源的线程数量，它通过协调各个线程以保证合理的使用公共资源。 3.1 使用场景可用于做流量控制，特别是公用资源有限的场景，比如数据库连接。 4. ExchangerExchanger类可用于两个线程之间交换信息。可简单地将Exchanger对象理解为一个包含两个格子的容器，通过exchanger方法可以向两个格子中填充信息。当两个格子中的均被填充时，该对象会自动将两个格子的信息交换，然后返回给线程，从而实现两个线程的信息交换。 Exchanger类仅可用作两个线程的信息交换，当超过两个线程调用同一个exchanger对象时，得到的结果是不确定的，exchanger对象仅关心其包含的两个“格子”是否已被填充数据，当两个格子都填充数据完成时，该对象就认为线程之间已经配对成功，然后开始执行数据交换操作。12345678910111213141516171819202122232425public class ExchangerTest &#123; private static Exchanger&lt;String&gt; exgr = new Exchanger&lt;&gt;(); private static ExecutorService threadpool = Executors.newFixedThreadPool(3); public static void main(String[] args)&#123; threadpool.execute(() -&gt; &#123; String a = \"银行流水A\"; try &#123; exgr.exchange(a); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); threadpool.execute(() -&gt; &#123; String b = \"银行流水B\"; try &#123; String a = exgr.exchange(b); System.out.println(a); &#125; catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125;); threadpool.shutdown(); &#125;&#125;","categories":[{"name":"并发编程的艺术","slug":"并发编程的艺术","permalink":"https://zzkenyon.github.io/categories/并发编程的艺术/"}],"tags":[{"name":"JDK","slug":"JDK","permalink":"https://zzkenyon.github.io/tags/JDK/"}],"keywords":[{"name":"并发编程的艺术","slug":"并发编程的艺术","permalink":"https://zzkenyon.github.io/categories/并发编程的艺术/"}]},{"title":"jvm(3)运行时数据区和内存模型","slug":"jvm(3)运行时数据区和内存模型","date":"2018-05-16T16:00:00.000Z","updated":"2021-01-15T05:04:17.281Z","comments":true,"path":"2018/05/17/jvm(3)运行时数据区和内存模型/","link":"","permalink":"https://zzkenyon.github.io/2018/05/17/jvm(3)运行时数据区和内存模型/","excerpt":"","text":"我现在已经了解了类的装载机制，当需要装载一个class时，会经历以下步骤： 通过全类名获取字节码文件的字节流 将字节流所代表的静态存储结构转换为方法区的运行时数据结构 在java堆中声称代表这个类的Class对象实例作为对方法去中这些数据访问的入口 在2.3两步中看到了方法区、堆等名词，这些都是jvm进程运行过程需要直接使用的运行时数据区域。 1. 运行时数据区1、方法区 方法区是所有线程共享的内存区域，在jvm进程启动时创建 用于存储被虚拟机加载的类信息、常量、静态变量、即使编译器编译后的代码等数据 java虚拟机规范将方法区描述为堆的一个逻辑部分，但是又有一个别名叫“非堆”，目的是与堆区分开来 当方法区无法满足内存分配要求，将抛OutOfMemory异常 2、堆 堆是虚拟机管理内存最大的一块，jvm启动时创建，所有线程共享 java对象实例以及数组都是在堆上创建 3、虚拟机栈 虚拟机栈是一个线程执行的区域，保存着线程中方法的调用状态，线程私有，随着线程的创建而创建 每个被线程执行的方法在虚拟机栈中对应一个栈桢 调用一次方法向栈中压栈一次，调用返回出栈 4、本地方法栈 执行Native方法的栈，与虚拟机栈类似 5、程序计数器 PC就是一个线程私有的指针，记录线程执行位置，确保线程调度之后重新获取cpu时能知道程序运行位置 如果线程正在执行java方法，PC记录的是正在执行的虚拟机字节码指令地址 如果线程正在执行native方法，PC值为空 了解了jvm的运行时数据区之后，来分析一下jvm的内存模型 2. 内存模型jvm内存用来存储数据的主要是堆和非堆两大块，这两块都是线程共享区域，因此内存的设计也着重错那个这两块展开。 堆分为两大块，一个是Old区，Young区 Young区又分为两块，一块是Eden区，一块是Survivor区 Survivor区有分为相同大小的s1 和 s2 ，也可以叫 from 和 to 1、新对象创建所在区域： 新对象创建时一般会放在Eden区，一些特殊的大对象会直接分配到Old区 比如有对象A，B，C等创建在Eden区，但是Eden区的内存空间肯定有限，比如有100M，假如已经使用了100M或者达到一个设定的临界值，这时候就需要对Eden内存空间进行清理，即垃圾收集(Garbage Collect)，这样的GC我们称之为Minor GC，Minor GC指得是Young区的GC。经过GC之后，有些对象就会被清理掉，有些对象可能还存活着，对于存活着的对象需要将其复制到Survivor区，然后再清空Eden区中的这些对象。 2、Survivor区详解： 由图解可以看出，Survivor区分为两块S0和S1，也可以叫做From和To。在同一个时间点上，S0和S1只能有一个区有数据，另外一个是空的。 接着上面的GC来说，比如一开始只有Eden区和From中有对象，To中是空的。 此时进行一次GC操作，From区中对象的年龄就会+1，我们知道Eden区中所有存活的对象会被复制到To区，From区中还能存活的对象会有两个去处。若对象年龄达到之前设置好的年龄阈值，此时对象会被移动到Old区，没有达到阈值的对象会被复制到To区。 此时Eden区和From区已经被清空(被GC的对象肯定没了，没有被GC的对象都有了各自的去处)。这时候From和To交换角色，之前的From变成了To，之前的To变成了From。也就是说无论如何都要保证名为To的Survivor区域是空的。Minor GC会一直重复这样的过程，直到To区被填满，然后会将所有对象复制到老年代中。 3、 Old区 从上面的分析可以看出，一般Old区都是年龄比较大的对象，或者相对超过了某个阈值的对象。在Old区也会有GC的操作，Old区的GC我们称作为Major GC。 4、一个对象的自述 我是一个普通的Java对象，我出生在Eden区，在Eden区我还看到很和我长的很像的小兄弟，我们在Eden区中玩了 挺长时间。有一天Eden区中的人实在是太多了，我就被迫去了Survivor区的“From”区，自从去了Survivor 区，我就开始漂了，有时候在Survivor的“From”区，有时候在Survivor的“To”区，居无定所。直到我18岁的 时候，爸爸说我成人了，该去社会上闯闯了。 于是我就去了Old区，Old区里面都是一些年龄都挺大的人，还有一些与我不太一样的巨人。我在这里也认识了很多人。在Old区里，我生活了20年(每次GC加一岁)，然后被回收。 5、 常见问题 如何理解Minor/Major/Full GC Minor GC:新生代 Major GC:老年代 Full GC:新生代+老年代 为什么需要Survivor区?只有Eden不行吗？ 如果没有Survivor,Eden区每进行一次Minor GC,并且没有年龄限制的条件下，存活的对象就会被送到老年 代。这样一来，老年代很快被填满,触发Major GC(因为Major GC一般伴随着Minor GC,也可以看做触发了 Full GC)。 老年代的内存空间远大于新生代,进行一次Full GC消耗的时间比Minor GC长得多。 执行时间长有什么坏处?频发的Full GC消耗的时间很长,会影响大型程序的执行和响应速度。 可能你会说，那就对老年代的空间进行增加或者较少咯。 假如增加老年代空间，更多存活对象才能填满老年代。虽然降低Full GC频率，但是随着老年代空间加大,一 旦发生Full GC,执行所需要的时间更长。 假如减少老年代空间，虽然Full GC所需时间减少，但是老年代很快被存活对象填满,Full GC频率增加。 所以Survivor的存在意义,就是减少被送到老年代的对象,进而减少Full GC的发生,Survivor的预筛选保 证,只有经历16次Minor GC还能在新生代中存活的对象,才会被送到老年代。 为什么需要两个Survivor区？ 最大的好处就是解决了碎片化。也就是说为什么一个Survivor区不行?第一部分中,我们知道了必须设置 Survivor区。假设现在只有一个Survivor区,我们来模拟一下流程: 刚刚新建的对象在Eden中,一旦Eden满了,触发一次Minor GC,Eden中的存活对象就会被移动到Survivor 区。这样继续循环下去,下一次Eden满了的时候,问题来了,此时进行Minor GC,Eden和Survivor各有一些 存活对象,如果此时把Eden区的存活对象硬放到Survivor区,很明显这两部分对象所占有的内存是不连续的, 也就导致了内存碎片化。 永远有一个Survivor space是空的,另一个非空的Survivor space无碎片。 新生代中Eden:S1:S2为什么是8:1:1？ 新生代中的可用内存：复制算法用来担保的内存为9：1 可用内存中Eden：S1区为8：1 即新生代中Eden:S1:S2 = 8：1：1","categories":[{"name":"深入理解java虚拟机","slug":"深入理解java虚拟机","permalink":"https://zzkenyon.github.io/categories/深入理解java虚拟机/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://zzkenyon.github.io/tags/jvm/"}],"keywords":[{"name":"深入理解java虚拟机","slug":"深入理解java虚拟机","permalink":"https://zzkenyon.github.io/categories/深入理解java虚拟机/"}]},{"title":"jvm(2)类加载过程","slug":"jvm(2)类加载过程","date":"2018-05-14T16:00:00.000Z","updated":"2021-01-15T04:50:14.605Z","comments":true,"path":"2018/05/15/jvm(2)类加载过程/","link":"","permalink":"https://zzkenyon.github.io/2018/05/15/jvm(2)类加载过程/","excerpt":"","text":"下图描述的是jvm加载类过程的一个逻辑顺序，具体的执行顺序不一定如下图所示，不同版本的虚拟机有不同的实现方式，本文将按照逻辑顺序逐步分析类加载过程中都发生了什么。 1 类加载时机jvm规范中没有明确规定类“加载”的时机，但是规定了有且只有以下五种情况下需要jvm对类立即执行“初始化”操作： 虚拟机启动时，要先初始化主类（含main方法的类） 使用new语句创建某类的实例，引用某类的静态变量、调用某类的静态方法 使用java.lang.reflect包对某类进行反射调用的时候 初始化一个类，需要先初始化其父类 使用动态语言支持时，java.lang.invoke.MethodHandle实例最后的解析结果是REF_getstatic、REF_putstatic、REF_invokestatic的方法句柄，且该句柄对应的类没有初始化 以上5种场景的行为称为对类的“主动引用”，一定会触发类加载 除了以上5种方式，其余的类引用方式都称为”被动引用“，被动引用不会触发类的初始化，至于会不会触发类加载，jvm规范未给出明确说明，取决于虚拟机的具体实现。被动引用方式有： 子类继承父类的静态变量，通过子类访问该变量时将不会初始化子类 123456789101112public class father&#123; public static final S = \"test\";&#125;public class son extend father&#123; &#125;public class Test&#123; public static void main(String[] args)&#123; // 执行到这里不会初始化Son类 System.out.println(Son.S); &#125;&#125; new一个数组，数组元素类型不会被初始化 访问一个类的常量 ？ 2 类加载步骤2.1 加载目标：通过类加载器将class二进制流加载到jvm方法区，具体步骤如下 根据全限定名找到class二进制文件 将class二进制文件的静态存储结构转换成jvm方法区的运行时数据结构 在java堆中生成一个代表这个类的java.lang.Class对象，作为这个类方法区的访问入口。 class二进制流的获取方式： 可以通过zip压缩文件获取，jar包war包 reflect反射，Class.forname() 网络获取 .jsp生成 数据库获取 加载阶段是类加载过程中唯一能让应用程序参与的步骤，应用程序可以根据应用场景选择不同的class二进制流获取方式，或自定义类加载器 2.2 验证包含格式验证、元数据验证、字节码验证、符号引用验证 格式验证：检查class文件魔数、版本号等信息 元数据验证： 字节码验证： 符号引用验证： 2.3 准备给类的静态变量分配内存，并初始化为默认值： 如果静态变量是String类型或者基本类型，从类的属性表中获取ConstantValue属性，进行初始化赋值； 如果静态变量是其他引用类型，将在后面的初始化阶段赋值。 2.4 解析链接阶段的关键步骤，将class文件中的符号引用转换成直接引用 符号引用包含：（这里是常量池的知识） 类的全限定描述符 com.pd.xxxx 字段的描述符 c.a:t 表示c类的字段a，类型是t 方法的描述符 c.func:()v 表示c类的方法func，参数为空，返回类型是void 符号引用是字节码文件对类信息的描述，按照惯例，人类能看懂的，机器都是不能直接使用的，所以需要有解析这一过程将其转换成jvm运行时能直接使用的直接引用 jvm通过直接引用能够直接获取类实例的成员，字段或方法入口。 2.4.1 字段的解析获取字段在对象中的偏移量 在《jvm-对象的内存布局》一文中，我们了解到了对象的内存结构，实例字段的“偏移量”是从对象起始位置开始算的。对于这样的字节码： 12getfield cp#12 // C.b:Z//这里用cp#12来表示常量池的第12项的意思 这个C.b:Z的符号引用，最终就会被解析为类似+40这样的偏移量（这里只是举例，不是真的+40），外加一些VM自己用的元数据(字段类型、访问权限等信息)。 这个偏移量加上额外元数据比原本的constant pool index要宽，原来是u2两字节，因此没办法直接替换原来constant pool项，所以HotSpot VM有另外一个叫做constant pool cache的东西来存放它们。在HotSpot VM里，上面的字节码经过解析后，就会变成： 12fast_bgetfield cpc#5 // (offset: +40, type: boolean, ...)//这里用cpc#5来表示constant pool cache的第5项的意思 于是解析后偏移量信息就记录在了constant pool cache里，getfield根据解析出来的constant pool cache entry里记录的类型信息被改写为对应类型的版本的字节码fast_bgetfield来避免以后每次都去解析一次，然后fast_bgetfield就可以根据偏移量信息以正确的类型来访问字段了。 2.4.2 静态变量的解析从JDK 1.3到JDK 6的HotSpot VM，静态变量保存在类的元数据（InstanceKlass）的末尾。而从JDK 7开始的HotSpot VM，静态变量则是保存在类的Java镜像（java.lang.Class实例）的末尾。 在HotSpot VM中，对象、类的元数据（InstanceKlass）、类的Java镜像，三者之间的关系是这样的： 引用知乎大神RednaxelaFX文章内容，链接在文后。 1234567Java object InstanceKlass Java mirror [ _mark ] (java.lang.Class instance) [ _klass ] --&gt; [ ... ] &lt;-\\ [ fields ] [ _java_mirror ] --+&gt; [ _mark ] [ ... ] | [ _klass ] | [ fields ] \\ [ klass ] 每个Java对象的对象头里，_klass字段会指向一个VM内部用来记录类的元数据用的InstanceKlass对象；InsanceKlass里有个_java_mirror字段，指向该类所对应的Java镜像——java.lang.Class实例。HotSpot VM会给Class对象注入一个隐藏字段“klass”，用于指回到其对应的InstanceKlass对象。这样，klass与mirror之间就有双向引用，可以来回导航。这个模型里，java.lang.Class实例并不负责记录真正的类元数据，而只是对VM内部的InstanceKlass对象的一个包装供Java的反射访问用。 在JDK 6及之前的HotSpot VM里，静态字段依附在InstanceKlass对象的末尾；而在JDK 7开始的HotSpot VM里，静态字段依附在java.lang.Class对象的末尾。 假如有这样的A类： 123class A &#123; static int value = 1;&#125; 那么在JDK 6或之前的HotSpot VM里： 1234567Java object InstanceKlass Java mirror [ _mark ] (java.lang.Class instance) [ _klass ] --&gt; [ ... ] &lt;-\\ [ fields ] [ _java_mirror ] --+&gt; [ _mark ] [ ... ] | [ _klass ] [ A.value ] | [ fields ] \\ [ klass ] 可以看到这个A.value静态字段就在InstanceKlass对象的末尾存着了。 而在JDK 7或之后的HotSpot VM里： 12345678Java object InstanceKlass Java mirror [ _mark ] (java.lang.Class instance) [ _klass ] --&gt; [ ... ] &lt;-\\ [ fields ] [ _java_mirror ] --+&gt; [ _mark ] [ ... ] | [ _klass ] | [ fields ] \\ [ klass ] [ A.value ] 可以看到这个A.value静态字段就在java.lang.Class对象的末尾存着了。 方法的解析： 要弄清楚方法是怎解析的，首选需要了解jvm中的虚方法表vtable ： vtable 是 Java 实现多态的基石 Java 子类会继承父类的 vtable。Java 所有的类都会继承 java.lang.Object 类，Object 类有五个虚方法可以被继承和重写。当一个类不包含任何方法时，vtable 的长度也最小为五，表示 Object 类的五个虚方法 final 和 static 修饰的方法不会被放到 vtable 方法表里 ，private方法也不会放到vtable中 当子类重写了父类方法，子类 vtable 原本指向父类的方法指针会被替换为子类的方法指针—-多态 子类的 vtable 保持了父类的 vtable 的顺序 vtable的位置：vtable属于类的元数据，存放在元空间，具体位置是在instanceKlass对象实例的尾部，而instanceKlass大小在64 位系统的大小为 0x1B8，因此 vtable 的起始地址等于 instanceKlass 的内存首地址加上 0x1B8。 使用HSDB查看虚方法表内容，最终得出的结果是 12345670x00000007c0060dd8: 0x000000001a120c10 //Object.finallize0x00000007c0060de0: 0x000000001a1206e8 //Object.equal0x00000007c0060de8: 0x000000001a120840 //Object.toString0x00000007c0060df0: 0x000000001a120640 //Object.hashCode0x00000007c0060df8: 0x000000001a120778 //Object.clone0x00000007c0060e00: 0x000000001a5232f8 0x00000007c0060e08: 0x000000001a522f88 第一列是堆内存地址（无需关心），第二列则是对应方法的入口地址（8个字节）。 2.4.3 方法的解析就是根据方法的描述符，在方法所在类的虚方法表中，获取到方法的入口指针。 考虑这样一个Java类： 1234567public class X &#123; public void foo() &#123; bar(); &#125; public void bar() &#123; &#125;&#125; 以上源码编译出来的结果如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273作者：RednaxelaFX链接：https://www.zhihu.com/question/30300585/answer/51335493来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。Classfile /private/tmp/X.class Last modified Jun 13, 2015; size 372 bytes MD5 checksum 8abb9cbb66266e8bc3f5eeb35c3cc4dd Compiled from &quot;X.java&quot;public class X SourceFile: &quot;X.java&quot; minor version: 0 major version: 51 flags: ACC_PUBLIC, ACC_SUPERConstant pool: #1 = Methodref #4.#16 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = Methodref #3.#17 // X.bar:()V #3 = Class #18 // X #4 = Class #19 // java/lang/Object #5 = Utf8 &lt;init&gt; #6 = Utf8 ()V #7 = Utf8 Code #8 = Utf8 LineNumberTable #9 = Utf8 LocalVariableTable #10 = Utf8 this #11 = Utf8 LX; #12 = Utf8 foo #13 = Utf8 bar #14 = Utf8 SourceFile #15 = Utf8 X.java #16 = NameAndType #5:#6 // &quot;&lt;init&gt;&quot;:()V #17 = NameAndType #13:#6 // bar:()V #18 = Utf8 X #19 = Utf8 java/lang/Object&#123; public X(); flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return LineNumberTable: line 1: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this LX; public void foo(); flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokevirtual #2 // Method bar:()V 4: return LineNumberTable: line 3: 0 line 4: 4 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this LX; public void bar(); flags: ACC_PUBLIC Code: stack=0, locals=1, args_size=1 0: return LineNumberTable: line 6: 0 LocalVariableTable: Start Length Slot Name Signature 0 1 0 this LX;&#125; HotSpot VM的实现略复杂，我们看个更简单的实现，Sun的元祖JVM——Sun JDK 1.0.2的32位x86上的做法。 Sun Classic VM:（以32位Sun JDK 1.0.2在x86上为例） 123456789HObject ClassObject -4 [ hdr ]--&gt; +0 [ obj ] --&gt; +0 [ ... fields ... ] +4 [ methods ] \\ \\ methodtable ClassClass &gt; +0 [ classdescriptor ] --&gt; +0 [ ... ] +4 [ vtable[0] ] methodblock +8 [ vtable[1] ] --&gt; +0 [ ... ] ... [ vtable... ] 元祖JVM在做类加载的时候会把Class文件的各个部分分别解析（parse）为JVM的内部数据结构。例如说类的元数据记录在ClassClass结构体里，每个方法的元数据记录在各自的methodblock结构体里，等等。在刚加载好一个类的时候，Class文件里的常量池和每个方法的字节码（Code属性）会被基本原样的拷贝到内存里先放着，也就是说仍然处于使用“符号引用”的状态；直到真的要被使用到的时候才会被解析（resolve）为直接引用。 假定我们要第一次执行到foo()方法里调用bar()方法的那条invokevirtual指令了。此时JVM会发现该指令尚未被解析（resolve），所以会先去解析一下。通过其操作数所记录的常量池下标0x0002，找到常量池项#2，发现该常量池项也尚未被解析（resolve），于是进一步去解析一下。通过Methodref所记录的class_index找到类名，进一步找到被调用方法的类的ClassClass结构体；然后通过name_and_type_index找到方法名和方法描述符，再到ClassClass结构体上记录的方法列表里找到匹配的那个methodblock；最终把找到的methodblock的指针写回到常量池项#2里。 也就是说，原本常量池项#2在类加载后的运行时常量池里的内容跟Class文件里的一致，是： 1[00 03] [00 11] （tag被放到了别的地方；小细节：刚加载进来的时候数据仍然是按高位在前字节序存储的）而在解析后，假设找到的methodblock*是0x45762300，那么常量池项#2的内容会变为： 1[00 23 76 45] （解析后字节序使用x86原生使用的低位在前字节序（little-endian），为了后续使用方便）这样，以后再查询到常量池项#2时，里面就不再是一个符号引用，而是一个能直接找到Java方法元数据的methodblock了。这里的methodblock就是一个“直接引用”。指向调用的方法的机器指令集合code属性 解析好常量池项#2之后回到invokevirtual指令的解析。 1[B6] [00 02] 而在解析后，这块代码被改写为： 1[D6] [06] [01] 其中opcode部分从invokevirtual改写为invokevirtual_quick，以表示该指令已经解析完毕。虚方法表的下标（vtable index）原本存储操作数的2字节空间现在分别存了2个1字节信息，第一个是，第二个是方法的参数个数。这两项信息都由前面解析常量池项#2得到的methodblock*读取而来。也就是： 1invokevirtual_quick vtable_index=6, args_size=1 这里例子里，类X对应在JVM里的虚方法表会是这个样子的： 1234567[0]: java.lang.Object.hashCode:()I[1]: java.lang.Object.equals:(Ljava/lang/Object;)Z[2]: java.lang.Object.clone:()Ljava/lang/Object;[3]: java.lang.Object.toString:()Ljava/lang/String;[4]: java.lang.Object.finalize:()V[5]: X.foo:()V[6]: X.bar:()V 所以JVM在执行invokevirtual_quick要调用X.bar()时，只要顺着对象引用查找到虚方法表，然后从中取出第6项的methodblock*，就可以找到实际应该调用的目标然后调用过去了。 假如类X还有子类Y，并且Y覆写了bar()方法，那么类Y的虚方法表就会像这样： 1234567[0]: java.lang.Object.hashCode:()I[1]: java.lang.Object.equals:(Ljava/lang/Object;)Z[2]: java.lang.Object.clone:()Ljava/lang/Object;[3]: java.lang.Object.toString:()Ljava/lang/String;[4]: java.lang.Object.finalize:()V[5]: X.foo:()V[6]: Y.bar:()V 于是通过vtable_index=6就可以找到类Y所实现的bar()方法。 所以说在解析/改写后的invokevirtual_quick指令里，虚方法表下标（vtable index）也是一个“直接引用”的表现。 在现在的HotSpot VM里，围绕常量池、invokevirtual的解析（再次强调是resolve）的具体实现方式跟元祖JVM不一样，但是大体的思路还是相通的。 HotSpot VM的运行时常量池有ConstantPool和ConstantPoolCache两部分，有些类型的常量池项会直接在ConstantPool里解析，另一些会把解析的结果放到ConstantPoolCache里。 2.5 初始化根据类中的静态代码块和静态变量赋值语句生成()方法对类进行初始化 不需要显示调用父类的()方法，在初始化子类之前或自动初始化父类 接口没有静态代码块，但是也会根据静态变量赋值语句生成()方法进行初始化，注意这里指的是引用类型对象 被类实现的接口或者接口的父接口，不会在子类的初始化之前初始化，接口的初始化时机是使用到该接口时 3. jvm启动运行一个main函数 根据JVM内存配置要求，为JVM申请特定大小的内存空间； 创建一个引导类加载器实例，初步加载系统类到内存方法区区域中； 创建JVM 启动器实例 Launcher,并取得类加载器ClassLoader； 使用上述获取的ClassLoader实例加载我们定义的 org.luanlouis.jvm.load.Main类； 加载完成时候JVM会执行Main类的main方法入口，执行Main类的main方法； 结束，java程序运行结束，JVM销毁。 参考文章： 《Java虚拟机原理图解》5. JVM类加载器机制与类加载过程 Hotspot 类加载、链接和初始化 C++源码解析 RednaxelaFX–字段解析 RednaxelaFX–方法解析","categories":[{"name":"深入理解java虚拟机","slug":"深入理解java虚拟机","permalink":"https://zzkenyon.github.io/categories/深入理解java虚拟机/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://zzkenyon.github.io/tags/jvm/"}],"keywords":[{"name":"深入理解java虚拟机","slug":"深入理解java虚拟机","permalink":"https://zzkenyon.github.io/categories/深入理解java虚拟机/"}]},{"title":"jvm(1)解构字节码文件","slug":"jvm(1)解构字节码文件","date":"2018-05-11T16:00:00.000Z","updated":"2021-01-15T04:49:50.536Z","comments":true,"path":"2018/05/12/jvm(1)解构字节码文件/","link":"","permalink":"https://zzkenyon.github.io/2018/05/12/jvm(1)解构字节码文件/","excerpt":"","text":"CSDN上亦山整理的文章，非常有助于理解，目录如下 《Java虚拟机原理图解》 1、class字节码文件 ​ 1.1、class文件基本组织结构 ​ 1.2、class文件中的常量池 ​ 1.2.2、Class文件中的常量池详解（上） ​ 1.2.3、Class文件中的常量池详解（下） ​ 1.3、class文件中的访问标志、类索引、父类索引、接口索引集合 ​ 1.4 class文件中的字段表集合–field字段在class文件中是怎样组织的 ​ 1.5、 class文件中的方法表集合–method方法在class文件中是怎样组织的 2、机器指令 3、运行时数据区 精彩片段： 目前的Sun javac编译器的选择是：如果使用final和static同时修饰一个final字段，并且这个字段是基本类型或者String类型的，那么编译器在编译这个字段的时候，会在对应的field_info结构体中增加一个ConstantValue类型的结构体，在赋值的时候使用这个ConstantValue进行赋值；如果该field字段并没有被final修饰，或者不是基本类型或者String类型，那么将在类构造方法&lt;cinit&gt;()中赋值。 常量池存有两种数据：字面量和符号引用 字面量又包含：文本字符串、final常量、基本数据类型的值等 符号引用包含：类的全限定名称、字段名称和描述符、方法名称和描述符 问题： private int a = 10;//这样声明，常量池中没有10 private final int a = 10;// int声明为final，常量池中才有10，亦山的文章中也是用final字段进行演示的 但是将类型换成float，没有final也可以将字面量存进常量池，为什么？ private float f = 10f; //常量池中有10f 参考链接 带参数的jvm字节码指令 参数一般是指向常量池的索引如#4 #5 等 这个索引长度是2字节，当int类型字面量能够用2字节表达的时候，该字面量可以直接跟随字节码指令一起存放 该范围是-32768~32767 当int字面量为32768时，就会出现在常量池中了 结论：对于const系列命令和push系列命令操作范围之外的字面量。都放在常量池中的。","categories":[{"name":"深入理解java虚拟机","slug":"深入理解java虚拟机","permalink":"https://zzkenyon.github.io/categories/深入理解java虚拟机/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://zzkenyon.github.io/tags/jvm/"}],"keywords":[{"name":"深入理解java虚拟机","slug":"深入理解java虚拟机","permalink":"https://zzkenyon.github.io/categories/深入理解java虚拟机/"}]},{"title":"并发编程-共享式AQS源码详解","slug":"并发编程-共享式AQS源码详解","date":"2018-04-25T12:36:12.000Z","updated":"2020-05-22T11:41:19.455Z","comments":true,"path":"2018/04/25/并发编程-共享式AQS源码详解/","link":"","permalink":"https://zzkenyon.github.io/2018/04/25/并发编程-共享式AQS源码详解/","excerpt":"","text":"上篇文章详细的阐述了AQS在独占模式下的底层原理，本篇主要讲述共享式同步器的原理。 1. acquireShared(int)此方式是共享模式下线程获取贡献资源的入口，他会获取指定量的资源，获取成功直接返回，失败则进入等待队列，知道获取到资源为止，整个过程忽略终端。下面看源码： 12345public final void acquireShared(int arg) &#123; // if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125; 123protected int tryAcquireShared(int arg) &#123; throw new UnsupportedOperationException();&#125; 这里 tryAcquireShared 依然需要自定义同步器去实现，但是AQS已经将返回值的语义定义好了，重载该函数的时候执行逻辑要符合下列语义：-返回负值表示获取失败 返回0表示获取成功，但是没有剩余资源 返回正数表示获取成功，还有剩余资源 tryAcquireShared获取失败则执行 doAcquireShared 方法，看下面源码：12345678910111213141516171819202122232425262728293031323334private void doAcquireShared(int arg) &#123; //将线程以共享方式加入同步队列尾部 final Node node = addWaiter(Node.SHARED); //获取失败吗，默认true（失败） boolean failed = true; try &#123; //记录等待过程是否被中断过 boolean interrupted = false; for (;;) &#123; //拿到前驱节点 final Node p = node.predecessor(); if (p == head) &#123;//如果前驱是头结点 //尝试获取 int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; //自己获取资源的同时，如果还有剩余资源,唤醒后继节点 setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted)//补上中断标志 selfInterrupt(); failed = false; return; &#125; &#125; //前驱不是头结点，获取失败后寻找安全点 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 整个过程与acquireQueued()很相似，区别在于唤醒等待线程的条件不同。setHeadAndPropagate方法在setHead()的基础上多了一步，就是自己苏醒的同时，如果条件符合（比如还有剩余资源），还会去唤醒后继结点，看代码： 1234567891011private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; //与独占式不同原head并没有释放资源 setHead(node); if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); &#125;&#125; 2. releaseShared()上一小节已经把acquireShared()说完了，这一小节就来讲讲它的反操作releaseShared()吧。此方法是共享模式下线程释放共享资源的顶层入口。它会释放指定量的资源，如果成功释放且允许唤醒等待线程，它会唤醒等待队列里的其他线程来获取资源。下面是releaseShared()的源码： 1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; 此方法的流程也比较简单，一句话：释放掉资源后，唤醒后继。跟独占模式下的release()相似，但有一点稍微需要注意：独占模式下的tryRelease()在完全释放掉资源（state=0）后，才会返回true去唤醒其他线程，这主要是基于独占下可重入的考量；而共享模式下的releaseShared()则没有这种要求，共享模式实质就是控制一定量的线程并发执行，那么拥有资源的线程在释放掉部分资源时就可以唤醒后继等待结点。例如，资源总量是13，A（5）和B（7）分别获取到资源并发运行，C（4）来时只剩1个资源就需要等待。A在运行过程中释放掉2个资源量，然后tryReleaseShared(2)返回true唤醒C，C一看只有3个仍不够继续等待；随后B又释放2个，tryReleaseShared(2)返回true唤醒C，C一看有5个够自己用了，然后C就可以跟A和B一起运行。而ReentrantReadWriteLock读锁的tryReleaseShared()只有在完全释放掉资源（state=0）才返回true，所以自定义同步器可以根据需要决定tryReleaseShared()的返回值。 2.1 doReleaseShared()此方法主要用于唤醒后继。下面是它的源码：123456789101112131415161718private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125; 3. Semaphore一个具象化的例子：停车场运作，假设停车场有10个车位，刚开始都是空的。如果同时来了11辆车，看守者只能允许10辆车进入，另一辆排队等候，当有车为空出来，等候车辆进入填满空车位。Semaphore就相当于停车场看守者。 和RentrantLock不同Semaphore没有实现Lock接口，获取资源有响应中断模式和忽略中断模式，中断模式获取资源： 123456public void acquire() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125;public void acquire(int i) throws InterruptedException &#123; sync.acquireSharedInterruptibly(i);&#125; 释放资源统一使用： 123456public void release() &#123; sync.releaseShared(1);&#125;public void release(int i) &#123; sync.releaseShared(i);&#125; 内部同步器sync重载的tryAcquireShared-tryRealseShared源码如下，代码逻辑简单易懂，实现自定义的同步器一般也只需要实现这几个方法。 123456789101112131415161718192021222324252627282930313233//非公平final int nonfairTryAcquireShared(int acquires) &#123; for (;;) &#123; int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125;&#125;//公平protected int tryAcquireShared(int acquires) &#123; for (;;) &#123; if (hasQueuedPredecessors()) return -1; int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125;&#125;protected final boolean tryReleaseShared(int releases) &#123; for (;;) &#123; int current = getState(); int next = current + releases; if (next &lt; current) // overflow throw new Error(\"Maximum permit count exceeded\"); if (compareAndSetState(current, next)) return true; &#125;&#125;","categories":[{"name":"并发编程的艺术","slug":"并发编程的艺术","permalink":"https://zzkenyon.github.io/categories/并发编程的艺术/"}],"tags":[{"name":"JDK","slug":"JDK","permalink":"https://zzkenyon.github.io/tags/JDK/"}],"keywords":[{"name":"并发编程的艺术","slug":"并发编程的艺术","permalink":"https://zzkenyon.github.io/categories/并发编程的艺术/"}]},{"title":"nginx入门","slug":"nginx入门","date":"2018-04-23T07:17:36.000Z","updated":"2019-04-26T07:17:24.000Z","comments":true,"path":"2018/04/23/nginx入门/","link":"","permalink":"https://zzkenyon.github.io/2018/04/23/nginx入门/","excerpt":"","text":"Nginx是一款自由的、开源的、高性能的HTTP服务器和反向代理服务器；同时也是一个IMAP、POP3、SMTP代理服务器；Nginx可以作为一个HTTP服务器进行网站的发布处理，另外Nginx可以作为反向代理进行负载均衡的实现。 1、正向代理与反向代理1.1 正向代理：代理服务器代表的是客户端，代理对服务器端透明。正向代理的应用场景： vpn 缓存，加速访问资源 对客户端访问授权，上网进行认证 记录用户的上网记录，对外隐藏用户信息 正向代理产品：CCProxy 1.2 反向代理：代理服务器代表的是服务器端，代理对客户端透明反向代理的应用场景： 保证内网的安全，可以使用反向代理提供WAF功能，阻止web攻击 负载均衡 反向代理产品：Nginx 2、nginx安装2.1 安装环境 yum -y install wget #安装下载工具 yum install -y gcc gcc-c++ #安装gcc编译环境 yum install -y pcre-devel #安装PERE库 yum -y install openssl openssl-devel #安装OpenSsl库 2.2 准备安装nginx wget http://nginx.org/download/nginx-1.14.0.tar.gz #下载 tar -zxf nginx-1.14.0.tar.gz #解压 cd nginx-1.14.0 sed -i -e’s/1.14.0//g’ -e’ s/nginx\\//WS/g’ -e’s/“NGINX”/“WS”/g’ src/core/nginx.h #隐藏版本号(安全性考虑，爆出有些版本的nginx存在漏洞，容易被攻击) 2.3编译安装nginx useradd www #添加用户，不添加默认为nobody ./configure –user=www –group=www –prefix=/usr/local/nginx –with-http_ssl_module make &amp; make install 3、nginx的五种负载分配算法3.1 round robin（默认）轮询方式，依次将请求分配到各个后台服务器中，默认的负载均衡方式。适用于后台机器性能一致的情况。挂掉的机器可以自动从服务列表中剔除。 3.2 weight根据权重来分发请求到不同的机器中，指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。1234upstream bakend &#123; server 192.168.0.14 weight=10; server 192.168.0.15 weight=10; &#125; 3.3 IP_hash根据请求者ip的hash值将请求发送到后台服务器中，可以保证来自同一ip的请求被打到固定的机器上，可以解决session问题 12345upstream bakend &#123; ip_hash; server 192.168.0.14:88; server 192.168.0.15:80; &#125; 3.4 url_hash（第三方）根据请求的url的hash值将请求分到不同的机器中，当后台服务器为缓存的时候效率高。例如：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法 123456upstream backend &#123; server squid1:3128; server squid2:3128; hash $request_uri; hash_method crc32; &#125; 3.5 fair（第三方）根据后台响应时间来分发请求，响应时间短的分发的请求多。例如：12345upstream backend &#123; server server1; server server2; fair; &#125;","categories":[],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://zzkenyon.github.io/tags/nginx/"}],"keywords":[]},{"title":"SpringBoot-数据校验","slug":"SpringBoot-数据校验","date":"2018-04-02T07:39:40.000Z","updated":"2020-05-28T11:23:09.602Z","comments":true,"path":"2018/04/02/SpringBoot-数据校验/","link":"","permalink":"https://zzkenyon.github.io/2018/04/02/SpringBoot-数据校验/","excerpt":"","text":"参数验证是一个常见的问题，无论是前端还是后台，都需对用户输入进行验证，以此来保证系统数据的正确性。对于web来说，有些人可能理所当然的想在前端验证就行了，但这样是非常错误的做法，前端代码对于用户来说是透明的，稍微有点技术的人就可以绕过这个验证，直接提交数据到后台。无论是前端网页提交的接口，还是提供给外部的接口，参数验证随处可见，也是必不可少的。前端做验证只是为了用户体验，比如控制按钮的显示隐藏，单页应用的路由跳转等等。后端才是最终的保障，总之，对于后端接口来说，一切用户的输入都是不可信的。 1、依赖关系1compile 'org.springframework.boot:spring-boot-starter-validation' 该依赖在spring-boot-starter-web中已经引入，如果是springboot Web项目，则不用再单独添加依赖。 springboot的数据绑定和数据校验功能在org.springframework.validation包中，@Validated注解就是在此定义的。 validation包实现参数校验主要通过调用Jakarta.Validation-api.jar包，该jar包定义了一套参数验证的接口，没有具体实现，我们常用的约束注解就是定义在此处。 validation-api的一个实现就是Hibernate-validator，spring默认使用该实现进行数据校验。 2、常用约束123456789101112131415161718@Null //被注释的元素必须为 null @NotNull //被注释的元素必须不为 null @AssertTrue //被注释的元素必须为 true @AssertFalse //被注释的元素必须为 false @Min(value) //被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @Max(value) //被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @DecimalMin(value) //被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @DecimalMax(value) //被注释的元素必须是一个数字，其值必须小于等于指定的最大值@Size(max=, min=) //被注释的元素的大小必须在指定的范围内 @Digits (integer, fraction) //被注释的元素必须是一个数字，其值必须在可接受的范围内 @Past //被注释的元素必须是一个过去的日期 @Future //被注释的元素必须是一个将来的日期 @Pattern(regex=,flag=) //被注释的元素必须符合指定的正则表达式Hibernate Validator附加的constraint @NotEmpty //被注释的字符串的必须非空 @Length(min=,max=) //被注释的字符串的大小必须在指定的范围内 @NotBlank(message =) //验证字符串非null，且长度必须大于0 @Email //被注释的元素必须是电子邮箱地址 @Range(min=,max=,message=) //被注释的元素必须在合适的范围内 3、controller层入参校验3.1 平铺参数的校验-GetMapping 参数校验controller类上需要注解@Validated，在controller方法入参前添加约束注解，校验方能生效。此外，类上注解@Validated后，方法的返回值也能进行约束。如下： 12345678@RestController@Validatedpublic class DemoController&#123; @GetMapping(\"/valid\") public @Length(min=4) String test(@RequestParam @Email String email)&#123; return email; &#125;&#125; 入参校验失败将抛出 javax.validation.ConstraintViolationException 平铺参数校验原理与下文的service层校验一致 此外，当GetMapping请求参数过多，开发时我们可能会使用queryVo接收请求参数，此时，Get方法中QueryVo前不能注解@RequestBody 和 @RequestParam，如下：1234@GetMapping(\"/vo_valid\")public String queryByVo(@Valid OrderItem item)&#123; // @Valid注解不生效 return item.toString();&#125; 此处@Valid校验不生效，因为queryVo看上去是一个javaBean，但实际上数据绑定阶段是逐个字段进行绑定的，并没有将其当成是一个javaBean。既然如此，如果去掉@Valid注解，queryVo中的约束注解会生效吗？答案是不生效 此时有两个选择 继续选择使用GetMapping方式，queryVo的校验在service层进行 改选PostMapping方式，对参数注解@Valid @RequestBody进行校验 3.2 javaBean参数校验在bean类中使用注解约束字段: 123456789@Datapublic class Order&#123; @NotEmpty private String oid; @NotNull private Date createTime; @Valid private List&lt;OrderItem&gt; items;&#125; 在方法中需要校验的javaBean参数前注解@Valid/@Validated（可分组）。 注意：此处所说的“方法”不包括controller层的GetMapping方法。 校验失败将抛出 org.springframework.web.bind.MethodArgumentNotValidExption ，该异常中含有一个BindingResult对象。 spring使用默认异常处理器DefaultExceptionHandlerResolver处理该异常，我们可以在controller方法参数列表中增加一个BindingResult对象来接受校验错误信息，然后使用自定义处理器处理。 123456789@PostMapping(value = \"/demo\")public Integer addDemo(@Valid @RequestBody Demo demo, BindingResult bindingResult)&#123; if(bindingResult.hasErrors())&#123; for(ObjectError error : bindingResult.getAllErrors())&#123; throw new DemoException(DemoExceptionEnum.PARAM_ERROR.getCode(),error.getDefaultMessage()); &#125; &#125; return demoService.insert(demo);&#125; 注意：如果在一个方法中有多个javaBean参数需要校验，那么每一个javaBean都需要定义一个BindingResult对象来接收校验结果 123public void test1()(@RequestBody @Valid DemoModel demo, BindingResult result)public void test2()(@RequestBody @Valid DemoModel demo, BindingResult result,@RequestBody @Valid DemoModel demo2, BindingResult result2) 3.3 配置校验模式 默认的校验模式为普通模式，普通模式下会校验完所有的属性然后返回所有的校验失败信息 可配置为快速失败返回模式，只要有一个属性校验失败则立即返回 配置方式:12345678910111213@Configurationpublic class ValidatorConfiguration &#123; @Bean public Validator validator()&#123; ValidatorFactory validatorFactory = Validation.byProvider( HibernateValidator.class ) .configure() /**设置validator模式为快速失败返回*/ .addProperty( \"hibernate.validator.fail_fast\", \"true\" ) .buildValidatorFactory(); Validator validator = validatorFactory.getValidator(); return validator; &#125;&#125; 4. service层数据校验在service类前注解@Validated开启校验。 在service接口方法参数类型或返回值类型前注解约束：12345678@Validated(Default.class)public interface OrderService &#123; Object hello(@NotNull @Min(10) Integer id, @NotNull String name); //平铺参数校验 Order queryById(@NumberLength(\"4,6,8,10,12\") @Length(max=10) String id); //使用@Valid实现javaBean参数校验 String saveOrder(@Valid Order order);&#125; 注意：在service层进行校验并不需要使用BindingResult来接收校验结果，因为参数的Binding是在controller层进行的。 @Validated(Default.class)也可以注解在接口实现类上面，实现类编写方式无殊。 校验失败抛异常javax.validation.ConstraintViolationException 5. 扩展需求5.1 分组校验分组校验只有使用@Validated注解才能实现 使用场景：针对同一个model类，不同的接口需要对不同的属性进行校验 例如，数据插入接口与数据更新接口需要校验的参数是不同的 使用方法 在model类中定义内部接口 约束增加组别属性 12345678910111213public class Demo&#123; public interface AddGorup&#123;&#125; public interface UpdateGroup&#123;&#125; @Range(min = 1,max = Integer.MAX_VALUE,groups = &#123;UpdateGroup.class&#125;) private Integer id; @Email(groups = &#123;AddGroup.class,UpdateGroup.class&#125;) private String email; @Past(groups = &#123;UpdateGroup.class&#125;) private Date birthday; &#125; 在接口方法或者方法参数上使用@Validated({Demo.AddGroup.class})来注解参数，表示该参数使用AddGroup来进行校验。约束的groups属性中可以填写多个接口名，表示该参数加入多个组进行校验 5.2 嵌套校验嵌套校验指的是需要校验的javaBean中有的校验成员也是JavaBean类型，此时在成员上面注解@Valid即可实现嵌套校验 5.3 自定义约束校验创建约束标注 12345678910@Target(&#123;ElementType.METHOD,ElementType.ANNOTATION_TYPE,ElementType.FIELD,ElementType.PARAMETER&#125;)@Retention(RetentionPolicy.RUNTIME)@Constraint(validatedBy = DemoConstraintValidator.class)@Documentedpublic @interface DemoConstraint &#123; String message() default \"default message\"; Class&lt;?&gt;[] groups() default &#123;&#125;; Class&lt;? extends Payload&gt;[] payload() default &#123;&#125;; E value();//约束中设置的value值&#125; 实现一个验证器 12345678910111213141516171819202122/** * A 自定义的约束注解类型 * T 需要检验的目标参数类型 */public class DemoConstraintValidator implements ConstraintValidator&lt;A, T&gt;&#123; private T value;//注入设置的具体约束 @Override public void initialize(A a) &#123; this.value = a.value(); &#125; @Override public boolean isValid(T t, ConstraintValidatorContext constraintValidatorContext) &#123; //根据value 对 参数t 进行一些判断 return true; if(!isValid) &#123; constraintContext.disableDefaultConstraintViolation(); constraintContext.buildConstraintViolationWithTemplate(\"new default message\").addConstraintViolation(); return false; &#125; &#125;&#125; A表示创建的注解，T表示该约束校验的数据类型 定义默认的验证错误信息，可以通过ConstraintValidatorContext修改默认的message信息，一旦使用，在注解中给message赋值将不起作用（一般情况下不推荐使用） 5.4 检验组序列默认情况下，约束的计算没有特定的顺序，这与它们属于哪个组无关。然而，在某些情况下，控制约束求值的顺序是有用的，例如，我们可以要求在检查汽车的道路价值之前，首先通过所有默认的汽车约束。最后，在我们开车离开之前，我们检查了实际司机的约束条件。为了实现这样的顺序，需要定义一个新的接口，并使用@GroupSequence对其进行注释，以定义必须验证组的顺序。 注意：如果这个校验组序列中有一个约束条件没有通过验证的话, 那么此约束条件后面的都不会再继续被校验了. 123@GroupSequence(&#123;Default.class, CarChecks.class, DriverChecks.class&#125;)public interface OrderedChecks &#123;&#125; 6. 总结@Validated 和 @Valid Java Bean中的嵌套校验只能用@Valid 在controller方法中校验@RequestBody参数，参数前注解@Valid和@Validated都行，但如果要使用分组校验功能，只能使用后者 controller中校验平铺型@RequestParam参数，需要在controller类前注解@Validated，参数前注解约束规则 service层校验统一在service接口类上注解@Validated，接口方法参数列表中注解约束（类型参数前可以注解@Valid），实现类中不涉及验证相关代码 参考：官方文档springboot使用hibernate validator校验@Validated和@Valid区别","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/tags/SpringBoot/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/categories/SpringBoot/"}]},{"title":"并发编程-容器之CopyOnWrite","slug":"并发编程-容器之CopyOnWrite","date":"2018-03-28T16:00:00.000Z","updated":"2021-01-13T01:42:09.602Z","comments":true,"path":"2018/03/29/并发编程-容器之CopyOnWrite/","link":"","permalink":"https://zzkenyon.github.io/2018/03/29/并发编程-容器之CopyOnWrite/","excerpt":"","text":"Copy-On-Write简称COW，是一种用于程序设计中的优化策略。其基本思路是，从一开始大家都在共享同一个内容，当某个人想要修改这个内容的时候，才会真正把内容Copy出去形成一个新的内容然后再改，这是一种延时懒惰策略。从JDK1.5开始Java并发包里提供了两个使用CopyOnWrite机制实现的并发容器,它们是CopyOnWriteArrayList和CopyOnWriteArraySet。CopyOnWrite容器非常有用，可以在非常多的并发场景中使用到。 1. 什么是CopyOnWrite容器CopyOnWrite容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。 2. CopyOnWriteArrayList的实现原理在使用CopyOnWriteArrayList之前，我们先阅读其源码了解下它是如何实现的。以下代码是向CopyOnWriteArrayList中add方法的实现（向CopyOnWriteArrayList里添加元素），可以发现在添加的时候是需要加锁的，否则多线程写的时候会Copy出N个副本出来。 1234567891011121314public boolean add(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); newElements[len] = e; setArray(newElements); return true; &#125; finally &#123; lock.unlock(); &#125;&#125; 读的时候不需要加锁，如果读的时候有多个线程正在向CopyOnWriteArrayList添加数据，读还是会读到旧的数据，因为写的时候不会锁住旧的CopyOnWriteArrayList。 123public E get(int index) &#123; return get(getArray(), index);&#125; JDK中并没有提供CopyOnWriteMap，我们可以参考CopyOnWriteArrayList来实现一个，基本代码如下： 123456789101112131415161718192021222324252627282930313233import java.util.Collection;import java.util.Map;import java.util.Set; public class CopyOnWriteMap&lt;K, V&gt; implements Map&lt;K, V&gt;, Cloneable &#123; private volatile Map&lt;K, V&gt; internalMap; public CopyOnWriteMap() &#123; internalMap = new HashMap&lt;K, V&gt;(); &#125; public V put(K key, V value) &#123; synchronized (this) &#123; Map&lt;K, V&gt; newMap = new HashMap&lt;K, V&gt;(internalMap); V val = newMap.put(key, value); internalMap = newMap; return val; &#125; &#125; public V get(Object key) &#123; return internalMap.get(key); &#125; public void putAll(Map&lt;? extends K, ? extends V&gt; newData) &#123; synchronized (this) &#123; Map&lt;K, V&gt; newMap = new HashMap&lt;K, V&gt;(internalMap); newMap.putAll(newData); internalMap = newMap; &#125; &#125;&#125; 实现很简单，只要了解了CopyOnWrite机制，我们可以实现各种CopyOnWrite容器，并且在不同的应用场景中使用。 3. CopyOnWrite的应用场景CopyOnWrite并发容器用于读多写少的并发场景。比如白名单，黑名单，商品类目的访问和更新场景，假如我们有一个搜索网站，用户在这个网站的搜索框中，输入关键字搜索内容，但是某些关键字不允许被搜索。这些不能被搜索的关键字会被放在一个黑名单当中，黑名单每天晚上更新一次。当用户搜索时，会检查当前关键字在不在黑名单当中，如果在，则提示不能搜索。实现代码如下： 123456789101112131415161718192021222324252627282930313233import java.util.Map; import com.ifeve.book.forkjoin.CopyOnWriteMap; /** * 黑名单服务 * * @author fangtengfei * */public class BlackListServiceImpl &#123; private static CopyOnWriteMap&lt;String, Boolean&gt; blackListMap = new CopyOnWriteMap&lt;String, Boolean&gt;( 1000); public static boolean isBlackList(String id) &#123; return blackListMap.get(id) == null ? false : true; &#125; public static void addBlackList(String id) &#123; blackListMap.put(id, Boolean.TRUE); &#125; /** * 批量添加黑名单 * * @param ids */ public static void addBlackList(Map&lt;String,Boolean&gt; ids) &#123; blackListMap.putAll(ids); &#125; &#125; 代码很简单，但是使用CopyOnWriteMap需要注意两件事情： 减少扩容开销。根据实际需要，初始化CopyOnWriteMap的大小，避免写时CopyOnWriteMap扩容的开销。 使用批量添加。因为每次添加，容器每次都会进行复制，所以减少添加次数，可以减少容器的复制次数。如使用上面代码里的addBlackList方法。 4. CopyOnWrite的缺点CopyOnWrite容器有很多优点，但是同时也存在两个问题，即内存占用问题和数据一致性问题。所以在开发的时候需要注意一下。 内存占用问题。因为CopyOnWrite的写时复制机制，所以在进行写操作的时候，内存里会同时驻扎两个对象的内存，旧的对象和新写入的对象（注意:在复制的时候只是复制容器里的引用，只是在写的时候会创建新对象添加到新容器里，而旧容器的对象还在使用，所以有两份对象内存）。如果这些对象占用的内存比较大，比如说200M左右，那么再写入100M数据进去，内存就会占用300M，那么这个时候很有可能造成频繁的Yong GC和Full GC。之前我们系统中使用了一个服务由于每晚使用CopyOnWrite机制更新大对象，造成了每晚15秒的Full GC，应用响应时间也随之变长。 针对内存占用问题，可以通过压缩容器中的元素的方法来减少大对象的内存消耗，比如，如果元素全是10进制的数字，可以考虑把它压缩成36进制或64进制。或者不使用CopyOnWrite容器，而使用其他的并发容器，如ConcurrentHashMap。 数据一致性问题。CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。所以如果你希望写入的的数据，马上能读到，请不要使用CopyOnWrite容器。 参考链接 CopyOnWriteArrayList和同步容器的性能验证 CopyOnWriteArrayList使用简介","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/categories/并发编程/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/tags/并发编程/"}],"keywords":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/categories/并发编程/"}]},{"title":"并发编程-容器阻塞队列BlockingQueue","slug":"并发编程-容器阻塞队列BlockingQueue","date":"2018-03-28T16:00:00.000Z","updated":"2021-01-13T01:32:26.183Z","comments":true,"path":"2018/03/29/并发编程-容器阻塞队列BlockingQueue/","link":"","permalink":"https://zzkenyon.github.io/2018/03/29/并发编程-容器阻塞队列BlockingQueue/","excerpt":"","text":"阻塞队列常用于生产者-消费者场景。 BQ有4套出队入队操作： offer(e) &amp; poll() 这套操作不会阻塞线程，队列满/空的时候返回特殊值 false/null add(e) &amp; remove() 该操作对offer(e) &amp; pool()返回的特殊值抛出异常 put(e) &amp; take() 阻塞方法，遇到队列满/空的时候会阻塞，直到收到通知可以继续执行 offer(e,time,unit) &amp; poll(time,unit) 超时阻塞方法，超时返回 false/null Jdk7中给出了7种BQ： ArrayBlockingQueue 数组实现的有界阻塞队列, 此队列按照先进先出（FIFO）的原则对元素进行排序。 LinkedBlockingQueue 链表实现的有界阻塞队列, 此队列的默认和最大长度为Integer.MAX_VALUE。此队列按照先进先出的原则对元素进行排序 PriorityBlockingQueue 支持优先级排序的无界阻塞队列, 默认情况下元素采取自然顺序升序排列。也可以自定义类实现 compareTo()方法来指定元素排序规则，或者初始化 PriorityBlockingQueue 时，指定构造参数 Comparator 来对元素进行排序。 DelayQueue 优先级队列实现的无界阻塞队列 SynchronousQueue 不存储元素的阻塞队列, 每一个 put 操作必须等待一个 take 操作，否则不能继续添加元素。 LinkenTransferQueue LinkedBlockingDeque 本文将以LinkedBlockingQueue为例进行源码解读 1. Condition任意的一个java对象，都拥有一组监视器方法（定义在Object类中），主要包括wait()、wait(long timeout)、notify()、notifyAll()方法，这些方法与sychronized关键字配合使用，可以实现等待/通知模式。Condition接口也通过类似Object的监视器方法，与Lock配合可以实现等待/通知模式。但是这两种方式在使用方式以及功能特性上还是有差别的： 每个Object监视器只有一个等待队列，而Condition接口可以支持多个等待队列 当前线程释放锁进入等待状态，Object监视器在等待过程中是不相应中断的，而Condition接口是可以的 Object监视器不支持线程等待到将来的某个特定时间，Condition接口支持 1.1 Condition的原理将在另一篇中解析AQS.ConditionObject类的源码 1.2 LBQ中的ConditionLBQ的入队和出队使用了两把重入锁，相应的也有两个条件队列notFull和notEmpty： 当队列满的时候执行入队操作，入队线程会进入notFull等待，当有元素出队则通知入队线程–队列notFull，可以继续执行； 当队列为空执行出队操作，出队线程会进入notEmpty等待，当有元素入队后则通知出队线程–队列notEmpty，可以继续执行。1234567891011/** Lock held by take, poll, etc */private final ReentrantLock takeLock = new ReentrantLock();/** Wait queue for waiting takes */private final Condition notEmpty = takeLock.newCondition();/** Lock held by put, offer, etc */private final ReentrantLock putLock = new ReentrantLock();/** Wait queue for waiting puts */private final Condition notFull = putLock.newCondition(); 具体如何使用的，见下文LBQ源码分析 2. offer(e) &amp; poll()这套方法是在接口 Queue 中定义12345678910111213141516171819202122232425262728//以下代码摘自： java.util.concurrent.LinkedBlockingQueuepublic boolean offer(E e) &#123; if (e == null) throw new NullPointerException(); final AtomicInteger count = this.count; //满了直接返回失败 if (count.get() == capacity) return false; int c = -1; Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; putLock.lock(); try &#123; if (count.get() &lt; capacity) &#123; enqueue(node); c = count.getAndIncrement(); //c是更新之前的计数 if (c + 1 &lt; capacity) //更新之后还未满，唤醒一个入队线程 notFull.signal(); &#125; &#125; finally &#123; putLock.unlock(); &#125; if (c == 0) //更新之前是空的，更新完就不空了，唤醒一个阻塞的出队线程 signalNotEmpty(); return c &gt;= 0;&#125; offer(e)方法总结： 开始先检查参数是否为null，null则抛出NPE异常； 然后判断队列是否已经满了，满了直接返回false； 以上检查都通过，构造新节点，获取入队锁putLock 二重检查，判断队列是否未满，如果未满执行入队，计数器加1，如果计数器更新之后还小于capacity，则唤醒一个入队线程(如果有入队线程阻塞) 最后判断一下该线程入队前是否为空队列，如果之前是空的，入队完成就可以唤醒一个阻塞的出队线程。 最后入队成功返回true12345678910111213141516171819202122public E poll() &#123; final AtomicInteger count = this.count; if (count.get() == 0) return null; E x = null; int c = -1; final ReentrantLock takeLock = this.takeLock; takeLock.lock(); try &#123; if (count.get() &gt; 0) &#123; x = dequeue(); c = count.getAndDecrement(); if (c &gt; 1) notEmpty.signal(); &#125; &#125; finally &#123; takeLock.unlock(); &#125; if (c == capacity) signalNotFull(); return x;&#125; poll()方法总结： 首先检查队列是否空，若空直接返回null，不空继续执行； 获取出队锁takelock 二重检查，检查队列是否不空，不空执行出队，计数器减1，计数器更新之后还大于0(出队后队列还不空)，唤醒一个出队线程（如果有阻塞的出队线程） 释放锁，然后判断此次出队前队列是否满的，若出队前满则此次出队结束就有余位了，唤醒一个阻塞入队线程执行 3. add(e) &amp; remove()这套方法也是在 Queue 中定义，add方法继承自Collection接口，内部调用了offer(e) &amp; pool()，对队空或队满返回的特殊值做异常处理，队满执行入队操作抛 IllegalStateException 异常；队空做出队操作抛 NoSuchElementException 异常 。源码如下：123456789101112131415以下代码摘自： java.util.AbstractQueuepublic boolean add(E e) &#123; if (offer(e)) return true; else throw new IllegalStateException(\"Queue full\");&#125;public E remove() &#123; E x = poll(); if (x != null) return x; else throw new NoSuchElementException();&#125; 4. put(e) &amp; take()这是阻塞接口，定义在 BlockingQueue 接口中12345678910111213141516171819202122232425262728//以下代码摘自： java.util.concurrent.LinkedBlockingQueuepublic void put(E e) throws InterruptedException &#123; if (e == null) throw new NullPointerException(); // 除非设置，否则保持计数器的值为-1表示失败 int c = -1; Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try &#123; //这里使用while进行判断，是因为await的线程被唤醒时从await返回，需要再进行一次判断 //如果使用if的话就直接往下运行了，运行结果会不稳定。 while (count.get() == capacity) &#123; notFull.await(); &#125; enqueue(node); //返回旧的计数然后计数+1 c = count.getAndIncrement(); //入队之后如果还有位置，给notFull队列发信号，唤醒put线程 if (c + 1 &lt; capacity) notFull.signal(); &#125; finally &#123; putLock.unlock(); &#125; //这个c是入队之前的计数，入队之前为空，入队后有元素了，所以要唤醒一个出队线程 if (c == 0) signalNotEmpty();&#125; put(e)方法总结： 检查参数为空抛NPE异常 使用参数构造新节点，获取入队锁putLock 当队满时，调用 notFull.await() 阻塞当前线程，注意此处使用while语句进行判断，原因后文分析。 队不满执行入队，计数器 +1 判断计数器更新后队是否未满，未满则唤醒阻塞的入队线程（如果存在的话） 解锁 判断此次入队前是否为空队列，如果是，此次入队完成后就不是了，所以要唤醒一个阻塞的出队线程。 无返回值 123456789101112131415161718192021public E take() throws InterruptedException &#123; E x; int c = -1; final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly();//1 try &#123; while (count.get() == 0) &#123;//2 notEmpty.await(); &#125; x = dequeue();//3 c = count.getAndDecrement(); if (c &gt; 1)//4 notEmpty.signal(); &#125; finally &#123; takeLock.unlock();//5 &#125; if (c == capacity)//6 signalNotFull(); return x;//7&#125; take()方法总结： 获取出队锁takeLock 判断队列是否为空，为空就调用notEmpty.await()阻塞线程 不空就执行出队操作，计数器 -1 如果出队后队列仍然不空，唤醒一个阻塞的出队线程（如果存在的话） 解锁 若此次出队之前队列满，执行完本次出队就不满了，可以唤醒一个入队线程 返回出队的元素 5. offer(e,time,unit) &amp; poll(time, unit)超时阻塞方法，定义在 BlockingQueue 接口中，该组方法在put/take的基础上加上了超时返回的功能，出队超时返回null，入队超时返回false。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455以下代码摘自： java.util.concurrent.LinkedBlockingQueuepublic boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException &#123; if (e == null) throw new NullPointerException(); long nanos = unit.toNanos(timeout);//1 int c = -1; final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try &#123; while (count.get() == capacity) &#123; if (nanos &lt;= 0)//超时了 return false; //没超时阻塞，nanos之后自动唤醒 nanos = notFull.awaitNanos(nanos); //唤醒后返回到这里，继续while循环判断队列是否满，还是满就妥妥的超时了 &#125; enqueue(new Node&lt;E&gt;(e)); c = count.getAndIncrement(); if (c + 1 &lt; capacity) notFull.signal(); &#125; finally &#123; putLock.unlock(); &#125; if (c == 0) signalNotEmpty(); return true;&#125;public E poll(long timeout, TimeUnit unit) throws InterruptedException &#123; E x = null; int c = -1; long nanos = unit.toNanos(timeout); final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly(); try &#123; while (count.get() == 0) &#123; if (nanos &lt;= 0)//超时了 return null; //没超时阻塞，nanos之后自动唤醒 nanos = notEmpty.awaitNanos(nanos); //唤醒后返回到这，继续为了循环判断队列是否为空，还是为空妥妥的超时 &#125; x = dequeue(); c = count.getAndDecrement(); if (c &gt; 1) notEmpty.signal(); &#125; finally &#123; takeLock.unlock(); &#125; if (c == capacity) signalNotFull(); return x;&#125; 6. await之前的判断为什么用while用put作为例子解释一下123456789101112putLock.lockInterruptibly();try &#123; while (count.get() == capacity) &#123; notFull.await();//1 &#125; enqueue(node); c = count.getAndIncrement(); //2 if (c + 1 &lt; capacity) notFull.signal();//3&#125; finally &#123; putLock.unlock();//4&#125; 假设A线程入队操作结束后(执行到2位置)，队列还剩一个空位，那么程序会唤醒阻塞队列中的put线程（3位置）B线程 B线程从await返回后需要竞争put锁（从等待池进入锁池），但这时候有个C线程也来竞争put锁并且成功，C执行入队之后队列已经满了 C释放锁之后B获得锁，从await返回（位置1），如果这里使用 if 判断，1位置之后继续向下执行入队操作，显然会出错，因为最后一个空位让C线程用掉了 但是使用 while 判断，await返回之后，还在循环体内，继续循环判断队列是否满，发现满了，再次await。 所以使用while判断其实是在这里进行了一次 double check， 不管是使用await还是wait，都需要while进行判断，不然在多线程环境中就会出错。 7. 其他方法 peek() 返回头结点，队列空返回null element() 调用peak()，peak()返回null则抛异常 NoSuchElementException remove(o) 移除指定的元素，参数接受null，若没找到该元素返回false contains(o) 判断是否包含指定元素，参数为空或不包含返回false remainingCapacity() 返回剩余容量 size() 返回现有元素数量 clear() 原子性的清除所有元素 drainTo(c) 将队列中的元素放到集合c中，返回转换的元素个数","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/categories/并发编程/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/tags/并发编程/"}],"keywords":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/categories/并发编程/"}]},{"title":"并发编程-容器ConcurrentHashMap源码分析","slug":"并发编程-容器ConcurrentHashMap源码分析","date":"2018-03-26T16:00:00.000Z","updated":"2021-01-13T01:16:40.659Z","comments":true,"path":"2018/03/27/并发编程-容器ConcurrentHashMap源码分析/","link":"","permalink":"https://zzkenyon.github.io/2018/03/27/并发编程-容器ConcurrentHashMap源码分析/","excerpt":"","text":"1.重要的属性首先来看几个重要的属性，与HashMap相同的就不再介绍了，这里重点解释一下sizeCtl这个属性。可以说它是ConcurrentHashMap中出镜率很高的一个属性，因为它是一个控制标识符，在不同的地方有不同用途，而且它的取值不同，也代表不同的含义。 负数代表正在进行初始化或扩容操作 -1代表正在初始化 -N 表示有N-1个线程正在进行扩容操作 0代表hash表还没有被初始化， 正数表示这个初始化或下一次进行扩容的大小，这一点类似于扩容阈值的概念。还后面可以看到，它的值始终是当前ConcurrentHashMap容量的0.75倍，这与loadfactor是对应的。12345678910111213141516171819202122232425//盛装Node元素的数组,它的大小是2的整数次幂transient volatile Node&lt;K,V&gt;[] table;/** hash表初始化或扩容时的一个控制位标识量。 负数代表正在进行初始化或扩容操作 -1代表正在初始化 -N 表示有N-1个线程正在进行扩容操作 正数或0代表hash表还没有被初始化，这个数值表示初始化或下一次进行扩容的大小 */private transient volatile int sizeCtl;// 以下两个是用来控制扩容的时候 单线程进入的变量 /** * The number of bits used for generation stamp in sizeCtl. * Must be at least 6 for 32bit arrays. */private static int RESIZE_STAMP_BITS = 16;/** * The bit shift for recording size stamp in sizeCtl. */private static final int RESIZE_STAMP_SHIFT = 32- RESIZE_STAMP_BITS;static final int MOVED = -1;// hash值是-1，表示这是一个forwardNode节点static final int TREEBIN = -2;// hash值是-2 表示这时一个TreeBin节点 2.重要的类2.1 NodeNode是最核心的内部类，它包装了key-value键值对，所有插入ConcurrentHashMap的数据都包装在这里面。它与HashMap中的定义很相似，但是但是有一些差别它对value和next属性设置了volatile同步锁(与JDK7的Segment相同)，它不允许调用setValue方法直接改变Node的value域，它增加了find方法辅助map.get()方法。 2.2 TreeNode树节点类，另外一个核心的数据结构。当链表长度过长的时候，会转换为TreeNode。但是与HashMap不相同的是，它并不是直接转换为红黑树，而是把这些结点包装成TreeNode放在TreeBin对象中，由TreeBin完成对红黑树的包装。而且TreeNode在ConcurrentHashMap继承自Node类，而不像HashMap中的继承自LinkedHashMap.Entry&lt;K,V&gt;类，也就是说TreeNode带有next指针，这样做的目的是方便基于TreeBin的访问。 2.3 TreeBin这个类并不负责包装用户的key、value信息，而是包装的TreeNode节点。它代替了TreeNode的根节点，也就是说在实际的ConcurrentHashMap“数组”中，存放的是TreeBin对象，而不是TreeNode对象，这是与HashMap的区别。另外这个类还带有了读写锁。 这里仅贴出它的构造方法。可以看到在构造TreeBin节点时，仅仅指定了它的hash值为TREEBIN常量，这也就是个标识为。同时也看到我们熟悉的红黑树构造方法 2.4 ForwardingNode一个用于连接两个table的节点类。它包含一个nextTable指针，用于指向下一张表。而且这个节点的key value next指针全部为null，它的hash值为-1。这里面定义的find的方法是从nextTable里进行查询节点，而不是以自身为头节点进行查找。 123456789101112131415161718192021222324252627282930313233343536/** * A node inserted at head of bins during transfer operations. */static final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; final Node&lt;K,V&gt;[] nextTable; ForwardingNode(Node&lt;K,V&gt;[] tab) &#123; super(MOVED,null,null,null); this.nextTable = tab; &#125; Node&lt;K,V&gt; find(inth, Object k) &#123; // loop to avoid arbitrarily deep recursion on forwarding nodes outer:for(Node&lt;K,V&gt;[] tab = nextTable;;) &#123; Node&lt;K,V&gt; e; intn; if(k == null|| tab == null|| (n = tab.length) == 0|| (e = tabAt(tab, (n - 1) &amp; h)) == null) returnnull; for(;;) &#123; inteh; K ek; if((eh = e.hash) == h &amp;&amp; ((ek = e.key) == k || (ek != null&amp;&amp; k.equals(ek)))) returne; if(eh &lt; 0) &#123; if(einstanceofForwardingNode) &#123; tab = ((ForwardingNode&lt;K,V&gt;)e).nextTable; continueouter; &#125; else returne.find(h, k); &#125; if((e = e.next) == null) returnnull; &#125; &#125; &#125;&#125; 3.Unsafe与CAS在ConcurrentHashMap中，随处可以看到U, 大量使用了U.compareAndSwapXXX的方法，这个方法是利用一个CAS算法实现无锁化的修改值的操作，他可以大大降低锁代理的性能消耗。这个算法的基本思想就是不断地去比较当前内存中的变量值与你指定的一个变量值是否相等，如果相等，则接受你指定的修改的值，否则拒绝你的操作。因为当前线程中的值已经不是最新的值，你的修改很可能会覆盖掉其他线程修改的结果。这一点与乐观锁，SVN的思想是比较类似的。 3.1 unsafe静态块unsafe代码块控制了一些属性的修改工作，比如最常用的SIZECTL 。在这一版本的concurrentHashMap中，大量应用来的CAS方法进行变量、属性的修改工作。利用CAS进行无锁操作，可以大大提高性能。 1234567891011121314151617181920212223242526272829private static final sun.misc.Unsafe U; private static final long SIZECTL; private static final long TRANSFERINDEX; private static final long BASECOUNT; private static final long CELLSBUSY; private static final long CELLVALUE; private static final long ABASE; private static final int ASHIFT; static&#123; try&#123; U = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; k = ConcurrentHashMap.class; SIZECTL = U.objectFieldOffset(k.getDeclaredField(\"sizeCtl\")); TRANSFERINDEX = U.objectFieldOffset(k.getDeclaredField(\"transferIndex\")); BASECOUNT = U.objectFieldOffset(k.getDeclaredField(\"baseCount\")); CELLSBUSY = U.objectFieldOffset(k.getDeclaredField(\"cellsBusy\")); Class&lt;?&gt; ck = CounterCell.class; CELLVALUE = U.objectFieldOffset(ck.getDeclaredField(\"value\")); Class&lt;?&gt; ak = Node[].class; ABASE = U.arrayBaseOffset(ak); intscale = U.arrayIndexScale(ak); if((scale &amp; (scale - 1)) != 0) thrownewError(\"data type scale not a power of two\"); ASHIFT = 31- Integer.numberOfLeadingZeros(scale); &#125;catch(Exception e) &#123; thrownewError(e); &#125; &#125; 3.2 三个核心方法ConcurrentHashMap定义了三个原子操作，用于对指定位置的节点进行操作。正是这些原子操作保证了ConcurrentHashMap的线程安全。 123456789101112static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) &#123; //获得在i位置上的Node节点, return(Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE);&#125; static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) &#123; //因此当前线程中的值并不是最新的值，这种修改可能会覆盖掉其他线程的修改结果有点类似于SVN returnU.compareAndSwapObject(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v);&#125;static final &lt;K,V&gt; voidsetTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; v) &#123; //利用volatile方法设置节点位置的值 U.putObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, v);&#125; tabAt操作能够实时感知其他线程对map的修改，它调用了native方法getObjectVolatile，该方法获取到的总是最新的值。 casTabAt通过CAS修改table中的值 4 初始化方法initTable对于ConcurrentHashMap来说，调用它的构造方法仅仅是设置了一些参数而已。而整个table的初始化是在向ConcurrentHashMap中插入元素的时候发生的。如调用put、computeIfAbsent、compute、merge等方法的时候，调用时机是检查table==null。 初始化方法主要应用了关键属性sizeCtl 如果这个值小于0，表示其他线程正在进行初始化，就放弃这个操作。在这也可以看出ConcurrentHashMap的初始化只能由一个线程完成。如果获得了初始化权限，就用CAS方法将sizeCtl置为-1，防止其他线程进入。初始化数组后，将sizeCtl的值改为0.75*n。 12345678910111213141516171819202122232425private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while((tab = table) == null|| tab.length == 0) &#123; //sizeCtl表示有其他线程正在进行初始化操作，把线程挂起。对于table的初始化工作，只能有一个线程在进行。 if((sc = sizeCtl) &lt; 0) Thread.yield(); else if(U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; //利用CAS方法把sizectl的值置为-1 表示本线程正在进行初始化 try&#123; if((tab = table) == null|| tab.length == 0) &#123; intn = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(\"unchecked\") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])newNode&lt;?,?&gt;[n]; table = tab = nt; sc = n - (n &gt;&gt;&gt; 2);//相当于0.75*n 设置一个扩容的阈值 &#125; &#125;finally&#123; sizeCtl = sc; &#125; break; &#125; &#125; returntab;&#125; 5 扩容方法 transfer当ConcurrentHashMap容量不足的时候，需要对table进行扩容。这个方法的基本思想跟HashMap是很像的，但是由于它是支持并发扩容的，所以要复杂的多。原因是它支持多线程进行扩容操作，而并没有加锁。我想这样做的目的不仅仅是为了满足concurrent的要求，而是希望利用并发处理去减少扩容带来的时间影响。因为在扩容的时候，总是会涉及到从一个“数组”到另一个“数组”拷贝的操作，如果这个操作能够并发进行，那真是太好了。 整个扩容操作分为两个部分 第一部分是构建一个nextTable，它的容量是原来的两倍，这个操作是单线程完成的。这个单线程的保证是通过RESIZE_STAMP_SHIFT这个常量经过一次运算来保证的，这个地方在后面会有提到； 第二个部分就是将原来table中的元素复制到nextTable中，这里允许多线程进行操作。 先来看一下单线程是如何完成的： 它的大体思想就是遍历、复制的过程。首先根据运算得到需要遍历的次数n，然后利用tabAt方法获得i位置的元素： 如果这个位置为空，就在原table中的i位置放入ForwardNode节点，这个也是触发并发扩容的关键点； 如果这个位置是Node节点（fh&gt;=0），且它是一个链表的头节点，就构造一个反序链表，把他们分别放在nextTable的i和i+n的位置上 如果这个位置是TreeBin节点（fh&lt;0），也做一个反序处理，并且判断是否需要untreefi，把处理的结果分别放在nextTable的i和i+n的位置上 遍历过所有的节点以后就完成了复制工作，这时让nextTable作为新的table，并且更新sizeCtl为新容量的0.75倍 ，完成扩容。再看一下多线程是如何完成的： 在代码的69行有一个判断，如果遍历到的节点是forward节点，就向后继续遍历，再加上给节点上锁的机制，就完成了多线程的控制。多线程遍历节点，处理了一个节点，就把对应点的值set为forward，另一个线程看到forward，就向后遍历。这样交叉就完成了复制工作。而且还很好的解决了线程安全的问题。 这个方法的设计实在是让人膜拜。 6 Put方法前面的所有的介绍其实都为这个方法做铺垫。ConcurrentHashMap最常用的就是put和get两个方法。现在来介绍put方法，这个put方法依然沿用HashMap的put方法的思想，根据hash值计算这个新插入的点在table中的位置i，如果i位置是空的，直接放进去，否则进行判断，如果i位置是树节点，按照树的方式插入新的节点，否则把i插入到链表的末尾。ConcurrentHashMap中依然沿用这个思想，有一个最重要的不同点就是ConcurrentHashMap不允许key或value为null值。另外由于涉及到多线程，put方法就要复杂一点。在多线程中可能有以下两个情况 如果一个或多个线程正在对ConcurrentHashMap进行扩容操作，当前线程也要进入扩容的操作中。这个扩容的操作之所以能被检测到，是因为transfer方法中在空结点上插入forward节点，如果检测到需要插入的位置被forward节点占有，就帮助进行扩容； 如果检测到要插入的节点是非空且不是forward节点，就对这个节点加锁，这样就保证了线程安全。尽管这个有一些影响效率，但是还是会比对整个hashTable的synchronized要好得多。 整体流程就是首先定义不允许key或value为null的情况放入，对于每一个放入的值，首先利用spread方法对key的hashcode进行一次hash计算，由此来确定这个值在table中的位置。 如果这个位置是空的，那么直接放入，而且不需要加锁操作。 如果这个位置存在结点，说明发生了hash碰撞，首先判断这个节点的类型。如果是链表节点（fh&gt;0），则得到的结点就是hash值相同的节点组成的链表的头节点。需要依次向后遍历确定这个新加入的值所在位置。如果遇到hash值与key值都与新加入节点是一致的情况，则只需要更新value值即可。否则依次向后遍历，直到链表尾插入这个结点。如果加入这个节点以后链表长度大于8，就把这个链表转换成红黑树。如果这个节点的类型已经是树节点的话，直接调用树节点的插入方法进行插入新的值。 12345678910111213141516171819202122232425publicV put(K key, V value) &#123; return putVal(key, value, false);&#125;/** Implementation for put and putIfAbsent */final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if(key == null|| value == null) throw new NullPointerException(); //计算hash值 int hash = spread(key.hashCode()); int binCount = 0; //死循环 何时插入成功 何时跳出 for(Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; if(tab == null|| (n = tab.length) == 0) //如果table为空的话，初始化table &gt;&gt; tab = initTable(); else if((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; //根据hash值计算出在table里面的位置，如果这个位置没有值，直接放进去，不需要加锁 if(casTabAt(tab, i, null,new Node&lt;K,V&gt;(hash, key, value, null))) break; &#125; ...&#125; 假如在上面这段代码中存在两个线程，在不加锁的情况下：线程 A 成功执行 casTabAt 操作后，随后的线程 B 可以通过 tabAt 方法立刻看到 table[i]的改变。原因如下：线程 A 的casTabAt 操作，具有 volatile 读写相同的内存语义，根据 volatile 的 happens-before 规则：线程 A 的 casTabAt 操作，一定对线程 B 的 tabAt 操作可见。 我们可以发现JDK8中的实现也是锁分离的思想，只是锁住的是一个Node，而不是JDK7中的Segment，而锁住Node之前的操作是无锁的并且也是线程安全的，建立在之前提到的3个原子操作上。 6.1 helpTransfer方法这是一个协助扩容的方法。这个方法被调用的时候，当前ConcurrentHashMap一定已经有了nextTable对象，首先拿到这个nextTable对象，调用transfer方法。回看上面的transfer方法可以看到，当本线程进入扩容方法的时候会直接进入复制阶段。 6.2 treeifyBin方法这个方法用于将过长的链表转换为TreeBin对象。但是他并不是直接转换，而是进行一次容量判断，如果容量没有达到转换的要求，直接进行扩容操作并返回；如果满足条件才链表的结构抓换为TreeBin ，这与HashMap不同的是，它并没有把TreeNode直接放入红黑树，而是利用了TreeBin这个小容器来封装所有的TreeNode. 7 get方法get方法比较简单，给定一个key来确定value的时候，必须满足两个条件 key相同 hash值相同，对于节点可能在链表或树上的情况，需要分别去查找。 1234567891011121314151617181920212223242526public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; //计算hash值 int h = spread(key.hashCode()); //根据hash值确定节点位置 if((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; //如果搜索到的节点key与传入的key相同且不为null,直接返回这个节点 if((eh = e.hash) == h) &#123; if((ek = e.key) == key || (ek != null&amp;&amp; key.equals(ek))) returne.val; &#125; //如果eh&lt;0 说明这个节点在树上 直接寻找 else if(eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; //否则遍历链表 找到对应的值并返回 while((e = e.next) != null) &#123; if(e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null&amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125; 8 Size相关的方法对于ConcurrentHashMap来说，这个table里到底装了多少东西其实是个不确定的数量，因为不可能在调用size()方法的时候像GC的“stop the world”一样让其他线程都停下来让你去统计，因此只能说这个数量是个估计值。对于这个估计值，ConcurrentHashMap也是大费周章才计算出来的。 8.1 辅助定义为了统计元素个数，ConcurrentHashMap定义了一些变量和一个内部类 1234567891011121314151617181920212223242526/** * A padded cell for distributing counts. Adapted from LongAdder * and Striped64. See their internal docs for explanation. */@sun.misc.Contendedstaticfinalclass CounterCell &#123; volatilelongvalue; CounterCell(longx) &#123; value = x; &#125;&#125;/******************************************/ /** * 实际上保存的是hashmap中的元素个数 利用CAS锁进行更新 但它并不用返回当前hashmap的元素个数 */privatetransientvolatile long baseCount;/** * Spinlock (locked via CAS) used when resizing and/or creating CounterCells. */privatetransientvolatile int cellsBusy;/** * Table of counter cells. When non-null, size is a power of 2. */privatetransientvolatile CounterCell[] counterCells; 8.2 mappingCount与Size方法mappingCount与size方法的类似 从Java工程师给出的注释来看，应该使用mappingCount代替size方法 两个方法都没有直接返回basecount 而是统计一次这个值，而这个值其实也是一个大概的数值，因此可能在统计的时候有其他线程正在执行插入或删除操作。 1234567891011121314151617181920212223242526272829303132publicintsize() &#123; longn = sumCount(); return((n &lt; 0L) ? 0: (n &gt; (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int)n); &#125; /** * Returns the number of mappings. This method should be used * instead of &#123;@link #size&#125; because a ConcurrentHashMap may * contain more mappings than can be represented as an int. The * value returned is an estimate; the actual count may differ if * there are concurrent insertions or removals. * * @return the number of mappings * @since 1.8 */ publiclongmappingCount() &#123; longn = sumCount(); return(n &lt; 0L) ? 0L : n; // ignore transient negative values &#125; finallongsumCount() &#123; CounterCell[] as = counterCells; CounterCell a; longsum = baseCount; if(as != null) &#123; for(inti = 0; i &lt; as.length; ++i) &#123; if((a = as[i]) != null) sum += a.value;//所有counter的值求和 &#125; &#125; returnsum; &#125; 8.3 addCount方法在put方法结尾处调用了addCount方法，把当前ConcurrentHashMap的元素个数+1这个方法一共做了两件事,更新baseCount的值，检测是否进行扩容。 123456789101112131415161718192021222324252627282930313233343536373839404142privatefinalvoid addCount(longx,intcheck) &#123; CounterCell[] as; longb, s; //利用CAS方法更新baseCount的值 if((as = counterCells) != null|| !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) &#123; CounterCell a; longv;intm; booleanuncontended = true; if(as == null|| (m = as.length - 1) &lt; 0|| (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null|| !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) &#123; fullAddCount(x, uncontended); return; &#125; if(check &lt;= 1) return; s = sumCount(); &#125; //如果check值大于等于0 则需要检验是否需要进行扩容操作 if(check &gt;= 0) &#123; Node&lt;K,V&gt;[] tab, nt; intn, sc; while(s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null&amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123; intrs = resizeStamp(n); // if(sc &lt; 0) &#123; if((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1|| sc == rs + MAX_RESIZERS || (nt = nextTable) == null|| transferIndex &lt;= 0) break; //如果已经有其他线程在执行扩容操作 if(U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; //当前线程是唯一的或是第一个发起扩容的线程 此时nextTable=null elseif(U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab,null); s = sumCount(); &#125; &#125;&#125; 总结JDK6,7中的ConcurrentHashmap主要使用Segment来实现减小锁粒度，把HashMap分割成若干个Segment，在put的时候需要锁住Segment，get时候不加锁，使用volatile来保证可见性，当要统计全局时（比如size），首先会尝试多次计算modcount来确定，这几次尝试中，是否有其他线程进行了修改操作，如果没有，则直接返回size。如果有，则需要依次锁住所有的Segment来计算。 jdk7中ConcurrentHashmap中，当长度过长碰撞会很频繁，链表的增改删查操作都会消耗很长的时间，影响性能,所以jdk8 中完全重写了concurrentHashmap,代码量从原来的1000多行变成了 6000多 行，实现上也和原来的分段式存储有很大的区别。 主要设计上的变化有以下几点: 不采用segment而采用node，锁住node来实现减小锁粒度。 设计了MOVED状态 当resize的中过程中 线程2还在put数据，线程2会帮助resize。 使用3个CAS操作来确保node的一些操作的原子性，这种方式代替了锁。 sizeCtl的不同值来代表不同含义，起到了控制的作用。 至于为什么JDK8中使用synchronized而不是ReentrantLock，我猜是因为JDK8中对synchronized有了足够的优化吧。 参考文档JDK1.8 实现解读扩容源码分析","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/categories/并发编程/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/tags/并发编程/"}],"keywords":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/categories/并发编程/"}]},{"title":"并发编程-线程池源码详解","slug":"并发编程-线程池源码详解","date":"2018-03-24T16:00:00.000Z","updated":"2021-01-12T06:31:29.602Z","comments":true,"path":"2018/03/25/并发编程-线程池源码详解/","link":"","permalink":"https://zzkenyon.github.io/2018/03/25/并发编程-线程池源码详解/","excerpt":"","text":"阿里巴巴Java手册有一条： 【强制】线程资源必须通过线程池提供，禁止在应用程序中显示创建线程。 说明：使用线程池的好处是减少在创建和销毁线程上所花的时间以及系统资源的开销，解决资源不足的问题。如果不使用线程池，有可能造成系统创建大量同类线程导致消耗完内存或者过度切换的问题。 简单来说使用线程池有以下几个目的： 避免频繁的创建。线程是稀缺资源。 解耦。线程的创建与执行分开，方便维护。 线程资源复用。 1. 线程池原理本文从线程池的创建开始说起，跟着源码分析一下线程池的工作原理，本文源码基于JDK1.8 1.1 ExecutorsExecutors有一个私有的默认构造函数，不能实例化，是一个工具类，主要用于提供各种类型线程池创建的静态方法。 提供的静态创建方法有： newSingleThreadExecutor 创建一个执行器，该执行器使用单个工作线程操作一个无界队列。(但是请注意，如果这个单线程在关闭之前的执行过程中由于失败而终止，如果需要执行后续任务，一个新的线程将取代它。)保证任务按顺序执行，并且在任何给定时间不会有超过一个任务处于活动状态。与等效的{@code newFixedThreadPool(1)}不同，返回的执行器保证不会被重新配置以使用其他线程。 newFixedThreadPool 创建一个线程池，该线程池重用固定数量的线程，在需要时使用提供的ThreadFactory创建新线程。在任何时候，最多有 nThreads个活动线程执行任务，如果在所有线程都处于活动状态时提交了额外的任务，那么它们将在队列中等待，直到有线程可用。如果任何线程在关闭之前的执行过程中由于失败而终止，那么如果需要执行后续任务，一个新的线程将取代它。线程池中的线程将一直存在，直到显式地shutdown。 newWorkStealingPool 创建一个线程池，该线程池维护足够的线程来支持给定的并行级别，并可以使用多个队列来减少争用。并行级别对应于积极参与或可参与任务处理的最大线程数。线程的实际数量可以动态地增长和收缩。工作窃取池不保证提交任务的执行顺序。 newCachedThreadPool 创建一个线程池，该线程池根据需要创建新线程，但在可用时将重用以前构造的线程。这些池通常会提高执行许多短期异步任务的程序的性能。如果可用，对execute的调用将重用以前构造的线程。如果没有可用的现有线程，将创建一个新线程并将其添加到池中。未使用60秒的线程将被终止并从缓存中删除。因此，长时间空闲的池不会消耗任何资源。注意，可以使用ThreadPoolExecutor构造函数创建具有相似属性但不同细节(例如超时参数)的池。 newSingleThreadScheduledExecutor 创建一个单线程执行器，该执行器可以安排命令在给定的延迟之后运行，或者定期执行。(但是请注意，如果这个线程在关闭之前的执行过程中由于失败而终止，那么如果需要执行后续任务，将会有一个新的线程代替它。)，与 newFixedThreadPool(1)不同，返回的executor不能被其他线程重新配置。 newScheduledThreadPool 创建一个线程池，该线程池可以在给定延迟之后调度命令运行，或者定期执行命令。 Executors 返回的线程池对象的弊端如下： FixedThreadPool 和 SingleThreadPool: 允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。 CachedThreadPool 和 ScheduledThreadPool: 允许的创建线程数量为 Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。 所以线程池的创建，一般会根据需求场景，使用自选参数，由用户主动构造，而不是使用静态方法构造。 1.2 ThreadPoolExecutor首先看一下newFixedThreadPool创建方法的源码：12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 事实上，大多数类型的线程池创建都是调用new ThreadPoolExecutor(…)创建一个ThreadPoolExecutor对象，只不过初始化参数不同而已。newWorkStealingPool创建时构造的是ForkJoinPool对象，本文不述。 下面是ThreadPoolExecutor的其中一个构造方法：123456789public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; ...&#125; 初始化参数的如下： corePoolSize ：表示线程池的核心数,线程池保持alive状态的线程数，即使线程是空闲的。 maximumPoolSize： 表示线程池支持的最大的线程个数。 keepAliveTime ：表示池中线程空闲后的生存时间 unit： 表示上一个时间参数的单位 workQueue： 用于存放任务的阻塞队列 threadFactory： 表示创建线程的工厂，一般使用默认的线程创建工厂Excutors.DefaultThreadFactory() handler： 当队列和最大线程池都满了之后的饱和策略，一般使用默认的handler—AbortPolicy（内部类） 1234567891011//代码摘自：java.util.concurrent.ThreadPoolExecutorprivate static final RejectedExecutionHandler defaultHandler = new AbortPolicy();public static class AbortPolicy implements RejectedExecutionHandler &#123; public AbortPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; throw new RejectedExecutionException(\"Task \" + r.toString() +\" rejected from \" + e.toString()); &#125;&#125;final void reject(Runnable command) &#123; handler.rejectedExecution(command, this);&#125; 用户也可以自己实现RejectedExecutionHandler接口定义一个handler，当提交的任务因为各种原因被线程池拒绝，就会调用rejectedExecution方法。 1.2.1 提交任务excute()使用线程池时，通常我们用1threadPool.execute(new Job()); 这样的方式提交一个任务到线程池中，所以线程池ThreadPoolExecutor的核心逻辑就是execute()函数了，这个方法是在Excutor接口中声明。 在分析核心逻辑之前，先了解一下线程池中定义的状态，这些状态都和线程的执行密切相关 1234567891011121314//代码摘自：java.util.concurrent.ThreadPoolExecutorprivate static final int COUNT_BITS = Integer.SIZE - 3;private static final int CAPCITY = (1 &lt;&lt; COUNT_BITS) - 1;private static final int RUNNING = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;private static final int STOP = 1 &lt;&lt; COUNT_BITS;private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS;private static int runStateOf(int c)&#123;return c &amp; ~CAPCITY;&#125;private static int workerCountOf(int c)&#123;return c &amp; CAPCITY;&#125;private static int ctlOf(int rs, int wc)&#123;return rs | wc;&#125; 分析上面的代码得到下表： 常量名 二进制 CAPCITY 0001 1111 1111 1111 1111 1111 1111 1111 RUNNING 1110 0000 0000 0000 0000 0000 0000 0000 SHUTDOWN 0000 0000 0000 0000 0000 0000 0000 0000 STOP 0010 0000 0000 0000 0000 0000 0000 0000 TIDYING 0100 0000 0000 0000 0000 0000 0000 0000 TERMINATED 0110 0000 0000 0000 0000 0000 0000 0000 由上表可以看出，原子对象ctl的前三位表示状态，后29位记录池中worker的个数，CAPCITY就像是一个掩码，通过掩码可以快速的从ctl中获得当前线程池的运行状态和池中的worker个数。 JDK1.8的并发包中不再通过设置阻塞队列的长度来限制任务的提交。阻塞队列的长度初始化之后就不能改变，因此如果担心阻塞队列太大导致内存占用太多，可以从两方面入手：1、初始化的时候选择合适的阻塞队列大小；2、调高corePoolSize或maxmumPoolSize加快任务的处理速度。参数的动态调整见下文。 线程池状态简述： RUNNING 是运行状态，指可以接受任务，执行队列里的任务。 SHUTDOWN 是指调用了shutdown()函数，不再接受新任务，但是会把队列里的任务执行完毕。 STOP 是指调用了shutdownNow()函数，不再接受新任务，同时终端正在执行的任务并丢弃队列中的待执行任务。 TIDYING 指所用任务都执行完毕。 TERMINATED 终止状态，在调用shutdown()或shutdownNow()时都会尝试更新这个状态。 下面分析核心代码excute()方法123456789101112131415161718192021222324252627//代码摘自：java.util.concurrent.ThreadPoolExecutorpublic void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); //1、获取当前线程池的状态 int c = ctl.get(); //2、当线程数量小于corePoolSize，创建新线程运行 if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; //线程池线程数到达核心线程数 或者 新增worker失败失败 //3、如果线程池处于运行状态，将任务写入阻塞队列，如果入队也顺利继续往下执行 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); //3-1.再次检查线程状态，若线程池状态发生改变（变为非运行状态），则从阻塞队列移除该任务，如果出队顺利就执行拒绝策略 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); //3-2.如果线程池仍然为运行态，检查当前池是否为空，为空就创建一个线程，但不指定任务 else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; //4、如果第一次检查就不通过（线程池非运行态或者任务入队失败），尝试新建线程，如果失败则执行拒绝策略 else if (!addWorker(command, false)) reject(command);&#125; 疑问：addWorker(null, false) 添加了一个没有具体任务的worker，作用是什么？ 如果线程池中的线程数为0，但任务队列中有需要执行的任务，这时候新建一个没有任务的线程是为了去执行任务队列中的任务。 下图表示了当有任务提交到线程池后线程池的处理流程： 1.2.2 创建工人（线程）addWorker(Runnable firstTask, boolean core) 参数： firstTask： worker线程的初始任务，可以为空core： true：将corePoolSize作为上限，false：将maximumPoolSize作为上限 addWorker函数是execute函数的核心逻辑，线程池持有一个HashSet对象存放池中的workers，每个worker对应一个线程，addWorker的作用就是创建worker执行任务。 addWorker方法有4种调用方式： addWorker(command, true) addWorker(command, false) addWorker(null, false) addWorker(null, true) 在execute方法中就使用了前3种，结合这个方法进行以下分析 线程数小于corePoolSize时，放一个需要处理的task进Workers Set。如果Workers Set长度超过corePoolSize，就返回false 当队列被放满时，就尝试将这个新来的task直接放入Workers Set，而此时Workers Set的长度限制是maximumPoolSize。如果线程池也满了的话就返回false 放入一个空的task进workers Set，长度限制是maximumPoolSize。这样一个task为空的worker在线程执行的时候会去任务队列里拿任务，这样就相当于创建了一个新的线程，只是没有马上分配任务 这个方法就是放一个null的task进Workers Set，而且是在小于corePoolSize时，如果此时Set中的数量已经达到corePoolSize那就返回false，什么也不干。实际使用中是在prestartAllCoreThreads()方法，这个方法用来为线程池预先启动corePoolSize个worker等待从workQueue中获取任务执行 下面将源代码分成两部分进行分析 12345678910111213141516171819202122232425262728293031323334//代码摘自：java.util.concurrent.ThreadPoolExecutorprivate final ReentrantLock mainLock = new ReentrantLock();private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); //状态为 RUNNING 继续往下执行 //状态为不为RUNNING时，如果状态为SHUTDOWN并且firstTask为null并且阻塞队列空时，可继续向下运行 //否则返回false，添加worker失败 if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); //线程数大于CAPACITY //线程数大于corePoolSize或maximumPoolSize（取决于core） if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; //线程数验证通过，使用CAS对c加1，执行成功则终止大循环继续向下运行 if (compareAndIncrementWorkerCount(c)) break retry; //CAS设置失败则重新获取运行状态，若线程池状态发生改变，从头开始大循环，否则继续小循环 c = ctl.get(); if (runStateOf(c) != rs) continue retry; &#125; &#125; ... &#125; 这段代码为主要负责检查，主要判断线程池当前是否为可以添加worker线程的状态，可以则继续下一步，不可以则返回 false，具体分为三种情况： 线程池状态&gt;shutdown，可能为stop、tidying、terminated，不能添加worker线程 线程池状态==shutdown，firstTask不为空，不能添加worker线程，因为shutdown状态的线程池不接收新任务 线程池状态==shutdown，firstTask==null，workQueue为空，不能添加worker线程，因为firstTask为空是为了添加一个没有任务的线程再从workQueue获取task，而workQueue为空，说明添加无任务线程已经没有意义 当以上的情况都不符合，继续向下执行。在创建worker之前还需要验证一下线程池中的线程数量有没有达到极限，达到极限直接返回false；没达到极限，先CAS修改线程池状态(+1操作)，若修改成功，直接退出检验模块循环，执行下面的运行模块。CAS设置状态失败则重新获取运行状态进行二重检验，若线程池状态发生改变，从头开始大循环检验，否则继续小循环执行cas。 第二部分为运行模块，直接进入主题，将提交的任务包装成worker对象，加入worker set 并启动该worker的线程，worker插入set需要加锁。 123456789101112131415161718192021222324252627282930313233343536373839404142private boolean addWorker(Runnable firstTask, boolean core) &#123; ... boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 二重验证，获取池状态 int rs = runStateOf(ctl.get()); //状态为RUNNING 则通过继续执行 //状态为SHUTDOWN并且提交的任务为null 则通过继续执行 //否则直接执行finally解锁 if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // 如果worker中的线程t已经处于运行状态 throw new IllegalThreadStateException();//抛异常 workers.add(w);//将w加入HashSet int s = workers.size(); //更新largestPoolSize，largestPoolSize只能在lock下修改 if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125; addWorker执行流程总结： 判断是否可以addworker 线程池当前线程数量是否超过上限（corePoolSize 或 maximumPoolSize），超过了return false，没超过则对workerCount+1，继续下一步 在线程池的ReentrantLock保证下，向Workers Set中添加新创建的worker实例，添加完成后解锁，并启动worker线程，只有在新建的线程成功启动的情况下才能返回 true。如果添加worker入Set失败或启动失败，调用addWorkerFailed()逻辑 1.2.3 worker创建失败的善后处理addWorkerFailed() 当任务执行失败，程序需要进行善后处理，即恢复任务执行过程中对内存的改动，移除Worker set中的worker对象，修改池状态，最后尝试终止线程池。1234567891011121314代码摘自：java.util.concurrent.ThreadPoolExecutorprivate void addWorkerFailed(Worker w) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; if (w != null) workers.remove(w); //CAS对ctl减1 decrementWorkerCount(); tryTerminate(); &#125; finally &#123; mainLock.unlock(); &#125;&#125; 1.2.4 Worker类我们发现 addWorker 方法只是构造了一个 Worker，并且把 firstTask 封装到 worker 中，它是做什么的呢？我们来看看 每个 worker,都是一条线程,同时里面包含了一个 firstTask,即初始化时要被首先执行的任务. 最终执行任务的,是 runWorker()方法 12345678910Worker(Runnable firstTask) &#123; setState(-1); //初始化信号量为-1 this.firstTask = firstTask; //创建线程将worker对象传入，线程执行的是worker的run方法 this.thread = getThreadFactory().newThread(this);&#125;public void run() &#123; runWorker(this);// 线程启动执行的是此方法&gt;&gt;&#125; Worker 类实现了 Runnable 接口，注意其中的 firstTask 和 thread 属性： firstTask 用它来保存传入的任务； thread 是在调用构造方法时通过 ThreadFactory 来创建的线程，是用来处理任务的线程。 在调用构造方法时，需要传入任务，这里通过 getThreadFactory().newThread(this);来新建一个线程，newThread 方法传入的参数是 this，因为 Worker 本身继承了 Runnable 接口，也就是一个线程，所以一个 Worker 对象在启动的时候会调用 Worker 类中的 run 方法。 Worker 继承了 AQS，使用 AQS 来实现独占锁的功能。为什么不使用 ReentrantLock 来实现呢？可以看到 tryAcquire 方法，它是不允许重入的，而 ReentrantLock 是允许重入的。 lock 方法一旦获取了独占锁，表示当前线程正在执行任务中，lock方法将state置为1，unlock方法将state置为0，那么它会有以下几个作用 如果正在执行任务，state =1 则不应该中断线程； 如果该线程现在不是独占锁的状态，也就是空闲的状态，说明它没有在处理任务，这时可以对该线程进行中断； 线程池在执行 shutdown 方法或 tryTerminate 方法时会调用 interruptIdleWorkers 方法来中断空闲的线程，interruptIdleWorkers 方法会使用 tryLock 方法来判断线程池中的线程是否是空闲状态 之所以设置为不可重入，是因为我们不希望任务在调用像 setCorePoolSize 这样的线程池 控制方法时重新获取锁，这样会中断正在运行的线程 1.2.5 runWorker方法前面已经了解了 ThreadPoolExecutor 的核心方法 addWorker，主要作用是增加工作线程，而 Worker 简单理解其实就是一个线程，里面重新了 run 方法，这块是线程池中执行任务的真正处理逻辑，也就是 runWorker 方法，这个方法主要做几件事 如果 task 不为空,则开始执行 task 如果 task 为空,则通过 getTask()再去取任务,并赋值给 task,如果取到的 Runnable 不为空,则执行该任务 执行完毕后,通过 while 循环继续 getTask()取任务 如果 getTask()取到的任务依然是空,那么整个 runWorker()方法执行完毕 12345678910111213141516171819202122232425262728293031323334353637383940414243444546final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; //unlock，表示当前 worker 线程允许中断，因为 new Worker 默认的 state=-1,此处是调用Worker 类的 tryRelease()方法，将 state 置为 0， 而 interruptIfStarted()中只有 state&gt;=0 才允许调用中断 w.unlock(); boolean completedAbruptly = true; try &#123; // 如果 task 为空，则通过getTask 来获取任务 while (task != null || (task = getTask()) != null) &#123; // 上锁不是为了防止并发执行任务，为了在 shutdown()时不终止正在运行的任务 w.lock(); // worker线程池为 stop 状态时不接受新任务，不执行已经加入任务队列的任务，还中断正在执行的任务 //所以对于 stop 状态以上是要中断线程的 //(Thread.interrupted() &amp;&amp;runStateAtLeast(ctl.get(), STOP)确保线程中断标志位为 true 且是 stop 状态以上，接着清除了 中断标志 !wt.isInterrupted()则再一次检查保证线程需要设置中断标志位 if ((runStateAtLeast(ctl.get(), STOP) ||(Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task);//这里默认是没有实现的，在一些特定的场景中我们可以自己继承 ThreadpoolExecutor 自己重写 Throwable thrown = null; try &#123; task.run(); //runWorker最终执行的是task的 run 方法 &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); //这里默认默认而也是没有实现 &#125; &#125; finally &#123; //置空任务(这样下次循环开始时,task 依然为 null,需要再通过 getTask()取) + 记录该 Worker 完成任务数量 + 解锁 task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); //1.将入参 worker 从数组 workers 里删除掉； //2.根据布尔值 allowCoreThreadTimeOut 来决定是否补充新的 Worker 进数组workers &#125; &#125; 2. 配置线程池流程介绍完了先来总结以下上文提到了几个核心参数在流程中的具体作用，然后介绍应该如何配置。 2.1 参数详解 corePoolSize：核心线程数 核心线程会一直存活，即使没有任务需要执行 当线程数小于核心线程数时，即使有线程空闲，线程池也会有限创建新的线程 设置allowCoreThreadTimeout=true（默认是false）时，核心线程会超时关闭 maximumPoolSize：最大线程数 当线程数 &gt;= corePoolSize，且队列已满。线程池会创建新线程来处理 当线程数 = maxmumPoolSize，且队列任务已满是，线程会拒绝处理任务 keepAliveTime：线程空闲时间 当线程空闲时间达到keepAliveTime时，线程会退出，直到线程数量 = corePoolSize 如果allowCoreThreadTimeout = true，则会直到线程数量 = 0 rejectedExecutionHandler：任务拒绝处理器，两种情况会拒绝处理任务： 当线程数已经达到maxmumPoolSize，且队列已满，会拒绝新任务 当线程池被调用shutdown()后，会等待线程池里的任务执行完毕，再shutdown。如果在调用shutdown()和线程池真正shutdown之间提交任务，会拒绝新任务 线程池会调用rejectedExecutionHandler来处理这个任务。如果没有设置默认是AbortPolicy，会抛出异常，ThreadPoolExecutor类有几个内部实现类来处理这类情况： AbortPolicy 丢弃任务，抛运行时异常 CallerRunsPolicy 执行任务，调用Runnable的run强制执行。 DiscardPolicy 忽视，什么都不会发生 DiscardOldestPolicy 如果是因为第一种情况被拒绝，则从阻塞队列中踢出最先进入队列的任务，然后再次提交当前任务。 实现RejectedExecutionHandler接口，可自定义处理器处理reject。 2.2 参数配置默认值：12345corePoolSize=1maxPoolSize=Integer.MAX_VALUEkeepAliveTime=60sallowCoreThreadTimeout=falserejectedExecutionHandler=AbortPolicy() 如何设置，需要根据几个值来决定： tasks ：系统每秒任务数，假设为500~1000 taskcost：单任务耗时，假设为0.1s responsetime：系统允许容忍的最大响应时间，假设为1s 做几个计算：corePoolSize = 系统每秒任务数/单线程每秒任务数 = 系统每秒任务数/（1/单任务耗时）corePoolSize = tasks/(1/taskcost) =taskstaskcout = (500~1000)0.1 = 50~100 。 corePoolSize设置应该大于50，根据8020原则，如果80%的系统每秒任务数小于800，那么corePoolSize设置为80即可 maxPoolSize = （最大任务数-队列容量）/每个线程每秒处理能力 = 最大线程数计算可得 maxPoolSize = (1000-80)/10 = 92队列容量在初始化池的时候指定，一旦指定不能修改 rejectedExecutionHandler：根据具体情况来决定，任务不重要可丢弃，任务重要则要利用一些缓冲机制来处理 keepAliveTime和allowCoreThreadTimeout采用默认通常能满足以上都是理想值，实际情况下要根据机器性能来决定。如果在未达到最大线程数的情况机器cpu load已经满了，则需要通过升级硬件和优化代码，降低taskcost来处理。 2.3 参数动态调整用户可以通过corePoolSize和maxmumPoolSize的getter/setter进行访问和设置，具体怎么设置需要根据当前池中一些状态变量进行判断，如： getLargestPoolSize() 获取到目前为止达到过的最大线程数 getPoolSize() 获取当前线程数 getQueue().size() 获取当前阻塞队列任务数 3. 关闭线程池关闭线程池无非就是两个方法 shutdown()/shutdownNow()。 但他们有着重要的区别： shutdown() 执行后停止接受新任务，会把队列的任务执行完毕。 shutdownNow() 也是停止接受新任务，但会中断所有的任务，将线程池状态变为 stop。 两个方法都会中断线程，用户可自行判断是否需要响应中断。shutdownNow() 要更简单粗暴，可以根据实际场景选择不同的方法。 通常是按照以下方式关闭线程池的：12345678910long start = System.currentTimeMillis();for (int i = 0; i &lt;= 5; i++) &#123; pool.execute(new Job());&#125;pool.shutdown();while (!pool.awaitTermination(1, TimeUnit.SECONDS)) &#123; LOGGER.info(\"线程还在执行。。。\");&#125;long end = System.currentTimeMillis();LOGGER.info(\"一共处理了【&#123;&#125;】\", (end - start)); pool.awaitTermination(1, TimeUnit.SECONDS) 会每隔一秒钟检查一次是否执行完毕（状态为 TERMINATED），当从 while 循环退出时就表明线程池已经完全终止了。","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/categories/并发编程/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/tags/并发编程/"}],"keywords":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/categories/并发编程/"}]},{"title":"并发编程-独占式AQS源码详解","slug":"并发编程-独占式AQS源码详解","date":"2018-03-22T16:00:00.000Z","updated":"2021-01-12T06:06:43.839Z","comments":true,"path":"2018/03/23/并发编程-独占式AQS源码详解/","link":"","permalink":"https://zzkenyon.github.io/2018/03/23/并发编程-独占式AQS源码详解/","excerpt":"","text":"1. 框架概述AQS是AbstractQueuedSynchronizer的简称，抽象队列同步器，AQS定义了一套多线程访问共享资源的同步器框架，许多同步类的实现都依赖于它，比如常用的ReentrantLock/CountDownLatch/Semaphore… AQS维护了一个volatile int state 代表共享资源，一个FIFO线程等待队列用来记录争用资源而进入等待的线程，这里有一点需要强调，AQS同步队列中的线程是处于WAITING状态的，而竞争synchronized同步块的线程是处于BLOCKED状态的。 线程获取AQS框架下的锁先是尝试CAS乐观锁去获取，获取不到才会转换为悲观锁，如线程获取ReentrantLock在CAS阶段是处于RUNNABLE状态的，获取失败进入等待队列才会转换成WAITING状态。 AQS定义了两种组员共享方式：Exclusive 和 Share 用户自定义同步器时只需要实现共享资源state的获取与释放方式，至于具体的线程等待队列的维护，AQS已经实现好了。自定义同步器需要实现的几个方法： isHeldExclusively() 该线程是否正在独占资源，只有用到Condition才需要实现它 tryAcquire(int) 独占方式获取资源，获取成功返回ture tryRelease(int) 独占方式释放资源，释放成功返回ture tryAcquireShared(int) 共享方式获取资源，负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。 tryReleaseShared(int) 共享方式释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。 以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程tryRelease()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会向上累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。 再以CountDownLatch以例，任务分为N个子线程去执行，state也初始化为N（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS减1。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作。 一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。但AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。 2. 源码详解本节依照acquire-release、acquireShared-releaseShared的次序来讲解AQS的源码实现。 2.1 acquire(int)该方法是在独占模式下获取独占资源的顶层入口，如果获取资源成功tryAcquire返回true，该函数直接返回，且整个过程忽略中断的影响；否则调用addWaiter将线程包装成Node对象进入阻塞队列，并不断acquireQueued获取资源。 这里使用模板方法设计模式：acquire定义在抽象类中实现，调用的tryAcquire方法抽象类并没有给出实现逻辑，而是交给子类去实现。 123456// AbstractQueuedSynchronizerpublic final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 函数流程如下： tryAcquire() 尝试直接去获取资源，如果成功acquire()方法直接返回，表示获取资源成功；若失败，则需要进行一系列处理 首先，调用addWaiter() 将该线程加入等待队列的尾部，并标记为独占模式； 然后，调用acquireQueued() 尝试在等待队列中获取资源，一直获取到资源后才返回。如果在整个等待资源的过程中被中断过，则返回true，否则返回false。 如果线程在等待过程中被中断过，它是不响应的（关于中断的介绍请参考文章线程中断），获取资源后通过selfInterrupt()，将该线程的中断标志置为true。 2.1.1 tryAcquire(int)此方法尝试获取独占资源，如果成功返回true，否则返回false。123protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException();&#125; AQS中该方法没有具体的执行逻辑，这是因为这是AQS定义的一个方法模板，具体的实现需要自定义同步类自己完成，能不能重入，竞争资源时可不可以加塞，都需要子类自己设计。如果子类没有实现该方法，就会调用AQS的默认实现，如上直接抛出异常。 2.1.2 addWaiter(Node)此方法作用是将当前线程加入到阻塞队列的队尾，并返回当前线程所在节点。123456789101112131415private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // 尝试快速入队 Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; //快速入队失败，调用enq方法入队 enq(node); return node;&#125; 此处先介绍一下Node，Node节点是对每一个竞争同步代码的线程的封装，主要包含了当前线程对象以及线程的状态。变量waitStatus表示当前Node节点的等待状态，共有4种取值CANCELLED、SIGNAL、CONDITION、PROPAGATE CANCELLED ： 值为1，表示当前节点处于结束状态，在同步队列中等待的线程等待超时或被中断，需要从同步队列中取消该Node节点 SIGNAL 值为-1，表示当前节点线程取消或者释放资源的时候，需要unpark其后继节点 CONDITION 值为-2，表示当前节点处于条件队列，在转变（状态被设为0）之前不会被当做同步队列节点 PROPAGATE 值为-3，与共享模式相关，在共享模式中，该状态标识结点的线程处于可运行状态 0 代表初始状态。 2.1.3 enq(Node)此方法用于将node加入队尾。源码如下：123456789101112131415private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 如果你看过AtomicInteger.getAndIncrement()函数源码，那么相信你一眼便看出这段代码的精华。CAS自旋volatile变量，是一种很常用很经典的用法。 2.1.4 acquireQueued(Node, int)通过tryAcquire()和addWaiter()，该线程获取资源失败，已经被放入等待队列尾部了，下一步该干什么？进入等待状态休息，直到其他线程彻底释放资源后唤醒自己，自己再拿到资源，然后就可以去干自己想干的事了。这个函数非常关键，上源码：1234567891011121314151617181920212223242526272829final boolean acquireQueued(final Node node, int arg) &#123; //获取资源失败了吗？ boolean failed = true; try &#123; //标识等待过程中是否被中断过 boolean interrupted = false; for (;;) &#123; //获得当前节点的前驱 final Node p = node.predecessor(); //如果前驱是head，那就有资格去尝试获取 if (p == head &amp;&amp; tryAcquire(arg)) &#123; //获取资源成功，将自己设置成head setHead(node); //help GC，原头结点断开与队列的链接，等待被回收 p.next = null; failed = false;//表示获取资源成功 return interrupted; &#125; //先判断此次获取失败后可不可以 WAITTING，如果不能，继续重复循环 //执行park让线程进入WAITTING状态，并判断等待过程中有没有中断，发生过就改状态 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 那么怎么判断线程是不是应该执行park()呢？继续看下面代码，shouldParkAfterFailedAcquire方法主要用于检查状态，看看自己是否真的可以去休息了（进入waiting状态），万一排在队列前边的线程都取消了只是瞎站着，那就需要往前加塞。 1234567891011121314151617181920private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; //获取前驱节点的状态 int ws = pred.waitStatus; //如果前驱节点状态是SIGNAL，说明前驱节点释放资源后会通知本节点，可以安全的执行park() if (ws == Node.SIGNAL) return true; if (ws &gt; 0) &#123; //如果前驱节点是取消状态CANCELLED，执行加塞操作，跳过所有取消节点 do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; // waitStatus must be 0 or PROPAGATE // 把前驱节点的状态设置成SIGNAL，前驱节点执行完释放资源就会通知本节点 compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; //返回false表示此次循环不能更改线程状态，返回到acquireQueued方法即系执行循环获取资源 return false;&#125; 整个流程用一句话概括，如果前驱结点的状态不是SIGNAL，那么自己就不能放心去休息，需要去找个安全的休息点，找到安全点后可以再尝试下看能不能获取资源，再次获取失败就可以放心进入WAITTING状态。 parkAndCheckInterrupt方法就是让线程执行park()进入WAITTINGZ状态，并返回该线程的中断标志 1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 注意，Thread.interrupted()方法在获取线程中断标志的同时会将该标志复位为false 2.1.5 小结源码再贴一遍：12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; 获取独占资源流程如下： 调用自定义同步器的tryAcquire()尝试直接去获取资源，如果成功则直接返回； 否则addWaiter()将该线程加入等待队列的尾部； acquireQueued()使线程在等待队列中休息，当前驱节点为head 会去尝试获取资源，获取到资源后将自己设置为head，获取失败寻找安全点等待。注意此处寻找到安全点后不会立即park()，而是在下一次循环尝试获取失败后才会执行park()。如果在整个等待过程中被中断过，则返回true，否则返回false。 如果线程在等待过程中被中断过，它是不响应的，并且中断标志被Thread.interrupted()重置为false了，所以获取资源后才再进行自我中断selfInterrupt()，将中断标志重置为true。 2.2 release(int)release是独占模式下线程释放共享资源的顶层接口。它会释放指定量的资源，如果彻底释放了（即state=0），它会唤醒等待队列里的其他线程来获取资源。源码： 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h);//唤醒后继节点 return true; &#125; return false; &#125; 逻辑并不复杂。它调用tryRelease()来释放资源。有一点需要注意的是，它是根据tryRelease()的返回值来判断该线程是否已经完成释放掉资源了。所以自定义同步器在设计tryRelease()的时候要明确这一点 2.2.1 tryRelease(int)123protected boolean tryRelease(int arg) &#123; throw new UnsupportedOperationException();&#125; 跟tryAcquire()一样，这个方法是需要独占模式的自定义同步器去实现的。正常来说，tryRelease()都会成功的，因为这是独占模式，该线程来释放资源，那么它肯定已经拿到独占资源了，直接减掉相应量的资源即可(state-=arg)，也不需要考虑线程安全的问题。但要注意它的返回值，上面已经提到了，release()是根据tryRelease()的返回值来判断该线程是否已经完成释放掉资源了！所以自义定同步器在实现时，如果已经彻底释放资源(state=0)，要返回true，否则返回false。 2.2.2 unparkSuccessor(Node)此方法用于唤醒等待队列中下一个线程。123456789101112131415161718private void unparkSuccessor(Node node) &#123; //获取当前节点的状态 int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0);//置0 //获取对列中下一个需唤醒的线程节点 Node s = node.next; //若后继节点已取消，找到最靠近head的有效节点 if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) //waitStatus&lt;=0的都是有效节点，都可以唤醒 if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);//唤醒 &#125; 一句话概括，用用unpark()唤醒等待队列中最前边的那个有效线程。 疑问：head的后继节点取消的情况下，要寻找离head最近的有效节点，为什么要从tail开始往前找？？ 3. ReentrantLockReentrantLock自身没有继承AQS，但是它持有一个AQS的子类Sync的对象实例sync，Sync又派生了两个子类 FairSync 和 NonfairSync。ReentrantLock实例化时，无参的默认构造函数会使用NonfairSync对sync进行初始化；而接受一个布尔型变量的构造函数根据用户传入的参数决定使用公平锁还是非公平锁。 公平性是针对锁获取而言的，如果是公平锁，那么锁的获取顺序应该符合请求的绝对时间顺序，也就是FIFO，该原则保证公平的代价是进行大量的线程切换。非公平锁虽然可能造成线程饥饿，但是极少的线程切换保证了其更大的吞吐量，因此ReentrantLock默认实现非公平锁。 3.1 获取锁下面代码是非公平锁和公平锁分别获取资源的操作：1234567891011121314151617181920final boolean nonfairTryAcquire(int acquires) &#123; //获取当前线程对象 final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123;//如果资源空闲，CAS设置状态量 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; //如果资源被占用，判断持有锁的线程是不是本线程，是的话重入 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false;&#125; 重入锁的意义就是持有锁的线程可以多次重复进入临界区，而不需要在同步队列中等待，每次进入状态量加1，进入几次就要释放几次，释放1次状态量减1，当状态量为0时，完全释放资源。 1234567891011121314151617181920protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; //注意与非公平锁的区别 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false;&#125; 比较以上两个获取资源的函数，发现唯一的区别在于公平锁在设置状态量之前多做了一次判断 !hasQueuedPredecessors()，该函数返回是否有线程排在当前线程前面，如果没有则可以获得锁。hasQueuedPredecessors源码如下123456789public final boolean hasQueuedPredecessors() &#123; Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; //队列中不止一个线程 //并且第二个线程节点为空或者第二个节点不是是自己 return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread()); &#125; 3.2 释放锁释放操作没有公平与非公平之分，所以释放操作是在父类Sync中实现，下面看源码： 1234567891011121314protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; //如果当前线程不是占用线程，抛异常 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; //状态量等于0，才是真正释放 if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 因为释放锁之前，当前线程还持有锁，其他线程无权访问，所以修改状态没有用CAS，直接使用setState 共享式同步器 请看下一篇 并发编程-共享式AQS源码详解","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/categories/并发编程/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/tags/并发编程/"}],"keywords":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/categories/并发编程/"}]},{"title":"Mybatis-批量操作","slug":"数据库技术-Mybatis-批量操作数据库","date":"2018-03-21T02:01:21.000Z","updated":"2020-05-22T11:54:37.190Z","comments":true,"path":"2018/03/21/数据库技术-Mybatis-批量操作数据库/","link":"","permalink":"https://zzkenyon.github.io/2018/03/21/数据库技术-Mybatis-批量操作数据库/","excerpt":"","text":"批量插入12345678910111213@Insert(\"&lt;script&gt;\" + \"INSERT INTO patent_post_info(patent_id,post_time,post_information) values \"+ \"&lt;foreach collection =\\\"postInfos\\\" item=\\\"postInfo\\\" index= \\\"index\\\" separator =\\\",\\\"&gt;\" + \"(\"+ \"#&#123;patentId&#125;, \" + \"CAST (#&#123;postInfo.postTime&#125; AS timestamp),\"+ \"#&#123;postInfo.postInformation&#125;\"+ \")\" + \"&lt;/foreach &gt;\"+ \"&lt;/script&gt;\" ) Integer insertPatentPostInfo(@Param(\"patentId\")Integer id, @Param(\"postInfos\")List&lt;PatentPostInfo&gt; postInfos) throws SQLException; 批量更新以下示例展示了更新两个字段，每一个字段使用一个片段1234567891011121314151617@Update(\"&lt;script&gt;\"+ \"UPDATE order_items \" + \"SET \" + \"goods_total_price=\" + \"&lt;foreach collection=\\\"orderItems\\\" item=\\\"orderItem\\\"index=\\\"index\\\" separator=\\\" \\\" open=\\\"CASE id\\\" close=\\\"END\\\"&gt;\" + \"WHEN #&#123;orderItem.id&#125; THEN #&#123;orderItem.goodsTotalPrice&#125;\" + \"&lt;/foreach&gt;\" + \",goods_name=\"+ \"&lt;foreach collection=\\\"list\\\" item=\\\"orderItem\\\" index=\\\"index\\\" separator=\\\" \\\" open=\\\"CASE id\\\" close=\\\"END\\\"&gt;\" + \"WHEN #&#123;orderItem.id&#125; THEN #&#123;orderItem.goodsName&#125;\" + \"&lt;/foreach&gt;\" + \"WHERE id IN \" + \"&lt;foreach collection=\\\"list\\\" item=\\\"orderItem\\\" index=\\\"index\\\" separator=\\\",\\\" open=\\\"(\\\" close=\\\")\\\"&gt;\" + \"#&#123;orderItem.id&#125;\"+ \"&lt;/foreach&gt;\" + \"&lt;/script&gt;\") Integer bathUpdateOrderItem(@Param(\"orderItems\")List&lt;OrderItemCustom&gt; orderItems) throws SQLException; 批量删除使用数组接受参数12345678@Delete(\"&lt;script&gt;\" + \"DELETE FROM order_items WHERE id IN\" + \"&lt;foreach collection=\\\"ids\\\" item=\\\"itemId\\\" index=\\\"index\\\" separator=\\\",\\\" open=\\\"(\\\" close=\\\")\\\"&gt;\"+ \"#&#123;itemId&#125;\" + \"&lt;/foreach&gt;\"+ \"&lt;/script&gt;\" ) Integer bathdeleteOrderItem(@Param(\"ids\") Integer[] itemIds)throws SQLException; controller中使用 @RequestParam 注解修饰数组，请求时将参数拼接到url后面（类似Get请求）","categories":[{"name":"ORM框架","slug":"ORM框架","permalink":"https://zzkenyon.github.io/categories/ORM框架/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://zzkenyon.github.io/tags/Mybatis/"}],"keywords":[{"name":"ORM框架","slug":"ORM框架","permalink":"https://zzkenyon.github.io/categories/ORM框架/"}]},{"title":"SpringBoot-跟踪启动过程","slug":"SpringBoot-跟踪启动过程","date":"2018-03-20T16:00:00.000Z","updated":"2020-05-28T11:23:46.481Z","comments":true,"path":"2018/03/21/SpringBoot-跟踪启动过程/","link":"","permalink":"https://zzkenyon.github.io/2018/03/21/SpringBoot-跟踪启动过程/","excerpt":"","text":"本文基于spring-boot版本2.1.4.RELEASE首先使用spring-boot-starter-web构建一个web项目，编写代码如下： 12345678910111213@SpringBootApplicationpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125;@RestControllerpublic class RootController &#123; @GetMapping(\"/\") public String welcome() &#123; return \"Hello world!\"; &#125;&#125; 入口程序执行的方法SpringApplication.run(Application.class, args)是SpringApplication类的静态run方法123456789代码摘自：org.springframework.boot.SpringApplicationpublic static ConfigurableApplicationContext run(Object source, String... args) &#123; return run(new Object[] &#123; source &#125;, args);&#125;public static ConfigurableApplicationContext run(Object[] sources, String[] args) &#123; return new SpringApplication(sources).run(args);&#125; 第一个静态run函数实际上是将单个的source构造成数组，然后调用了第二个静态run函数。第二个函数创建了SpringApplication对象，并调用该对象的非静态run函数（有三个run函数） 因此，我们也可以将前面程序主类的启动过程修改为： 123456public class SBApplication &#123; public static void main(String args[]) throws Exception&#123; SpringApplication sa = new SpringApplication(SBConfiguration.class); sa.run(args); &#125;&#125; 如此一来，我们可以使用到SpringApplication提供的一系列实例方法对其进行配置。从上面代码看，应用的启动过程分为两部分：首先创建一个SpringApplication对象；然后执行其对象方法run。构造函数中实际业务逻辑都放在了initialize方法中。下面我们分别分析这两部分都干了什么。 1. 创建SpringApplication对象123456789101112131415代码摘自：org.springframework.boot.SpringApplicationpublic SpringApplication(Class&lt;?&gt;... primarySources) &#123; this(null, primarySources);&#125;public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123; this.resourceLoader = resourceLoader; Assert.notNull(primarySources, \"PrimarySources must not be null\"); this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources));//1 this.webApplicationType = WebApplicationType.deduceFromClasspath();//2 setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class));//3 setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class));//4 this.mainApplicationClass = deduceMainApplicationClass();//5&#125; 将Application类当做主配置类传给第一个构造函数，然后调用第二个构造函数，ResourceLoader默认值为null。 构造过程如下： 将传进来的配置类参数set进this.primarySources，该参数代表了SpringBoot启动时指定的Configuration类（可多个）。 设置this.webApplicationType，改参数表示此应用是Servlet或Reactive或者是None 设置Initializers 设置Listeners 设置this.mainApplicationClass，改参数记录了入口类的类对象实例。 1.1 webApplicationType通过判断当前是否含有：12345678910111213141516代码摘自：org.springframework.boot.WebApplicationTypestatic WebApplicationType deduceFromClasspath() &#123; if (ClassUtils.isPresent(WEBFLUX_INDICATOR_CLASS, null) &amp;&amp; !ClassUtils.isPresent(WEBMVC_INDICATOR_CLASS, null) &amp;&amp; !ClassUtils.isPresent(JERSEY_INDICATOR_CLASS, null)) &#123; return WebApplicationType.REACTIVE; &#125; for (String className : SERVLET_INDICATOR_CLASSES) &#123; if (!ClassUtils.isPresent(className, null)) &#123; return WebApplicationType.NONE; &#125; &#125; return WebApplicationType.SERVLET;&#125;ClassUtils.isPresent(String className, @Nullable ClassLoader classLoader)//判断当前类路径上是否存在className表示的类 WebApplicationType是一个枚举类型，有三种类型的常量：SERVLET、REACTIVE和NONE枚举类型内部通过判断类路径上存在哪些类型从而判断应用属于那种类型，具体可看源码，简明易懂 1.2 初始化initializer和listener通过两个函数getSpringFactoriesInstances(ApplicationContextInitializer.class)、getSpringFactoriesInstances(ApplicationListener.class)得到以SpringFactoriesLoader扩展方案注册的ApplicationContextInitializer和ApplicationListener类型的实例，并设置到当前SpringApplication的对象中。在这两个函数都调用了： 1234567891011private &lt;T&gt; Collection&lt;? extends T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) &#123; ClassLoader classLoader = Thread.currentThread().getContextClassLoader(); // Use names and ensure unique to protect against duplicates Set&lt;String&gt; names = new LinkedHashSet&lt;String&gt;( SpringFactoriesLoader.loadFactoryNames(type, classLoader)); List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); AnnotationAwareOrderComparator.sort(instances); return instances;&#125; 可以看到，该方法首先调用SpringFactoriesLoader.loadFactoryNames(type, classLoader))方法获取type类型的组件的名称，再调用createSpringFactoriesInstances方法根据读取到的类名创建对象，最后将所有创建好的对象排序并返回。 从loadFactoryNames方法中看出是从一个名字叫spring.factories的资源文件中读取的类名，spring.factories的部分内容如下：123456789101112131415161718代码摘自：spring-boot-2.1.4.RELEASE.jar!/META-INF/spring.factories:10# Application Context Initializersorg.springframework.context.ApplicationContextInitializer=\\org.springframework.boot.context.ConfigurationWarningsApplicationContextInitializer,\\org.springframework.boot.context.ContextIdApplicationContextInitializer,\\org.springframework.boot.context.config.DelegatingApplicationContextInitializer,\\org.springframework.boot.web.context.ServerPortInfoApplicationContextInitializer# Application Listenersorg.springframework.context.ApplicationListener=\\org.springframework.boot.ClearCachesApplicationListener,\\org.springframework.boot.builder.ParentContextCloserApplicationListener,\\org.springframework.boot.context.FileEncodingApplicationListener,\\org.springframework.boot.context.config.AnsiOutputApplicationListener,\\org.springframework.boot.context.config.ConfigFileApplicationListener,\\org.springframework.boot.context.config.DelegatingApplicationListener,\\org.springframework.boot.context.logging.ClasspathLoggingApplicationListener,\\org.springframework.boot.context.logging.LoggingApplicationListener,\\org.springframework.boot.liquibase.LiquibaseServiceLocatorApplicationListener 所以在我们的例子中，SpringApplication对象的成员变量initalizers就被初始化为，ConfigurationWarningsApplicationContextInitializer，ContextIdApplicationContextInitializer，DelegatingApplicationContextInitializer，ServerPortInfoApplicationContextInitializer这四个类的对象组成的list。 下图画出了加载的ApplicationContextInitializer，并说明了他们的作用，后文将分析何时应用他们。listener最终会被初始化为ClearCachesApplicationListener，ParentContextCloserApplicationListener，FileEncodingApplicationListener，AnsiOutputApplicationListener，ConfigFileApplicationListener，DelegatingApplicationListener，LiquibaseServiceLocatorApplicationListener，ClasspathLoggingApplicationListener，LoggingApplicationListener这几个类的对象组成的list。 下图画出了加载的ApplicationListener，并说明了他们的作用后文将解释何时使用他们。 1.3 设置mainApplicationClass1234567891011121314private Class&lt;?&gt; deduceMainApplicationClass() &#123; try &#123; StackTraceElement[] stackTrace = new RuntimeException().getStackTrace(); for (StackTraceElement stackTraceElement : stackTrace) &#123; if (\"main\".equals(stackTraceElement.getMethodName())) &#123; return Class.forName(stackTraceElement.getClassName()); &#125; &#125; &#125; catch (ClassNotFoundException ex) &#123; // Swallow and continue &#125; return null;&#125; 通过new RuntimeException().getStackTrace()获取运行时方法栈，遍历栈找到main方法，继而找到main方法所在的类对象。 2. 实际启动过程runSpringApplication将SpringBoot应用启动流程模板化，并在启动过程的不同时机定义了一系列不同类型的的扩展点，方便我们对其进行定制。下面对整个启动过程代码进行分析： 1234567891011121314151617181920212223242526272829303132333435363738//代码引用自org.springframework.boot.SpringApplicationpublic ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); configureHeadlessProperty(); SpringApplicationRunListeners listeners = getRunListeners(args);//1 listeners.starting(); try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments(args);//2 ConfigurableEnvironment environment = prepareEnvironment(listeners,applicationArguments);//3 configureIgnoreBeanInfo(environment); Banner printedBanner = printBanner(environment); context = createApplicationContext();//4 exceptionReporters = getSpringFactoriesInstances(//5 SpringBootExceptionReporter.class, new Class[] &#123; ConfigurableApplicationContext.class &#125;, context); prepareContext(context, environment, listeners, applicationArguments,printedBanner);//6 refreshContext(context);//7 afterRefresh(context, applicationArguments);//8 ... listeners.started(context);//9 callRunners(context, applicationArguments); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, listeners);//10 throw new IllegalStateException(ex); &#125; try &#123; listeners.running(context); &#125; catch (Throwable ex) &#123; ... &#125; return context;&#125; 可变个数参数args即是我们整个应用程序的入口main方法的参数，在本文的例子中，参数个数为零。 StopWatch是来自org.springframework.util的工具类，可以用来方便的记录程序的运行时间。 设置Headless实际上是就是设置系统属性java.awt.headless，在我们的例子中该属性会被设置为true，因为我们开发的是服务器程序，一般运行在没有显示器和键盘的环境。 2.1 配置运行监听器12SpringApplicationRunListeners listeners = getRunListeners(args);//1listeners.starting(); 1234摘自资源文件META-INF/spring.factories# Run Listenersorg.springframework.boot.SpringApplicationRunListener=\\org.springframework.boot.context.event.EventPublishingRunListener 通过SpringFactoriesLoader来获取定义在spring.factories中的SpringApplicationRunListener，SpringBoot框架默认只定义了一个EventPublishingRunListener，其中维护了一个SimpleApplicationEventMulticaster，并将上节初始化的ApplicationListener实例注册进去。然后调用其starting()方法，给所有的SpringApplicationRunListener发送一个start事件，然后EventPublishingRunListener给注册在其中的所有ApplicationListener发送ApplicationStartedEvent。 此处包含了两个扩展点: 可以自定义SpringApplicationRunListener以扩展SpringBoot程序启动过程。 可以自定义ApplicationListener以扩展EventPublishingRunListener。 在启动的不同阶段，会发送不同的事件给SpringApplicationRunListeners，listeners通知相应的ApplicationListeners处理事件。 1listeners.starting(); LoggingApplicationListener响应此事件，会根据classpath中的类情况创建相应的日志系统对象，并执行一些初始化之前的操作；123456789101112@Overridepublic void onApplicationEvent(ApplicationEvent event) &#123; if (event instanceof ApplicationStartedEvent) &#123; onApplicationStartedEvent((ApplicationStartedEvent) event); &#125; ...&#125;private void onApplicationStartedEvent(ApplicationStartedEvent event) &#123; this.loggingSystem = LoggingSystem .get(event.getSpringApplication().getClassLoader()); this.loggingSystem.beforeInitialize();&#125; 本文例子中，创建的是org.springframework.boot.logging.logback.LogbackLoggingSystem类的对象，Logback是SpringBoot默认采用的日志系统。 LiquibaseServiceLocatorApplicationListener响应此事件，会检查classpath中是否有liquibase.servicelocator.ServiceLocator并做相应操作，本文的例子中classpath中不存在liquibase，所以不执行任何操作。1234567@Overridepublic void onApplicationEvent(ApplicationStartingEvent event) &#123; if (ClassUtils.isPresent(\"liquibase.servicelocator.CustomResolverServiceLocator\", event.getSpringApplication().getClassLoader())) &#123; new LiquibasePresent().replaceServiceLocator(); &#125;&#125; 2.2 包装参数1ApplicationArguments applicationArguments = new DefaultApplicationArguments(args);//2 将参数包装为ApplicationArguments，DefaultApplicationArguments是用来维护命令行参数的，例如可以方便的将命令行参数中的options和non options区分开，以及获得某option的值等。 DefaultApplicationArguments将String[] args中的参数解析包装成 Source类型，Source类的继承关系如下： 123public class SimpleCommandLinePropertySource extends CommandLinePropertySource&lt;CommandLineArgs&gt;private static class Source extends SimpleCommandLinePropertySource &#123;&#125; 这里的关键是泛型类型变量CommandLineArgs，这个类型中的两个成员变量： 12private final Map&lt;String, List&lt;String&gt;&gt; optionArgs = new HashMap&lt;&gt;();private final List&lt;String&gt; nonOptionArgs = new ArrayList&lt;&gt;(); 就是用来存放从args中解析出来的optionArgs和nonOptionArgs。 2.3 准备应用环境1ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments);//3 通过ApplicationArguments来准备应用环境Environment， Environment包含了两个层面的信息：属性（properties）和轮廓（profiles）。 profiles用来描述哪些bean definition是可用的， properties用来描述系统的配置，其来源可能是配置文件、jvm属性文件、操作系统环境变量等等。 配置属性源（propertySource），关于Environment中的属性来源分散在启动的若干个阶段，并且按照特定的优先级顺序，也就是说一个属性值可以在不同的地方配置，但是优先级高的值会覆盖优先级低的值。 配置轮廓（profile）可以认为是程序的运行环境，典型的环境比如有开发环境（Develop）、生产环境（Production）、测试环境（Test）等等。我们可以定义某个Bean在特定的环境中才生效，这样就可以通过指定profile来方便的切换运行环境。可通过SpringApplication.setAdditionalProfiles()来设置轮廓，environment内通过activeProfiles来维护生效的轮廓（可不止一个）。prepareEnvironment方法的代码如下：123456789101112private ConfigurableEnvironment prepareEnvironment(SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments) &#123; // Create and configure the environment ConfigurableEnvironment environment = getOrCreateEnvironment(); configureEnvironment(environment, applicationArguments.getSourceArgs()); listeners.environmentPrepared(environment); if (!this.webEnvironment) &#123; environment = new EnvironmentConverter(getClassLoader()) .convertToStandardEnvironmentIfNecessary(environment); &#125; return environment;&#125; 在getOrCreateEnvironment()方法中通过上节初始化的webApplicationType判断是否为web应用创建一个StandardServletEnvironment或StandardEnvironment。 接着执行configureEnvironment函数：123456789101112131415161718192021222324252627282930313233343536373839404142以下代码摘自：org.springframework.boot.SpringApplicationprivate Map&lt;String, Object&gt; defaultProperties;private boolean addCommandLineProperties = true;private Set&lt;String&gt; additionalProfiles = new HashSet&lt;String&gt;();protected void configureEnvironment(ConfigurableEnvironment environment,String[] args) &#123; ... configurePropertySources(environment, args); configureProfiles(environment, args);&#125;protected void configurePropertySources(ConfigurableEnvironment environment, String[] args) &#123; MutablePropertySources sources = environment.getPropertySources(); if (this.defaultProperties != null &amp;&amp; !this.defaultProperties.isEmpty()) &#123; sources.addLast( new MapPropertySource(\"defaultProperties\", this.defaultProperties)); &#125; if (this.addCommandLineProperties &amp;&amp; args.length &gt; 0) &#123; String name = CommandLinePropertySource.COMMAND_LINE_PROPERTY_SOURCE_NAME; if (sources.contains(name)) &#123; PropertySource&lt;?&gt; source = sources.get(name); CompositePropertySource composite = new CompositePropertySource(name); composite.addPropertySource(new SimpleCommandLinePropertySource( \"springApplicationCommandLineArgs\", args)); composite.addPropertySource(source); sources.replace(name, composite); &#125; else &#123; sources.addFirst(new SimpleCommandLinePropertySource(args)); &#125; &#125;&#125;protected void configureProfiles(ConfigurableEnvironment environment, String[] args) &#123; environment.getActiveProfiles(); // ensure they are initialized // But these ones should go first (last wins in a property key clash) Set&lt;String&gt; profiles = new LinkedHashSet&lt;String&gt;(this.additionalProfiles); profiles.addAll(Arrays.asList(environment.getActiveProfiles())); environment.setActiveProfiles(profiles.toArray(new String[profiles.size()]));&#125; configurePropertySources首先查看SpringApplication对象的成员变量defaultProperties，如果该变量非null且内容非空，则将其加入到Environment的PropertySource列表的最后。然后查看SpringApplication对象的成员变量addCommandLineProperties和main函数的参数args，如果设置了addCommandLineProperties=true，且args个数大于0，那么就构造一个由main函数的参数组成的PropertySource放到Environment的PropertySource列表的最前面(这就能保证，我们通过main函数的参数来做的配置是最优先的，可以覆盖其他配置）。在我们的例子中，由于没有配置defaultProperties且main函数的参数args个数为0，所以这个函数什么也不做。 configureProfiles首先会读取Properties中key为spring.profiles.active的配置项，配置到Environment，然后再将SpringApplication对象的成员变量additionalProfiles加入到Environment的active profiles配置中。在我们的例子中，配置文件里没有spring.profiles.active的配置项，而SpringApplication对象的成员变量additionalProfiles也是一个空的集合，所以这个函数没有配置任何active profile。 在环境配置完毕后，执行所有SpringApplicationRunListeners的environmentPrepared函数，然后EventPublishingRunListener给所有注册其中的ApplicationListeners发送一个“环境准备好了”ApplicationEnvironmentPreparedEvent事件：1listeners.environmentPrepared(environment); FileEncodingApplicationListener响应该事件，检查file.encoding配置是否与spring.mandatory_file_encoding一致，在本文的例子中，因为没有spring.mandatory_file_encoding的配置，所以这个响应方法什么都不做。 AnsiOutputApplicationListener响应该事件，根据spring.output.ansi.enabled和spring.output.ansi.console-available对AnsiOutput类做相应配置，本文的例子中，这两项配置都是空的，所以这个响应方法什么都不做。 ConfigFileApplicationListener加载该事件，从一些约定的位置加载一些配置文件，而且这些位置是可配置的。 DelegatingApplicationListener响应该事件，将配置文件中key为context.listener.classes的配置项，加载在成员变量multicaster中 LoggingApplicationListener响应该事件，并对在ApplicationStarted时加载的LoggingSystem做一些初始化工作 2.4 创建ApplicationContext关于ApplicationContext：ApplicationContext用于扩展BeanFactory中的功能，ApplicationContext拥有BeanFactory对于Bean的管理维护的所有功能，并且提供了更多的扩展功能，实际上ApplicationContext的实现在内部持有一个BeanFactory的实现来完成BeanFactory的工作。AbstractApplicationContext是ApplicationContext的第一个抽象实现类，其中使用模板方法模式定义了springcontext的核心扩展流程refresh，并提供几个抽象函数供具体子类去实现。其直接子类有AbstractRefreshableApplicationContext和GenericApplicationContext两种。 这两个子类的不同之处在于对内部的DefaultListableBeanFactory的管理：AbstractRefreshableApplicationContext允许多次调用其refreshBeanFactory()函数，每次调用时都会重新创建一个DefaultListableBeanFactory，并将已有的销毁；而GenericApplicationContext不允许刷新beanFactory,只能调用refreshBeanFactory()一次，当多次调用时会抛出异常。 无论AnnotationConfigApplicationContext还是AnnotationConfigServletWebServerApplicationContext，它们都是GenericApplicationContext的子类。因此其内部持有的BeanFactory是不可刷新的，并且从初始化开始就一直持有一个唯一的BeanFactory。 1context = createApplicationContext();//4 根据前面判断的是web应用还是普通应用决定创建什么类型的ApplicationContext，createApplicationContext方法代码如下：123456789101112131415161718192021222324252627282930313233public static final String DEFAULT_SERVLET_WEB_CONTEXT_CLASS = \"org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext\";public static final String DEFAULT_REACTIVE_WEB_CONTEXT_CLASS = \"org.springframework.boot.web.reactive.context.AnnotationConfigReactiveWebServerApplicationContext\";public static final String DEFAULT_CONTEXT_CLASS = \"org.springframework.context.annotation.AnnotationConfigApplicationContext\";protected ConfigurableApplicationContext createApplicationContext() &#123; Class&lt;?&gt; contextClass = this.applicationContextClass; if (contextClass == null) &#123; try &#123; switch (this.webApplicationType) &#123; case SERVLET: contextClass = Class.forName(DEFAULT_SERVLET_WEB_CONTEXT_CLASS); break; case REACTIVE: contextClass = Class.forName(DEFAULT_REACTIVE_WEB_CONTEXT_CLASS); break; default: contextClass = Class.forName(DEFAULT_CONTEXT_CLASS); &#125; &#125; catch (ClassNotFoundException ex) &#123; throw new IllegalStateException( \"Unable create a default ApplicationContext, \" + \"please specify an ApplicationContextClass\", ex); &#125; &#125; return (ConfigurableApplicationContext) BeanUtils.instantiateClass(contextClass); &#125;&#125; 2.5 代码5-配置异常分析器借助SpringFactoriesLoader获得spring.factories中注册的FailureAnalyzers以供当运行过程中出现异常时进行分析： 123exceptionReporters = getSpringFactoriesInstances( SpringBootExceptionReporter.class, new Class[] &#123; ConfigurableApplicationContext.class &#125;, context); 2.6 代码6-准备context接着就是SpringBoot启动过程中的最核心流程，对第4步创建的ApplicationContext进行准备： 1prepareContext(context, environment, listeners, applicationArguments,printedBanner); 详细内容见下节。 2.7 代码7调用ApplicationContext的refresh函数，开启spring context的核心流程，就是根据配置加载bean（spring beans核心功能）以及在各个时机开放的不同扩展机制（spring context）： 1refreshContext(context); 详细内容见下节。 2.8 代码8获取所有的ApplicationRunner和CommandLineRunner并执行：1afterRefresh(context, applicationArguments); 此时由于context已经refresh完毕，因此bean都已经加载完毕了。所以这两个类型的runner都是直接从context中获取的： 123456789101112131415161718protected void afterRefresh(ConfigurableApplicationContext context,ApplicationArguments args) &#123; callRunners(context, args);&#125;private void callRunners(ApplicationContext context, ApplicationArguments args) &#123; List&lt;Object&gt; runners = new ArrayList&lt;Object&gt;(); runners.addAll(context.getBeansOfType(ApplicationRunner.class).values()); runners.addAll(context.getBeansOfType(CommandLineRunner.class).values()); AnnotationAwareOrderComparator.sort(runners); for (Object runner : new LinkedHashSet&lt;Object&gt;(runners)) &#123; if (runner instanceof ApplicationRunner) &#123; callRunner((ApplicationRunner) runner, args); &#125; if (runner instanceof CommandLineRunner) &#123; callRunner((CommandLineRunner) runner, args); &#125; &#125;&#125; 两者的执行时机是完全一样的，唯一的区别在于一个接受ApplicationArguments，一个接受String[]类型的原始命令行参数。而ApplicationArguments也只是对原始命令行参数的一个封装，因此本质上是一样的。此处又定义了两个扩展机制，我们可以自定义ApplicationRunner或CommandLineRunner并将其配置为Bean，便可以在context refresh完毕后执行。 2.9 代码9spring-context refresh过程完毕后执行所有SpringApplicationRunListeners的finished函数，然后EventPublishingRunListener给所有注册其中的ApplicationListeners发送一个“应用启动完毕”ApplicationReadyEvent事件：1listeners.finished(context, null); 2.10 代码10-异常处理当运行时出现异常时，向context发送退出码事件ExitCodeEvent，供其内部listener执行退出前的操作；并使用前面第5步获得的analyzers来打印可能的原因：1handleRunFailure(context, listeners, analyzers, ex); 另外，就算运行异常，也会向SpringApplication中的listeners发送“应用启动完毕”的事件，代码如下：1234567891011121314151617181920private void handleRunFailure(ConfigurableApplicationContext context, SpringApplicationRunListeners listeners, FailureAnalyzers analyzers, Throwable exception) &#123; try &#123; try &#123; handleExitCode(context, exception); listeners.finished(context, exception); &#125; finally &#123; reportFailure(analyzers, exception); if (context != null) &#123; context.close(); &#125; &#125; &#125; catch (Exception ex) &#123; logger.warn(\"Unable to close ApplicationContext\", ex); &#125; ReflectionUtils.rethrowRuntimeException(exception);&#125; 此时，EventPublishingRunListener发送给注册其中的ApplicationListeners的事件成了“应用启动异常”ApplicationFailedEvent。 至此，SpringApplication的run函数，也就是SpringBoot应用的启动过程就执行完毕了。可以看出，SpringBoot的启动过程是对Spring context启动过程的扩展，在其中定义了若干的扩展点并提供了不同的扩展机制。并提供了默认配置，我们可以什么都不配，也可以进行功能非常强大的配置和扩展。这也正是SpringBoot的优势所在。 3 核心过程prepareContext顾名思义，该函数的功能就是对前面创建的ApplicationContext进行准备，其执行步骤如下： 3.1 将environment设置到context中1context.setEnvironment(environment); environment是我们在run过程的第3步创建的。 3.2对ApplicationContext应用相关的后处理，子类可以重写该方法来添加任意的后处理功能： 1postProcessApplicationContext(context); 该方法代码如下： 1234567891011121314151617protected void postProcessApplicationContext(ConfigurableApplicationContext context) &#123; if (this.beanNameGenerator != null) &#123; context.getBeanFactory().registerSingleton( AnnotationConfigUtils.CONFIGURATION_BEAN_NAME_GENERATOR, this.beanNameGenerator); &#125; if (this.resourceLoader != null) &#123; if (context instanceof GenericApplicationContext) &#123; ((GenericApplicationContext) context) .setResourceLoader(this.resourceLoader); &#125; if (context instanceof DefaultResourceLoader) &#123; ((DefaultResourceLoader) context) .setClassLoader(this.resourceLoader.getClassLoader()); &#125; &#125;&#125; 如果SpringApplication设置了beanNameGenerator，则将其注册为singleton类型的bean，并命名为： org.springframework.context.annotation.internalConfigurationBeanNameGenerator 另外，若SpringApplication设置了resourceLoader，则设置进context中。 3.3 使用Initializer修改context对initialize阶段得到的通过spring.factories注册进来的所有ApplicationContextInitializer，逐个执行其initialize方法来修改context，并在执行之前对其进行校验： 12345678protected void applyInitializers(ConfigurableApplicationContext context) &#123; for (ApplicationContextInitializer initializer : getInitializers()) &#123; Class&lt;?&gt; requiredType = GenericTypeResolver.resolveTypeArgument( initializer.getClass(), ApplicationContextInitializer.class); Assert.isInstanceOf(requiredType, context, \"Unable to call initializer.\"); initializer.initialize(context); &#125;&#125; 此处定义了一个扩展点，可以自定义并通过spring.factories注册ApplicationContextInitializer，这些ApplicationContextInitializer可在ApplicationContext准备完毕后对其进行维护修改，例如可以改变其定义的activeProfiles以改变应用环境。 3.4 发布contextPrepared事件执行所有SpringApplicationRunListeners的contextPrepared函数，注意EventPublishingRunListener并没有给所有注册其中的ApplicationListeners发送对应的事件： 1listeners.contextPrepared(context); 此时的listeners可以获得context作为参数，从而对context进行修改。 3.5 注册applicationArguments和printBanner将applicationArguments注册进context.getBeanFactory()中，名字为”SpringApplicationArguments”、若printBanner不为空，将printBanner注册到context.getBeanFactory()中，名字为”SpringBootBanner”： 12345context.getBeanFactory().registerSingleton(\"springApplicationArguments\", applicationArguments); if (printedBanner != null) &#123; context.getBeanFactory().registerSingleton(\"springBootBanner\", printedBanner); &#125; 3.6 通过sources加载配置类得到所有的sources（可通过SpringApplication的run函数、构造函数和setSources函数指定，代表了一个或多个Configuration类），然后执行load(context, sources)函数： 123Set&lt;Object&gt; sources = getSources();Assert.notEmpty(sources, \"Sources must not be empty\");load(context, sources.toArray(new Object[sources.size()])); load函数中会创建一个BeanDefinitionLoader并设置其beanNameGenerator, resourceLoader, environment等属性，然后委托其执行具体的load动作，代码如下： 123456789101112131415161718protected void load(ApplicationContext context, Object[] sources) &#123; if (logger.isDebugEnabled()) &#123; logger.debug( \"Loading source \" + StringUtils.arrayToCommaDelimitedString(sources)); &#125; BeanDefinitionLoader loader = createBeanDefinitionLoader( getBeanDefinitionRegistry(context), sources); if (this.beanNameGenerator != null) &#123; loader.setBeanNameGenerator(this.beanNameGenerator); &#125; if (this.resourceLoader != null) &#123; loader.setResourceLoader(this.resourceLoader); &#125; if (this.environment != null) &#123; loader.setEnvironment(this.environment); &#125; loader.load();&#125; 其中对于每一个source根据其类型不同执行不同的load逻辑：class, Resource, Package, CharSequence等。将解析出来的所有bean的BeanDefinition注册到BeanDefinitionRegistry中（注意，只是source本身，并不包括其内部定义的@Bean方法）： 1234567891011121314151617181920212223public int load() &#123; int count = 0; for (Object source : this.sources) &#123; count += load(source); &#125; return count;&#125;private int load(Object source) &#123; Assert.notNull(source, \"Source must not be null\"); if (source instanceof Class&lt;?&gt;) &#123; return load((Class&lt;?&gt;) source); &#125; if (source instanceof Resource) &#123; return load((Resource) source); &#125; if (source instanceof Package) &#123; return load((Package) source); &#125; if (source instanceof CharSequence) &#123; return load((CharSequence) source); &#125; throw new IllegalArgumentException(\"Invalid source type \" + source.getClass());&#125; 由于我们的source是class类，所以load某一个具体source的行为是委托给了AnnotatedBeanDefinitionReader的register方法： 12345public void register(Class&lt;?&gt;... annotatedClasses) &#123; for (Class&lt;?&gt; annotatedClass : annotatedClasses) &#123; registerBean(annotatedClass); &#125;&#125; 此处已是spring context的功能了，将通过注释定义的Configuration类的BeanDefinition注册到BeanDefinitionRegistry中。（此时尚不解析Configuration类内部定义的@Bean方法） 3.7 发布context加载完毕事件执行所有SpringApplicationRunListeners的contextLoaded函数，然后EventPublishingRunListener给所有注册其中的ApplicationListeners发送一个“应用上下文准备完毕”ApplicationPreparedEvent事件，另外还将所有注册在自身的ApplicationListener注册到context之中： listeners.contextLoaded(context); 其中调用到EventPublishingRunListener的contextLoaded函数: 12345678910public void contextLoaded(ConfigurableApplicationContext context) &#123; for (ApplicationListener&lt;?&gt; listener : this.application.getListeners()) &#123; if (listener instanceof ApplicationContextAware) &#123; ((ApplicationContextAware) listener).setApplicationContext(context); &#125; context.addApplicationListener(listener); &#125; this.initialMulticaster.multicastEvent( new ApplicationPreparedEvent(this.application, this.args, context));&#125;","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/tags/SpringBoot/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/categories/SpringBoot/"}]},{"title":"并发编程-锁","slug":"并发编程-锁","date":"2018-03-19T16:00:00.000Z","updated":"2021-01-11T11:38:29.763Z","comments":true,"path":"2018/03/20/并发编程-锁/","link":"","permalink":"https://zzkenyon.github.io/2018/03/20/并发编程-锁/","excerpt":"","text":"1 基础知识1.1 锁的宏观分类锁从宏观上分类，可以分为悲观锁与乐观锁。 乐观锁是一种乐观思想，认为读多写少，遇到并发写的可能性低。每次读数据的时候，都认为别的线程没有修改过数据，所以不会上锁；但是写数据的时候会判断一下其他线程有没有更新过该数据。java中的乐观锁基本上都是使用CAS实现的。 悲观锁就是一种悲观思想，认为写多读少，遇到并发写的可能性高。每次读数据的时候都认为会被其他线程修改，所以每次读写都会上锁。 1.2 java线程阻塞的代价明确java线程切换的代价，是理解java中各种锁的优缺点的基础。 java的线程是映射到操作系统原生线程上的，如果要阻塞或唤醒一个线程就需要操作系统介入，操作系统需要在用户态与核心态之间转换，这种切换会消耗大量的系统资源，这是因为用户态与核心态有各自的内存区域、寄存器等资源，用户态切换至内核态需要传递给许多变量、参数给内核，内核也需要保护好用户态在切换时的一些寄存器值、变量等，以便内核态调用结束后切换回用户态继续工作。 如果线程状态切换是一个高频操作时，这将会消耗很多CPU处理时间； 如果对于那些需要同步的简单的代码块，获取锁挂起操作消耗的时间比用户代码执行的时间还要长，这种同步策略显然非常糟糕的。 synchronized会导致争用不到锁的线程进入阻塞状态，所以说它是java语言中一个重量级的同步操纵，被称为重量级锁，为了缓解上述性能问题，JVM从1.6开始，引入了轻量级锁与偏向锁，默认启用了自旋锁，他们都属于乐观锁。 1.3 java的对象头 字宽（Word）: 内存大小的单位概念， 32 位处理器 1 Word = 4 Bytes， 64 位处理器 1 Word = 8 Bytes 每一个 Java 对象都至少占用 2 个字宽的内存(数组类型占用3个字宽)。 第一个字被称为Markword。 Markword包含了多种不同的信息， 其中就包含对象锁相关的信息。 第二个字是指向类元数据信息（class metadata）的指针_klass，将在jvm部分介绍。 markword数据的长度在32位和64位的虚拟机（未开启压缩指针）中分别为32bit和64bit，它的最后2bit是锁状态标志位，用来标记当前对象的状态，对象的所处的状态，决定了markword存储的内容，如下表所示: 状态 标志位 存储内容 重量级锁 10 执行重量级锁定的指针 轻量级锁 00 指向锁记录的指针 GC标记 11 空(不需要记录信息) 偏向锁 01 偏向线程ID、偏向时间戳、对象分代年龄 未锁定 01 对象哈希码、对象分代年龄 32位虚拟机在不同状态下markword结构如下图所示： 说明： MarkWord 中包含对象 hashCode 的那种无锁状态是偏向机制被禁用时， 分配出来的无锁对象MarkWord 起始状态，无实际用途。 偏向机制被启用时，分配出来的对象状态是 ThreadId|Epoch|age|1|01, ThreadId 为空时标识对象尚未偏向于任何一个线程， ThreadId 不为空时， 对象既可能处于偏向特定线程的状态， 也有可能处于已经被特定线程占用完毕释放的状态， 需结合 Epoch 和其他信息判断对象是否允许再偏向（rebias）。 2. java中的锁2.1 自旋锁原理简单，如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要重复执行获取锁操作（自旋），等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。 缺点是线程自旋是需要消耗cup时间片，即cup在空转，若持有锁的线程需要长时间占用锁，线程自旋的消耗大于线程阻塞挂起操作的消耗，会造成CPU浪费，因此需要设定一个自旋等待的最大时间。 适用性 自旋锁尽可能的减少线程的阻塞，这对于锁的竞争不激烈，且占用锁时间非常短的代码块来说性能能大幅度的提升，因为自旋的消耗会小于线程阻塞挂起操作的消耗！ JVM对于自旋周期的选择，jdk1.5这个限度是一定的写死的，在1.6引入了适应性自旋锁。 适应性自旋锁意味着自旋的时间不在是固定的了，而是由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定，基本认为一个线程上下文切换的时间是最佳的一个时间。 同时JVM还针对当前CPU的负荷情况做了较多的优化： 如果平均负载小于CPUs则一直自旋 如果有超过(CPUs/2)个线程正在自旋，则后来线程直接阻塞 如果正在自旋的线程发现Owner发生了变化则延迟自旋时间（自旋计数）或进入阻塞 如果CPU处于节电模式则停止自旋 自旋时间的最坏情况是CPU的存储延迟（CPU A存储了一个数据，到CPU B得知这个数据直接的时间差） 自旋时会适当放弃线程优先级之间的差异 2.2 偏向锁Java偏向锁(Biased Locking)是Java6引入的一项多线程优化。偏向锁，它会偏向于第一个访问锁的线程，如果在运行过程中，同步对象只有一个线程访问，不存在多线程争用的情况，则线程是不需要触发同步的，这种情况下，就会让同步对象偏向该线程。偏向线程运行过程中，若其他线程请求锁，则持有偏向锁的线程会被挂起，JVM会撤销该偏向锁，升级为轻量级锁。 2.2.1 jvm开启/关闭偏向锁开启偏向锁：-XX:+UseBiasedLocking -XX:BiasedLockingStartupDelay=0 关闭偏向锁：-XX:-UseBiasedLocking 2.2.2 偏向锁获取过程 访问对象的Mark Word确认是否为可偏向状态。（偏向锁的标识是为1，锁标志位为01，并且ThreadID为null表示可偏向状态） 12345// Indicates that the mark has the bias bit set but that it has not // yet been biased toward a particular thread bool is_biased_anonymously() const &#123; return (has_bias_pattern() &amp;&amp; (biased_locker() == NULL)); &#125; has_bias_pattern() 返回 true 时代表 markword 的可偏向标志 bit 位为 1 ，且对象头末尾标志为 01。 biased_locker() == null 返回 true 时代表对象 Mark Word 中 bit field 域存储的 Thread Id 为空。 如果为可偏向状态，尝试用 CAS 操作， 将自己的线程 ID 写入MarkWord 如果 CAS 操作失败， 则说明， 有另外一个线程 Thread B 抢先获取了该对象的偏向锁。 这种状态说明该对象的竞争比较激烈， 此时需要撤销 Thread B 获得的偏向锁，将 Thread B 持有的锁升级为轻量级锁。 该操作需要等待全局安全点 JVM safepoint ( 此时间点， 没有线程在执行字节码) 。 1注意：到达安全点safepoint会导致stop the word，时间很短。 如果是已偏向状态， 则检测 MarkWord 中存储的 thread ID 是否等于当前 thread ID 。 如果相等， 则证明本线程已经获取到偏向锁， 可以直接继续执行同步代码块 如果不等， 则证明该对象目前偏向于其他线程， 需要撤销偏向锁 2.2.3 偏向锁的撤销偏向锁只有遇到其他线程尝试竞争偏向锁时，偏向锁才会撤销，线程不会主动去释放偏向锁。 偏向锁的撤销，需要等待全局安全点，此时没有字节码正在执行。 jvm会根据markword中的偏向线程ID来判断锁对象是否处于被锁定状态，从而决定撤销偏向锁后恢复到未锁定“01”状态（偏向的线程已死）或轻量级锁“00”状态（偏向的线程还在执行）。 2.2.4 偏向锁的批量再偏向（Bulk Rebias）机制那么作为开发人员， 很自然会产生的一个问题就是， 如果一个对象先偏向于某个线程， 执行完同步代码后， 另一个线程就不能直接重新获得偏向锁吗？ 答案是可以， JVM 提供了批量再偏向机制机制（Bulk Rebias） 在偏向机制的工作原理如下： 引入一个概念 epoch，其本质是一个时间戳 ， 代表了偏向锁的有效性，从前文描述的对象头结构中可以看到， epoch 存储在可偏向对象的 MarkWord 中。 除了对象中的 epoch， 对象所属的类 class 信息中， 也会保存一个 epoch 值 每当遇到一个全局安全点时， 如果要对 class C 对象进行批量再偏向， 则首先对 class C 中保存的 epoch 进行增加操作， 得到一个新的 epoch_new 然后扫描所有持有 class C 对象的线程栈， 根据线程栈的信息判断出该线程是否锁定了该对象， 仅将 epoch_new 的值赋给被锁定的对象中。 退出安全点后， 当有线程需要尝试获取偏向锁时， 直接检查 class C 中存储的 epoch 值是否与目标对象中存储的 epoch 值相等， 如果不相等， 则说明该对象的偏向锁已经无效了（更新epoch时，该对象处于未锁定状态）， 可以尝试对此对象重新进行偏向操作。 总结如下：使用epoch，将已锁定的偏向锁和已失效的偏向锁区分开来，失效的偏向锁可以重新偏向。 2.2.5 升级成轻量级锁偏向锁撤销后， 对象可能处于两种状态。 无锁状态 轻量级锁定状态 之所以会产生两种状态，是因为撤销偏向锁时，偏向锁可能处于两种状态： 第一种情况：原来已经获取了偏向锁的线程可能已经执行完了同步代码块， 使得对象处于 “闲置状态”，相当于原有的偏向锁已经过期无效了。此时该对象就应该被直接转换为无锁状态，无锁状态下有线程请求锁将进入轻量级锁定状态。 第二种情况：原来已经获取了偏向锁的线程也可能尚未执行完同步代码块， 偏向锁依旧有效， 此时对象就应该直接被转换为轻量级加锁的状态，具体做法是先阻塞偏向线程，在线程的栈桢中创建锁记录，再将markword修改为轻量级锁状态。 2.2.6 偏向锁的适用场景始终只有一个线程在执行同步块，在它没有执行完释放锁之前，没有其它线程去执行同步块，在锁无竞争的情况下使用，一旦有了竞争就升级为轻量级锁，升级为轻量级锁的时候需要撤销偏向锁，撤销偏向锁的时候会导致stop the word操作；在有锁的竞争时，偏向锁会多做很多额外操作，尤其是撤销偏向所的时候会导致进入安全点，安全点会导致stw，导致性能下降，所以高并发的应用会禁用掉偏向锁。 2.3 轻量级锁轻量级锁是由偏向所升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，偏向锁就会升级为轻量级锁； 轻量级锁的加锁过程： 在代码进入同步块之前，如果同步对象锁状态为无锁状态（偏向锁标志为“0”，锁标志位为“01”），JVM会在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的MarkWord复制到锁记录中，官方称为Displaced Mark Word。 然后线程尝试使用CAS将对象头中的Mark Word替换为指向该线程锁记录的指针，并将Lock record里的owner指针指向object mark word。 如果成功，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00” 如果失败，表示有其他线程竞争锁，当前线程自旋来获取锁，若自旋获取锁失败，将Markword区替换为重量级指针，并挂起竞争线程。 轻量级锁解锁过程： 轻量级解锁时，会使用CAS操作将Displaced Mark Word替换回对象头 如果替换失败，说明有其他线程尝试过获取该锁（此时锁已膨胀成重量级），那就要在释放锁的同时，唤醒被挂起的竞争线程。 2.4 重量级锁重量级锁是通过对象内部的监视器锁monitor实现的，而监视器的本质是依赖操作系统的mutex lock实现的。 轻量级锁在向重量级锁膨胀的过程中， 一个操作系统的互斥量（mutex）和条件变量( condition variable )会和这个被锁的对象关联起来。具体而言， 在锁膨胀时， 被锁对象的 markword 会被通过 CAS 操作尝试更新为一个数据结构的指针，即重量级锁指针。这个数据结构中进一步包含了指向操作系统互斥量和条件变量的指针。 获取重量级锁失败，线程会被阻塞，需要等待操作系统的唤醒才能继续执行。 2.5 锁升级过程","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/categories/并发编程/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/tags/并发编程/"}],"keywords":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/categories/并发编程/"}]},{"title":"并发编程-线程中断","slug":"并发编程-线程中断","date":"2018-03-17T16:00:00.000Z","updated":"2021-01-11T09:02:19.996Z","comments":true,"path":"2018/03/18/并发编程-线程中断/","link":"","permalink":"https://zzkenyon.github.io/2018/03/18/并发编程-线程中断/","excerpt":"","text":"中断标志就是线程对象的一个成员变量，它表示一个运行中的线程是否被被其他线程进行了中断操作。中断好比其他线程对该线程打了个招呼，其他线程通过调用该线程对象的interrupt()方法对其进行中断操作。 线程通过检查自身是否被中断来进行响应，线程通过对象方法 isInterrupted()来进行判断是否被中断。 在线程中调用静态方法 Thread.interrupted() 对当前线程的中断标识进行复位。 中断与响应中断是异步的。 本文将从以下两个方面来介绍Java中对线程中断机制的具体实现： Java中对线程中断所提供的API支持 线程在不同状态下对于中断所产生的反应 1. Java中线程中断的API在以前的jdk版本中，我们使用stop方法中断线程，但是现在的jdk版本中已经不再推荐使用该方法了，反而由以下三个方法完成对线程中断的支持。12345public boolean isInterrupted()public void interrupt()public static boolean interrupted() 每个线程都一个状态位用于标识当前线程对象是否是中断状态。isInterrupted是一个实例方法，主要用于判断当前线程对象的中断标志位是否被标记了，如果被标记了则返回true表示当前已经被中断，否则返回false。我们也可以看看它的实现源码：123public boolean isInterrupted() &#123; return isInterrupted(false);&#125; 1private native boolean isInterrupted(boolean ClearInterrupted); 底层调用的本地方法isInterrupted，传入一个boolean类型的参数，用于指定调用该方法之后是否需要清除该线程对象的中断标识位。由于参数值是false，所以调用isInterrupted并不会清除线程对象的中断标识位。 interrupt也是一个实例方法，该方法用于设置线程对象的中断标识位，只要能获取到线程对象，就能调用该方法。 interrupted()是一个静态的方法，只能在线程内部执行中调用，用于返回当前线程执行的线程是否被外部中断了，返回后清空标志位。 123public static boolean interrupted() &#123; return currentThread().isInterrupted(true);&#125; 1private native boolean isInterrupted(boolean ClearInterrupted); 该方法用于判断当前线程是否被中断，并且该方法调用结束的时候会清空中断标识位。 下面我们看看线程所处不同状态下对于中断操作的反应。 2. 线程在不同状态下对于中断所产生的反应线程一共6种状态，分别是NEW，RUNNABLE，BLOCKED，WAITING，TIMED_WAITING，TERMINATED（Thread类中有一个State枚举类型列举了线程的所有状态）。下面我们就将把线程分别置于上述的不同种状态，然后看看我们的中断操作对它们的影响。 2.1 NEW和TERMINATED线程的new状态表示还未调用start方法，还未真正启动。线程的terminated状态表示线程已经运行终止。这两个状态下调用中断方法来中断线程的时候，Java认为毫无意义，所以并不会设置线程的中断标识位，什么事也不会发生。例如：123456public static void main(String[] args) throws InterruptedException &#123; Thread thread = new MyThread(); System.out.println(thread.getState()); thread.interrupt(); System.out.println(thread.isInterrupted());&#125; 输出结果如下：12NEWfales terminated状态：12345678public static void main(String[] args) throws InterruptedException &#123; Thread thread = new MyThread(); thread.start(); thread.join(); System.out.println(thread.getState()); thread.interrupt(); System.out.println(thread.isInterrupted());&#125; 输出结果如下：12TERMINATEDfalse 从上述的两个例子来看，对于处于new和terminated状态的线程对于中断是屏蔽的，也就是说中断操作对这两种状态下的线程是无效的。 2.2 RUNNABLE如果线程处于运行状态，那么该线程的状态就是RUNNABLE，但是不一定所有处于RUNNABLE状态的线程都能获得CPU运行，在某个时间段，只能由一个线程占用CPU，那么其余的线程虽然状态是RUNNABLE，但是都没有处于运行状态。而我们处于RUNNABLE状态的线程在遭遇中断操作的时候只会设置该线程的中断标志位，并不会让线程实际中断，想要发现本线程已经被要求中断了则需要用程序去判断。例如： 1234567891011121314151617public class MyThread extends Thread&#123; @Override public void run()&#123; while(true)&#123; &#125; &#125;&#125;public static void main(String[] args) throws InterruptedException &#123; Thread thread = new MyThread(); thread.start(); System.out.println(thread.getState()); thread.interrupt(); Thread.sleep(1000);//等到thread线程被中断之后 System.out.println(thread.isInterrupted()); System.out.println(thread.getState());&#125; 我们定义的线程始终循环做一些事情，主线程启动该线程并输出该线程的状态，然后调用中断方法中断该线程并再次输出该线程的状态。总的输出结果如下： 123RUNNABLEtureRUNNABLE 可以看到在我们启动线程之后，线程状态变为RUNNABLE，中断之后输出中断标志，显然中断位已经被标记，但是当我们再次输出线程状态的时候发现，线程仍然处于RUNNABLE状态。很显然，处于RUNNBALE状态下的线程即便遇到中断操作，也只会设置中断标志位并不会实际中断线程运行。那么问题是，既然不能直接中断线程，我要中断标志有何用处？这里其实Java将这种权力交给了我们的程序，Java给我们提供了一个中断标志位，我们的程序可以通过if判断中断标志位是否被设置来中断我们的程序而不是系统强制的中断。例如： 12345678public void run()&#123; while(true)&#123; if (Thread.currentThread().isInterrupted())&#123; System.out.println(\"exit MyThread\"); break; &#125; &#125;&#125; 线程一旦发现自己的中断标志为被设置了，立马跳出死循环。这样的设计好处就在于给了我们程序更大的灵活性。 2.3 BLOCKED当线程处于BLOCKED状态说明该线程由于竞争某个对象的锁失败而被挂在了该对象的阻塞队列上了。那么此时发起中断操作不会对该线程产生任何影响，依然只是设置中断标志位。例如：1234567891011public class MyThread extends Thread&#123; public synchronized static void doSomething()&#123; while(true)&#123; //do something &#125; &#125; @Override public void run()&#123; doSomething(); &#125;&#125; 这里我们自定义了一个线程类，run方法中主要就做一件事情，调用一个有锁的静态方法，该方法内部是一个死循环（占用该锁让其他线程阻塞）。123456789101112131415public static void main(String[] args) throws InterruptedException &#123; Thread thread1 = new MyThread(); thread1.start(); Thread thread2 = new MyThread(); thread2.start(); Thread.sleep(1000); System.out.println(thread1.getState()); System.out.println(thread2.getState()); thread2.interrupt(); System.out.println(thread2.isInterrupted()); System.out.println(thread2.getState());&#125; 在我们的主线程中，我们定义了两个线程并按照定义顺序启动他们，显然thread1启动后便占用MyThread类锁，此后thread2在获取锁的时候一定失败，自然被阻塞在阻塞队列上，而我们对thread2进行中断，输出结果如下：1234RUNNABLEBLOCKEDtrueBLOCKED 从输出结果看来，thread2处于BLOCKED状态，执行中断操作之后，该线程仍然处于BLOCKED状态，但是中断标志位却已被修改。这种状态下的线程和处于RUNNABLE状态下的线程是类似的，给了我们程序更大的灵活性去判断和处理中断。 2.4 WAITING/TIMED_WAITING这两种状态本质上是同一种状态，只不过TIMED_WAITING在等待一段时间后会自动释放自己，而WAITING则是无限期等待，需要其他线程调用notify方法释放自己。但是他们都是线程在运行的过程中由于缺少某些条件而被挂起在某个对象的等待队列上。当这些线程遇到中断操作的时候，会抛出一个InterruptedException异常，并清空中断标志位。例如：123456789101112public class MyThread extends Thread&#123; @Override public void run()&#123; synchronized (this)&#123; try &#123; wait(); &#125; catch (InterruptedException e) &#123; System.out.println(\"i am waiting but facing interruptexception now\"); &#125; &#125; &#125;&#125; 我们定义了一个线程类，其中run方法让当前线程阻塞到条件队列上，并且针对InterruptedException 进行捕获，如果遇到InterruptedException 异常则输出一行信息。12345678910public static void main(String[] args) throws InterruptedException &#123; Thread thread = new MyThread(); thread.start(); Thread.sleep(500); System.out.println(thread.getState()); thread.interrupt(); Thread.sleep(1000); System.out.println(thread.isInterrupted());&#125; 在main线程中我们启动一个MyThread线程，然后对其进行中断操作。运行结果如下：123WAITINGi am waiting but facing interruptexception nowfalse 从运行结果看，当前程thread启动之后就被挂起到该线程对象的条件队列上，然后我们调用interrupt方法对该线程进行中断，输出了我们在catch中的输出语句，显然是捕获了InterruptedException异常，接着就看到该线程的中断标志位被清空。 3. 总结综上所述，我们分别介绍了不同种线程的不同状态下对于中断请求的反应。 NEW 和 TERMINATED对于中断操作几乎是屏蔽的。 对于RUNNABLE 和 BLOCKED状态，中断操作只是设置中断标志位并没有强制终止线程，对于线程的终止权利依然在程序手中，对于中断标志位的重置当然也是交给用户的。java将中断感知交给用户自己实现，即调用api进行判断。 对于WAITING / TIMED_WAITING 状态下的线程，java牢牢控制着中断感知的权限，一旦被外部线程中断，会立即抛出异常并清空中断标志位。 对于2、3两点的总结： 实质上是中断感知异步同步的区别，第2点采用异步的方式感知中断，第三点采用同步的方式","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/categories/并发编程/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/tags/并发编程/"}],"keywords":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/categories/并发编程/"}]},{"title":"并发编程-ThreadLocal原理","slug":"并发编程-ThreadLocal原理","date":"2018-03-15T16:00:00.000Z","updated":"2021-01-11T08:45:08.260Z","comments":true,"path":"2018/03/16/并发编程-ThreadLocal原理/","link":"","permalink":"https://zzkenyon.github.io/2018/03/16/并发编程-ThreadLocal原理/","excerpt":"","text":"ThreadLocal是一个本地线程副本变量工具类，ThreadLocal的实例代表了一个线程局部的变量，主要用于将私有线程和该线程存放的副本对象做一个映射，各个线程之间的变量互不干扰，在高并发场景下，可以实现无状态的调用，特别适用于各个线程依赖不通的变量值完成操作的场景。 1. 是什么 是让线程拥有独占的变量 它通过set、get方法进行设值和取值操作 它可以覆盖initialValue方法设置初始值，在没进行set之前调用get会调用初始化方法，一个线程只会调用一次 每个线程都会有一个指向threadLocal的弱引用，只要线程一直存活或者该threadLocal实例能被访问到，就不会被GC清理掉。当jvm内存溢出时，会清理掉值为Null的弱引用。 2. 使用方法1234567891011121314public static void main(String[] args)&#123; ThreadLocal&lt;String&gt; stringThreadLocal = new ThreadLocal&lt;String&gt;()&#123; @Override protected String initialValue()&#123; return \"default string\"; &#125; &#125;; for(int i = 0; i&lt; 10; i++)&#123; new Thread(() -&gt; &#123; stringThreadLocal.set(Thread.currentThread().getName()); System.out.println(stringThreadLocal.get()); &#125;).start(); &#125;&#125; 3. 在一个map里每个线程都有一个ThreadLocalMap对象，map中存放了(ThreadLocal,t)键值对 123456789/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null;/* * InheritableThreadLocal values pertaining to this thread. This map is * maintained by the InheritableThreadLocal class. */ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; 看看ThreadLocalMap的Entry定义： 123456789101112131415// ThreadLocal.ThreadLocalMapstatic class ThreadLocalMap &#123; // 存放条目的数组 private Entry[] table; //Entry定义 static class Entry extends WeakRefezrence&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; &#125; ThreadLocalMap的Key是ThreadLocal&lt;?&gt; 引用，value是？类型的值 1ThreadLocal&lt;String&gt; stringThreadLocal = new ThreadLocal&lt;String&gt;()&#123; 当我们在代码中创建了一个ThreadLocal变量时，此时并没有与某个指定的线程对象关联，那么是什么时候关联起来的呢？ 3.1 get源码1234567891011121314// ThreadLocal.get()public T get() &#123; Thread t = Thread.currentThread(); // 获取当前线程 ThreadLocalMap map = getMap(t); //获取线程的ThreadLocalMap if (map != null) &#123; // 若当前操作的ThreadLocal变量第一个的话，那么map肯定返回null ThreadLocalMap.Entry e = map.getEntry(this); // 从Entry数组中获得本Local变量的Entry if (e != null) &#123; @SuppressWarnings(\"unchecked\") T result = (T)e.value; // 获取值 return result; &#125; &#125; return setInitialValue(); // 没有获取到则进行初始化，并返回默认值&#125; 获取当前线程内部的ThreadLocalMap map存在则获取当前ThreadLocal对应的值 不存在则调用setInitialValue进行初始化 3.2 setInitialValue()源码12345678910private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); // 为Thread创建map，并将当前的k-v放进去 return value;&#125; 调用重载的initialValue方法获取初始值 获取当前线程的ThreadLocalMap map存在则将初始值put进去 map不存在则使用初始值为当前线程创建ThreadLocalMap 3.3 set(T value)源码12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125; 获取当前线程内部的ThreadLocalMap map存在则把当前ThreadLocal和value添加到map中 map不存在则创建一个ThreadLocalMap，保存到当前线程内部 总结：每个线程都有一个ThreadLocalMap类型的私有变量，当为线程添加ThreadLocal对象时，就是保存到了这个map中，所以线程之间不会相互干扰。 4. 我还有一个大坑ThreadLocal使用不当，会引发内存泄露的问题 ThreadLocal对象存在thread对象中，只要线程没有死亡，该对象就不会被回收 remove()源码12345public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this); &#125; 获取当前线程内部的ThreadLocalMap，存在则从map中删除这个ThreadLocal对象。","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/categories/并发编程/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/tags/并发编程/"}],"keywords":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/categories/并发编程/"}]},{"title":"Mybatis-TypeHandler<T>的使用","slug":"数据库技术-Mybatis-TypeHandlerT的使用","date":"2018-03-14T16:00:00.000Z","updated":"2020-07-16T00:17:04.151Z","comments":true,"path":"2018/03/15/数据库技术-Mybatis-TypeHandlerT的使用/","link":"","permalink":"https://zzkenyon.github.io/2018/03/15/数据库技术-Mybatis-TypeHandlerT的使用/","excerpt":"","text":"orm框架需要解决的问题之一就是数据库中的数据类型与java数据类型相互转换，以Mysql为例： JdbcType.Varchar类型与String类型需要相互转换，mybatis内置了StringTypeHandler来处理这种转换 JdbcType.double类型与Double或double类型转换，内置有DoubleTypeHandler 。。。 在实际开发中，会遇到一些特殊类型的转换，例如： JdbcType.Varchar 与 JSON类型 JdbcType.int 与 枚举类型 JdbcType.Varchar 与 List类型的转换 要实现这些特殊的类型转换，我们一般通过继承BaseTypeHandler 来自定义TypeHandler，泛型 T 表示需要转换的java类型 一个例子： java对象某属性为List类型，存到数据库中需要转换为vachar类型形如“1，2，3”的字符串，自定义handler如下 1234567891011121314151617181920212223242526272829303132333435363738394041//泛型接收的是java类型public class MyTypeHandler_2 extends BaseTypeHandler&lt;List&lt;Integer&gt;&gt; &#123; @Override public void setNonNullParameter(PreparedStatement ps, int i, List&lt;Integer&gt; parameter, JdbcType jdbcType) throws SQLException &#123; //该方法用于将list转换成varchar，并设置到PreparedStatement中进行存储 StringBuilder sb = new StringBuilder(); for (int j = 0; j &lt; parameter.size(); j++) &#123; sb.append(parameter.get(i) + \",\"); &#125; String s = sb.toString(); ps.setString(i,s.substring(0,s.length()-1)); &#125; //后面三个方法都是将数据库中读取的varchar 转换成java需要的list类型 @Override public List&lt;Integer&gt; getNullableResult(ResultSet rs, String columnName) throws SQLException &#123; String str = rs.getString(columnName); return convert(str); &#125; @Override public List&lt;Integer&gt; getNullableResult(ResultSet rs, int columnIndex) throws SQLException &#123; String str = rs.getString(columnIndex); return convert(str); &#125; @Override public List&lt;Integer&gt; getNullableResult(CallableStatement cs, int columnIndex) throws SQLException &#123; String str = cs.getString(columnIndex); return convert(str); &#125; private List&lt;Integer&gt; convert(String str)&#123; String[] strArray = str.split(\",\"); List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); for(String s : strArray)&#123; res.add(Integer.valueOf(s)) ; &#125; return res; &#125; 如何配置自定义的TypeHandler： 1.在Mapper.xml中声明 1&lt;result column=\"enum1\" jdbcType=\"INTEGER\" property=\"enum1\"typeHandler=\"com.xxx.handler.EnumTypeHandler\"/&gt; 2.在mybatis全局配置文件中设置 123&lt;typeHandlers&gt; &lt;typeHandler handler=\"com.xxx.handler.EnumTypeHandler\"/&gt;&lt;/typeHandlers&gt; 3.在spring-boot的yml配置文件中设置类型处理器所在的包名 12mybatis: type-handlers-package: com.xxx.handler","categories":[{"name":"ORM框架","slug":"ORM框架","permalink":"https://zzkenyon.github.io/categories/ORM框架/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://zzkenyon.github.io/tags/Mybatis/"}],"keywords":[{"name":"ORM框架","slug":"ORM框架","permalink":"https://zzkenyon.github.io/categories/ORM框架/"}]},{"title":"并发编程-并发的基础知识","slug":"并发编程-基础","date":"2018-03-14T16:00:00.000Z","updated":"2021-01-11T08:18:12.554Z","comments":true,"path":"2018/03/15/并发编程-基础/","link":"","permalink":"https://zzkenyon.github.io/2018/03/15/并发编程-基础/","excerpt":"","text":"1. 线程状态转换重点注意： Waiting和 Blocked 从linux内核来看，线程Waiting和 Blocked都是等待状态，都是暂停线程，都需要进行上下文切换没区别，他们的区别在于唤醒方式不同，Waiting 是用户唤醒，而 Blocked 是系统唤醒。 通常我们在系统级别说线程的Blocked，是说线程操作I/O，被暂停了，这种线程由linux内核来唤醒，例如：I/O设备报告数据来了，内核把Blocked线程放进可运行的进程队列，依次得到处理器时间；而Waiting是说，该线程在等待一个内核mutex对象，另个线程signal这个mutex后，这个线程才可以继续运行。区别在于由谁唤醒，是操作系统，还是另一个线程。 sleep(long) 不释放锁，而wait()会释放锁，都进入WAITING状态，wait()返回后，重新竞争锁，进入BLOCKED状态。 2. 如何减少上下文切换上下文切换指的是单个处理器处理多个线程时，时间片分配给不同的线程引起的处理器当前状态的保存和加载。发生在线程切换的时刻，保存当前线程运行状态，加载即将执行的线程状态。 锁竞争会引起上下文的切换，要减少上下文切换可以使用： 无锁并发编程，例如将数据分段处理 CAS算法，CAS没有竞争锁的过程，自然也不会引起线程切换。 避免创建不必要的线程 协程：在单线程里实现多任务调度，在单线程里维持多任务间的切换。 3. 避免死锁 避免一个线程同时获取多个锁 避免一个线程在一个锁内占用多个资源 尝试使用定时锁，使用lock.tryLock(timeout)来替代使用内部锁 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败 4. CAS操作compare and set 原子操作，实现不被打断的数据交换操作，避免多线程同时改写某数据时由于执行顺序不确定以及中断的不可预知性而产生数据不一致问题 操作方式：将内存中的值与预期值进行比较，如果两个值一致，可以写入新的值；否则什么都不做或者重试 12345678CAS有3个操作数：内存值V旧的预期值A要设置的新值B当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值(A和内存值V相同时，将内存值V修改为B)，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试(或者什么都不做)。 5. 重量级锁Synchronized在JDK1.5之前都是使用synchronized关键字保证同步的，Synchronized 的作用相信大家都已经非常熟悉了； 它可以把任意一个非NULL的对象当作锁： 作用于方法时，锁住的是对象的实例(this)； 当作用于静态方法时，锁住的是Class实例，又因为Class的相关数据存储在永久带PermGen（jdk1.8则是metaspace），永久带是全局共享的，因此静态方法锁相当于类的一个全局锁，会锁所有调用该方法的线程； synchronized作用于一个对象实例时，锁住的是所有以该对象为锁的代码块。 它有多个队列，当多个线程一起访问某个对象监视器的时候，对象监视器会将这些线程存储在不同的容器中。 Contention List：竞争队列，所有请求锁的线程首先被放在这个竞争队列中； Entry List：锁池，Contention List中那些有资格成为候选资源的线程被移动到Entry List中； Wait Set：等待池，哪些调用wait方法的线程被放置在这里进行WAITING； OnDeck：任意时刻，最多只有一个线程正在竞争锁资源，该线程被成为OnDeck； Owner：当前已经获取到所资源的线程被称为Owner； !Owner：当前释放锁的线程。 JVM每次从队列的尾部取出一个数据用于锁竞争候选者（OnDeck），但是并发情况下，ContentionList会被大量的并发线程进行CAS访问，为了降低对尾部元素的竞争，JVM会将一部分线程移动到EntryList中作为候选竞争线程。Owner线程会在unlock时，将ContentionList中的部分线程迁移到EntryList中，并指定EntryList中的某个线程为OnDeck线程（一般是最先进去的那个线程）。Owner线程并不直接把锁传递给OnDeck线程，而是把锁竞争的权利交给OnDeck，OnDeck需要重新竞争锁。这样虽然牺牲了一些公平性，但是能极大的提升系统的吞吐量，在JVM中，也把这种选择行为称之为“竞争切换”。 OnDeck线程获取到锁资源后会变为Owner线程，而没有得到锁资源的仍然停留在EntryList中。如果Owner线程调用wait方法，则转移到WaitSet队列中，直到某个时刻通过notify或者notifyAll唤醒，会重新进去EntryList中。 处于ContentionList、EntryList中的线程都处于阻塞状态，该阻塞是由操作系统来完成的（Linux内核下采用pthread_mutex_lock内核函数实现的）。 Synchronized是非公平锁。Synchronized在线程进入ContentionList时，等待的线程会先尝试自旋获取锁，如果获取不到就进入ContentionList，这明显对于已经进入队列的线程是不公平的，还有一个不公平的事情就是自旋获取锁的线程还可能直接抢占OnDeck线程的锁资源。 5.1 Synchronized的作用在JDK1.5之前都是使用synchronized关键字保证同步的，它可以把任意一个非NULL的对象当作锁。 作用于方法时，锁住的是对象的实例(this)； 当作用于静态方法时，锁住的是Class实例，又因为Class的相关数据存储在永久带PermGen（jdk1.8则是metaspace），永久带是全局共享的，因此静态方法锁相当于类的一个全局锁，会锁所有调用该方法的线程； 当作用于一个对象实例时，锁住的是所有以该对象为锁的代码块。 5.2 Synchronized的实现它有多个队列，当多个线程一起访问某个对象监视器的时候，对象监视器会将这些线程存储在不同的容器中，如下如所示： Contention List：竞争队列，所有请求锁的线程首先被放在这个竞争队列中； Entry List：Contention List中那些有资格成为候选资源的线程被移动到Entry List中； Wait Set：哪些调用wait方法被阻塞的线程被放置在这里； OnDeck：任意时刻，最多只有一个线程正在竞争锁资源，该线程被成为OnDeck； Owner：当前已经获取到所资源的线程被称为Owner； !Owner：当前释放锁的线程。 JVM每次从队列的尾部取出一个数据用于锁竞争候选者（OnDeck），但是并发情况下，ContentionList会被大量的并发线程进行CAS访问，为了降低对尾部元素的竞争，JVM会将一部分线程移动到EntryList中作为候选竞争线程。Owner线程会在unlock时，将ContentionList中的部分线程迁移到EntryList中，并指定EntryList中的某个线程为OnDeck线程（一般是最先进去的那个线程）。Owner线程并不直接把锁传递给OnDeck线程，而是把锁竞争的权利交给OnDeck，OnDeck需要重新竞争锁。这样虽然牺牲了一些公平性，但是能极大的提升系统的吞吐量，在JVM中，也把这种选择行为称之为“竞争切换”。 OnDeck线程获取到锁资源后会变为Owner线程，而没有得到锁资源的仍然停留在EntryList中。如果Owner线程被wait方法阻塞，则转移到WaitSet队列中，直到某个时刻通过notify或者notifyAll唤醒，会重新进去EntryList中。 处于ContentionList、EntryList、WaitSet中的线程都处于阻塞状态，该阻塞是由操作系统来完成的（Linux内核下采用pthread_mutex_lock内核函数实现的）。 5.3 Synchronized的非公平性 Synchronized在线程进入ContentionList时，等待的线程会先尝试自旋获取锁，如果获取不到就进入ContentionList，这明显对于已经进入队列的线程是不公平的 自旋获取锁的线程还可能直接抢占OnDeck线程的锁资源。 6.等待/通知机制帮助理解：每个对象都有一个等待池与锁池，并发编程访问临界资源时（共享对象）， 当共享对象调用wait函数时，当前线程阻塞进入等待池，等待池中的线程处于Waiting状态 当共享对象调用notify函数时，随机从等待池中唤醒一个线程，该线程进入到锁池参与锁竞争，若没有立即获取到锁，此时处于Blocked状态； 当共享对象调用notifyAll函数时，唤醒等待池中所有的线程，所有线程进入到锁池参与锁竞争。开发中常建议使用notifyAll()","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/categories/并发编程/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/tags/并发编程/"}],"keywords":[{"name":"并发编程","slug":"并发编程","permalink":"https://zzkenyon.github.io/categories/并发编程/"}]},{"title":"Mybatis-MyBatisGenerator的使用","slug":"数据库技术-Mybatis-MyBatisGenerator的使用","date":"2018-03-11T16:00:00.000Z","updated":"2020-05-22T11:54:12.257Z","comments":true,"path":"2018/03/12/数据库技术-Mybatis-MyBatisGenerator的使用/","link":"","permalink":"https://zzkenyon.github.io/2018/03/12/数据库技术-Mybatis-MyBatisGenerator的使用/","excerpt":"","text":"使用MyBatisGenerator可以根据数据库中的table自动生成entity、dao以及mapper映射器文件，简单配置就能实现 首先引入依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt; &lt;version&gt;1.3.5&lt;/version&gt;&lt;/dependency&gt; 引入插件： 1234567891011121314&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.5&lt;/version&gt; &lt;configuration&gt; &lt;configurationFile&gt;src/main/resources/generator-config.xml&lt;/configurationFile&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 在项目资源文件夹下创建MyBatisGenerator配置文件：generator-config.xml 123456789101112131415161718192021222324252627282930313233343536&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;!DOCTYPE generatorConfiguration PUBLIC \"-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN\" \"http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd\"&gt; &lt;generatorConfiguration&gt; &lt;!-- 数据库驱动--&gt; &lt;classPathEntry location=\"Users\\xxx\\.m2\\repository\\mysql\\mysql-connector-java\\8.0.18\\mysql-connector-java-8.0.18.jar\"/&gt; &lt;context id=\"DB2Tables\" targetRuntime=\"MyBatis3\"&gt; &lt;commentGenerator&gt; &lt;property name=\"suppressDate\" value=\"true\"/&gt; &lt;!-- 是否去除自动生成的注释 true：是 ： false:否 --&gt; &lt;property name=\"suppressAllComments\" value=\"true\"/&gt; &lt;/commentGenerator&gt; &lt;!--数据库链接URL，用户名、密码 --&gt; &lt;jdbcConnection driverClass=\"com.mysql.cj.jdbc.Driver\" connectionURL=\"jdbc:mysql://10.0.12.72/mybatis-demo\" userId=\"root\" password=\"C!Fr0ShoW9Nu\"&gt; &lt;/jdbcConnection&gt; &lt;javaTypeResolver&gt; &lt;property name=\"forceBigDecimals\" value=\"false\"/&gt; &lt;/javaTypeResolver&gt; &lt;!-- 生成模型的包名和位置--&gt; &lt;javaModelGenerator targetPackage=\"com.panda.generate.entity\" targetProject=\"/Users/xxx/IdeaProjects/github/thinking/mybatis-demo/src/main/java\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\"/&gt; &lt;property name=\"trimStrings\" value=\"true\"/&gt; &lt;/javaModelGenerator&gt; &lt;!-- 生成映射文件的包名和位置--&gt; &lt;sqlMapGenerator targetPackage=\"com.panda.generate.mapper\" targetProject=\"/Users/xxx/IdeaProjects/github/thinking/mybatis-demo/src/main/java\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\"/&gt; &lt;/sqlMapGenerator&gt; &lt;!-- 生成DAO的包名和位置--&gt; &lt;javaClientGenerator type=\"XMLMAPPER\" targetPackage=\"com.panda.generate.dao\" targetProject=\"/Users/xxx/IdeaProjects/github/thinking/mybatis-demo/src/main/java\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\"/&gt; &lt;/javaClientGenerator&gt; &lt;!-- 要生成的表 tableName是数据库中的表名或视图名 domainObjectName是实体类名--&gt; &lt;table tableName=\"blog\" domainObjectName=\"Blog\" enableCountByExample=\"false\" enableUpdateByExample=\"false\" enableDeleteByExample=\"false\" enableSelectByExample=\"false\" selectByExampleQueryId=\"false\"&gt;&lt;/table&gt; &lt;/context&gt; &lt;/generatorConfiguration&gt; 到此配置完成，在idea中刷新maven，在maven工具中点开Plugins，能看到mybatis-generator插件，双击运行。","categories":[{"name":"ORM框架","slug":"ORM框架","permalink":"https://zzkenyon.github.io/categories/ORM框架/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://zzkenyon.github.io/tags/Mybatis/"}],"keywords":[{"name":"ORM框架","slug":"ORM框架","permalink":"https://zzkenyon.github.io/categories/ORM框架/"}]},{"title":"SpringBoot-自定义starter","slug":"SpringBoot-自定义starter","date":"2018-02-27T16:00:00.000Z","updated":"2020-05-28T09:21:04.511Z","comments":true,"path":"2018/02/28/SpringBoot-自定义starter/","link":"","permalink":"https://zzkenyon.github.io/2018/02/28/SpringBoot-自定义starter/","excerpt":"","text":"1. 命名SpringBoot提供的starter以spring-boot-starter-xxx的方式命名的。 官方建议自定义的starter使用xxx-spring-boot-starter命名规则。以区分SpringBoot生态提供的starter。 2. 开发 编写properties 属性类（@ConfigurationProperties） 123456@ConfigurationProperties(prefix = \"demo\")@Datapublic class DemoProperties &#123; private String what; private String who;&#125; 编写service 接口类 1234567891011public class DemoService &#123; private String what; private String who; public DemoService(String sayWhat, String toWho)&#123; this.what = sayWhat; this.who = toWho; &#125; public String say()&#123; return this.what + \"! \" + this.who; &#125;&#125; 编写config 自动配置类（@EnableConfigurationProperties、） 12345678910@Configuration@EnableConfigurationProperties(DemoProperties.class)public class DemoConfig &#123; @Resource private DemoProperties properties; @Bean public DemoService service()&#123; return new DemoService(properties.getSayWhat(),properties.getToWho()); &#125;&#125; 在META-INF/spring.factories 配置自动配置类的全限定名称 12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\com.pd.starter.config.DemoConfig 3. 打包安装到本地仓库springboot项目pom中一般会有以下代码，表明这是一个有启动类的springboot工程。 jar包不需要启动类，所以打包之前要把pom中这一段删掉，否则maven-install时会报cannot find main class 错误12345678&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 4. 引用 新工程pom中添加依赖 application配置文件中可以对以上编写的properties类成员进行配置赋值 使用spring注入方式创建service对象，调用接口方法","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/tags/SpringBoot/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/categories/SpringBoot/"}]},{"title":"NAT原理概述","slug":"其他-NAT原理概述","date":"2018-02-11T16:00:00.000Z","updated":"2020-06-12T00:32:16.469Z","comments":true,"path":"2018/02/12/其他-NAT原理概述/","link":"","permalink":"https://zzkenyon.github.io/2018/02/12/其他-NAT原理概述/","excerpt":"","text":"1 概述1.1 简介1.1.1 名词解释公有IP地址：也叫全局地址，是指合法的IP地址，它是由NIC（网络信息中心）或者ISP(网络服务提供商)分配的地址，对外代表一个或多个内部局部地址，是全球统一的可寻 址的地址。 私有IP地址：也叫内部地址，属于非注册地址，专门为组织机构内部使用。因特网分配编号委员会（IANA）保留了3块IP地址做为私有IP地址： 10.0.0.0 ——— 10.255.255.255 172.16.0.0——— 172.16.255.255 192.168.0.0———192.168.255.255 地址池：地址池是有一些外部地址（全球唯一的IP地址）组合而成，我们称这样的一个地址集合为地址池。在内部网络的数据包通过地址转换到达外部网络时，将会在地址池中选择某个IP地址作为数据包的源IP地址，这样可以有效的利用用户的外部地址，提高访问外部网络的能力。 1.1.2关于NATNAT英文全称是“Network Address Translation”，中文意思是“网络地址转换”，它是一个IETF(Internet Engineering Task Force, Internet工程任务组)标准，允许一个整体机构以一个公用IP（Internet Protocol）地址出现在Internet上。顾名思义，它是一种把内部私有网络地址（IP地址）翻译成合法网络IP地址的技术，如下图所示。因此我们可以认为，NAT在一定程度上，能够有效的解决公网地址不足的问题。 简单地说，NAT就是在局域网内部网络中使用内部地址，而当内部节点要与外部网络进行通讯时，就在网关（可以理解为出口，打个比方就像院子的门一样）处，将内部地址替换成公用地址，从而在外部公网（internet）上正常使用，NAT可以使多台计算机共享Internet连接，这一功能很好地解决了公共 IP地址紧缺的问题。通过这种方法，可以只申请一个合法IP地址，就把整个局域网中的计算机接入Internet中。这时，NAT屏蔽了内部网络，所有内部网计算机对于公共网络来说是不可见的，而内部网计算机用户通常不会意识到NAT的存在。如下图所示。这里提到的内部地址，是指在内部网络中分配给节点的私有IP地址，这个地址只能在内部网络中使用，不能被路由转发。 NAT 功能通常被集成到路由器、防火墙、ISDN路由器或者单独的NAT设备中。比如Cisco路由器中已经加入这一功能，网络管理员只需在路由器的IOS中设置NAT功能，就可以实现对内部网络的屏蔽。 再比如防火墙将WEB Server的内部地址192.168.1.1映射为外部地址202.96.23.11，外部访问202.96.23.11地址实际上就是访问访问 192.168.1.1。此外，对于资金有限的小型企业来说，现在通过软件也可以实现这一功能。Windows 98 SE、Windows 2000 都包含了这一功能。 1.2 分类NAT有三种类型：静态NAT(Static NAT)、动态地址NAT(Pooled NAT)、网络地址端口转换NAPT（Port-Level NAT）。 1.2.1 静态NAT通过手动设置，使 Internet 客户进行的通信能够映射到某个特定的私有网络地址和端口。如果想让连接在 Internet 上的计算机能够使用某个私有网络上的服务器（如网站服务器）以及应用程序（如游戏），那么静态映射是必需的。静态映射不会从 NAT 转换表中删除。如果在 NAT 转换表中存在某个映射，那么 NAT 只是单向地从 Internet 向私有网络传送数据。这样，NAT 就为连接到私有网络部分的计算机提供了某种程度的保护。但是，如果考虑到 Internet 的安全性，NAT 就要配合全功能的防火墙一起使用。 对于以上网络拓扑图，当内网主机 10.1.1.1如果要与外网的主机201.0.0.11通信时，主机（IP：10.1.1.1）的数据包经过路由器时，路由器通过查找NAT table 将IP数据包的源IP地址（10.1.1.1）改成与之对应的全局IP地址（201.0.0.1），而目标IP地址201.0.0.11保持不变，这样，数据包就能到达201.0.0.11。而当主机HostB(IP:201.0.0.11) 响应的数据包到达与内网相连接的路由器时，路由器同样查找NAT table，将IP数据包的目的IP 地址改成10.1.1.1，这样内网主机就能接收到外网主机发过来的数据包。 在静态NAT方式中，内部的IP地址与公有IP地址是一种一一对应的映射关系，所以，采用这种方式的前提是，机构能够申请到足够多的全局IP地址。 1.2.2 动态NAT动态地址NAT只是转换IP地址，它为每一个内部的IP地址分配一个临时的外部IP地址，主要应用于拨号，对于频繁的远程联接也可以采用动态NAT。当远程用户联接上之后，动态地址NAT就会分配给他一个IP地址，用户断开时，这个IP地址就会被释放而留待以后使用。 动态NAT方式适合于 当机构申请到的全局IP地址较少，而内部网络主机较多的情况。内网主机IP与全局IP地址是多对一的关系。当数据包进出内网时，具有NAT功能的设备对IP数据包的处理与静态NAT的一样，只是NAT table表中的记录是动态的，若内网主机在一定时间内没有和外部网络通信，有关它的IP地址映射关系将会被删除，并且会把该全局IP地址分配给新的IP数据包使用，形成新的NAT table映射记录。 1.2.3网络地址端口转换NAPT网络地址端口转换NAPT（Network Address Port Translation）则是把内部地址映射到外部网络的一个IP地址的不同端口上。它可以将中小型的网络隐藏在一个合法的IP地址后面。NAPT与 动态地址NAT不同，它将内部连接映射到外部网络中的一个单独的IP地址上，同时在该地址上加上一个由NAT设备选定的端口号。 NAPT是使用最普遍的一种转换方式，它又包含两种转换方式：SNAT和DNAT。 源NAT（Source NAT，SNAT）：修改数据包的源地址。源NAT改变第一个数据包的来源地址，它永远会在数据包发送到网络之前完成，数据包伪装就是一具SNAT的例子。 目的NAT（Destination NAT，DNAT）：修改数据包的目的地址。Destination NAT刚好与SNAT相反，它是改变第一个数据包的目的地地址，如平衡负载、端口转发和透明代理就是属于DNAT。 源NAT举例：对于以上网络拓扑图，内网的主机数量比较多，但是该组织只有一个合法的IP地址，当内网主机（10.1.1.3）往外发送数据包时，则需要修改数据包的IP地址和TCP/UDP端口号，例如将 源IP：10.1.1.3 源port：1493 改成 源IP：201.0.0.1 源port：1492（注意：源端口号可以与原来的一样也可以不一样） 当外网主机（201.0.0.11）响应内网主机（10.1.1.3）时，应将： 目的IP：201.0.0.1 目的port：1492 改成 目的IP：10.1.1.3 目的port：1493 这样，通过修改IP地址和端口的方法就可以使内网中所有的主机都能访问外网，此类NAT适用于组织或机构内只有一个合法的IP地址的情况，也是动态NAT的一种特例。 目的NAT举例：这种方式适用于内网的某些服务器需要为外网提供某些服务的情况。**例如以上拓扑结构，内网服务器群（ip地址分别为：10.1.1.1,10.1.1.2,10.1.1.3等）需要为外网提供WEB 服务，当外网主机HostB访问内网时，所发送的数据包的目的IP地址为10.1.1.127，端口号为：80，当该数据包到达内网连接的路由器时，路由器查找NAT table，路由器通过修改目的IP地址和端口号，将外网的数据包平均发送到不同的主机上（10.1.1.1,10.1.1.2,10.1.1.3等），这样就实现了负载均衡。 2 NAT原理2.1 地址转换NAT的基本工作原理是，当私有网主机和公共网主机通信的IP包经过NAT网关时，将IP包中的源IP或目的IP在私有IP和NAT的公共IP之间进行转换。 如下图所示，NAT网关有2个网络端口，其中公共网络端口的IP地址是统一分配的公共 IP，为202.20.65.5；私有网络端口的IP地址是保留地址为192.168.1.1。私有网中的主机192.168.1.2向公共网中的主机202.20.65.4发送了1个IP包(Dst=202.20.65.4,Src=192.168.1.2)。 当IP包经过NAT网关时，NAT Gateway会将IP包的源IP转换为NAT Gateway的公共IP并转发到公共网，此时IP包（Dst=202.20.65.4，Src=202.20.65.5）中已经不含任何私有网IP的信息。由于IP包的源IP已经被转换成NAT Gateway的公共IP，Web Server发出的响应IP包（Dst= 202.20.65.5,Src=202.20.65.4）将被发送到NAT Gateway。 这时，NAT Gateway会将IP包的目的IP转换成私有网中主机的IP，然后将IP包（Des=192.168.1.2，Src=202.20.65.4）转发到私有网。对于通信双方而言，这种地址的转换过程是完全透明的。转换示意图如下。 如果内网主机发出的请求包未经过NAT，那么当Web Server收到请求包，回复的响应包中的目的地址就是私有网络IP地址，在Internet上无法正确送达，导致连接失败。 2.2 连接跟踪在上述过程中，NAT Gateway在收到响应包后，就需要判断将数据包转发给谁。此时如果子网内仅有少量客户机，可以用静态NAT手工指定；但如果内网有多台客户机，并且各自访问不同网站，这时候就需要连接跟踪（connection track）。如下图所示： 在NAT Gateway收到客户机发来的请求包后，做源地址转换，并且将该连接记录保存下来，当NAT Gateway收到服务器来的响应包后，查找Track Table，确定转发目标，做目的地址转换，转发给客户机。 2.3 端口转换以上述客户机访问服务器为例，当仅有一台客户机访问服务器时，NAT Gateway只须更改数据包的源IP或目的IP即可正常通讯。但是如果Client A和Client B同时访问Web Server，那么当NAT Gateway收到响应包的时候，就无法判断将数据包转发给哪台客户机，如下图所示。 此时，NAT Gateway会在Connection Track中加入端口信息加以区分。如果两客户机访问同一服务器的源端口不同，那么在Track Table里加入端口信息即可区分，如果源端口正好相同，那么在实行SNAT和DNAT的同时对源端口也要做相应的转换，如下图所示。 3 应用NAT主要可以实现以下几个功能：数据包伪装、平衡负载、端口转发和透明代理。 数据伪装： 可以将内网数据包中的地址信息更改成统一的对外地址信息，不让内网主机直接暴露在因特网上，保证内网主机的安全。同时，该功能也常用来实现共享上网。例如，内网主机访问外网时，为了隐藏内网拓扑结构，使用全局地址替换私有地址。 端口转发：当内网主机对外提供服务时，由于使用的是内部私有IP地址，外网无法直接访问。因此，需要在网关上进行端口转发，将特定服务的数据包转发给内网主机。例如公司小王在自己的服务器上架设了一个Web网站，他的IP地址为192.168.0.5，使用默认端口80，现在他想让局域网外的用户也能直接访问他的Web站点。利用NAT即可很轻松的解决这个问题，服务器的IP地址为210.59.120.89，那么为小王分配一个端口，例如81，即所有访问210.59.120.89:81的请求都自动转向192.168.0.5:80，而且这个过程对用户来说是透明的。 负载平衡：目的地址转换NAT可以重定向一些服务器的连接到其他随机选定的服务器。例如1.2.3所讲的目的NAT的例子。 失效终结：目的地址转换NAT可以用来提供高可靠性的服务。如果一个系统有一台通过路由器访问的关键服务器，一旦路由器检测到该服务器当机，它可以使用目的地址转换NAT透明的把连接转移到一个备份服务器上，提高系统的可靠性。 透明代理：例如自己架设的服务器空间不足，需要将某些链接指向存在另外一台服务器的空间；或者某台计算机上没有安装IIS服务，但是却想让网友访问该台计算机上的内容，这个时候利用IIS的Web站点重定向即可轻松的帮助我们搞定。 4 NAT的缺陷NAT在最开始的时候是非常完美的，但随着网络的发展，各种新的应用层出不穷，此时NAT也暴露出了缺点。NAT的缺陷主要表现在以下几方面： (1) 不能处理嵌入式IP地址或端口 NAT设备不能翻译那些嵌入到应用数据部分的IP地址或端口信息，它只能翻译那种正常位于IP首部中的地址信息和位于TCP/UDP首部中的端口信息，如下图,由于对方会使用接收到的数据包中嵌入的地址和端口进行通信，这样就可能产生连接故障，如果通信双方都是使用的公网IP，这不会造成什么问题，但如果那个嵌入式地址和端口是内网的，显然连接就不可能成攻，原因就如开篇所说的一样。MSN Messenger的部分功能就使用了这种方式来传递IP和端口信息，这样就导致了NAT设备后的客户端网络应用程序出现连接故障。 (2) 不能从公网访问内部网络服务 由于内网是私有IP，所以不能直接从公网访问内部网络服务，比如WEB服务，对于这个问题，我们可以采用建立静态映射的方法来解决。比如有一条静态映射，是把218.70.201.185:80与192.168.0.88:80映射起的，当公网用户要访问内部WEB服务器时，它就首先连接到218.70.201.185:80，然后NAT设备把请求传给192.168.0.88:80，192.168.0.88把响应返回NAT设备，再由NAT设备传给公网访问用户。 (3) 有一些应用程序虽然是用A端口发送数据的，但却要用B端口进行接收，不过NAT设备翻译时却不知道这一点，它仍然建立一条针对A端口的映射，结果对方响应的数据要传给B端口时，NAT设备却找不到相关映射条目而会丢弃数据包。(4) 一些P2P应用在NAT后无法进行对于那些没有中间服务器的纯P2P应用（如电视会议，娱乐等）来说，如果大家都位于NAT设备之后，双方是无法建立连接的。因为没有中间服务器的中转，NAT设备后的P2P程序在NAT设备上是不会有映射条目的，也就是说对方是不能向你发起一个连接的。现在已经有一种叫做P2P NAT穿越的技术来解决这个问题。 5.结语NAT技术无可否认是在ipv4地址资源的短缺时候起到了缓解作用；在减少用户申请ISP服务的花费和提供比较完善的负载平衡功能等方面带来了不少好处。但是在ipv4地址在以后几年将会枯竭，NAT技术不能改变ip地址空间不足的本质。然而在安全机制上也潜在着威胁，在配置和管理上也是一个挑战。如果要从根本上解决ip地址资源的问题，ipv6才是最根本之路。在ipv4转换到ipv6的过程中，NAT技术确实是一个不错的选择，相对其他的方案优势也非常明显。","categories":[{"name":"其他","slug":"其他","permalink":"https://zzkenyon.github.io/categories/其他/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://zzkenyon.github.io/tags/网络/"}],"keywords":[{"name":"其他","slug":"其他","permalink":"https://zzkenyon.github.io/categories/其他/"}]},{"title":"正则表达式基础","slug":"其他-正则表达式","date":"2018-01-20T16:00:00.000Z","updated":"2020-06-19T01:45:28.216Z","comments":true,"path":"2018/01/21/其他-正则表达式/","link":"","permalink":"https://zzkenyon.github.io/2018/01/21/其他-正则表达式/","excerpt":"","text":"正则表达式在几乎所有语言中都可以使用，无论是前端的JavaScript、还是后端的Java、c#。他们都提供相应的接口/函数支持正则表达式。 但很神奇的是：无论你大学选择哪一门计算机语言，都没有关于正则表达式的课程给你修，在你学会正则之前，你只能看着那些正则大师们，写了一串外星文似的字符串，替代了你用一大篇幅的if else代码来做一些数据校验。 既然喜欢，那就动手学呗，可当你百度出一一堆相关资料时，你发现无一不例外的枯燥至极，难以学习。 本文旨在用最通俗的语言讲述最枯燥的基本知识！ 正则基础知识点：1.元字符万物皆有缘，正则也是如此，元字符是构造正则表达式的一种基本元素。我们先来记几个常用的元字符： 有了元字符之后，我们就可以利用这些元字符来写一些简单的正则表达式了，比如： 匹配有abc开头的字符串： 1\\babc或者^abc 匹配8位数字的QQ号码： 1^\\d\\d\\d\\d\\d\\d\\d\\d$ 匹配1开头11位数字的手机号码： 1^1\\d\\d\\d\\d\\d\\d\\d\\d\\d\\d$ 2. 重复限定符有了元字符就可以写不少的正则表达式了，但细心的你们可能会发现：别人写的正则简洁明了，而不理君写的正则一堆乱七八糟而且重复的元字符组成的。正则没提供办法处理这些重复的元字符吗？ 答案是有的！为了处理这些重复问题，正则表达式中一些重复限定符，把重复部分用合适的限定符替代，下面我们来看一些限定符： 有了这些限定符之后，我们就可以对之前的正则表达式进行改造了，比如： 匹配8位数字的QQ号码： 1^\\d&#123;8&#125;$ 匹配1开头11位数字的手机号码： 1^1\\d&#123;10&#125;$ 匹配银行卡号是14~18位的数字： 1^\\d&#123;14,18&#125;$ 匹配以a开头的，0个或多个b结尾的字符串 1^ab*$ 3. 分组从上面的例子（4）中看到，限定符是作用在与他左边最近的一个字符，那么问题来了，如果我想要ab同时被限定那怎么办呢？ 正则表达式中用小括号()来做分组，也就是括号中的内容作为一个整体。 因此当我们要匹配多个ab时，我们可以这样如：匹配字符串中包含0到多个ab开头： 1^(ab)* 4. 转义我们看到正则表达式用小括号来做分组，那么问题来了： 如果要匹配的字符串中本身就包含小括号，那是不是冲突？应该怎么办？ 针对这种情况，正则提供了转义的方式，也就是要把这些元字符、限定符或者关键字转义成普通的字符，做法很简答，就是在要转义的字符前面加个斜杠，也就是\\即可。如：要匹配以(ab)开头： 1^(\\(ab\\))* 5. 条件或回到我们刚才的手机号匹配，我们都知道：国内号码都来自三大网，它们都有属于自己的号段，比如联通有130/131/132/155/156/185/186/145/176等号段，假如让我们匹配一个联通的号码，那按照我们目前所学到的正则，应该无从下手的，因为这里包含了一些并列的条件，也就是“或”，那么在正则中是如何表示“或”的呢？ 正则用符号 | 来表示或，也叫做分支条件，当满足正则里的分支条件的任何一种条件时，都会当成是匹配成功。 那么我们就可以用或条件来处理这个问题 1^(130|131|132|155|156|185|186|145|176)\\d&#123;8&#125;$ 6. 区间看到上面的例子，是不是看到有什么规律？是不是还有一种想要简化的冲动？实际是有的 正则提供一个元字符中括号 [] 来表示区间条件。 限定0到9 可以写成[0-9] 限定A-Z 写成[A-Z] 限定某些数字 [165] 那上面的正则我们还改成这样： 1^((13[0-2])|(15[56])|(18[5-6])|145|176)\\d&#123;8&#125;$ 好了，正则表达式的基本用法就讲到这里了，其实它还有非常多的知识点以及元字符，我们在此只列举了部分元字符和语法来讲，旨在给那些不懂正则或者想学正则但有看不下去文档的人做一个快速入门级的教程，看完本教程，即使你不能写出高大上的正则，至少也能写一些简单的正则或者看得懂别人写的正则了。 正则进阶知识点：1. 零宽断言 无论是零宽还是断言，听起来都古古怪怪的，那先解释一下这两个词。 断言：俗话的断言就是“我断定什么什么”，而正则中的断言，就是说正则可以指明在指定的内容的前面或后面会出现满足指定规则的内容，意思正则也可以像人类那样断定什么什么，比如”ss1aa2bb3”,正则可以用断言找出aa2前面有bb3，也可以找出aa2后面有ss1. 零宽：就是没有宽度，在正则中，断言只是匹配位置，不占字符，也就是说，匹配结果里是不会返回断言本身。 意思是讲明白了，那他有什么用呢？我们来举个栗子：假设我们要用爬虫抓取csdn里的文章阅读量。通过查看源代码可以看到文章阅读量这个内容是这样的结构 1&quot;&lt;span class=&quot;read-count&quot;&gt;阅读数：641&lt;/span&gt;&quot; 其中也就‘641’这个是变量，也就是说不同文章不同的值，当我们拿到这个字符串时，需要获得这里边的‘641’有很多种办法，但如果正则应该怎么匹配呢？ 下面先来讲几种类型的断言： 正向先行断言（正前瞻）： 语法：（?=pattern） 作用：匹配pattern表达式的前面内容，不返回本身。 这样子说，还是一脸懵逼，好吧，回归刚才那个栗子，要取到阅读量，在正则表达式中就意味着要能匹配到‘’前面的数字内容按照上所说的正向先行断言可以匹配表达式前面的内容，那意思就是:(?=) 就可以匹配到前面的内容了。匹配什么内容呢？如果要所有内容那就是： 123456789101112 1 String reg=\".+(?=&lt;/span&gt;)\"; 2 3 String test = \"&lt;span class=\\\"read-count\\\"&gt;阅读数：641&lt;/span&gt;\"; 4 Pattern pattern = Pattern.compile(reg); 5 Matcher mc= pattern.matcher(test); 6 while(mc.find())&#123; 7 System.out.println(\"匹配结果：\") 8 System.out.println(mc.group()); 9 &#125;1011 //匹配结果：12 //&lt;span class=\"read-count\"&gt;阅读数：641 可是老哥我们要的只是前面的数字呀，那也简单咯，匹配数字 \\d,那可以改成： 1234567891 String reg=\"\\\\d+(?=&lt;/span&gt;)\";2 String test = \"&lt;span class=\\\"read-count\\\"&gt;阅读数：641&lt;/span&gt;\";3 Pattern pattern = Pattern.compile(reg);4 Matcher mc= pattern.matcher(test);5 while(mc.find())&#123;6 System.out.println(mc.group());7 &#125;8 //匹配结果：9 //641 大功告成！ \\2. 正向后行断言（正后顾）: 语法：（?&lt;=pattern） 作用：匹配pattern表达式的后面的内容，不返回本身。 有先行就有后行，先行是匹配前面的内容，那后行就是匹配后面的内容啦。上面的栗子，我们也可以用后行断言来处理. 1234567891011 1 //(?&lt;=&lt;span class=\"read-count\"&gt;阅读数：)\\d+ 2 String reg=\"(?&lt;=&lt;span class=\\\"read-count\\\"&gt;阅读数：)\\\\d+\"; 3 4 String test = \"&lt;span class=\\\"read-count\\\"&gt;阅读数：641&lt;/span&gt;\"; 5 Pattern pattern = Pattern.compile(reg); 6 Matcher mc= pattern.matcher(test); 7 while(mc.find())&#123; 8 System.out.println(mc.group()); 9 &#125;10 //匹配结果：11 //641 就这么简单。 \\3. 负向先行断言（负前瞻） 语法：(?!pattern) 作用：匹配非pattern表达式的前面内容，不返回本身。 有正向也有负向，负向在这里其实就是非的意思。举个栗子：比如有一句 “我爱祖国，我是祖国的花朵”现在要找到不是’的花朵’前面的祖国用正则就可以这样写： 11 祖国(?!的花朵) \\4. 负向后行断言（负后顾） 语法：(?&lt;!pattern) 作用：匹配非pattern表达式的后面内容，不返回本身。 2. 捕获和非捕获单纯说到捕获，他的意思是匹配表达式，但捕获通常和分组联系在一起，也就是“捕获组” 捕获组：匹配子表达式的内容，把匹配结果保存到内存中中数字编号或显示命名的组里，以深度优先进行编号，之后可以通过序号或名称来使用这些匹配结果。 而根据命名方式的不同，又可以分为两种组： \\1. 数字编号捕获组：语法：(exp)解释：从表达式左侧开始，每出现一个左括号和它对应的右括号之间的内容为一个分组，在分组中，第0组为整个表达式，第一组开始为分组。比如固定电话的：020-85653333他的正则表达式为：(0\\d{2})-(\\d{8})按照左括号的顺序，这个表达式有如下分组： 我们用Java来验证一下： 12345678910 1 String test = \"020-85653333\"; 2 String reg=\"(0\\\\d&#123;2&#125;)-(\\\\d&#123;8&#125;)\"; 3 Pattern pattern = Pattern.compile(reg); 4 Matcher mc= pattern.matcher(test); 5 if(mc.find())&#123; 6 System.out.println(\"分组的个数有：\"+mc.groupCount()); 7 for(int i=0;i&lt;=mc.groupCount();i++)&#123; 8 System.out.println(\"第\"+i+\"个分组为：\"+mc.group(i)); 9 &#125;10 &#125; 输出结果： 12341 分组的个数有：22 第0个分组为：020-856533333 第1个分组为：0204 第2个分组为：85653333 可见，分组个数是2，但是因为第0个为整个表达式本身，因此也一起输出了。 \\2. 命名编号捕获组：语法：(?exp)解释：分组的命名由表达式中的name指定比如区号也可以这样写:(?\\0\\d{2})-(?\\d{8})按照左括号的顺序，这个表达式有如下分组： 用代码来验证一下： 1234567891 String test = \"020-85653333\";2 String reg=\"(?&lt;quhao&gt;0\\\\d&#123;2&#125;)-(?&lt;haoma&gt;\\\\d&#123;8&#125;)\";3 Pattern pattern = Pattern.compile(reg);4 Matcher mc= pattern.matcher(test);5 if(mc.find())&#123;6 System.out.println(\"分组的个数有：\"+mc.groupCount());7 System.out.println(mc.group(\"quhao\"));8 System.out.println(mc.group(\"haoma\"));9 &#125; 输出结果： 1231 分组的个数有：22 分组名称为:quhao,匹配内容为：0203 分组名称为:haoma,匹配内容为：85653333 \\3. 非捕获组：语法：(?:exp)解释：和捕获组刚好相反，它用来标识那些不需要捕获的分组，说的通俗一点，就是你可以根据需要去保存你的分组。 比如上面的正则表达式，程序不需要用到第一个分组，那就可以这样写： 11 (?:\\0\\d&#123;2&#125;)-(\\d&#123;8&#125;) 验证一下： 12345678910 1 String test = \"020-85653333\"; 2 String reg=\"(?:0\\\\d&#123;2&#125;)-(\\\\d&#123;8&#125;)\"; 3 Pattern pattern = Pattern.compile(reg); 4 Matcher mc= pattern.matcher(test); 5 if(mc.find())&#123; 6 System.out.println(\"分组的个数有：\"+mc.groupCount()); 7 for(int i=0;i&lt;=mc.groupCount();i++)&#123; 8 System.out.println(\"第\"+i+\"个分组为：\"+mc.group(i)); 9 &#125;10 &#125; 输出结果： 1231 分组的个数有：12 第0个分组为：020-856533333 第1个分组为：85653333 3. 反向引用上面讲到捕获，我们知道：捕获会返回一个捕获组，这个分组是保存在内存中，不仅可以在正则表达式外部通过程序进行引用，也可以在正则表达式内部进行引用，这种引用方式就是反向引用。 根据捕获组的命名规则，反向引用可分为： 数字编号组反向引用：\\k或\\number 命名编号组反向引用：\\k或者\\’name’ 好了 讲完了，懂吗？不懂！！！可能连前面讲的捕获有什么用都还不懂吧？其实只是看完捕获不懂不会用是很正常的！因为捕获组通常是和反向引用一起使用的 上面说到捕获组是匹配子表达式的内容按序号或者命名保存起来以便使用注意两个字眼：“内容” 和 “使用”这里所说的“内容”，是匹配结果，而不是子表达式本身，强调这个有什么用？嗯，先记住那这里所说的“使用”是怎样使用呢？ 因为它的作用主要是用来查找一些重复的内容或者做替换指定字符。 还是举栗子吧：比如要查找一串字母”aabbbbgbddesddfiid”里成对的字母如果按照我们之前学到的正则，什么区间啊限定啊断言啊可能是办不到的，现在我们先用程序思维理一下思路： 1）匹配到一个字母 2）匹配第下一个字母，检查是否和上一个字母是否一样 3）如果一样，则匹配成功，否则失败 这里的思路2中匹配下一个字母时，需要用到上一个字母，那怎么记住上一个字母呢？？？这下子捕获就有用处啦，我们可以利用捕获把上一个匹配成功的内容用来作为本次匹配的条件好了，有思路就要实践首先匹配一个字母：\\w我们需要做成分组才能捕获，因此写成这样：(\\w) 那这个表达式就有一个捕获组：（\\w）然后我们要用这个捕获组作为条件，那就可以：(\\w)\\1这样就大功告成了可能有人不明白了，\\1是什么意思呢？还记得捕获组有两种命名方式吗，一种是是根据捕获分组顺序命名，一种是自定义命名来作为捕获组的命名在默认情况下都是以数字来命名，而且数字命名的顺序是从1开始的因此要引用第一个捕获组，根据反向引用的数字命名规则 就需要 \\k或者\\1当然，通常都是是后者。我们来测试一下： 12345671 String test = \"aabbbbgbddesddfiid\";2 Pattern pattern = Pattern.compile(\"(\\\\w)\\\\1\");3 Matcher mc= pattern.matcher(test);4 while(mc.find())&#123;5 System.out.println(mc.group());67 &#125; 输出结果： 1234561 aa2 bb3 bb4 dd5 dd6 ii 嗯，这就是我们想要的了。 在举个替换的例子，假如想要把字符串中abc换成a 1231 String test = \"abcbbabcbcgbddesddfiid\";2 String reg=\"(a)(b)c\";3 System.out.println(test.replaceAll(reg, \"$1\"));; 输出结果： 11 abbabcgbddesddfiid 4. 贪婪和非贪婪1.贪婪 我们都知道，贪婪就是不满足，尽可能多的要。在正则中，贪婪也是差不多的意思: 贪婪匹配：当正则表达式中包含能接受重复的限定符时，通常的行为是（在使整个表达式能得到匹配的前提下）匹配尽可能多的字符，这匹配方式叫做贪婪匹配。特性：一次性读入整个字符串进行匹配，每当不匹配就舍弃最右边一个字符，继续匹配，依次匹配和舍弃（这种匹配-舍弃的方式也叫做回溯），直到匹配成功或者把整个字符串舍弃完为止，因此它是一种最大化的数据返回，能多不会少。 前面我们讲过重复限定符，其实这些限定符就是贪婪量词，比如表达式： 11 \\d&#123;3,6&#125; 用来匹配3到6位数字，在这种情况下，它是一种贪婪模式的匹配，也就是假如字符串里有6个个数字可以匹配，那它就是全部匹配到。如 1234567891 String reg=\"\\\\d&#123;3,6&#125;\"; 2 String test=\"61762828 176 2991 871\";3 System.out.println(\"文本：\"+test);4 System.out.println(\"贪婪模式：\"+reg);5 Pattern p1 =Pattern.compile(reg);6 Matcher m1 = p1.matcher(test);7 while(m1.find())&#123;8 System.out.println(\"匹配结果：\"+m1.group(0));9 &#125; 输出结果： 1234561 文本：61762828 176 2991 44 8712 贪婪模式：\\d&#123;3,6&#125;3 匹配结果：6176284 匹配结果：1765 匹配结果：29916 匹配结果：871 由结果可见：本来字符串中的“61762828”这一段，其实只需要出现3个（617）就已经匹配成功了的，但是他并不满足，而是匹配到了最大能匹配的字符，也就是6个。一个量词就如此贪婪了，那有人会问，如果多个贪婪量词凑在一起，那他们是如何支配自己的匹配权的呢？ 是这样的，多个贪婪在一起时，如果字符串能满足他们各自最大程度的匹配时，就互不干扰，但如果不能满足时，会根据深度优先原则，也就是从左到右的每一个贪婪量词，优先最大数量的满足，剩余再分配下一个量词匹配。 1234567891 String reg=\"(\\\\d&#123;1,2&#125;)(\\\\d&#123;3,4&#125;)\"; 2 String test=\"61762828 176 2991 87321\";3 System.out.println(\"文本：\"+test);4 System.out.println(\"贪婪模式：\"+reg);5 Pattern p1 =Pattern.compile(reg);6 Matcher m1 = p1.matcher(test);7 while(m1.find())&#123;8 System.out.println(\"匹配结果：\"+m1.group(0));9 &#125; 输出结果： 123451 文本：61762828 176 2991 873212 贪婪模式：(\\d&#123;1,2&#125;)(\\d&#123;3,4&#125;)3 匹配结果：6176284 匹配结果：29915 匹配结果：87321 “617628” 是前面的\\d{1,2}匹配出了61，后面的匹配出了7628 “2991” 是前面的\\d{1,2}匹配出了29 ，后面的匹配出了91 “87321”是前面的\\d{1,2}匹配出了87，后面的匹配出了321 2. 懒惰（非贪婪） 懒惰匹配：当正则表达式中包含能接受重复的限定符时，通常的行为是（在使整个表达式能得到匹配的前提下）匹配尽可能少的字符，这匹配方式叫做懒惰匹配。特性：从左到右，从字符串的最左边开始匹配，每次试图不读入字符匹配，匹配成功，则完成匹配，否则读入一个字符再匹配，依此循环（读入字符、匹配）直到匹配成功或者把字符串的字符匹配完为止。 懒惰量词是在贪婪量词后面加个“？” 1234567891 String reg=\"(\\\\d&#123;1,2&#125;?)(\\\\d&#123;3,4&#125;)\"; 2 String test=\"61762828 176 2991 87321\";3 System.out.println(\"文本：\"+test);4 System.out.println(\"贪婪模式：\"+reg);5 Pattern p1 =Pattern.compile(reg);6 Matcher m1 = p1.matcher(test);7 while(m1.find())&#123;8 System.out.println(\"匹配结果：\"+m1.group(0));9 &#125; 输出结果： 123451 文本：61762828 176 2991 873212 贪婪模式：(\\d&#123;1,2&#125;?)(\\d&#123;3,4&#125;)3 匹配结果：617624 匹配结果：29915 匹配结果：87321 解答： “61762” 是左边的懒惰匹配出6，右边的贪婪匹配出1762“2991” 是左边的懒惰匹配出2，右边的贪婪匹配出991“87321” 左边的懒惰匹配出8，右边的贪婪匹配出7321 5. 反义前面说到元字符的都是要匹配什么什么，当然如果你想反着来，不想匹配某些字符，正则也提供了一些常用的反义元字符： 正则进阶知识就讲到这里，正则是一门博大精深的语言，其实学会它的一些语法和知识点还算不太难，但想要做到真正学以致用能写出非常6的正则，还有很远的距离，只有真正对它感兴趣的，并且经常研究和使用它，才会渐渐的理解它的博大精深之处，我就带你们走到这，剩下的，靠自己啦。","categories":[{"name":"其他","slug":"其他","permalink":"https://zzkenyon.github.io/categories/其他/"}],"tags":[{"name":"正则","slug":"正则","permalink":"https://zzkenyon.github.io/tags/正则/"}],"keywords":[{"name":"其他","slug":"其他","permalink":"https://zzkenyon.github.io/categories/其他/"}]},{"title":"java-SimpleDateFormat的用法以及线程安全","slug":"java-SimpleDateFormat的用法以及线程安全","date":"2017-12-21T01:02:32.000Z","updated":"2021-01-12T07:27:45.462Z","comments":true,"path":"2017/12/21/java-SimpleDateFormat的用法以及线程安全/","link":"","permalink":"https://zzkenyon.github.io/2017/12/21/java-SimpleDateFormat的用法以及线程安全/","excerpt":"","text":"开发中我们经常会用到时间相关类，我们有很多办法在Java代码中获取时间。但是不同的方法获取到的时间的格式都不尽相同，这时候就需要一种格式化工具，把时间显示成我们需要的格式。最常用的方法就是使用SimpleDateFormat类。这是一个看上去功能比较简单的类，但是，一旦使用不当也有可能导致很大的问题。 在阿里巴巴Java开发手册中，有如下明确规定：本文就围绕SimpleDateFormat的用法、原理等来深入分析下如何以正确使用它。 1. SimpleDateFormat用法1.1 基本用法SimpleDateFormat是java提供的能对时间格式化及解析的工具类。 格式化：将规范日期格式化成日期文本（时间字符串） 12SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);String dateStr = sdf.format(new Date()); 解析： 将文本日期解析成规范化的时间格式 1Date d = sdf.parse(dataStr); 用户可以自定义文本日期的格式，通过字母来描述时间元素，并组装成想要的日期和时间格式。常用的时间元素和字母的对应表如下：模式字母通常是重复的，其数量确定其精确表示。如下表是常用的输出格式的表示方法。 1.2 时区如何在Java代码中获取不同时区的时间呢？SimpleDateFormat可以实现这个功能。123456public static void main(String[] args)&#123; SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); System.out.println(sdf.format(Calendar.getInstance().getTime())); sdf.setTimeZone(TimeZone.getTimeZone(&quot;America/Los_Angeles&quot;)); System.out.println(sdf.format(Calendar.getInstance().getTime())); &#125; 以上代码，输出的结果 122019-04-24 09:26:382019-04-23 18:26:38 中国的时间第一行，而美国洛杉矶时间比中国北京时间慢了17个小时（这还和冬夏令时有关系）。当然，这不是显示其他时区的唯一方法 2. SimpleDateFormat线程安全性由于SimpleDateFormat比较常用，而且在一般情况下，一个应用中的时间显示模式都是一样的，所以很多人愿意使用如下方式定义SimpleDateFormat：1234567public class Main &#123; private static SimpleDateFormat sdf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); public static void main(String[] args) &#123; sdf.setTimeZone(TimeZone.getTimeZone(\"America/New_York\")); ... &#125;&#125; 这种定义方式，存在很大的线程安全隐患。 2.1 问题重现以下代码使用线程池来执行时间输出。12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class Main &#123; /** * 定义一个全局的SimpleDateFormat */ private static SimpleDateFormat sdf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); /** * 使用ThreadFactoryBuilder定义一个线程池 */ private static ThreadFactory namedThreadFactory = new ThreadFactoryBuilder() .setNameFormat(\"demo-pool-%d\").build(); private static ExecutorService pool = new ThreadPoolExecutor(5, 200, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(1024), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy()); /** * 定义一个CountDownLatch，保证所有子线程执行完之后主线程再执行 */ private static CountDownLatch countDownLatch = new CountDownLatch(100); public static void main(String[] args) &#123; //定义一个线程安全的HashSet Set&lt;String&gt; dates = Collections.synchronizedSet(new HashSet&lt;String&gt;()); for (int i = 0; i &lt; 100; i++) &#123; //获取当前时间 Calendar calendar = Calendar.getInstance(); int finalI = i; pool.execute(() -&gt; &#123; //时间增加 calendar.add(Calendar.DATE, finalI); //通过simpleDateFormat把时间转换成字符串 String dateString = sdf.format(calendar.getTime()); //把字符串放入Set中 dates.add(dateString); //countDown countDownLatch.countDown(); &#125;); &#125; //阻塞，直到countDown数量为0 countDownLatch.await(); //输出去重后的时间个数 System.out.println(dates.size()); &#125;&#125; 以上代码，其实比较容易理解。就是循环一百次，每次循环的时候都在当前时间基础上增加一个天数（这个天数随着循环次数而变化），然后把所有日期放入一个线程安全的、带有去重功能的Set中，然后输出Set中元素个数。 正常情况下，以上代码输出结果应该是100。但是实际执行结果是一个小于100的数字。 原因就是因为SimpleDateFormat作为一个非线程安全的类，被当做了共享变量在多个线程中进行使用，这就出现了线程安全问题。 2.2 线程不安全原因其实，JDK文档中已经明确表明了SimpleDateFormat不应该用在多线程场景中： Date formats are not synchronized.It is recommended to create separate format instances for each thread.If multiple threads access a format concurrently, it must be synchronized externally. 那么为什么会出现这种问题，SimpleDateFormat底层到底是怎么实现的？跟踪一下SimpleDateFormat类中format方法的实现其实就能发现端倪。 1234567891011121314151617181920212223242526272829303132333435363738394041@Overridepublic StringBuffer format(Date date, StringBuffer toAppendTo, FieldPosition pos)&#123; pos.beginIndex = pos.endIndex = 0; return format(date, toAppendTo, pos.getFieldDelegate());&#125;// Called from Format after creating a FieldDelegateprivate StringBuffer format(Date date, StringBuffer toAppendTo, FieldDelegate delegate) &#123; // Convert input date to time field list calendar.setTime(date); boolean useDateFormatSymbols = useDateFormatSymbols(); for (int i = 0; i &lt; compiledPattern.length; ) &#123; int tag = compiledPattern[i] &gt;&gt;&gt; 8; int count = compiledPattern[i++] &amp; 0xff; if (count == 255) &#123; count = compiledPattern[i++] &lt;&lt; 16; count |= compiledPattern[i++]; &#125; switch (tag) &#123; case TAG_QUOTE_ASCII_CHAR: toAppendTo.append((char)count); break; case TAG_QUOTE_CHARS: toAppendTo.append(compiledPattern, i, count); i += count; break; default: subFormat(tag, count, delegate, toAppendTo, useDateFormatSymbols); break; &#125; &#125; return toAppendTo;&#125; SimpleDateFormat中的format方法在执行过程中，会使用一个成员变量calendar来保存时间。这其实就是问题的关键。 由于我们在声明SimpleDateFormat的时候，使用的是static定义的。那么这个SimpleDateFormat就是一个共享变量，随之，SimpleDateFormat中的calendar也就可以被多个线程访问到。 假设线程1刚刚执行完calendar.setTime把时间设置成2018-11-11，还没等执行完，线程2又执行了calendar.setTime把时间改成了2018-12-12。这时候线程1继续往下执行，拿到的calendar.getTime得到的时间就是线程2改过之后的。 除了format方法以外，SimpleDateFormat的parse方法也有同样的问题。 3. 如何解决解决方法有很多，先介绍三个比较常用的方法。 3.1 使用局部变量SimpleDateFormat变成了局部变量，就不会被多个线程同时访问到了，就避免了线程安全问题。1234567891011121314151617for (int i = 0; i &lt; 100; i++) &#123; //获取当前时间 Calendar calendar = Calendar.getInstance(); int finalI = i; pool.execute(() -&gt; &#123; // SimpleDateFormat声明成局部变量 SimpleDateFormat simpleDateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); //时间增加 calendar.add(Calendar.DATE, finalI); //通过simpleDateFormat把时间转换成字符串 String dateString = simpleDateFormat.format(calendar.getTime()); //把字符串放入Set中 dates.add(dateString); //countDown countDownLatch.countDown(); &#125;);&#125; 3.2 加同步锁除了改成局部变量以外，还有一种方法大家可能比较熟悉的，就是对于共享变量进行加锁。12345678910111213141516171819for (int i = 0; i &lt; 100; i++) &#123; //获取当前时间 Calendar calendar = Calendar.getInstance(); int finalI = i; pool.execute(() -&gt; &#123; //时间增加 calendar.add(Calendar.DATE, finalI); //通过simpleDateFormat把时间转换成字符串 //加锁 synchronized (simpleDateFormat) &#123; String dateString = simpleDateFormat.format(calendar.getTime()); &#125; //把字符串放入Set中 dates.add(dateString); //countDown countDownLatch.countDown(); &#125;);&#125; 通过加锁，使多个线程排队顺序执行。避免了并发导致的线程安全问题。 3.3 使用ThreadLocal第三种方式，就是使用 ThreadLocal。 ThreadLocal 可以确保每个线程都可以得到单独的一个 SimpleDateFormat 的对象，那么自然也就不存在竞争问题了。1234567891011/*** 使用ThreadLocal定义一个全局的SimpleDateFormat*/private static ThreadLocal&lt;SimpleDateFormat&gt; simpleDateFormatThreadLocal = new ThreadLocal&lt;SimpleDateFormat&gt;() &#123; @Override protected SimpleDateFormat initialValue() &#123; return new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); &#125;&#125;;//用法String dateString = simpleDateFormatThreadLocal.get().format(calendar.getTime()); 当然，以上代码也有改进空间，就是，其实SimpleDateFormat的创建过程可以改为延迟加载。这里就不详细介绍了。 4. 使用DateTimeFormatter如果是Java8应用，可以使用DateTimeFormatter代替SimpleDateFormat，这是一个线程安全的格式化工具类。12345678910//解析日期String dateStr= \"2016年10月25日\";DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\"yyyy年MM月dd日\");LocalDate date= LocalDate.parse(dateStr, formatter);//日期转换为字符串LocalDateTime now = LocalDateTime.now();DateTimeFormatter format = DateTimeFormatter.ofPattern(\"yyyy年MM月dd日 hh:mm a\");String nowStr = now .format(format);System.out.println(nowStr); 5. 总结本文介绍了SimpleDateFormat的用法，SimpleDateFormat主要可以在String和Date之间做转换，还可以将时间转换成不同时区输出。同时提到在并发场景中SimpleDateFormat是不能保证线程安全的，需要开发者自己来保证其安全性。 主要的几个手段有改为局部变量、使用synchronized加锁、使用Threadlocal为每一个线程单独创建一个和使用Java8中的DateTimeFormatter类代替等。","categories":[{"name":"不知如何分类","slug":"不知如何分类","permalink":"https://zzkenyon.github.io/categories/不知如何分类/"}],"tags":[{"name":"java","slug":"java","permalink":"https://zzkenyon.github.io/tags/java/"}],"keywords":[{"name":"不知如何分类","slug":"不知如何分类","permalink":"https://zzkenyon.github.io/categories/不知如何分类/"}]},{"title":"SpringBoot-单元测试","slug":"SpringBoot-单元测试","date":"2017-06-01T16:00:00.000Z","updated":"2020-05-28T11:23:29.829Z","comments":true,"path":"2017/06/02/SpringBoot-单元测试/","link":"","permalink":"https://zzkenyon.github.io/2017/06/02/SpringBoot-单元测试/","excerpt":"","text":"在开发过程中，如果要测试某个service类的接口，按照以下流程操作： 引入依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; 在单元测试类上添加@SpringTest 和 @RunWith(SpringRunner.class) 两个注解 方法上添加@Test注解，注意是org.junit.jupiter.api.Test 这样就可以正常的将service自动注入进来了 如果要让单元测试事务回滚，只需要让测试类继承AbstractTransactionalJUnit4SpringContextTests类就行了 示例： 123456789101112131415161718@SpringBootTest@RunWith(SpringRunner.class)public class BlogServiceTest extends AbstractTransactionalJUnit4SpringContextTests &#123; @Autowired private BlogService service; @Test public void jdbcTest()&#123; List&lt;Blog&gt; blogs = service.listBlog(); System.out.println(blogs); &#125; @Test public void testDeleteAll()&#123; System.out.println(service.deleteAll()); &#125;&#125; 测试DeleteAll()接口时会删除所有的记录，测试完成会回滚，恢复所有删除的数据。","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/tags/SpringBoot/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/categories/SpringBoot/"}]},{"title":"设计模式-享元模式","slug":"设计模式-享元模式","date":"2017-05-15T16:00:00.000Z","updated":"2021-01-27T06:59:53.908Z","comments":true,"path":"2017/05/16/设计模式-享元模式/","link":"","permalink":"https://zzkenyon.github.io/2017/05/16/设计模式-享元模式/","excerpt":"","text":"结构型—享元模式，提高对象的复用性质，避免创建过多的重复对象 实现方式 池化，将享元对象存放到一个集合中，与工厂方法配合获取/回收享元对象 经典案例：抢票案例、数据库连接池、String字面量管理优化、包装类Integer/Long中的享元模式 两种状态 内部状态：存放在享元对象内部，运行过程中不会随外部环境改变的状态 外部状态：与内部状态相反，在运行中会随时改变的状态，比如连接的isActive状态 优缺点： 优点：减少对象创建，降低内存中的对象数量，降低系统内存占用，提高效率。减少内存之外的其他资源占用（连接池TCP） 缺点：需要关注内部外部状态 、关注线程安全是系统的逻辑复杂化 应用场景： 当系统中多处需要同一组信息时，可以吧这些信息封装一个对象中，然后对该对象尽心缓存，这样一个对象就可以提供给多处使用，避免大量同一对象的多次创建 享元模式就是工厂模式的一个改进机制，享元模式同样要求创建一个或一组对象，并且就是通过工厂方法生成对象的，不过享元模式中为工厂方法增加了缓存这一功能。主要总结为一下应用场景： 用于系统底层开发，以便解决系统性能问题。 系统有大量相似对象，需要缓冲池的场景。 Integer中的享元模式 12345678public static void main(String[] args) &#123; Integer a = 100; Integer b = Integer.valueOf(100); System.out.println(a==b); Integer c = 1000; Integer d = Integer.valueOf(1000); System.out.println(c==d);&#125; 上面代码的结果是 true false 要理解这其中的玄机，我们先看到valueOf的代码： 12345public static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i);&#125; IntegerCache.low = -128 IntegerCache.high = 127 所以当valueOf的参数在-128到127之间的时候，返回的是IntegerCache中缓存的值，否则会新建一个对象。 “==”比较的是引用，两边是同一个对象返回true， 所以引用a,b都是指向缓存中的用一个对象，第一个返回 true 而引用c,d都是指向新建的新对象，不是同一个，所以返回false","categories":[{"name":"源码中的设计模式","slug":"源码中的设计模式","permalink":"https://zzkenyon.github.io/categories/源码中的设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://zzkenyon.github.io/tags/设计模式/"}],"keywords":[{"name":"源码中的设计模式","slug":"源码中的设计模式","permalink":"https://zzkenyon.github.io/categories/源码中的设计模式/"}]},{"title":"设计模式-委派模式","slug":"设计模式-委派模式","date":"2017-05-14T16:00:00.000Z","updated":"2021-01-25T09:18:22.984Z","comments":true,"path":"2017/05/15/设计模式-委派模式/","link":"","permalink":"https://zzkenyon.github.io/2017/05/15/设计模式-委派模式/","excerpt":"","text":"Delegate Pattern 又叫委托模式，是一种面向对象的设计模式，允许对象组合实现与及城乡同的代码重用。它的基本作用就是负责任务的调用和分配，是一种特殊的静态代理，可以理解为全权代理。 代理模式注重过程，委派模式注重结果。委派模式属于行为模式，且不适于GOF23中设计模式之中。 委派模式有三个参与角色： 抽象任务角色 委派者角色 具体任务角色 类图： 优点：通过任务委派能够将一个大型的任务细化，然后通过统一管理这些子任务的完成情况实现任务的跟进，能够加快任务执行的效率。 缺点：需要根据任务的复杂程度进行不同的改变，在任务比较复杂的情况下，可能需要进行多重委派，容易造成紊乱 举例： 1、JDK有一个典型的委派，那就是类加载时的双亲委派机制， 2、在Spring IoC中，在调用doRegisterBeanDefinitions()方法时，会设置BeanDefinitionParserDelegate类型的Delegate对象给this.delegate，并将这个对象作为参数传给parserBeanDefinitions(root,this.delegate)中，然后主要的解析工作就是通过Delegate完成的","categories":[{"name":"源码中的设计模式","slug":"源码中的设计模式","permalink":"https://zzkenyon.github.io/categories/源码中的设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://zzkenyon.github.io/tags/设计模式/"}],"keywords":[{"name":"源码中的设计模式","slug":"源码中的设计模式","permalink":"https://zzkenyon.github.io/categories/源码中的设计模式/"}]},{"title":"设计模式之策略模式","slug":"设计模式之策略模式","date":"2017-05-14T03:17:23.000Z","updated":"2020-05-22T11:58:05.154Z","comments":true,"path":"2017/05/14/设计模式之策略模式/","link":"","permalink":"https://zzkenyon.github.io/2017/05/14/设计模式之策略模式/","excerpt":"","text":"文章以jdk并发包中的一个策略模式实现作为开篇。 使用线程池处理并发任务时，当用户提交任务到线程池，线程池因为线程池已满或者线程池处于SHUTDOWN状态拒接任务的时候，会调用reject函数对任务进行后处理，代码如下： 123456789代码摘自：java.util.concurrent.ThreadPoolExecutorprivate volatile RejectedExecutionHandler handler;private static final RejectedExecutionHandler defaultHandler = new AbortPolicy(); final void reject(Runnable command) &#123; handler.rejectedExecution(command, this);&#125; 在线程池创建的时候，用户会初始化handler变量，或者使用默认的初始化defaultHandler，即AbortPolicy对象，AbortPolicy就是策略的一种实现，该策略丢弃被拒绝的任务，并抛出RejectedExecutionException异常。12345678910代码摘自：java.util.concurrent.ThreadPoolExecutorpublic static class AbortPolicy implements RejectedExecutionHandler &#123; public AbortPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; throw new RejectedExecutionException(\"Task \" + r.toString() + \" rejected from \" + e.toString()); &#125;&#125; 策略接口类：12345代码摘自：java.util.concurrent.RejectedExecutionHandlerpublic interface RejectedExecutionHandler &#123; void rejectedExecution(Runnable r, ThreadPoolExecutor executor);&#125; 所有的后处理策略都要实现该接口，ThreadPoolExecutor持有改接口对象，在初始化ThreadPoolExecutor的时候再指定使用哪种策略，下面我们看一下其他策略源码： 12345678910111213141516171819202122232425//该策略直接调用被拒绝任务的Run函数强制执行任务public static class CallerRunsPolicy implements RejectedExecutionHandler &#123; public CallerRunsPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; r.run(); &#125; &#125;&#125;//该策略忽略被拒任务，不做任何处理public static class DiscardPolicy implements RejectedExecutionHandler &#123; public DiscardPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; &#125;&#125;//该策略丢弃阻塞队列中等待最久的任务（下一个被执行的任务），再次提交被拒任务public static class implements RejectedExecutionHandler &#123; public DiscardOldestPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; e.getQueue().poll(); e.execute(r); &#125; &#125;&#125; 到此我们可以画一个简单的类图表示上述类型之间的关系：可以说这是一个很典型的策略模式类图了。 策略模式其思想是针对一组算法，将每一种算法都封装到具有共同接口的独立的类中，从而是它们可以相互替换。策略模式的最大特点是使得算法可以在不影响客户端的情况下发生变化，从而改变不同的功能。 下图所示为策略模式的UML图，上文所述的ThreadPoolExecutor就是Context，contextInterface指的就是reject函数。 策略模式的优缺点 优点 策略模式提供了管理相关的算法族的办法。策略类的等级结构定义了一个算法或行为族。恰当使用继承可以把公共的代码转移到父类里面，从而避免重复的代码。 策略模式提供了可以替换继承关系的办法。继承可以处理多种算法或行为。如果不是用策略模式，那么使用算法或行为的环境类就可能会有一些子类，每一个子类提供一个不同的算法或行为。但是，这样一来算法或行为的使用者就和算法或行为本身混在一起。决定使用哪一种算法或采取哪一种行为的逻辑就和算法或行为的逻辑混合在一起，从而不可能再独立演化。继承使得动态改变算法或行为变得不可能。 使用策略模式可以避免使用多重条件转移语句。多重转移语句不易维护，它把采取哪一种算法或采取哪一种行为的逻辑与算法或行为的逻辑混合在一起，统统列在一个多重转移语句里面，比使用继承的办法还要原始和落后。 缺点 客户端必须知道所有的策略类，并自行决定使用哪一个策略类。这就意味着客户端必须理解这些算法的区别，以便适时选择恰当的算法类。换言之，策略模式只适用于客户端知道所有的算法或行为的情况。 策略模式造成很多的策略类，每个具体策略类都会产生一个新类。有时候可以通过把依赖于环境的状态保存到客户端里面，而将策略类设计成可共享的，这样策略类实例可以被不同客户端使用。换言之，可以使用享元模式来减少对象的数量。 应用场景 多个类只区别在表现行为不同，可以使用Strategy模式，在运行时动态选择具体要执行的行为。 需要在不同情况下使用不同的策略(算法)，或者策略还可能在未来用其它方式来实现。 对客户隐藏具体策略(算法)的实现细节，彼此完全独立。 参考文档：www.w3sdesign.com/strategy_design_pattern.php","categories":[{"name":"源码中的设计模式","slug":"源码中的设计模式","permalink":"https://zzkenyon.github.io/categories/源码中的设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://zzkenyon.github.io/tags/设计模式/"}],"keywords":[{"name":"源码中的设计模式","slug":"源码中的设计模式","permalink":"https://zzkenyon.github.io/categories/源码中的设计模式/"}]},{"title":"SpringBoot-入门注解介绍","slug":"SpringBoot-入门注解介绍","date":"2017-05-11T16:00:00.000Z","updated":"2020-05-28T11:22:59.805Z","comments":true,"path":"2017/05/12/SpringBoot-入门注解介绍/","link":"","permalink":"https://zzkenyon.github.io/2017/05/12/SpringBoot-入门注解介绍/","excerpt":"","text":"@SpringBootApplication我们经常直接将@SpringBootApplication打在了主类上，其实更加清晰的写法应该是将主类和SpringBoot配置类分开，如下所示： 123456789@SpringBootApplicationpublic class SBConfiguration &#123;&#125;public class SBApplication &#123; public static void main(String args[]) throws Exception&#123; SpringApplication.run(SBConfiguration.class, args); &#125;&#125; 如此一来，就能比较清晰的看出主类SBApplication只是程序的入口，没有什么特殊的。调用了SpringApplication的静态方法run，并使用SpringBoot主配置类SBConfigration.class作为参数。 主配置类就是打上@SpringBootApplication注释的类，首先看一下注释SpringBootApplication的代码： 12345678910111213141516@Target(&#123;ElementType.TYPE&#125;) //表示该注解只能用于类型@Retention(RetentionPolicy.RUNTIME)//表示该注解的生命周期可以维持到运行时@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan( excludeFilters = &#123;@Filter( type = FilterType.CUSTOM, classes = &#123;TypeExcludeFilter.class&#125; ), @Filter( type = FilterType.CUSTOM, classes = &#123;AutoConfigurationExcludeFilter.class&#125; )&#125;)public @interface SpringBootApplication &#123;&#125; 这是一个复合注释，其中@SpringBootConfiguration代表了SpringBoot的配置类，除了测试时有些区别，大体上就是Spring标准@Configuration的替代品。 @EnableAutoConfiguration用于启动SpringBoot的自动配置机制，这是SpringBoot的核心特色之一，自动对各种机制进最大可能的进行配置。 @ComponentScan是Spring原来就有的注释，用于对指定的路径进行扫描，并将其中的@Configuration配置类加载。接下来分别对其一一介绍。 @SpringBootConfiguration123456@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Configurationpublic @interface SpringBootConfiguration &#123;&#125; 从代码可见，其本质上就是一个@Configuration。唯一不同的地方是在测试时，如果打上了@SpringBootConfiguration注释，那么SpringBootTest中并不需要指定就可以自动加载该配置类；而当打上@Configuration时，需要通过@SpringBootTest(classes = SBConfiguration.class)来指定加载的SpringBoot配置类。 若不考虑测试时非要省略指定Configuration类的话，该注释可有可无。因为在作为参数传递给SpringApplication.run方法后，只要其中配置了@Bean方法，就会直接被认为是一个配置类进行加载处理，并不需要@Configuration来标识。 @EnableAutoConfigurationEnableAutoConfiguration自动配置机制是SpringBoot的核心特色之一。可根据引入的jar包对可能需要的各种机制进进行默认配置。 该注释的定义如下： 12345678910@SuppressWarnings(\"deprecation\")@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(EnableAutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; ..........&#125; 其中@AutoConfigurationPackage用来指示打了该注解的类的包（package）应该被注册到AutoConfigurationPackages中，以备后续扩展机制（例如JPA或Mybatis等）的实体扫描器使用。 @EnableAutoConfiguration真正核心的动作就是通过Import机制加载EnableAutoConfigurationImportSelector.selectImports函数返回的配置类： 123456789101112131415161718192021222324、、org.springframework.boot.autoconfigurepublic String[] selectImports(AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return NO_IMPORTS; &#125; try &#123; AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader .loadMetadata(this.beanClassLoader); AnnotationAttributes attributes = getAttributes(annotationMetadata); List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); configurations = removeDuplicates(configurations); configurations = sort(configurations, autoConfigurationMetadata); Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); configurations = filter(configurations, autoConfigurationMetadata); fireAutoConfigurationImportEvents(configurations, exclusions); return configurations.toArray(new String[configurations.size()]); &#125; catch (IOException ex) &#123; throw new IllegalStateException(ex); &#125;&#125; 其中比较核心的动作为getCandidateConfigurations(annotationMetadata, attributes)，代码如下： 123456789101112protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) &#123; List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames( getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader()); Assert.notEmpty(configurations, \"No auto configuration classes found in META-INF/spring.factories. If you \" + \"are using a custom packaging, make sure that file is correct.\"); return configurations;&#125;protected Class&lt;?&gt; getSpringFactoriesLoaderFactoryClass() &#123; return EnableAutoConfiguration.class;&#125; 我们注意： 12List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames( getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader()); 这句，SpringFactoriesLoader是spring framework内部使用的通用的工厂加载机制，其可加载并实例化可能出现在classpath上的多个jar包中的META-INF/spring.factories文件中定义的指定类型的工厂，可视为一种类似于SPI的接口。 SpringBoot利用这种SPI接口实现了autoconfiguration机制：委托SpringFactoriesLoader来加载所有配置在META-INF/spring.factories中的org.springframework.boot.autoconfigure.EnableAutoConfiguration对应的值，spring-boot-autoconfiguration jar包中的META-INF/spring.factories中的EnableAutoConfiguration配置摘录如下： 12345678910# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\\org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\\org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\\org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\\org.springframework.boot.autoconfigure.cloud.CloudAutoConfiguration,\\.......................... 其中我们可以看到相当多非常熟悉的自动配置类，例如AopAutoConfiguration、CacheAutoConfiguration等等。其中的每一个自动配置类都会在一定条件（@Condition）下启动生效，并对相关的机制进行默认自动的配置。这便是SpringBoot自动配置机制的核心功能所在。 @ComponentScan这是spring-context原来就存在的注释，需要在@Configuration标注的类上标注，用来指示扫描某些包及其子包上的组件。可通过配置属性basePackageClasses、basePackages或value来指出需要扫描哪些包（包括其子包），如果没有指定任何一个属性值，则默认扫描当前包及其子包。 例如，在前面例子中，如果SBConfiguration所在的包是springbootext，那么由于SBConfiguration打了@ComponentScan注释，那么在springbootext、springbootext.service、springbootext.config等等地方定义的@Configuration、@Component、@Service、@Controller等等组件都可以直接被加载，无需额外配置。而在anotherpackage中定义的组件，无法被直接加载。可以通过设置扫描路径来解决： 1234@EnableAutoConfiguration@ComponentScan(basePackages=&#123;&quot;springbootext&quot;, &quot;anotherpackage&quot;&#125;)public class SBConfiguration&#123;&#125; 当然也可以通过借助3.2节中介绍的在spring.factories中定义扩展机制定义EnableAutoConfiguration来实现加载。 启动过程中@ComponentScan起作用的时机是在springcontext refresh主流程的invokeBeanFactoryPostProcessor阶段，也就是BeanFactory创建并准备完毕后通过BeanFactoryPostProcessors来进一步对beanFactory进行处理的阶段。 在该阶段，ConfigurationClassPostProcessor中对于Configuration类的处理里包括了识别其打的@ComponentScan注释，并委托ComponentScanAnnotationParser根据该注释的属性值进行组件扫描。将扫描生成的beanDefinitions注册到beanFactory中供下一个阶段创建beans。 @Conntroller@Conntroller注解在类上，表名这个类是MVC里的Controller，并将其声明为Spring中的一个Bean，Dispatcher Servlet会自动扫描注解了@Conntroller的类，并将Web请求映射到注解了@ResquesrMapping的方法。 Ps: 在声明普通Bean时，使用@Component、@Service、@Repository和@Conntroller是等同的（@Service、@Repository和@Conntroller都组合了@Component元注解），但是在MVC声明控制器的时候，只能使用@Conntroller。 @RequestMapping@RequestMapping注解用来映射Web请求(访问路径和参数)到处理类和方法的。可注解到方法上，也可以注解在类上（方法会继承类上的注解）。 @ResponseBody和@RequestBody@ResponseBody该注解用于将Controller的方法返回的对象，注解到方法返回值前面或者方法前面，通过HttpMessageConverter接口转换为指定格式的数据如：json,xml等，通过Response响应给客户端。 解析：在使用@RequestMapping后，返回值通常解析为跳转路径，加上@Responsebody后返回结果不会被解析为跳转路径，而是直接写入HTTP 响应正文中。 @RequestBody注解用于读取http请求的内容(字符串)，注解到想要获取的参数前面，通过springmvc提供的HttpMessageConverter接口将读到的内容转换为json、xml等格式的数据并绑定到controller方法的参数上。 @RequestMapping(value = “person/login”) @ResponseBody public Person login(@RequestBody Person person) { // 将请求中的datas写入 Person 对象中 return person; // 不会被解析为跳转路径，而是直接写入 HTTP 响应正文中 } @RequestBody注解会根据content-type选择对应的MessageConverter对请求中的数据进行处理(与对象绑定或解绑) ps:GetMapping 不支持@RequestBody @PathVariable@PathVariable用来接收路径参数，如/new/001，可接收001作为参数，此注解放置在参数前。 @RequestMapping(value = “person/profile/{id}/{name}/{status}”) @ResponseBody public Person porfile(@PathVariable int id, @PathVariable String name, @PathVariable boolean status) { ​ return new Person(id, name, status); } @RequestMapping(value = “/person/profile/{id}/{name}/{status}”) 中的 {id}/{name}/{status}与 @PathVariable int id、@PathVariable String name、@PathVariable boolean status一一对应，按名匹配。 @RequestParam@ExceptionHandler和@ResponseStatus@ExceptionHandler注解在方法上，捕获并处理controller中抛出的异常 当一个Controller中有多个HandleException注解出现时，那么异常被哪个方法捕捉呢？这就存在一个优先级的问题。 ExceptionHandler的优先级是：在异常的体系结构中，哪个异常与目标方法抛出的异常血缘关系越紧密，就会被哪个捕捉到。 @ResponseStatus可以注解到异常类上或者注解到具体的处理函数上。 @ControllerAdvice介绍 是Spring3.2提供的新注解，注解在类上，通过@ControllerAdvice可以将对于控制器的全局配置放到同一个位置上。 @ControllerAdvice是一个@Component，使用context:component-scan扫描时也能扫描到。主要用于定义@ExceptionHandler，@InitBinder和@ModelAttribute方法，适用于所有使用@RequestMapping方法。 据经验之谈，只有配合@ExceptionHandler最有用，其它两个不常用。","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/tags/SpringBoot/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zzkenyon.github.io/categories/SpringBoot/"}]},{"title":"linux命令-tail","slug":"linux命令-tail","date":"2017-04-23T07:52:38.000Z","updated":"2019-05-23T03:03:01.787Z","comments":true,"path":"2017/04/23/linux命令-tail/","link":"","permalink":"https://zzkenyon.github.io/2017/04/23/linux命令-tail/","excerpt":"","text":"tail显示文件的末尾部分，默认显示10行 举例：看日志文件时 1tail -fn 30 xxxx.log","categories":[],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://zzkenyon.github.io/tags/linux命令/"}],"keywords":[]},{"title":"linux命令-nohup","slug":"linux命令-nohup","date":"2017-04-23T07:39:40.000Z","updated":"2019-05-23T03:03:26.891Z","comments":true,"path":"2017/04/23/linux命令-nohup/","link":"","permalink":"https://zzkenyon.github.io/2017/04/23/linux命令-nohup/","excerpt":"","text":"nohup 是 no hang up 的缩写，就是不挂断的意思。 nohup命令：如果你正在运行一个进程，而且你觉得在退出帐户时该进程还不会结束，那么可以 使用nohup命令,该命令可以在你退出帐户/关闭终端之后继续运行相应的进程。 在缺省情况下该作业的所有输出都被重定向到一个名为nohup.out的文件中。nohup 命令运行由 Command参数和任何相关的Arg参数指定的命令，忽略所有挂断（SIGHUP）信号。在注销后使用 nohup 命令运行后台中的程序。要运行后台中的 nohup 命令，添加 &amp; （表示“and”的符号）到命令的尾部。 案例1. nohup command &gt; myout.file 2&gt;&amp;1 &amp;在上面的例子中，0 – stdin (standard input)，1 – stdout (standard output)，2 – stderr (standard error) ；2&gt;&amp;1是将标准错误（2）重定向到标准输出（&amp;1），标准输出（&amp;1）再被重定向输入到myout.file文件中。 2. 0 22 * /usr/bin/python /home/pu/download_pdf/download_dfcf_pdf_to_oss.py &gt; /home/pu/download_pdf/download_dfcf_pdf_to_oss.log 2&gt;&amp;1这是放在crontab中的定时任务，晚上22点时候怕这个任务，启动这个python的脚本，并把日志写在download_dfcf_pdf_to_oss.log文件中 nohup和&amp;的区别&amp; ： 指在后台运行nohup ： 不挂断的运行，注意并没有后台运行的功能，就是指用nohup运行命令可以使命令永久的执行下去，和用户终端没有关系，例如我们断开SSH连接都不会影响他的运行 例如： sh test.sh &amp;将sh test.sh任务放到后台 ，关闭xshell，对应的任务也跟着停止。 nohup sh test.sh将sh test.sh任务放到后台，关闭标准输入，终端不再能够接收任何输入（标准输入），重定向标准输出和标准错误到当前目录下的nohup.out文件，即使关闭xshell退出当前session依然继续运行。 nohup sh test.sh &amp;将sh test.sh任务放到后台，但是依然可以使用标准输入，终端能够接收任何输入，重定向标准输出和标准错误到当前目录下的nohup.out文件，即使关闭xshell退出当前session依然继续运行。","categories":[],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://zzkenyon.github.io/tags/linux命令/"}],"keywords":[]},{"title":"postgreSQL让主键自增","slug":"数据库技术-postgreSQL-让主键自增","date":"2017-03-21T01:48:56.000Z","updated":"2020-05-22T12:18:09.521Z","comments":true,"path":"2017/03/21/数据库技术-postgreSQL-让主键自增/","link":"","permalink":"https://zzkenyon.github.io/2017/03/21/数据库技术-postgreSQL-让主键自增/","excerpt":"","text":"1.建表时创建12345678CREATE TABLE test( test_id SERIAL primary key , test_name character varying, contactname character varying, phone character varying, country character varying ) 2.在已建表的情况下创建12345678CREATE SEQUENCE test_id_seq START WITH 1 INCREMENT BY 1 NO MINVALUE NO MAXVALUE CACHE 1; alter table test alter column id set default nextval(&apos;test_id_seq&apos;);","categories":[{"name":"数据库技术","slug":"数据库技术","permalink":"https://zzkenyon.github.io/categories/数据库技术/"}],"tags":[{"name":"postgreSQL","slug":"postgreSQL","permalink":"https://zzkenyon.github.io/tags/postgreSQL/"}],"keywords":[{"name":"数据库技术","slug":"数据库技术","permalink":"https://zzkenyon.github.io/categories/数据库技术/"}]},{"title":"设计模式-七大设计原则","slug":"设计模式-七大设计原则","date":"2017-03-12T16:00:00.000Z","updated":"2021-01-25T09:16:23.061Z","comments":true,"path":"2017/03/13/设计模式-七大设计原则/","link":"","permalink":"https://zzkenyon.github.io/2017/03/13/设计模式-七大设计原则/","excerpt":"","text":"1、合成复用原则合成复用原则（Composite/Aggregate Reuse Principle，CARP） 是指尽量使用对象组合（has-a）/ 聚合（contanis-a），而不是继承关系（is-a）达到软件复用的目的。 可以使系统更加灵活，降低类与类之间的耦合度，一个类的变化对其他类造成的影响相对较少。 继承我们叫做白箱复用，相当于把所有的实现细节暴露给子类。组合/聚合也称之为黑箱复用，对类 以外的对象是无法获取到实现细节的。要根据具体的业务场景来做代码设计，其实也都需要遵循 OOP 模型。 2、里式替换原则里氏替换原则（Liskov Substitution Principle，LSP） 是指如果对每一个类型为 T1 的对象 o1，都有类型为 T2 的对象 o2，使得以 T1 定义的所有程序 P 在所有的对象 o1 都替换成 o2 时，程序 P 的行为没有发生变化，那么类型 T2 是类型 T1 的子类型。 定义看上去还是比较抽象，我们重新理解一下，可以理解为一个软件实体如果适用一个父类的话， 那一定是适用于其子类，所有引用父类的地方必须能透明地使用其子类的对象，子类对象能够替换父类对象，而程序逻辑不变。 根据这个理解，我们总结一下： 引申含义：子类可以扩展父类的功能，但不能改变父类原有的功能。 子类可以实现父类的抽象方法，但不能覆盖父类的非抽象方法。 子类中可以增加自己特有的方法。 当子类的方法重载父类的方法时，方法的前置条件（即方法的输入/入参）要比父类方法的输入参数更宽松（能覆盖父类原方法的入参）。 当子类的方法实现父类的方法时（重写/重载或实现抽象方法），方法的后置条件（即方法的输出/返回值）要比父类更严格或相等。 使用里氏替换原则有以下优点: 约束继承泛滥，开闭原则的一种体现。 加强程序的健壮性，同时变更时也可以做到非常好的兼容性，提高程序的维护性、扩展性。降低 需求变更时引入的风险。 以上两条总结：当我们复用代码时，先遵循合成复用原则，首先使用合成复用方式；如一定要使用继承方式，那么继承时一定要遵循里式替换原则，对继承进行一些约束。 3、迪米特法则迪米特原则（Law of Demeter，LoD） 是指一个对象应该对其他对象保持最少的了解，又叫最少知道原则（Least Knowledge Principle，LKP），尽量降低类与类之间的耦合。迪米特原则主要强调只和朋友交流，不和陌生人说话。出现在成员变量、方法的输入参数、输出结果中的类都可以称之为成员朋友类， 而出现在方法体内部的类不属于朋友类。 4、接口隔离原则接口隔离原则（Interface Segregation Principle， ISP） 是指用多个专门的接口，而不使用单一的 总接口，客户端不应该依赖它不需要的接口。这个原则指导我们在设计接口时应当注意一下几点： 一个类对一类的依赖应该建立在最小的接口之上。 建立单一接口，不要建立庞大臃肿的接口。 尽量细化接口，接口中的方法尽量少（不是越少越好，一定要适度）。 接口隔离原则符合我们常说的高内聚低耦合的设计思想，从而使得类具有很好的可读性、可扩展性和可维护性。我们在设计接口的时候，要多花时间去思考，要考虑业务模型，包括以后有可能发生变更的地方还要做一些预判。所以，对于抽象，对业务模型的理解是非常重要的。 5、依赖倒置原则依赖倒置原则（Dependence Inversion Principle，DIP） 是指设计代码结构时，高层模块不应该依赖底层模块，二者都应该依赖其抽象。抽象不应该依赖细节；细节应该依赖抽象。通过依赖倒置，可以减少类与类之间的耦合性，提高系统的稳定性，提高代码的可读性和可维护性，并能够降低修改程序所造成的风险。 6、开闭原则开闭原则（Open-Closed Principle， OCP） 是指一个软件实体如类、模块和函数应该对扩展开放， 对修改关闭。 所谓的开闭，也正是对扩展和修改两个行为的一个原则。强调的是用抽象构建框架，用实现扩展细节。可以提高软件系统的可复用性及可维护性。开闭原则，是面向对象设计中最基础的设计原则。它指导我们如何建立稳定灵活的系统，例如：我们版本更新，我尽可能不修改源代码，但是可以增 加新功能。 7、单一职责原则单一职责（Simple Responsibility Pinciple，SRP） 是指不要存在多于一个导致类变更的原因。假设我们有一个 Class 负责两个职责，一旦发生需求变更，修改其中一个职责的逻辑代码，有可能会导致 另一个职责的功能发生故障。这样一来，这个 Class 存在两个导致类变更的原因。 如何解决这个问题呢? 我们就要给两个职责分别用两个 Class 来实现，进行解耦。后期需求变更维护互不影响。这样的设计， 可以降低类的复杂度，提高类的可读性，提高系统的可维护性，降低变更引起的风险。总体来说就是一 个Class/Interface/Method 只负责一项职责。","categories":[{"name":"源码中的设计模式","slug":"源码中的设计模式","permalink":"https://zzkenyon.github.io/categories/源码中的设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://zzkenyon.github.io/tags/设计模式/"}],"keywords":[{"name":"源码中的设计模式","slug":"源码中的设计模式","permalink":"https://zzkenyon.github.io/categories/源码中的设计模式/"}]},{"title":"java-移位操作符","slug":"java-移位操作符","date":"2016-12-23T13:00:45.000Z","updated":"2021-01-12T07:27:23.186Z","comments":true,"path":"2016/12/23/java-移位操作符/","link":"","permalink":"https://zzkenyon.github.io/2016/12/23/java-移位操作符/","excerpt":"","text":"在java代码优化时一般会遵循一个原则， 尽量使用移位来代替’a/b’和’a*b’的操作，这两个操作代价很高，使用移位操作将会更快更有效。 1、三种移位操作 “&lt;&lt;” 不带符号左移，符号位不动，低位补0，高位丢失 “&gt;&gt;” 不带符号右移，符号位不动，正数高位补0，负数高位补1(机器数为补码)，低位丢失 “&gt;&gt;&gt;” 带符号右移，高位补0，低位丢失 2、五种左操作数类型左操作数有五种：long, int, short, byte, char int 移位时左操作数是32位的，此时移位操作作用到32bit上 long 移位时做操作数是64位的，此时移位操作作用到32bit上 short byte char 在移位之前先将左操作数转换成int，然后在32bit上进行移位最终得到一个int类型，所以用&gt;&gt;=,&gt;&gt;&gt;=, &lt;&lt;= 其实是将得到的int做低位截取得到的数值，这里往往容易犯错。 3、右操作数有坑 如果左操作数（转换之后的）是int,那么右操作数只有低5位有效，因为int只有32位，低5位最多可以移动31位 如果左边操作数是long，那么右边操作数只有低6位有效，同理 4、移位操作是对补码进行的 正数的 补码 = 原码 负数的 补码 = 反码 + 1 补码的补码等于原码","categories":[{"name":"不知如何分类","slug":"不知如何分类","permalink":"https://zzkenyon.github.io/categories/不知如何分类/"}],"tags":[{"name":"java","slug":"java","permalink":"https://zzkenyon.github.io/tags/java/"}],"keywords":[{"name":"不知如何分类","slug":"不知如何分类","permalink":"https://zzkenyon.github.io/categories/不知如何分类/"}]},{"title":"设计模式之代理模式","slug":"设计模式之代理模式","date":"2016-08-19T13:23:12.000Z","updated":"2021-01-27T12:09:15.834Z","comments":true,"path":"2016/08/19/设计模式之代理模式/","link":"","permalink":"https://zzkenyon.github.io/2016/08/19/设计模式之代理模式/","excerpt":"","text":"代理模式提供了目标对象另外的访问方式，在不修改目标类型的基础上对目标类型进行扩展，符合设计模式中遵循的开闭原则，对扩展开放，对修改关闭。 1. 静态代理静态代理在使用时需要定义接口或者超类，被代理对象与代理对象一起实现同一个接口或者是继承同一个超类。 下面举个例子说明：我们在购买火车票时可以到火车站购买，也可到各个代售点购买，火车站就是目标对象，代售点即是代理对象，他们都能完成购票，最主要的是代售点使用的售票接口就是车站官方的售票接口。 票务接口 TicketService.java1234public interface TicketService&#123; void buyTicket(); void refund();//退票&#125; 目标对象车站 Station.java12345678public class Station implement TicketService&#123; public void buyTicket()&#123; System.out.println(\"----买票-----\"); &#125; public void refund()&#123; System.out.println(\"----退票----\"); &#125;&#125; 代理对象代售处 Agency.java12345678910public class Agency implement TicketService&#123; private Station station; public void buyTicket()&#123; System.out.println(\"----这里是代售点-----\"); station.buyTicket(); &#125; public void refund()&#123; System.out.println(\"----代售点不支持退票----\") &#125;&#125; 静态代理可以在不修改目标对象的前提下对目标扩展，但也存在缺点。 因为代理对象需要与目标对象实现一样的接口,所以会有很多代理类,类太多；此外，一旦接口增加方法,目标对象与代理对象都要维护。那么如何解决这些缺点呢，JDK中给出了动态代理的解决方案。 2. JDK动态代理又叫做接口代理 特点： 被代理对象需要实现接口 代理对象的生成，是利用JDK中的api，动态的在内存中构建代理对象（需要我们指定创建代理对象/目标对象实现的接口类型） 2.1 使用JDK中生成代理对象的API代理类所在包:java.lang.reflect.ProxyJDK实现代理只需要使用newProxyInstance方法，但是该方法需要接收三个参数，完整的写法是: 1static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces,InvocationHandler h ) 注意该方法是在Proxy类中是静态方法,且接收的三个参数依次为: ClassLoader loader：指定当前目标对象使用类加载器,获取加载器的方法是固定的 Class&lt;?&gt;[] interfaces：目标对象实现的接口的类型,使用泛型方式确认类型 InvocationHandler h：事件处理,执行目标对象的方法时，会触发事件处理器的方法，会把当前执行目标对象的方法作为参数传入。 代码示例:接口类 TicketService.java以及接口实现类,目标对象Station是一样的，没有做修改。在这个基础上，增加一个代理工厂类(ProxyFactory.java)，将代理类写在这个地方，然后在测试类(需要使用到代理的代码)中先建立目标对象和代理对象的联系，然后代用代理对象的中同名方法代理工厂类:ProxyFactory.java 1234567891011121314151617181920212223242526public class ProxyFactory&#123; //维护一个目标对象 private Object target; public ProxyFactory(Object target)&#123; this.target=target; &#125; //给目标对象生成代理对象 public Object getProxyInstance()&#123; return Proxy.newProxyInstance( target.getClass().getClassLoader(), target.getClass().getInterfaces(), new InvocationHandler() &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(\"--这是代售点购票系统--\"); //执行目标对象方法 Object returnValue = method.invoke(target, args); return returnValue; &#125; &#125; ); &#125;&#125; 测试类:DynamicProxyTest.java123456789101112public class DynamicProxyTest &#123; public static void main(String[] args) &#123; // 目标对象 TicketService target = new Station(); System.out.println(target.getClass()); // 创建代理对象 TicketService proxy = (TicketService) new ProxyFactory(target).getProxyInstance(); System.out.println(proxy.getClass()); // 代理对象执行方法 proxy.buyTicket(); &#125;&#125; 总结：代理对象不需要实现接口，但是目标对象一定要实现接口，否则不能用动态代理。 2.2 原理3. Cglib动态代理3.1 使用上面的静态代理和动态代理模式都是要求目标对象是实现一个接口的目标对象，但是有时候目标对象只是一个单独的对象,并没有实现任何的接口，这个时候就可以使用以目标对象子类的方式类实现代理，这种方法就叫做:Cglib代理 Cglib代理，也叫作子类代理，它是在内存中构建一个子类对象从而实现对目标对象功能的扩展。 JDK的动态代理有一个限制，就是使用动态代理的对象必须实现一个或多个接口，如果想代理没有实现接口的类,就可以使用Cglib实现。 Cglib是一个强大的高性能的代码生成包，它可以在运行期扩展java类与实现java接口。它广泛的被许多AOP的框架使用，例如Spring AOP和synaop，为他们提供方法的interception(拦截)。 Cglib包的底层是通过使用一个小而块的字节码处理框架ASM来转换字节码并生成新的类。不鼓励直接使用ASM,因为它要求你必须对JVM内部结构包括class文件的格式和指令集都很熟悉。 Cglib子类代理实现方法: 需要引入cglib的jar文件，但是Spring的核心包中已经包括了Cglib功能,所以直接引入pring-core-3.2.5.jar即可。 引入功能包后，就可以在内存中动态构建子类 代理的类不能为final，否则报错 目标对象的方法如果为final/stati，那么就不会被拦截，即不会执行目标对象额外的业务方法。 代码示例:目标对象类 Station.java ，目标对象,没有实现任何接口123456public class Station &#123; public void buyTicket() &#123; System.out.println(\"----买票----\"); &#125;&#125; Cglib代理工厂 ProxyFactory.java123456789101112131415161718192021222324252627public class ProxyFactory implements MethodInterceptor&#123; private Object target; public ProxyFactory(Object target) &#123; this.target = target; &#125; //给目标对象创建一个代理对象 public Object getProxyInstance()&#123; //1.工具类 Enhancer en = new Enhancer(); //2.设置父类 en.setSuperclass(target.getClass()); //3.设置回调函数 en.setCallback(this); //4.创建子类(代理对象) return en.create(); &#125; @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; System.out.println(\"--这是代售点购票系统--\"); //执行目标对象的方法 Object returnValue = method.invoke(target, args); return returnValue; &#125;&#125; 测试类:1234567891011public class CglibProxyTest &#123; @Test public void test()&#123; //目标对象 Station target = new Station(); //代理对象 Station proxy = (Station)new ProxyFactory(target).getProxyInstance(); //执行代理对象的方法 proxy.buyTicket(); &#125;&#125; 在Spring的AOP编程中:如果加入容器的目标对象有实现接口，用JDK代理如果目标对象没有实现接口，用Cglib代理 3.2 原理","categories":[{"name":"源码中的设计模式","slug":"源码中的设计模式","permalink":"https://zzkenyon.github.io/categories/源码中的设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://zzkenyon.github.io/tags/设计模式/"}],"keywords":[{"name":"源码中的设计模式","slug":"源码中的设计模式","permalink":"https://zzkenyon.github.io/categories/源码中的设计模式/"}]},{"title":"设计模式之单例模式","slug":"设计模式之单例模式","date":"2016-08-04T07:15:31.000Z","updated":"2020-05-22T11:57:51.545Z","comments":true,"path":"2016/08/04/设计模式之单例模式/","link":"","permalink":"https://zzkenyon.github.io/2016/08/04/设计模式之单例模式/","excerpt":"","text":"许多时候整个系统只需要拥有一个的全局对象，这样有利于我们协调系统整体的行为。比如在某个服务器程序中，该服务器的配置信息存放在一个文件中，这些配置数据由一个单例对象统一读取，然后服务进程中的其他对象再通过这个单例对象获取这些配置信息。这种方式简化了在复杂环境下的配置管理。 1、什么是单例1.1 定义单例模式，也叫单子模式，是一种常用的软件设计模式。在应用这个模式时，单例对象的类必须保证只有一个实例存在。 1.2 实现思路面向对象编程中，我们通过类的构造器生成对象，只要内存足够就可以构造出很多个实例，所以要限制某个类型只有唯一的一个实例对象，那就要从构造函数着手。 需要声明一个能返回对象的引用，定义一个获得该对象引用的方法（必须是静态方法，通常使用getInstance这个名称) 当我们调用这个方法时，如果类持有的引用不为空就返回这个引用，如果类保持的引用为空就创建该类的实例并将实例的引用赋予该类保持的引用 最后将该类的构造函数定义为私有方法 2、懒汉式单例按照以上的实现思路，实现出第一个单例类型：1234567891011public class Singleton &#123; private static Singleton instance; //引用 private Singleton ()&#123;&#125; //私有构造器 public static Singleton getInstance() &#123; //静态方法 if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; &#125; 这种实现方式称为懒汉式，所谓懒汉，指的是只有在需要对象的时候才生成。 2.1 单例的线程安全单例的线程安全是指在并发环境中，不同的线程拿到的单例对象也必须保证是同一个实例。 上文实现的单例类型是线程不安全的，如果有两个线程同时执行到 if (instance == null) 这行代码，判断都通过，然后各自执行 new 语句并各自返回一个实例，这时候就产生了多个对象。 解决方法有两种： 给getInstance方法加互斥锁(不推荐使用) 12345678910public class Singleton &#123; private static Singleton instance; private Singleton ()&#123;&#125; public static synchronized Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; &#125; 缺点：效率太低了，每个线程在想获得类的实例时候，执行getInstance()方法都要进行同步。而其实这个方法只执行一次实例化代码就够了，后面的想获得该类实例，直接return就行了。方法进行同步效率太低要改进。 双重检验锁（推荐使用）1234567891011121314public class Singleton &#123; private volatile static Singleton singleton; private Singleton ()&#123;&#125; public static Singleton getSingleton() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125; &#125; Double-Check概念对于多线程开发者来说不会陌生，如代码中所示，我们进行了两次if (singleton == null)检查,这样实例化代码只用执行一次，后面再次访问时，判断if (singleton == null)，直接return实例化对象。 还有值得注意的是，双重校验锁的实现方式中，静态成员变量singleton必须通过volatile来修饰，保证其初始化的原子性，否则可能被引用到一个未初始化完成的对象。 3、饿汉式单例前面提到的懒汉模式，其实是一种lazy-loading思想的实践，这种实现有一个比较大的好处，就是只有真正用到的时候才创建，如果没被使用到，就一直不会被创建，这就避免了不必要的开销。 但是这种做法，其实也有一个小缺点，就是第一次使用的时候，需要进行初始化操作，可能会有比较高的耗时。如果是已知某一个对象一定会使用到的话，其实可以采用一种饿汉的实现方式。所谓饿汉，就是事先准备好，需要的时候直接给你就行了。 1234567891011121314151617public class Singleton &#123; private static Singleton instance = new Singleton(); private Singleton ()&#123;&#125; public static Singleton getInstance() &#123; return instance; &#125; &#125; public class Singleton &#123; private Singleton instance = null; static &#123; instance = new Singleton(); &#125; private Singleton ()&#123;&#125; public static Singleton getInstance() &#123; return this.instance; &#125; 以上两段代码都是通过定义静态的成员变量（懒汉式只有声明没有定义）。饿汉模式中的静态变量是随着类加载时被完成实例化的。饿汉变种中的静态代码块也会随着类的加载一块执行。 因为类的初始化是由ClassLoader完成的，这其实是利用了ClassLoader的线程安全机制。ClassLoader的loadClass方法在加载类的时候使用了synchronized关键字。也正是因为这样， 除非被重写，这个方法默认在整个装载过程中都是同步的（线程安全的） 除了以上两种饿汉方式，还有一种实现方式也是借助了calss的初始化来实现的，那就是通过静态内部类来实现的单例（推荐使用）： 123456789public class Singleton &#123; private static class SingletonHolder &#123; private static final Singleton INSTANCE = new Singleton(); &#125; private Singleton ()&#123;&#125; public static final Singleton getInstance() &#123; return SingletonHolder.INSTANCE; &#125; &#125; 前面提到的饿汉模式，只要Singleton类被装载了，那么instance就会被实例化。 而这种方式是Singleton类被装载了，instance不一定被初始化。因为SingletonHolder类没有被主动使用，只有显示通过调用getInstance方法时，才会显示装载SingletonHolder类，从而实例化instance。 使用静态内部类，借助了classloader来实现了线程安全，这与饿汉模式有着异曲同工之妙，但是他有兼顾了懒汉模式的lazy-loading功能，相比较之下，有很大优势。 4、枚举式单例Joshua Bloch大神在《Effective Java》中明确表达过的观点： 使用枚举实现单例的方法虽然还没有广泛采用，但是单元素的枚举类型已经成为实现Singleton的最佳方法。 枚举单例：（墙裂推荐）12345public enum Singleton &#123; INSTANCE; public void whateverMethod() &#123; &#125; &#125; 最精简的 线程安全的 可解决反序列化破坏单例的问题 5、应用场景 Windows的Task Manager（任务管理器）就是很典型的单例模式 windows的Recycle Bin（回收站）也是典型的单例应用。在整个系统运行过程中，回收站一直维护着仅有的一个实例。 操作系统的文件系统，也是大的单例模式实现的具体例子，一个操作系统只能有一个文件系统。 网站的计数器，一般也是采用单例模式实现，否则难以同步。 应用程序的日志应用，一般都何用单例模式实现，这一般是由于共享的日志文件一直处于打开状态，因为只能有一个实例去操作，否则内容不好追加。 Web应用的配置对象的读取，一般也应用单例模式，这个是由于配置文件是共享的资源。 数据库连接池的设计一般也是采用单例模式，因为数据库连接是一种数据库资源。数据库软件系统中使用数据库连接池，主要是节省打开或者关闭数据库连接所引起的效率损耗，这种效率上的损耗还是非常昂贵的，用单例模式来维护，就可以大大降低这种损耗。 多线程的线程池的设计一般也是采用单例模式，这是由于线程池要方便对池中的线程进行控制。 HttpApplication 也是单例的典型应用。","categories":[{"name":"源码中的设计模式","slug":"源码中的设计模式","permalink":"https://zzkenyon.github.io/categories/源码中的设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://zzkenyon.github.io/tags/设计模式/"}],"keywords":[{"name":"源码中的设计模式","slug":"源码中的设计模式","permalink":"https://zzkenyon.github.io/categories/源码中的设计模式/"}]},{"title":"logback配置详解","slug":"日志框架-logback配置详解","date":"2016-08-03T16:00:00.000Z","updated":"2020-05-07T09:00:14.391Z","comments":true,"path":"2016/08/04/日志框架-logback配置详解/","link":"","permalink":"https://zzkenyon.github.io/2016/08/04/日志框架-logback配置详解/","excerpt":"","text":"logback是java的日志开源组件，是log4j创始人写的，性能比log4j要好，目前主要分为3个模块 logback-core:核心代码模块 logback-classic:log4j的一个改良版本，同时实现了slf4j的接口，这样你如果之后要切换其他日志组件也是一件很容易的事 logback-access:访问模块与Servlet容器集成提供通过Http来访问日志的功能 1. logback的配置1.1 配置获取顺序logback在启动的时候，会按照下面的顺序加载配置文件 如果java程序启动时指定了logback.configurationFile属性，就用该属性指定的配置文件。如java -Dlogback.configurationFile=/path/to/mylogback.xml Test ，这样执行Test类的时候就会加载/path/to/mylogback.xml配置 在classpath中查找 logback.groovy 文件 在classpath中查找 logback-test.xml 文件 在classpath中查找 logback.xml 文件 如果是 jdk6+,那么会调用ServiceLoader 查找 com.qos.logback.classic.spi.Configurator接口的第一个实现类 自动使用ch.qos.logback.classic.BasicConfigurator，在控制台输出日志 上面的顺序表示优先级，使用java -D配置的优先级最高，只要获取到配置后就不会再执行下面的流程。相关代码可以看ContextInitializer#autoConfig()方法。 1.2 关于SLF4j的日志输出级别在slf4j中，从小到大的日志级别依旧是trace &lt; debug &lt; info &lt; warn &lt; error，级别越小输出信息越多。 1.3 logback.xml 配置样例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!--debug属性表示要不要打印 logback内部日志信息，true则表示要打印--&gt;&lt;configuration debug=\"false\" scan=\"true\" scanPeriod=\"1 seconds\"&gt; &lt;!--后面输出格式中可以通过 %contextName 来打印日志上下文名称--&gt; &lt;contextName&gt;logback&lt;/contextName&gt; &lt;!--定义参数,后面可以通过$&#123;app.name&#125;使用--&gt; &lt;property name=\"app.name\" value=\"effective\"/&gt; &lt;!--ConsoleAppender 用于在屏幕上输出日志--&gt; &lt;appender name=\"stdout\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;!--定义了一个过滤器,在LEVEL之下的日志输出不会被打印出来--&gt; &lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"/&gt; &lt;!-- encoder 默认配置为PatternLayoutEncoder --&gt; &lt;!--定义控制台输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d [%thread] %-5level %logger&#123;36&#125; [%file : %line] - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name=\"file\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!--定义日志输出的路径--&gt; &lt;!--这里的scheduler.manager.server.home 没有在上面的配置中设定，所以会使用java启动时配置的值--&gt; &lt;!--比如通过 java -Dscheduler.manager.server.home=/path/to XXXX 配置该属性--&gt; &lt;file&gt;../logs/$&#123;app.name&#125;.log&lt;/file&gt; &lt;!--定义日志滚动的策略--&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!--定义文件滚动时的文件名的格式--&gt; &lt;fileNamePattern&gt;../logs/$&#123;app.name&#125;.%d&#123;yyyy-MM-dd.HH&#125;.log.gz&lt;/fileNamePattern&gt; &lt;!--60天的时间周期，日志量最大20GB--&gt; &lt;maxHistory&gt;60&lt;/maxHistory&gt; &lt;!-- 该属性在 1.1.6版本后 才开始支持--&gt; &lt;totalSizeCap&gt;20GB&lt;/totalSizeCap&gt; &lt;/rollingPolicy&gt; &lt;triggeringPolicy class=\"ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy\"&gt; &lt;!--每个日志文件最大100MB--&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;!--定义输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d [%thread] %-5level %logger&#123;36&#125; [%file : %line] - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!--root是默认的logger 这里设定输出级别是info--&gt; &lt;root level=\"info\"&gt; &lt;!--定义了两个appender，日志会通过往这两个appender里面写--&gt; &lt;appender-ref ref=\"stdout\"/&gt; &lt;appender-ref ref=\"file\"/&gt; &lt;/root&gt; &lt;!--对于类路径以 com.panda 开头的Logger,并设置输出级别--&gt; &lt;!--这个logger没有指定appender，它会继承root节点中定义的那些appender--&gt; &lt;logger name=\"com.panda\" level=\"debug\"/&gt; &lt;!--通过 LoggerFactory.getLogger(\"mytest\") 可以获取到这个logger--&gt; &lt;!--由于这个logger自动继承了root的appender，root中已经有stdout的appender了，自己这边又引入了stdout的appender--&gt; &lt;!--如果没有设置 additivity=\"false\" ,就会导致一条日志在控制台输出两次的情况--&gt; &lt;!--additivity表示要不要使用rootLogger配置的appender进行输出--&gt; &lt;logger name=\"mytest\" level=\"info\" additivity=\"false\"&gt; &lt;appender-ref ref=\"stdout\"/&gt; &lt;/logger&gt; &lt;!--由于设置了 additivity=\"false\" ，所以输出时不会使用rootLogger的appender--&gt; &lt;!--但是这个logger本身又没有配置appender，所以使用这个logger输出日志的话就不会输出到任何地方--&gt; &lt;logger name=\"mytest2\" level=\"info\" additivity=\"false\"/&gt;&lt;/configuration&gt; 2. 配置详解2.1 configuration节点相关属性 属性名称 默认值 介绍 debug false 要不要打印 logback内部日志信息，true则表示要打印。建议开启 scan true 配置发送改变时，要不要重新加载 scanPeriod 1 seconds 检测配置发生变化的时间间隔。如果没给出时间单位，默认时间单位是毫秒 2.2 configuration子节点介绍2.2.1 contextName节点设置日志上下文名称，后面输出格式中可以通过定义 %contextName 来打印日志上下文名称 2.2.2 property节点用来设置相关变量,通过key-value的方式配置，然后在后面的配置文件中通过 ${key}来访问 2.2.3 appender 节点日志输出组件，主要负责日志的输出以及格式化日志。常用的属性有name和class 属性名称 默认值 介绍 name 无默认值 appender组件的名称，后面给logger指定appender使用 class 无默认值 appender的具体实现类。常用的有 ConsoleAppender、FileAppender、RollingFileAppender ConsoleAppender：向控制台输出日志内容的组件，只要定义好encoder节点就可以使用。 FileAppender：向文件输出日志内容的组件，用法也很简单，不过由于没有日志滚动策略，一般很少使用 RollingFileAppender：向文件输出日志内容的组件，同时可以配置日志文件滚动策略，在日志达到一定条件后生成一个新的日志文件。 appender节点中有一个子节点filter，配置具体的过滤器，比如上面的例子配置了一个内置的过滤器ThresholdFilter，然后设置了level的值为DEBUG。这样用这个appender输出日志的时候都会经过这个过滤器，日志级别低于DEBUG的都不会输出来。 在RollingFileAppender中，可以配置相关的滚动策略，具体可以看配置样例的注释。 2.2.4 logger以及root节点root节点和logger节点其实都是表示Logger组件。个人觉的可以把他们之间的关系可以理解为父子关系，root是最顶层的logger，正常情况getLogger(“name/class”)没有找到对应logger的情况下，都是使用root节点配置的logger。 如果配置了logger，并且通过getLogger(“name/class”)获取到这个logger，输出日志的时候，就会使用这个logger配置的appender输出，同时还会使用rootLogger配置的appender。我们可以使用logger节点的additivity=&quot;false&quot;属性来屏蔽rootLogger的appender。这样就可以不使用rootLogger的appender输出日志了。 关于logger的获取，一般logger是配置name的。我们再代码中经常通过指定的CLass来获取Logger，比如这样LoggerFactory.getLogger(Test.class);,其实这个最后也是转成对应的包名+类名的字符串com.kongtrio.Test.class。假设有一个logger配置的那么是com.kongtrio，那么通过LoggerFactory.getLogger(Test.class)获取到的logger就是这个logger。 也就是说，name可以配置包名，也可以配置自定义名称。 上面说的logger和root节点的父子关系只是为了方便理解，具体的底层实现本人并没有看，他们之间真正的关系读者有兴趣的话可以去看logback的源码","categories":[],"tags":[{"name":"日志","slug":"日志","permalink":"https://zzkenyon.github.io/tags/日志/"}],"keywords":[]},{"title":"设计模式之建造者模式","slug":"设计模式之建造者模式","date":"2016-08-02T05:35:36.000Z","updated":"2020-05-22T11:57:30.257Z","comments":true,"path":"2016/08/02/设计模式之建造者模式/","link":"","permalink":"https://zzkenyon.github.io/2016/08/02/设计模式之建造者模式/","excerpt":"","text":"静态工厂和构造器有一个共同的局限性：不能很好的扩展到大量的可选参数。对于初始化参数很多的类，常规的做法是使用重载构造器，但是当参数很多的时候，客户端代码会很难写，并且较难阅读。 这时，还有另外一种替代方案，使用javaBean模式，在这种模式下先默认构造器创建对象，然后用setter方法设置需要的参数。遗憾的是，JavaBean模式自身有着很严重的缺点，因为构造过程分成了好几个调用，在构造过程中JavaBean可能处于不一致的状态，类无法仅仅通过检查构造器参数的有效性来保证一致性。 最终还有第三种替代方案，既能确保安全性，也能保证可读性，那就是建造者模式。 1. 建造者模式直接看一个简单例子：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Person &#123; private final String name; private final String address; private final int age; private final int sex; private final String tel; public static class Builder &#123; //Required parameters private final String name; private final int age; private final int sex; //Optional parameters private String address = &quot;浙江杭州&quot;; private String tel = &quot;0571&quot;; public Builder(String name, int age, int sex) &#123; this.name = name; this.age = age; this.sex = sex; &#125; public Builder address(String address) &#123; this.address = address; return this; &#125; public Builder tel(String tel) &#123; this.tel = tel; return this; &#125; public Person build()&#123; return new Person(this); &#125; &#125; private Person(Builder builder)&#123; name = builder.name; address = builder.address; sex = builder.sex; age = builder.age; tel = builder.tel; &#125; public static void main(String[] args)&#123; Person p = new Builder(&quot;zhaozhengkang&quot;,25,1).address(&quot;yuhang&quot;).tel(&quot;123456789&quot;).build(); &#125;&#125; builder的设值方法返回builder本身，以便把调用连接起来形成一个流式的API. 2. 类层次中使用建造者模式 （effective java rule2,30）使用平行层次结构的builder时，各自嵌套在相应类中。抽象类有抽象类的builder，具体类有具体类的builder。12345678910111213141516171819public abstract class Pizza &#123; public enum Topping &#123; HAM, MUSHROOM, ONION, PEPPER, SAUSAGE &#125; final Set&lt;Topping&gt; toppings; abstract static class Builder&lt;T extends Builder&lt;T&gt;&gt;&#123; EnumSet&lt;Topping&gt; toppings = EnumSet.noneOf(Topping.class); public T addTopping(Topping topping)&#123; toppings.add(Objects.requireNonNull(topping)); return self(); &#125; abstract Pizza build(); protected abstract T self(); &#125; Pizza(Builder&lt;?&gt; builder)&#123; toppings = builder.toppings.clone(); &#125;&#125; Builder&lt;T extends Builder&gt;这一句使用了递归类型限制中的模拟自类型模拟自类型（自限定类型）所做的就是要求在继承关系中，强制要求将正在定义的类当做参数传递给基类，看下面代码： 1234567891011121314151617181920212223242526public class NyPizza extends Pizza &#123; public enum Size&#123;SMALL, MEDIUM, LARGER&#125; private final Size size; public static class NyPizzaBuilder extends Pizza.Builder&lt;NyPizzaBuilder&gt;&#123; private final Size size; public NyPizzaBuilder(Size size)&#123; this.size = Objects.requireNonNull(size); &#125; @Override public NyPizza build() &#123; return new NyPizza(this); &#125; @Override protected NyPizzaBuilder self() &#123; return this; &#125; &#125; private NyPizza(NyPizzaBuilder builder) &#123; super(builder); size = builder.size; &#125; public static void main(String[] args)&#123; NyPizza p = new NyPizzaBuilder(Size.SMALL).addTopping(Topping.SAUSAGE).addTopping(Topping.ONION).build(); &#125;&#125; 继承时，必须将正在定义的类NyPizzaBuilder作为类型参数传给基类Pizza.Builder，否则无法编译。自限定类型属于泛型知识，将另开一篇进行研究。 参考资料《Effcitive Java》","categories":[{"name":"源码中的设计模式","slug":"源码中的设计模式","permalink":"https://zzkenyon.github.io/categories/源码中的设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://zzkenyon.github.io/tags/设计模式/"}],"keywords":[{"name":"源码中的设计模式","slug":"源码中的设计模式","permalink":"https://zzkenyon.github.io/categories/源码中的设计模式/"}]},{"title":"设计模式之工厂模式","slug":"设计模式之工厂模式","date":"2016-08-01T05:35:36.000Z","updated":"2020-05-22T11:57:44.913Z","comments":true,"path":"2016/08/01/设计模式之工厂模式/","link":"","permalink":"https://zzkenyon.github.io/2016/08/01/设计模式之工厂模式/","excerpt":"","text":"1. 简单工厂根据客户端传入的参数进行判断，再决定创建哪种实例，缺点很明显： 传参错误则不能创建正确的实例 扩展需要修改工厂方法 2.工厂方法在工厂类中定义若干的函数来创建实例，每个函数创建一种实例，解决的简单工厂需要传参的问题 3. 静态工厂方法3.1 定义将工厂类中的工厂方法定义为静态类型，使用静态工厂不需要创建工厂实例。1234567891011121314151617public class SendFactory &#123; public static Sender produceMail()&#123; return new MailSender(); &#125; public static Sender produceSms()&#123; return new SmsSender(); &#125; &#125; public class FactoryTest &#123; public static void main(String[] args) &#123; Sender sender = SendFactory.produceMail(); sender.Send(); &#125; &#125; （静态）工厂方法缺点是： 对于扩展需要修改工厂类 3.2 用静态工厂方法代替构造器（Effective java：rule 1）如果不通过共有构造器，或者说除了公有构造器之外，类还可以给他的客户端提供静态工厂方法，这样做既有优势又有劣势。优势在于： 第一点：它们有名称。使客户端代码更容易阅读，例如：构造器BigInteger(int,int,Random)返回的BigInteger可能是素数，如果用静态工厂方法BigInteger.probablePrime来表示，就会更清楚。 第二点：不必每次调用的时候都创建一个新对象。静态工厂方法能够为重复的调用返回相同的对象 第三点：静态工厂方法可以返回类型的任何子类型对象，构造器则做不到这一点。 第四点：每次调用返回对象的类可以变化，取决于静态工厂方法的参数 12345678910111213141516171819202122232425262728//该代码 解释以上四点优势public class Child &#123; protected String classId; public Child()&#123; classId = &quot;CHILD&quot;; &#125; public static class Son extends Child &#123; public Son()&#123; classId = &quot;SON&quot;; &#125; &#125; public static class Daughter extends Child &#123; public Daughter()&#123; classId = &quot;DAUGHTER&quot;; &#125; &#125; public static Child sonFactory()&#123; return new Son(); &#125; public static Child daughterFactory()&#123; return new Daughter(); &#125; public static Child childFactory(int sex)&#123; return sex == 1 ? new Son() : new Daughter(); &#125; public static void main(String[] args)&#123; Child son = Child.sonFactory(); Child child = Child.childFactory(2); System.out.println(son.classId + &quot;\\n&quot; + child.classId); &#125;&#125; 第五点：方法返回对象的类，在编写包含该静态方法的类时是可以不存在的。第五点的灵活性是构成服务提供者框架（Service Provider Framework）的基础，将另起一片单独研究。 静态工厂方法的劣势在于： 程序员很难发现这些静态工厂方法。 类如果没有公有或者受保护的构造器，就不能被子类化（不允许被继承）。 4.抽象工厂对每一个需要创建实例的类都配置了一个工厂类，需要扩展的时候，增加一个工厂类，实现工厂类的抽象方法进行实例创建，实现了开闭原则。","categories":[{"name":"源码中的设计模式","slug":"源码中的设计模式","permalink":"https://zzkenyon.github.io/categories/源码中的设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://zzkenyon.github.io/tags/设计模式/"}],"keywords":[{"name":"源码中的设计模式","slug":"源码中的设计模式","permalink":"https://zzkenyon.github.io/categories/源码中的设计模式/"}]},{"title":"Log4j配置文件详解","slug":"日志框架-Log4j 配置文件","date":"2016-07-22T16:00:00.000Z","updated":"2020-05-07T09:00:32.590Z","comments":true,"path":"2016/07/23/日志框架-Log4j 配置文件/","link":"","permalink":"https://zzkenyon.github.io/2016/07/23/日志框架-Log4j 配置文件/","excerpt":"","text":"1、简介Log4j有三个主要的组件： Loggers(记录器):日志类别和级别; Appenders (输出源):日志要输出的地方; Layouts(布局):日志以何种形式输出 1.1、Loggers Loggers组件在此系统中被分为五个级别,分别用来指定这条日志信息的重要程度：DEBUG、INFO、WARN、ERROR和FATAL; 这五个级别是有顺序的，DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL; Log4j有一个规则：只输出级别不低于设定级别的日志信息，假设Loggers级别设定为INFO，则INFO、WARN、ERROR和FATAL级别的日志信息都会输出，而级别比INFO低的DEBUG则不会输出。 1.2、Appenders禁用和使用日志请求只是Log4j的基本功能，Log4j日志系统还提供许多强大的功能，比如允许把日志输出到不同的地方，如控制台（Console）、文件（Files）等，可以根据天数或者文件大小产生新的文件，可以以流的形式发送到其它地方等等。 常使用的类如下： org.apache.log4j.ConsoleAppender（控制台） org.apache.log4j.FileAppender（文件） org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件） org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件） org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方） 配置模式1234log4j.appender.appenderName = classNamelog4j.appender.appenderName.Option1 = value1…log4j.appender.appenderName.OptionN = valueN 1.3、LayoutsLog4j可以在Appenders的后面附加Layouts来完成这个功能。Layouts提供四种日志输出样式，如根据HTML样式、自由指定样式、包含日志级别与信息的样式和包含日志时间、线程、类别等信息的样式。 常使用的类如下： org.apache.log4j.HTMLLayout（以HTML表格形式布局） org.apache.log4j.PatternLayout（可以灵活地指定布局模式） org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串） org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等信息） 配置模式： 1234log4j.appender.appenderName.layout =classNamelog4j.appender.appenderName.layout.Option1 = value1...log4j.appender.appenderName.layout.OptionN = valueN 2、配置详解在实际应用中，要使Log4j在系统中运行须事先设定配置文件。配置文件事实上也就是对Logger、Appender及Layout进行相应设定。Log4j支持两种配置文件格式: 一种是XML格式的文件， 一种是properties属性文件。 下面以properties属性文件为例介绍log4j.properties的配置。 2.1、配置根Logger12log4j.rootLogger = [ level ] , appenderName1, appenderName2, …log4j.additivity.org.apache=false：表示Logger不会在父Logger的appender里输出，默认为true。 level ：设定日志记录的最低级别，可设的值有OFF、FATAL、ERROR、WARN、INFO、DEBUG、ALL或者自定义的级别，Log4j建议只使用中间四个级别。通过在这里设定级别，您可以控制应用程序中相应级别的日志信息的开关，比如在这里设定了INFO级别，则应用程序中所有DEBUG级别的日志信息将不会被打印出来。 appenderName：就是指定日志信息要输出到哪里。可以同时指定多个输出目的地，用逗号隔开。例如：log4j.rootLogger＝INFO,A1,B2,C3 2.2、配置日志信息输出目的地（appender）1log4j.appender.appenderName = className appenderName：自定义appderName，在log4j.rootLogger设置中使用；className：可设值如下： org.apache.log4j.ConsoleAppender（控制台） org.apache.log4j.FileAppender（文件） org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件） org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件） org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方） ConsoleAppender选项 Threshold=WARN：指定日志信息的最低输出级别，默认为DEBUG。 ImmediateFlush=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。 Target=System.err：默认值是System.out。 FileAppender选项 Threshold=WARN：指定日志信息的最低输出级别，默认为DEBUG。 ImmediateFlush=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。 Append=false：true表示消息增加到指定文件中，false则将消息覆盖指定的文件内容，默认值是true。 File=D:/logs/logging.log4j：指定消息输出到logging.log4j文件中。 DailyRollingFileAppender选项 Threshold=WARN：指定日志信息的最低输出级别，默认为DEBUG。 ImmediateFlush=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。 Append=false：true表示消息增加到指定文件中，false则将消息覆盖指定的文件内容，默认值是true。 File=D:/logs/logging.log4j：指定当前消息输出到logging.log4j文件中。 DatePattern=’.’yyyy-MM：每月滚动一次日志文件，即每月产生一个新的日志文件。当前月的日志文件名为logging.log4j，前一个月的日志文件名为logging.log4j.yyyy-MM。另外，也可以指定按周、天、时、分等来滚动日志文件，对应的格式如下：123456&apos;.&apos;yyyy-MM：每月&apos;.&apos;yyyy-ww：每周&apos;.&apos;yyyy-MM-dd：每天&apos;.&apos;yyyy-MM-dd-a：每天两次&apos;.&apos;yyyy-MM-dd-HH：每小时&apos;.&apos;yyyy-MM-dd-HH-mm：每分钟 RollingFileAppender选项 Threshold=WARN：指定日志信息的最低输出级别，默认为DEBUG。 ImmediateFlush=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。 Append=false：true表示消息增加到指定文件中，false则将消息覆盖指定的文件内容，默认值是true。 File=D:/logs/logging.log4j：指定消息输出到logging.log4j文件中。 MaxFileSize=100KB：后缀可以是KB, MB 或者GB。在日志文件到达该大小时，将会自动滚动，即将原来的内容移到logging.log4j.1文件中。 MaxBackupIndex=2：指定可以产生的滚动文件的最大数，例如，设为2则可以产生logging.log4j.1，logging.log4j.2两个滚动文件和一个logging.log4j文件。 2.3、配置日志信息的输出格式（Layout）1log4j.appender.appenderName.layout=className className：可设值如下： org.apache.log4j.HTMLLayout（以HTML表格形式布局） org.apache.log4j.PatternLayout（可以灵活地指定布局模式） org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串） org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等等信息） HTMLLayout选项 LocationInfo=true：输出java文件名称和行号，默认值是false。 Title=My Logging： 默认值是Log4J Log Messages。 PatternLayout选项：ConversionPattern=%m%n：设定以怎样的格式显示消息。 格式化符号说明：12345678910111213%p：输出日志信息的优先级，即DEBUG，INFO，WARN，ERROR，FATAL。%d：输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，如：%d&#123;yyyy/MM/dd HH:mm:ss,SSS&#125;。%r：输出自应用程序启动到输出该log信息耗费的毫秒数。%t：输出产生该日志事件的线程名。%l：输出日志事件的发生位置，相当于%c.%M(%F:%L)的组合，包括类全名、方法、文件名以及在代码中的行数。例如：test.TestLog4j.main(TestLog4j.java:10)。%c：输出日志信息所属的类目，通常就是所在类的全名。%M：输出产生日志信息的方法名。%F：输出日志消息产生时所在的文件名称。%L:：输出代码中的行号。%m:：输出代码中指定的具体日志信息。%n：输出一个回车换行符，Windows平台为&quot;\\r\\n&quot;，Unix平台为&quot;\\n&quot;。%x：输出和当前线程相关联的NDC(嵌套诊断环境)，尤其用到像java servlets这样的多客户多线程的应用中。%%：输出一个&quot;%&quot;字符。 另外，还可以在%与格式字符之间加上修饰符来控制其最小长度、最大长度、和文本的对齐方式。如： 指定输出category的名称，最小的长度是20，如果category的名称长度小于20的话，默认的情况下右对齐。 %-20c：”-“号表示左对齐。 %.30c：指定输出category的名称，最大的长度是30，如果category的名称长度大于30的话，就会将左边多出的字符截掉，但小于30的话也不会补空格。 附：Log4j比较全面的配置Log4j配置文件实现了输出到控制台、文件、回滚文件、发送日志邮件、输出到数据库日志表、自定义标签等全套功能。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475log4j.rootLogger=DEBUG,console,dailyFile,imlog4j.additivity.org.apache=true# 控制台(console)log4j.appender.console=org.apache.log4j.ConsoleAppenderlog4j.appender.console.Threshold=DEBUGlog4j.appender.console.ImmediateFlush=truelog4j.appender.console.Target=System.errlog4j.appender.console.layout=org.apache.log4j.PatternLayoutlog4j.appender.console.layout.ConversionPattern=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n# 日志文件(logFile)log4j.appender.logFile=org.apache.log4j.FileAppenderlog4j.appender.logFile.Threshold=DEBUGlog4j.appender.logFile.ImmediateFlush=truelog4j.appender.logFile.Append=truelog4j.appender.logFile.File=D:/logs/log.log4jlog4j.appender.logFile.layout=org.apache.log4j.PatternLayoutlog4j.appender.logFile.layout.ConversionPattern=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n# 回滚文件(rollingFile)log4j.appender.rollingFile=org.apache.log4j.RollingFileAppenderlog4j.appender.rollingFile.Threshold=DEBUGlog4j.appender.rollingFile.ImmediateFlush=truelog4j.appender.rollingFile.Append=truelog4j.appender.rollingFile.File=D:/logs/log.log4jlog4j.appender.rollingFile.MaxFileSize=200KBlog4j.appender.rollingFile.MaxBackupIndex=50log4j.appender.rollingFile.layout=org.apache.log4j.PatternLayoutlog4j.appender.rollingFile.layout.ConversionPattern=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n# 定期回滚日志文件(dailyFile)log4j.appender.dailyFile=org.apache.log4j.DailyRollingFileAppenderlog4j.appender.dailyFile.Threshold=DEBUGlog4j.appender.dailyFile.ImmediateFlush=truelog4j.appender.dailyFile.Append=truelog4j.appender.dailyFile.File=D:/logs/log.log4jlog4j.appender.dailyFile.DatePattern=&apos;.&apos;yyyy-MM-ddlog4j.appender.dailyFile.layout=org.apache.log4j.PatternLayoutlog4j.appender.dailyFile.layout.ConversionPattern=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n# 应用于socketlog4j.appender.socket=org.apache.log4j.RollingFileAppenderlog4j.appender.socket.RemoteHost=localhostlog4j.appender.socket.Port=5001log4j.appender.socket.LocationInfo=true# Set up for Log Factor 5log4j.appender.socket.layout=org.apache.log4j.PatternLayoutlog4j.appender.socket.layout.ConversionPattern=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n# Log Factor 5 Appenderlog4j.appender.LF5_APPENDER=org.apache.log4j.lf5.LF5Appenderlog4j.appender.LF5_APPENDER.MaxNumberOfRecords=2000# 发送日志到指定邮件log4j.appender.mail=org.apache.log4j.net.SMTPAppenderlog4j.appender.mail.Threshold=FATALlog4j.appender.mail.BufferSize=10log4j.appender.mail.From = xxx@mail.comlog4j.appender.mail.SMTPHost=mail.comlog4j.appender.mail.Subject=Log4J Messagelog4j.appender.mail.To= xxx@mail.comlog4j.appender.mail.layout=org.apache.log4j.PatternLayoutlog4j.appender.mail.layout.ConversionPattern=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n# 应用于数据库log4j.appender.database=org.apache.log4j.jdbc.JDBCAppenderlog4j.appender.database.URL=jdbc:mysql://localhost:3306/testlog4j.appender.database.driver=com.mysql.jdbc.Driverlog4j.appender.database.user=rootlog4j.appender.database.password=log4j.appender.database.sql=INSERT INTO LOG4J (Message) VALUES(&apos;=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n&apos;)log4j.appender.database.layout=org.apache.log4j.PatternLayoutlog4j.appender.database.layout.ConversionPattern=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n# 自定义Appenderlog4j.appender.im = net.cybercorlin.util.logger.appender.IMAppenderlog4j.appender.im.host = mail.cybercorlin.netlog4j.appender.im.username = usernamelog4j.appender.im.password = passwordlog4j.appender.im.recipient = corlin@cybercorlin.netlog4j.appender.im.layout=org.apache.log4j.PatternLayoutlog4j.appender.im.layout.ConversionPattern=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n 附: 输出独立日志文件log4j的强大功能无可置疑，但实际应用中免不了遇到某个功能需要输出独立的日志文件的情况，怎样才能把所需的内容从原有日志中分离，形成单独的日志文件呢？其实只要在现有的log4j基础上稍加配置即可轻松实现这一功能。 常见先看一个常见的log4j.properties文件，它是在控制台和myweb.log文件中记录日志：123456789101112131415log4j.rootLogger=DEBUG, stdout, logfile log4j.category.org.springframework=ERRORlog4j.category.org.apache=INFO log4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%n log4j.appender.logfile=org.apache.log4j.RollingFileAppenderlog4j.appender.logfile.File=$&#123;myweb.root&#125;/WEB-INF/log/myweb.loglog4j.appender.logfile.MaxFileSize=512KBlog4j.appender.logfile.MaxBackupIndex=5log4j.appender.logfile.layout=org.apache.log4j.PatternLayoutlog4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n 不同类输出不同文件如果想对不同的类输出不同的文件(以cn.com.Test为例)，先要在Test.java中定义: 12345678private static Log logger = LogFactory.getLog(Test.class); 然后在log4j.properties中加入:log4j.logger.cn.com.Test= DEBUG, testlog4j.appender.test=org.apache.log4j.FileAppenderlog4j.appender.test.File=$&#123;myweb.root&#125;/WEB-INF/log/test.loglog4j.appender.test.layout=org.apache.log4j.PatternLayoutlog4j.appender.test.layout.ConversionPattern=%d %p [%c] - %m%n 也就是让cn.com.Test中的logger使用log4j.appender.test所做的配置。 同一类输出多个日志文件但是，如果在同一类中需要输出多个日志文件呢？其实道理是一样的，先在Test.java中定义: 12private static Log logger1 = LogFactory.getLog(&quot;myTest1&quot;);private static Log logger2 = LogFactory.getLog(&quot;myTest2&quot;); 然后在log4j.properties中加入: 1234567891011log4j.logger.myTest1= DEBUG, test1log4j.appender.test1=org.apache.log4j.FileAppenderlog4j.appender.test1.File=$&#123;myweb.root&#125;/WEB-INF/log/test1.loglog4j.appender.test1.layout=org.apache.log4j.PatternLayoutlog4j.appender.test1.layout.ConversionPattern=%d %p [%c] - %m%n log4j.logger.myTest2= DEBUG, test2log4j.appender.test2=org.apache.log4j.FileAppenderlog4j.appender.test2.File=$&#123;myweb.root&#125;/WEB-INF/log/test2.loglog4j.appender.test2.layout=org.apache.log4j.PatternLayoutlog4j.appender.test2.layout.ConversionPattern=%d %p [%c] - %m%n 也就是在用logger时给它一个自定义的名字(如这里的”myTest1”)，然后在log4j.properties中做出相应配置即可。别忘了不同日志要使用不同的logger如输出到test1.log的要用logger1.info(“abc”)。 还有一个问题，就是这些自定义的日志默认是同时输出到log4j.rootLogger所配置的日志中的，如何能只让它们输出到自己指定的日志中呢？别急，这里有个开关： 1log4j.additivity.myTest1 = false 它用来设置是否同时输出到log4j.rootLogger所配置的日志中，设为false就不会输出到其它地方啦！注意这里的”myTest1”是你在程序中给logger起的那个自定义的名字！如果你说，我只是不想同时输出这个日志到log4j.rootLogger所配置的logfile中，stdout里我还想同时输出呢！那也好办，把你的log4j.logger.myTest1 = DEBUG, test1改为下式就OK啦！ 1log4j.logger.myTest1=DEBUG, test1","categories":[],"tags":[{"name":"日志","slug":"日志","permalink":"https://zzkenyon.github.io/tags/日志/"}],"keywords":[]},{"title":"Java中的日志框架","slug":"日志框架-Java中的日志框架","date":"2016-07-21T16:00:00.000Z","updated":"2020-05-07T09:00:47.344Z","comments":true,"path":"2016/07/22/日志框架-Java中的日志框架/","link":"","permalink":"https://zzkenyon.github.io/2016/07/22/日志框架-Java中的日志框架/","excerpt":"","text":"1 java常用日志框架类别介绍 Log4j Apache Log4j是一个基于Java的日志记录工具。它是由Ceki Gülcü首创的，现在则是Apache软件基金会的一个项目。 Log4j是几种Java日志框架之一。 Log4j 2 Apache Log4j 2是apache开发的一款Log4j的升级产品。 Commons Logging Apache基金会所属的项目，是一套Java日志接口，之前叫Jakarta Commons Logging，后更名为Commons Logging。 Slf4j 类似于Commons Logging，是一套简易Java日志门面，本身并无日志的实现。（Simple Logging Facade for Java，缩写Slf4j）。 Logback 一套日志组件的实现(slf4j阵营)。 Jul (Java Util Logging),自Java1.4以来的官方日志实现。 看了上面的介绍是否会觉得比较混乱，这些日志框架之间有什么异同，都是由谁在维护? 下文会逐一介绍。 2 Java常用日志框架历史 1996年早期，欧洲安全电子市场项目组决定编写它自己的程序跟踪API(Tracing API)。经过不断的完善，这个API终于成为一个十分受欢迎的Java日志软件包，即Log4j。后来Log4j成为Apache基金会项目中的一员。 期间Log4j近乎成了Java社区的日志标准。据说Apache基金会还曾经建议sun引入Log4j到java的标准库中，但Sun拒绝了。 2002年Java1.4发布，Sun推出了自己的日志库JUL(Java Util Logging),其实现基本模仿了Log4j的实现。在JUL出来以前，log4j就已经成为一项成熟的技术，使得log4j在选择上占据了一定的优势。 接着，Apache推出了Jakarta Commons Logging，JCL只是定义了一套日志接口(其内部也提供一个Simple Log的简单实现)，支持运行时动态加载日志组件的实现，也就是说，在你应用代码里，只需调用Commons Logging的接口，底层实现可以是log4j，也可以是Java Util Logging。 后来(2006年)，Ceki Gülcü不适应Apache的工作方式，离开了Apache。然后先后创建了slf4j(日志门面接口，类似于Commons Logging)和Logback(Slf4j的实现)两个项目，并回瑞典创建了QOS公司，QOS官网上是这样描述Logback的：The Generic，Reliable Fast&amp;Flexible Logging Framework(一个通用，可靠，快速且灵活的日志框架)。 现今，Java日志领域被划分为两大阵营：Commons Logging阵营和SLF4J阵营。Commons Logging在Apache大树的笼罩下，有很大的用户基数。但有证据表明，形式正在发生变化。2013年底有人分析了GitHub上30000个项目，统计出了最流行的100个Libraries，可以看出slf4j的发展趋势更好： Apache眼看有被Logback反超的势头，于2012-07重写了log4j 1.x，成立了新的项目Log4j 2。Log4j 2具有logback的所有特性。 3 java常用日志框架之间的关系 Log4j2与Log4j1发生了很大的变化，log4j2不兼容log4j1。 Commons Logging和Slf4j是日志门面(门面模式是软件工程中常用的一种软件设计模式，也被称为正面模式、外观模式。它为子系统中的一组接口提供一个统一的高层接口，使得子系统更容易使用)。log4j和Logback则是具体的日志实现方案。可以简单的理解为接口与接口的实现，调用这只需要关注接口而无需关注具体的实现，做到解耦。 比较常用的组合使用方式是Slf4j与Logback组合使用，Commons Logging与Log4j组合使用。 Logback必须配合Slf4j使用。由于Logback和Slf4j是同一个作者，其兼容性不言而喻。 4 Commons Logging与Slf4j实现机制对比4.1 Commons logging实现机制Commons logging是通过动态查找机制，在程序运行时，使用自己的ClassLoader寻找和载入本地具体的实现。详细策略可以查看commons-logging-*.jar包中的org.apache.commons.logging.impl.LogFactoryImpl.java文件。由于OSGi不同的插件使用独立的ClassLoader，OSGI的这种机制保证了插件互相独立, 其机制限制了commons logging在OSGi中的正常使用。 4.2 Slf4j实现机制Slf4j在编译期间，静态绑定本地的LOG库，因此可以在OSGi中正常使用。它是通过查找类路径下org.slf4j.impl.StaticLoggerBinder，然后绑定工作都在这类里面进。 5 如何选择日志框架如果是在一个新的项目中建议使用Slf4j与Logback组合，这样有如下的几个优点。 Slf4j实现机制决定Slf4j限制较少，使用范围更广。由于Slf4j在编译期间，静态绑定本地的LOG库使得通用性要比Commons logging要好。 Logback拥有更好的性能。Logback声称：某些关键操作，比如判定是否记录一条日志语句的操作，其性能得到了显著的提高。这个操作在Logback中需要3纳秒，而在Log4J中则需要30纳秒。LogBack创建记录器（logger）的速度也更快：13毫秒，而在Log4J中需要23毫秒。更重要的是，它获取已存在的记录器只需94纳秒，而Log4J需要2234纳秒，时间减少到了1/23。跟JUL相比的性能提高也是显著的。 Commons Logging开销更高 在使Commons Logging时为了减少构建日志信息的开销，通常的做法是：if(log.isDebugEnabled()){log.debug(“User name： “ +user.getName() + “ buy goods id ：” + good.getId());}在Slf4j阵营，你只需这么做：log.debug(“User name：{} ,buy goods id ：{}”, user.getName(),good.getId());也就是说，slf4j把构建日志的开销放在了它确认需要显示这条日志之后，减少内存和cup的开销，使用占位符号，代码也更为简洁 Logback文档免费。Logback的所有文档是全面免费提供的，不象Log4J那样只提供部分免费文档而需要用户去购买付费文档。","categories":[],"tags":[{"name":"日志","slug":"日志","permalink":"https://zzkenyon.github.io/tags/日志/"}],"keywords":[]},{"title":"mysql-5.7 windows下安装","slug":"数据库技术-mysql-5-7-windows下安装","date":"2016-05-10T02:56:23.000Z","updated":"2020-05-22T11:53:14.694Z","comments":true,"path":"2016/05/10/数据库技术-mysql-5-7-windows下安装/","link":"","permalink":"https://zzkenyon.github.io/2016/05/10/数据库技术-mysql-5-7-windows下安装/","excerpt":"","text":"1. 下载选择zip格式的压缩包，解压到指定盘中D:\\mysql-5.7 2. 配置环境变量MYSQL_HOME:D:\\mysql-5.7在path 后面添加 ;%MYSQL_HOME%\\bin 3. 添加文件my.ini文件将如下代码放入my.ini文件中basedir和datadir，请根据实际安装目录进行修改 12345678910111213141516[mysql]# 设置mysql客户端默认字符集default-character-set=utf8[mysqld]#设置3306端口port = 3306# 设置mysql的安装目录basedir=D:\\mysql5.7# 设置mysql数据库的数据的存放目录datadir=D:\\mysql5.7\\data# 允许最大连接数max_connections=200# 服务端使用的字符集默认为8比特编码的latin1字符集character-set-server=utf8# 创建新表时将使用的默认存储引擎default-storage-engine=INNODB 4. 打开cmd.exe必须以管理员的身份运行，从c:/windows/systen32文件夹中找到cmd.exe，右击以管理员身份打开。 5. 初始化数据库mysqld –initialize –user=mysql –console记住分配的密码:最后一行（很重要） 6. 安装服务mysqld –install MySQL 7. 启动服务net start MySQL 8. 修改初始化密码使用初始密码登陆后,执行下面指令：set password for root@localhost=password(‘111111’); * 附录：相关指令 停止服务：net stop MySQL 删除服务：sc delete MySQL 移除mysql：mysqld -remove MySQL","categories":[{"name":"数据库技术","slug":"数据库技术","permalink":"https://zzkenyon.github.io/categories/数据库技术/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://zzkenyon.github.io/tags/mysql/"}],"keywords":[{"name":"数据库技术","slug":"数据库技术","permalink":"https://zzkenyon.github.io/categories/数据库技术/"}]}]}