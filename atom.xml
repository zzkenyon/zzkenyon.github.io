<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>黑风雅过吟</title>
  
  <subtitle>不积跬步无以至千里</subtitle>
  <link href="/zzkenyon.github.io/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/child/"/>
  <updated>2020-01-02T06:34:36.000Z</updated>
  <id>http://yoursite.com/child/</id>
  
  <author>
    <name>Zhao Zhengkang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>SpringCloud-服务注册、调用以及负载均衡</title>
    <link href="http://yoursite.com/child/2020/01/02/SpringCloud-%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E3%80%81%E8%B0%83%E7%94%A8%E4%BB%A5%E5%8F%8A%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    <id>http://yoursite.com/child/2020/01/02/SpringCloud-服务注册、调用以及负载均衡/</id>
    <published>2020-01-01T16:00:00.000Z</published>
    <updated>2020-01-02T06:34:36.000Z</updated>
    
    <content type="html"><![CDATA[<h4 id="父项目依赖配置："><a href="#父项目依赖配置：" class="headerlink" title="父项目依赖配置："></a>父项目依赖配置：</h4><p>父项目pom配置：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">spring.boot.version</span>&gt;</span>2.2.0.RELEASE<span class="tag">&lt;/<span class="name">spring.boot.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">spring.cloud.version</span>&gt;</span>Hoxton.RELEASE<span class="tag">&lt;/<span class="name">spring.cloud.version</span>&gt;</span></span><br><span class="line">    ...</span><br><span class="line"><span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependencyManagement</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-dependencies<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;spring.boot.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">type</span>&gt;</span>pom<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>import<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-dependencies<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;spring.cloud.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>import<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">type</span>&gt;</span>pom<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencyManagement</span>&gt;</span></span><br></pre></td></tr></table></figure><p>boot版本号 2.2.x.RELEASE 应当使用的cloud版本序列为Hoxton.RELEASE</p><p>父pom中这样配置，子模块中引入boot和cloud的依赖不再需要填写版本号信息，统一了系统的依赖版本</p><h4 id="服务器配置："><a href="#服务器配置：" class="headerlink" title="服务器配置："></a>服务器配置：</h4><p>主类上注解@EnableEurekaServer，表示是服务器</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr"> application:</span></span><br><span class="line"><span class="attr">   name:</span> <span class="string">eureka-server</span></span><br><span class="line"><span class="attr">eureka:</span></span><br><span class="line"><span class="attr">  instance:</span></span><br><span class="line"><span class="attr">    hostname:</span> <span class="string">localhost</span></span><br><span class="line"><span class="attr">  client:</span></span><br><span class="line"><span class="attr">    registerWithEureka:</span> <span class="literal">false</span> <span class="comment">#是否要注册到eureka</span></span><br><span class="line"><span class="attr">    fetchRegistry:</span> <span class="literal">false</span> <span class="comment">#表示是否从Eureka Server获取注册信息</span></span><br><span class="line"><span class="attr">    serviceUrl:</span></span><br><span class="line"><span class="attr">      defaultZone:</span> <span class="attr">http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/</span> <span class="comment">#单机配置</span></span><br></pre></td></tr></table></figure><p>eureka服务器不需要注册注册中心让别人发线，所以配置registerWithEureka为false </p><p>也不需要获取其他服务的注册信息所以registerWithEureka 也为false</p><p><strong>安全访问</strong></p><p>eureka服务器可以配置安全访问，需要引入依赖spring-boot-stater-security，并配置user和password</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr"> security:</span></span><br><span class="line"><span class="attr">   user:</span></span><br><span class="line"><span class="attr">     name:</span> <span class="string">admin</span></span><br><span class="line"><span class="attr">     password:</span> <span class="number">123456</span></span><br></pre></td></tr></table></figure><p>所有的客户端对的client.serviceUrl.defaultZone 都需要使用user:passwod@host 的形式进行配置</p><p>eg:  <a href="http://admin:123456@localhost:8761/erueka/" target="_blank" rel="noopener">http://admin:123456@localhost:8761/erueka/</a></p><h4 id="注册服务"><a href="#注册服务" class="headerlink" title="注册服务"></a>注册服务</h4><p>主类注解@EnableEurekaClient，表示是客户端</p><p>基本配置：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  application:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">user-provider</span></span><br><span class="line"><span class="attr">eureka:</span></span><br><span class="line"><span class="attr">  client:</span></span><br><span class="line"><span class="attr">    healthcheck:</span></span><br><span class="line"><span class="attr">      enabled:</span> <span class="literal">true</span> <span class="comment">#开启健康检查，需要引入actuator依赖</span></span><br><span class="line"><span class="attr">    service-url:</span></span><br><span class="line"><span class="attr">      defaultZone:</span> <span class="attr">http://localhost:8761/eureka/</span> <span class="comment">#告诉服务提供者要把服务注册到哪儿</span></span><br><span class="line"><span class="attr">  instance:</span></span><br><span class="line"><span class="attr">      prefer-ip-address:</span> <span class="literal">true</span> <span class="comment">#显示客户端真实ip</span></span><br></pre></td></tr></table></figure><p>如果是eureka服务器集群，defaultZone可以写个url，用“,”隔开</p><p>若同一个服务需要部署多个实例，配置文件中服务名称srping.application.name需要一致</p><h4 id="调用服务"><a href="#调用服务" class="headerlink" title="调用服务"></a>调用服务</h4><p>服务调用方也需要引入eureka-client依赖，但需设置不注册到服务中心</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">eureka:</span></span><br><span class="line"><span class="attr">  client:</span></span><br><span class="line"><span class="attr">    register-with-eureka:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure><p>服务调用可以使用ribbon或者feign进行负载均衡</p><p><strong>使用ribbon：</strong></p><p>eureka-client包中已经引入了netflix-ribbon，所以不用单独添加依赖。</p><p>注册一个RestTemplate Bean</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="meta">@EnableEurekaClient</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConsumerApp</span></span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">SpringApplication.run(ConsumerApp.class);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="meta">@LoadBalanced</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> RestTemplater <span class="title">restTemplate</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> RestTemplate();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>根据服务名称调用服务：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span>  <span class="title">UserController</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span>  <span class="keyword">final</span> String URL_PREFIX = <span class="string">"http://USER-PROVIDER"</span>;</span><br><span class="line">    <span class="keyword">private</span> RestTemplate restTemplate;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setRestTemplate</span><span class="params">(RestTemplate template)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.restTemplate = template;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping</span>(<span class="string">"/user/&#123;id&#125;"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> User <span class="title">getUser</span><span class="params">(@PathVariable(<span class="string">"id"</span>)</span>Long id)</span>&#123;</span><br><span class="line">        <span class="comment">//调用远程服务 http请求</span></span><br><span class="line">        String url = URL_PREFIX+<span class="string">"/provider/user/"</span>+id;</span><br><span class="line">        <span class="keyword">return</span> restTemplate.getForObject(url,User.class);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>缺点是需要拼接字符串。</p><p><strong>使用feign</strong></p><p>feign底层也是使用的ribbon</p><p>主类添加注解@EnableEurekaClient表示服务消费者是Eurrka客户端</p><p>主类添加注解@EnableFeignClients表示使用Fegin进行负载</p><p>首先定义fegint访问接口：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@FeignClient</span>(value=<span class="string">"user-provider"</span>)<span class="comment">//需要调用的服务名称</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">UserServiceFeignClient</span></span>&#123;</span><br><span class="line">    <span class="comment">//此处为服务提供者提供的url</span></span><br><span class="line">    <span class="meta">@GetMapping</span>(<span class="string">"provider/user/&#123;id&#125;"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> User <span class="title">getUser</span><span class="params">(@PathVariable(<span class="string">"id"</span>)</span>Long id)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在Controller中访问</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserController</span></span>&#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> UserServiceFeignClient client;</span><br><span class="line">    <span class="comment">//此处为服务消费者提供的url</span></span><br><span class="line">    <span class="meta">@GetMapping</span>(<span class="string">"/user/&#123;id&#125;"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> User <span class="title">getUser</span><span class="params">(@PathVariable(<span class="string">"id"</span>)</span> Long id)</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> client.getUser(id);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>比直接使用ribbon优雅多了</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;父项目依赖配置：&quot;&gt;&lt;a href=&quot;#父项目依赖配置：&quot; class=&quot;headerlink&quot; title=&quot;父项目依赖配置：&quot;&gt;&lt;/a&gt;父项目依赖配置：&lt;/h4&gt;&lt;p&gt;父项目pom配置：&lt;/p&gt;
&lt;figure class=&quot;highlight xml&quot;&gt;&lt;t
      
    
    </summary>
    
    
      <category term="SpringCloud" scheme="http://yoursite.com/child/tags/SpringCloud/"/>
    
  </entry>
  
  <entry>
    <title>redis-热key问题</title>
    <link href="http://yoursite.com/child/2020/01/02/redis-%E7%83%AD%E7%82%B9key%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/child/2020/01/02/redis-热点key问题/</id>
    <published>2020-01-01T16:00:00.000Z</published>
    <updated>2020-01-02T09:24:23.593Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.cnblogs.com/rjzheng/p/10874537.html" target="_blank" rel="noopener">原文链接</a></p><p>所谓热key问题就是，突然有几十万的请求去访问redis上的某个特定key。那么，这样会造成流量过于集中，达到物理网卡上限，从而导致这台redis的服务器宕机。<br>那接下来这个key的请求，就会直接怼到你的数据库上，导致你的服务不可用。</p><h3 id="1-怎么发现热key"><a href="#1-怎么发现热key" class="headerlink" title="1. 怎么发现热key"></a>1. 怎么发现热key</h3><p><strong><em>方法一:凭借业务经验，进行预估哪些是热key</em></strong><br>其实这个方法还是挺有可行性的。比如某商品在做秒杀，那这个商品的key就可以判断出是热key。</p><p>缺点很明显，并非所有业务都能预估出哪些key是热key。</p><p><strong><em>方法二:在客户端进行收集</em></strong><br>这个方式就是在操作redis之前，加入一行代码进行数据统计。那么这个数据统计的方式有很多种，也可以是给外部的通讯系统发送一个通知信息。缺点就是对客户端代码造成入侵。</p><p><strong><em>方法三:在Proxy层做收集</em></strong><br>有些集群架构是下面这样的，Proxy可以是Twemproxy，是统一的入口。可以在Proxy层做收集上报，但是缺点很明显，并非所有的redis集群架构都有proxy。</p><p><img src="https://img2018.cnblogs.com/blog/725429/201905/725429-20190516112209464-1290077151.png" alt="img"></p><p><strong><em>方法四:用redis自带命令</em></strong></p><ol><li>monitor命令，该命令可以实时抓取出redis服务器接收到的命令，然后写代码统计出热key是啥。当然，也有现成的分析工具可以给你使用，比如<code>redis-faina</code>。但是该命令在高并发的条件下，有内存增暴增的隐患，还会降低redis的性能。</li><li>hotkeys参数，redis 4.0.3提供了redis-cli的热点key发现功能，执行redis-cli时加上–hotkeys选项即可。但是该参数在执行的时候，如果key比较多，执行起来比较慢。</li></ol><p>缺点是对redis性能影响较大</p><p><strong><em>方法五:自己抓包评估</em></strong><br>Redis客户端使用TCP协议与服务端进行交互，通信协议采用的是RESP。自己写程序监听端口，按照RESP协议规则解析数据，进行分析。缺点就是开发成本高，维护困难，有丢包可能性。</p><p>以上五种方案，各有优缺点。根据自己业务场景进行抉择即可。那么发现热key后，如何解决呢？</p><h3 id="2-如何解决"><a href="#2-如何解决" class="headerlink" title="2. 如何解决"></a>2. 如何解决</h3><p>目前业内的方案有两种</p><p><strong><em>方案一：利用二级缓存</em></strong><br>比如利用<code>ehcache</code>，或者一个<code>HashMap</code>都可以。在你发现热key以后，把热key加载到系统的JVM中。<br>针对这种热key请求，会直接从jvm中取，而不会走到redis层。<br>假设此时有十万个针对同一个key的请求过来,如果没有本地缓存，这十万个请求就直接怼到同一台redis上了。<br>现在假设，你的应用层有50台机器，OK，你也有jvm缓存了。这十万个请求平均分散开来，每个机器有2000个请求，会从JVM中取到value值，然后返回数据。避免了十万个请求怼到同一台redis上的情形。</p><p><strong><em>方案二：备份热key</em></strong><br>这个方案也很简单。不要让key走到同一台redis上不就行了。我们把这个key，在多个redis上都存一份不就好了。接下来，有热key请求进来的时候，我们就在有备份的redis上随机选取一台，进行访问取值，返回数据。<br>假设redis的集群数量为N，步骤如下图所示</p><p><img src="https://img2018.cnblogs.com/blog/725429/201905/725429-20190516112222759-656135438.png" alt="img"></p><p>注:不一定是2N，你想取3N，4N都可以，看要求。<br>伪代码如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> M = N * <span class="number">2</span></span><br><span class="line"><span class="comment">//生成随机数</span></span><br><span class="line">random = GenRandom(<span class="number">0</span>, M)</span><br><span class="line"><span class="comment">//构造备份新key</span></span><br><span class="line">bakHotKey = hotKey + “_” + random</span><br><span class="line">data = redis.GET(bakHotKey)</span><br><span class="line"><span class="keyword">if</span> data == NULL &#123;</span><br><span class="line">    data = GetFromDB()</span><br><span class="line">    redis.SET(bakHotKey, expireTime + GenRandom(<span class="number">0</span>,<span class="number">5</span>))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-业内方案"><a href="#3-业内方案" class="headerlink" title="3. 业内方案"></a>3. 业内方案</h3><p>OK，其实看完上面的内容，大家可能会有一个疑问。</p><blockquote><p><strong>有办法在项目运行过程中，自动发现热key，然后程序自动处理么？</strong></p></blockquote><p>嗯，好问题，那我们来讲讲业内怎么做的。其实只有两步</p><ol><li>监控热key</li><li>通知系统做处理</li></ol><p>正巧，前几天有赞出了一篇《有赞透明多级缓存解决方案（TMC）》，里头也有提到热点key问题，我们刚好借此说明</p><ul><li>监控热key</li></ul><p>在监控热key方面，有赞用的是<strong><em>方式二：在客户端进行收集</em></strong>。<br>在《有赞透明多级缓存解决方案（TMC）》中有一句话提到</p><blockquote><p><strong>TMC 对原生jedis包的JedisPool和Jedis类做了改造，在JedisPool初始化过程中集成TMC“热点发现”+“本地缓存”功能Hermes-SDK包的初始化逻辑。</strong></p></blockquote><p>也就说人家改写了jedis原生的jar包，加入了Hermes-SDK包。<br>那Hermes-SDK包用来干嘛？<br>OK，就是做<strong>热点发现</strong>和<strong>本地缓存</strong>。</p><p>从监控的角度看，该包对于Jedis-Client的每次key值访问请求，Hermes-SDK 都会通过其通信模块将key访问事件异步上报给Hermes服务端集群，以便其根据上报数据进行“热点探测”。</p><p>当然，这只是其中一种方式，有的公司在监控方面用的是方式五:<strong>自己抓包评估</strong>。</p><p>具体是这么做的，先利用flink搭建一套流式计算系统。然后自己写一个抓包程序抓redis监听端口的数据，抓到数据后往kafka里丢。接下来，流式计算系统消费kafka里的数据，进行数据统计即可，也能达到监控热key的目的。</p><ul><li>通知系统做处理</li></ul><p>在这个角度，有赞用的是上面的<strong><em>解决方案一:利用二级缓存进行处理</em></strong>。</p><p>有赞在监控到热key后，Hermes服务端集群会通过各种手段通知各业务系统里的Hermes-SDK，告诉他们:”老弟，这个key是热key，记得做本地缓存。”</p><p>于是Hermes-SDK就会将该key缓存在本地，对于后面的请求。Hermes-SDK发现这个是一个热key，直接从本地中拿，而不会去访问集群。</p><p>除了这种通知方式以外。我们也可以这么做，比如你的流式计算系统监控到热key了，往zookeeper里头的某个节点里写。然后你的业务系统监听该节点，发现节点数据变化了，就代表发现热key。最后往本地缓存里写，也是可以的。</p><p>通知方式各种各样，大家可以自由发挥。本文只是提供一个思路。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/rjzheng/p/10874537.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原文链接&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;所谓热key问题就是，突然有几十万的请求去访问redis上的某个
      
    
    </summary>
    
    
      <category term="redis" scheme="http://yoursite.com/child/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>mysql-innoDB架构分析</title>
    <link href="http://yoursite.com/child/2020/01/02/mysql-innoDB%E6%9E%B6%E6%9E%84%E5%88%86%E6%9E%90/"/>
    <id>http://yoursite.com/child/2020/01/02/mysql-innoDB架构分析/</id>
    <published>2020-01-01T16:00:00.000Z</published>
    <updated>2020-03-31T15:05:22.133Z</updated>
    
    <content type="html"><![CDATA[<p>先上一张官网的架构图，本文将按照架构图中的组件逐一分析。</p><p><img src="https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/mysql/innodb-architecture.png" alt="https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/mysql/innodb-architecture.png"></p><h4 id="1-buffer-pool"><a href="#1-buffer-pool" class="headerlink" title="1. buffer pool"></a>1. buffer pool</h4><p>按照局部性原理，将预期会使用到的数据缓存到内存中，避免每次读取数据都需要进行磁盘i/o，提升i/o性能，这块存放缓存的内存区域就是buffer pool。</p><p>buffer pool 是一种降低磁盘访问的机制。</p><p>磁盘访问通常以页为单位。</p><p>缓存池常见的实现方式是LRU（链表实现，为了减少数据移动），管理磁盘页。</p><p>缓存池管理方式–LRU（链表实现，为了减少数据移动）</p><p>普通LRU会有以下问题：</p><ul><li>预读取失效，预读取的页不会真正被读取<ul><li>优化思路：让预读失效页尽快出内存，真正读取页才挪到LRU头部</li><li>方案：分代管理，预读取进入老生代，真正读取再进入新生代</li></ul></li><li>缓冲池污染，要批量扫描大量数据，导致缓冲池中的热点页被大量替换出去<ul><li>方案：在老生代设置停留时间，只有被真正读取并且停留时间达到阈值，才会移步新生代</li></ul></li></ul><p><strong>innoDB 的buffer pool 对应参数</strong></p><p>参数：innodb_buffer_pool_size</p><p>介绍：配置缓冲池的大小，在内存允许的情况下，DBA往往会建议调大这个参数，越多数据和索引放到内存里，数据库的性能会越好。 </p><p>参数：innodb_old_blocks_pct</p><p>介绍：老生代占整个LRU链长度的比例，默认是37，即整个LRU中新生代与老生代长度比例是63:37。</p><p><em>画外音：如果把这个参数设为100，就退化为普通LRU了。</em></p><p>参数：innodb_old_blocks_time</p><p>介绍：老生代停留时间窗口，单位是毫秒，默认是1000，即同时满足“被访问”与“在老生代停留时间超过1秒”两个条件，才会被插入到新生代头部。</p><p><a href="https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&amp;mid=2651962450&amp;idx=1&amp;sn=ce17c4da8d20ce275f75d0f2ef5e40c9&amp;chksm=bd2d098e8a5a809834aaa07da0d7546555385543fb6d687a7cf94d183ab061cd301a76547411&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Buffer pool 参考链接</a></p><p>对于读请求，buffer pool 能够减少磁盘的io，提高性能，那么对于写请求呢？change buffer此时登场。</p><h4 id="2-Change-Buffer"><a href="#2-Change-Buffer" class="headerlink" title="2. Change Buffer"></a>2. Change Buffer</h4><p>而对于写请求的优化，就是使用change buffer 来降低磁盘io的</p><p>主要应用于<strong>不在缓冲池中的非唯一普通索引页的写操作</strong></p><p>如果要写的页写已经在缓冲池中了是怎样一个写流程？</p><p>为什么唯一索引不适用呢？</p><p>唯一索引的话每次插入操作都需要检查索引的唯一性</p><p><a href="https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&amp;mid=2651962467&amp;idx=1&amp;sn=899ea157b0fc6f849ec80a4d055a309b&amp;chksm=bd2d09bf8a5a80a972a2e16a190ed7dffe03f89015ead707bdfcc5aeb8388fb278f397c125f1&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">change buffer 参考</a></p><p>相关参数：</p><p><strong>参数</strong>：innodb_change_buffer_max_size</p><p><strong>介绍</strong>：配置写缓冲的大小，占整个缓冲池的比例，默认值是25%，最大值是50%。</p><p><em>画外音：写多读少的业务，才需要调大这个值，读多写少的业务，25%其实也多了。</em></p><p><strong>参数</strong>：innodb_change_buffering</p><p><strong>介绍</strong>：配置哪些写操作启用写缓冲，可以设置成all/none/inserts/deletes等。</p><h4 id="3-Log-buffer"><a href="#3-Log-buffer" class="headerlink" title="3. Log buffer"></a>3. Log buffer</h4><p>知其然，知其所以然。思路比结论重要</p><p>事务提交时，事务日志为什么要先写到log buffer 在写到os cache中呢？</p><p>虽然是内存操作，但是日志写到os cache中需要进行上下文切换切换到内核态，每次事务提交都直接写则每次都要切换到内核态。先写到log buffer中，将每次写优化为批量写，减少上下文切换次数。</p><p><em>这个优化思路很常见，高并发的MQ落盘，高并发的业务数据落盘，都可以使用。</em></p><h4 id="4-AHI–Adaptive-Hash-Index"><a href="#4-AHI–Adaptive-Hash-Index" class="headerlink" title="4. AHI–Adaptive Hash Index"></a>4. AHI–Adaptive Hash Index</h4><p>自适应哈希索引</p><p><strong>为什么叫自适应？</strong></p><p>用户不能创建，是mysql优化器自行判断，需要时创建</p><p><strong>既然是hash，key是什么，value是什么？</strong></p><p>key是索引键值</p><p>value是索引记录的页面位置</p><p>所以hash索引是索引的索引</p><p><strong>为什么要用哈希索引进行优化？</strong></p><p>通过附加索引查询数据时，有时候会进行回表查询，这样会导致查询连路很长降低查询效率</p><p><strong>哪些业务适用，哪些业务不适用？</strong></p><p>单行记录查询、索引范围查询、记录数不多能全部放到内存中—-适用</p><p>业务中有大量join、like时，AHI的维护会成为负担，建议手动关闭。</p><h4 id="5-redo-log"><a href="#5-redo-log" class="headerlink" title="5. redo log"></a>5. redo log</h4><p>有单独文章讲解</p><h4 id="6-double-write-buffer"><a href="#6-double-write-buffer" class="headerlink" title="6. double write buffer"></a>6. double write buffer</h4><p>知其然，知其所以然。思路比结论重要</p><p><strong>解决什么问题？</strong></p><p>innoDB数据页大小是16k，文件系统中的数据页（后称系统页）大小是4K，那么写数据库时我们将一页数据页落盘，需要刷写4页系统页，如果在此过程中系统掉电，将造成磁盘数据页损坏（例如，前两页系统页已被刷写，后两页未刷写）。</p><p><strong>如何解决？</strong></p><p>DWB缓存即将刷写的数据页。。</p><p>DWB具有两层架构，分为内存和磁盘</p><p>当有数据要落盘时：</p><p>第一步：将内存中修改后的数据页memcopy到dwb内存中</p><p>第二步：将dwb内存中的数据页写入dwb磁盘</p><p>第三步：将dwb中的数据页落盘到磁盘数据页</p><p>假使第二步掉电，磁盘数据页也还是完整的，可以通过redo log进行恢复</p><p>假如第三笔掉电，dwb中的数据页也是完整的，可以直接落盘</p><p><strong>性能影响大吗？</strong></p><p>第一步属于内存操作，速度很快</p><p>第二步属于磁盘顺序追加写，1秒几万次没问题</p><p>第三步不属于额外操作</p><p>另外，dwb 由128页组成，容量2MB，会分两次刷入dwb磁盘，每次1M，速度也很快</p><p><em>有第三方评测，性能损失约为10%</em></p><p>可以通过：</p><p>show global status like “%dblwr%” 查看dwb使用情况</p><p>Innodb_dblwr_pages_written 记录dwb中的写入页数</p><p>Innodb_dblwr_writes 记录dwb的写入次数</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;先上一张官网的架构图，本文将按照架构图中的组件逐一分析。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/mysql/innodb-architecture.png&quot; alt=&quot;https
      
    
    </summary>
    
    
      <category term="数据库" scheme="http://yoursite.com/child/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>jvm-对象的内存布局</title>
    <link href="http://yoursite.com/child/2019/12/31/jvm-%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80/"/>
    <id>http://yoursite.com/child/2019/12/31/jvm-对象的内存布局/</id>
    <published>2019-12-30T16:00:00.000Z</published>
    <updated>2019-12-31T02:29:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>对象内的布局是：最前面是对象头，有两个VM内部字段：_mark 和 _klass。</p><p>后面紧跟着就是对象的所有实例字段，紧凑排布，规则如下：</p><ul><li>继承深度越浅的类所声明的字段越靠前，继承深度越深的类所声明的字段越靠后。</li><li>在同一个类中声明的字段按字段的类型宽度来重排序，对普通Java类默认的排序是：long/double - 8字节、int/float - 4字节、short/char - 2字节、byte/boolean - 1字节，最后是引用类型字段（4或8字节）。</li><li>每个字段按照其宽度来对齐；最终对象默认再做一次8字节对齐。在类继承的边界上如果有因对齐而带来的空隙的话，可以把子类的字段拉到空隙里。</li></ul><p>这种排布方式可以让原始类型字段最大限度地紧凑排布在一起，减少字段间因为对齐而带来的空隙；同时又让引用类型字段尽可能排布在一起，减少OopMap的开销。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span> </span>&#123;</span><br><span class="line">  <span class="keyword">boolean</span> b;</span><br><span class="line">  Object o1;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">B</span> <span class="keyword">extends</span> <span class="title">A</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> i;</span><br><span class="line">  <span class="keyword">long</span> l;</span><br><span class="line">  Object o2;</span><br><span class="line">  <span class="keyword">float</span> f;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">C</span> <span class="keyword">extends</span> <span class="title">B</span> </span>&#123;</span><br><span class="line">  <span class="keyword">boolean</span> b;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>它的实例对象布局就是：（假定是64位HotSpot VM，默认开启压缩指针的话）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">--&gt;  +0 [ _mark     ] (64-bit header word)</span><br><span class="line">     +8 [ _klass    ] (32-bit header word, compressed klass pointer)</span><br><span class="line">    +12 [ A.b       ] (boolean, 1 byte)</span><br><span class="line">    +13 [ (padding) ] (padding for alignment, 3 bytes)</span><br><span class="line">    +16 [ A.o1      ] (reference, compressed pointer, 4 bytes)</span><br><span class="line">    +20 [ B.i       ] (int, 4 bytes)</span><br><span class="line">    +24 [ B.l       ] (long, 8 bytes)</span><br><span class="line">    +32 [ B.f       ] (float, 4 bytes)</span><br><span class="line">    +36 [ B.o2      ] (reference, compressed pointer, 4 bytes)</span><br><span class="line">    +40 [ C.b       ] (boolean, 1 byte)</span><br><span class="line">    +41 [ (padding) ] (padding for object alignment, 7 bytes)</span><br></pre></td></tr></table></figure><p>所以C类的对象实例大小，在这个设定下是48字节，其中有10字节是为对齐而浪费掉的padding，12字节是对象头，剩下的26字节是用户自己代码声明的实例字段。</p><p>留意到C类里字段的排布是按照这个顺序的：对象头 - Object声明的字段（无） - A声明的字段 - B声明的字段 - C声明的字段——按继承深度从浅到深排布。而每个类里面的字段排布顺序则按前面说的规则，按宽度来重排序。同时，如果类继承边界上有空隙（例如这里A和B之间其实本来会有一个4字节的空隙，但B里正好声明了一些不宽于4字节的字段，就可以把第一个不宽于4字节的字段拉到该空隙里，也就是 B.i 的位置）。</p><p>同时也请留意到A类和C类都声明了名字为b的字段。它们之间有什么关系？——没关系。<br>Java里，<strong>字段是不参与多态</strong>的。</p><p>派生类如果声明了跟基类同名的字段，则两个字段在最终的实例中都会存在；派生类的版本只会在名字上遮盖（shadow / hide）掉基类字段的名字，而不会与基类字段合并或令其消失。上面例子特意演示了一下A.b 与 C.b 同时存在的这个情况。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;对象内的布局是：最前面是对象头，有两个VM内部字段：_mark 和 _klass。&lt;/p&gt;
&lt;p&gt;后面紧跟着就是对象的所有实例字段，紧凑排布，规则如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;继承深度越浅的类所声明的字段越靠前，继承深度越深的类所声明的字段越靠后。&lt;/li&gt;
&lt;li&gt;在
      
    
    </summary>
    
    
      <category term="jvm" scheme="http://yoursite.com/child/tags/jvm/"/>
    
  </entry>
  
  <entry>
    <title>reids-5.0版本的高可用集群搭建</title>
    <link href="http://yoursite.com/child/2019/12/31/redis-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    <id>http://yoursite.com/child/2019/12/31/redis-集群搭建/</id>
    <published>2019-12-30T16:00:00.000Z</published>
    <updated>2020-01-02T08:05:49.915Z</updated>
    
    <content type="html"><![CDATA[<p>Redis系统介绍：</p><p><a href="https://www.jianshu.com/p/2a23257af57b" target="_blank" rel="noopener">Redis的基础介绍与安装使用步骤</a><br><a href="https://www.jianshu.com/p/c95c8450c5b6" target="_blank" rel="noopener">Redis的基础数据结构与使用</a><br><a href="https://www.jianshu.com/p/4e6b7809e10a" target="_blank" rel="noopener">Redis核心原理</a><br><a href="https://www.jianshu.com/p/8045b92fafb2" target="_blank" rel="noopener">Redis 5 之后版本的高可用集群搭建</a><br><a href="https://www.jianshu.com/p/6355d0827aea" target="_blank" rel="noopener">Redis 5 版本的高可用集群的水平扩展</a><br><a href="https://www.jianshu.com/p/e6894713a6d5" target="_blank" rel="noopener">Redis 5 集群选举原理分析</a><br><a href="https://www.jianshu.com/p/575544f68615" target="_blank" rel="noopener">Redis 5 通信协议解析以及手写一个Jedis客户端</a></p><hr><h4 id="1-集群方案比较："><a href="#1-集群方案比较：" class="headerlink" title="1. 集群方案比较："></a>1. 集群方案比较：</h4><h5 id="1-1-哨兵模式："><a href="#1-1-哨兵模式：" class="headerlink" title="1.1 哨兵模式："></a>1.1 哨兵模式：</h5><p>在redis3.0以前的版本要实现集群一般是借助哨兵sentinel工具来监控master节点的状态，如果master节点异常，则会做主从切换，将某一台slave作为master，哨兵的配置略微复杂，并且性能和高可用性等各方面表现一般，特别是在主从切换的瞬间存在访问瞬断的情况，而且哨兵模式只有一个主节点对外提供服务，没法支持很高的并发，且单个主节点内存也不宜设置得过大，否则会导致持久化文件过大，影响数据恢复或主从同步的效率。</p><p><img src="https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/redis/redis-cluster%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F.png" alt="哨兵模式"></p><h5 id="1-2-高可用集群模式："><a href="#1-2-高可用集群模式：" class="headerlink" title="1.2 高可用集群模式："></a>1.2 高可用集群模式：</h5><p>redis集群是一个由多个主从节点群组成的分布式服务器群，它具有复制、高可用和分片特性。Redis集群不需要sentinel哨兵也能完成节点移除和故障转移的功能。需要将每个节点设置成集群模式，这种集群模式没有中心节点，可水平扩展，据官方文档称可以线性扩展到上万个节点(官方推荐不超过1000个节点)。redis集群的性能和高可用性均优于之前版本的哨兵模式，且集群配置非常简单。</p><p><img src="https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/redis/redis-cluster%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84.png" alt="高可用架构"></p><h4 id="2-开始搭建"><a href="#2-开始搭建" class="headerlink" title="2. 开始搭建"></a>2. 开始搭建</h4><h5 id="2-1-安装redis"><a href="#2-1-安装redis" class="headerlink" title="2.1 安装redis"></a>2.1 安装redis</h5><p>参考之前博客：Redis的基础介绍与安装使用步骤：<a href="https://www.jianshu.com/p/2a23257af57b" target="_blank" rel="noopener">https://www.jianshu.com/p/2a23257af57b</a></p><p>下载地址：<a href="http://redis.io/download" target="_blank" rel="noopener">http://redis.io/download</a></p><p>1、安装gcc</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install gcc</span><br></pre></td></tr></table></figure><p>2、把下载好的redis-5.0.2.tar.gz放在/usr/local文件夹下，并解压</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget http://download.redis.io/releases/redis-5.0.2.tar.gz</span><br><span class="line">tar xzf redis-5.0.2.tar.gz</span><br><span class="line"><span class="built_in">cd</span> redis-5.0.2</span><br></pre></td></tr></table></figure><p>3、进入到解压好的redis-5.0.2目录下，进行编译与安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make &amp; make install</span><br></pre></td></tr></table></figure><p>4、启动并指定配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">src/redis-server redis.conf</span><br></pre></td></tr></table></figure><p>（注意要使用后台启动，所以修改redis.conf里的daemonize改为yes)</p><p>5、验证启动是否成功</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -ef | grep redis</span><br></pre></td></tr></table></figure><p>6、进入redis客户端</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/redis/redis-5.0.2/src</span><br><span class="line">./redis-cli</span><br></pre></td></tr></table></figure><p>7、退出客户端</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">exit</span></span><br></pre></td></tr></table></figure><p>8、退出redis服务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pkill redis-server</span><br><span class="line"><span class="built_in">kill</span> 进程号</span><br><span class="line">src/redis-cli shutdown</span><br></pre></td></tr></table></figure><h5 id="2-2-集群搭建"><a href="#2-2-集群搭建" class="headerlink" title="2.2 集群搭建"></a>2.2 集群搭建</h5><p>redis集群需要至少要三个master节点，我们这里搭建三个master节点，并且给每个master再搭建一个slave节点，总共6个redis节点，这里用一台机器（可以多台机器部署，修改一下ip地址就可以了）部署6个redis实例，三主三从，搭建集群的步骤如下：</p><p><strong>第一步：</strong>在机器的/usr/local下创建文件夹redis-cluster，然后在其下面创建6个文件夾如下:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /usr/<span class="built_in">local</span>/redis-cluster</span><br><span class="line"></span><br><span class="line">mkdir 8001 8002 8003 8004 8005 8006</span><br></pre></td></tr></table></figure><p><strong>第二步：</strong>把之前的redis.conf配置文件copy到8001下，修改如下内容：</p><blockquote><p>1）daemonize yes</p><p>2）port 8001（分别对每个机器的端口号进行设置）</p><p>3）dir /usr/local/redis-cluster/8001/（指定数据文件存放位置，必须要指定不同的目录位置，不然会丢失数据）</p><p>4）cluster-enabled yes（启动集群模式）</p><p>5）cluster-config-file nodes-8001.conf（集群节点信息文件，这里800x最好和port对应上）</p><p>6）cluster-node-timeout 5000</p><p>7)  bind 127.0.0.1（去掉bind绑定访问ip信息）</p><p>8)  protected-mode  no   （关闭保护模式）</p><p>9）appendonly yes</p><p>如果要设置密码需要增加如下配置：</p><p>10）requirepass xxx     (设置redis访问密码)</p><p>11）masterauth  xxx     (设置集群节点间访问密码，跟上面一致)</p></blockquote><p><strong>第三步：</strong>把修改后的配置文件，copy到8002-8006，修改第2、3、5项里的端口号，可以用批量替换：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%s/源字符串/目的字符串/g</span><br></pre></td></tr></table></figure><p><strong>第四步：</strong>分别启动6个redis实例，然后检查是否启动成功</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/redis-5.0.7/src/redis-server /usr/<span class="built_in">local</span>/redis-cluster/800*/redis.conf</span><br></pre></td></tr></table></figure><p><strong>第五步：</strong>用redis-cli创建整个redis集群(redis5以前的版本集群是依靠ruby脚本redis-trib.rb实现)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/redis-5.0.7/src/redis-cli -a xxx --cluster create --cluster-replicas 1 192.168.2.116:8001 192.168.2.116:8002 192.168.2.116:8003 192.168.2.116:8004 192.168.2.116:8005 192.168.2.116:8006</span><br></pre></td></tr></table></figure><p>代表为每个创建的主服务器节点创建一个从服务器节点</p><p><strong>第六步：</strong>验证集群：</p><p>1）连接任意一个客户端即可：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./redis-cli -c -a xxx -h 192.168.2.116 -p 8001</span><br></pre></td></tr></table></figure><p>提示：-a访问服务端密码，-c表示集群模式，指定ip地址和端口号</p><p>例如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/redis-5.0.2/src/redis-cli -a xxx -c -h 192.168.2.116 -p 8001</span><br></pre></td></tr></table></figure><p>注意这里进入到8002了，redirected。</p><p>2）进行验证： cluster info（查看集群信息）、cluster nodes（查看节点列表）</p><p>3）进行数据操作验证</p><p>4）关闭集群则需要逐个进行关闭，使用命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/redis/src/redis-cli -a xxx -c -h 192.168.2.116 -p 8001 shutdown</span><br></pre></td></tr></table></figure><h4 id="3-设置开机自启"><a href="#3-设置开机自启" class="headerlink" title="3. 设置开机自启"></a>3. 设置开机自启</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/init.d/redis</span><br></pre></td></tr></table></figure><p>将如下代码粘贴进去：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/src/sh</span></span><br><span class="line"><span class="comment"># chkconfig: 2345 80 90</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Simple Redis init.d script conceived to work on Linux systems</span></span><br><span class="line"><span class="comment"># as it does use of the /proc filesystem.</span></span><br><span class="line">​</span><br><span class="line">REDISPORT1=8001</span><br><span class="line">REDISPORT2=8002</span><br><span class="line">REDISPORT3=8003</span><br><span class="line">REDISPORT4=8004</span><br><span class="line">REDISPORT5=8005</span><br><span class="line">REDISPORT6=8006</span><br><span class="line">EXEC=/usr/<span class="built_in">local</span>/redis-5.0.7/src/redis-server</span><br><span class="line">CLIEXEC=/usr/<span class="built_in">local</span>/redis-5.0.7/src/redis-cli</span><br><span class="line">​</span><br><span class="line">PIDFILE=/var/run/redis_<span class="variable">$&#123;REDISPORT1&#125;</span>.pid</span><br><span class="line">​</span><br><span class="line">CONF1=<span class="string">"/usr/local/redis-cluster/<span class="variable">$&#123;REDISPORT1&#125;</span>/redis.conf"</span></span><br><span class="line">CONF2=<span class="string">"/usr/local/redis-cluster/<span class="variable">$&#123;REDISPORT2&#125;</span>/redis.conf"</span></span><br><span class="line">CONF3=<span class="string">"/usr/local/redis-cluster/<span class="variable">$&#123;REDISPORT3&#125;</span>/redis.conf"</span></span><br><span class="line">CONF4=<span class="string">"/usr/local/redis-cluster/<span class="variable">$&#123;REDISPORT4&#125;</span>/redis.conf"</span></span><br><span class="line">CONF5=<span class="string">"/usr/local/redis-cluster/<span class="variable">$&#123;REDISPORT5&#125;</span>/redis.conf"</span></span><br><span class="line">CONF6=<span class="string">"/usr/local/redis-cluster/<span class="variable">$&#123;REDISPORT6&#125;</span>/redis.conf"</span></span><br><span class="line">​</span><br><span class="line"><span class="keyword">case</span> <span class="string">"<span class="variable">$1</span>"</span> <span class="keyword">in</span></span><br><span class="line">    start)</span><br><span class="line">        <span class="keyword">if</span> [ -f <span class="variable">$PIDFILE</span> ]</span><br><span class="line">        <span class="keyword">then</span></span><br><span class="line">                <span class="built_in">echo</span> <span class="string">"<span class="variable">$PIDFILE</span> exists, process is already running or crashed"</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">                <span class="built_in">echo</span> <span class="string">"Starting Redis cluster server..."</span></span><br><span class="line">                <span class="variable">$EXEC</span> <span class="variable">$CONF1</span> &amp;</span><br><span class="line">                <span class="variable">$EXEC</span> <span class="variable">$CONF2</span> &amp;</span><br><span class="line">                <span class="variable">$EXEC</span> <span class="variable">$CONF3</span> &amp;</span><br><span class="line">                <span class="variable">$EXEC</span> <span class="variable">$CONF4</span> &amp;</span><br><span class="line">                <span class="variable">$EXEC</span> <span class="variable">$CONF5</span> &amp;</span><br><span class="line">                <span class="variable">$EXEC</span> <span class="variable">$CONF6</span> &amp;</span><br><span class="line">                <span class="built_in">echo</span> <span class="string">"启动成功..."</span></span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">        ;;</span><br><span class="line">    stop)</span><br><span class="line">        <span class="keyword">if</span> [ ! -f <span class="variable">$PIDFILE</span> ]</span><br><span class="line">        <span class="keyword">then</span></span><br><span class="line">                <span class="built_in">echo</span> <span class="string">"<span class="variable">$PIDFILE</span> does not exist, process is not running"</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">                PID=$(cat <span class="variable">$PIDFILE</span>)</span><br><span class="line">                <span class="built_in">echo</span> <span class="string">"Stopping ..."</span></span><br><span class="line">                <span class="variable">$CLIEXEC</span> -p <span class="variable">$REDISPORT1</span> shutdown</span><br><span class="line">                <span class="variable">$CLIEXEC</span> -p <span class="variable">$REDISPORT2</span> shutdown</span><br><span class="line">                <span class="variable">$CLIEXEC</span> -p <span class="variable">$REDISPORT3</span> shutdown</span><br><span class="line">                <span class="variable">$CLIEXEC</span> -p <span class="variable">$REDISPORT4</span> shutdown</span><br><span class="line">                <span class="variable">$CLIEXEC</span> -p <span class="variable">$REDISPORT5</span> shutdown</span><br><span class="line">                <span class="variable">$CLIEXEC</span> -p <span class="variable">$REDISPORT6</span> shutdown</span><br><span class="line">                <span class="keyword">while</span> [ -x /proc/<span class="variable">$&#123;PID&#125;</span> ]</span><br><span class="line">                <span class="keyword">do</span></span><br><span class="line">                    <span class="built_in">echo</span> <span class="string">"Waiting for Redis cluster to shutdown ..."</span></span><br><span class="line">                    sleep 1</span><br><span class="line">                <span class="keyword">done</span></span><br><span class="line">                <span class="built_in">echo</span> <span class="string">"Redis cluster stopped"</span></span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">        ;;</span><br><span class="line">    *)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"Please use start or stop as first argument"</span></span><br><span class="line">        ;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure><p>添加权限</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod +x /etc/init.d/redis</span><br></pre></td></tr></table></figure><p>加入开机启动服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chkconfig --add redis</span><br></pre></td></tr></table></figure><p>使用命令进行开启或关闭redis集群</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">service redis start </span><br><span class="line">service redis stop</span><br></pre></td></tr></table></figure><p><a href="https://www.jianshu.com/p/8045b92fafb2" target="_blank" rel="noopener">原文连接</a></p><p><a href="https://blog.csdn.net/qq_37859539/article/details/83715803" target="_blank" rel="noopener">https://blog.csdn.net/qq_37859539/article/details/83715803</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Redis系统介绍：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/2a23257af57b&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Redis的基础介绍与安装使用步骤&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https
      
    
    </summary>
    
    
      <category term="redis" scheme="http://yoursite.com/child/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>nio-说说零拷贝</title>
    <link href="http://yoursite.com/child/2019/12/19/nio-%E8%AF%B4%E8%AF%B4%E9%9B%B6%E6%8B%B7%E8%B4%9D/"/>
    <id>http://yoursite.com/child/2019/12/19/nio-说说零拷贝/</id>
    <published>2019-12-18T16:00:00.000Z</published>
    <updated>2019-12-23T02:56:22.000Z</updated>
    
    <content type="html"><![CDATA[<p>从一个业务场景开始：从本地磁盘读取一个文件通过socket发送出去。</p><p>传统的I/O接口处理流程如下：读文件到应用-&gt;应用打包文件到socket-&gt;发送</p><ol><li>应用发起系统调用sys_read()（或等价的方法）请求读磁盘文件</li><li>系统切换到内核态，读磁盘数据到内核读缓冲区（DMA方式）</li><li>系统将内核读缓冲区数据拷贝到应用缓冲区（CPU拷贝），read方法返回，系统切换到用户态。</li><li>应用包装好数据后发起send() 系统调用</li><li>系统切换到内核态，将数据写入到socket缓冲区（CPU拷贝）</li><li>将socket缓冲区的数据发送给网络接口卡（DMA方式），网卡发出</li><li>send() 返回，系统切换到用户态回到应用。</li></ol><p>整个过程将经历4次上下文切换，2次CPU拷贝。</p><p><img src="https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/java%E7%BC%96%E7%A8%8B/nio/%E8%AF%B4%E8%AF%B4%E9%9B%B6%E6%8B%B7%E8%B4%9D-%E4%BC%A0%E7%BB%9FIO%E8%BF%87%E7%A8%8B.jpg" alt="I/O过程"></p><h3 id="1-NIO的零拷贝"><a href="#1-NIO的零拷贝" class="headerlink" title="1. NIO的零拷贝"></a>1. NIO的零拷贝</h3><p>java.nio包中有一个TransferTo接口，专门用来发送数据，我们来看看它是怎么做的。</p><p>TransferTo接口调用了本地TransferTo方法，在Linux平台上将发起<strong>sendfile</strong>系统调用，执行过程如下：</p><ol><li>应用发起sendfile系统调用请求发送文件</li><li>系统切换到内核态，读磁盘数据到内核读缓冲区（DMA方式）</li><li>将内核读缓冲区的数据直接拷贝到socket缓冲区（CPU拷贝）</li><li>将socket缓冲区的数据发送给网络接口卡（DMA方式），网卡发出</li><li>系统切换到用户态回到应用</li></ol><p>整个过程经历2次上下文切换和1次CPU拷贝。</p><p><img src="https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/java%E7%BC%96%E7%A8%8B/nio/%E8%AF%B4%E8%AF%B4%E9%9B%B6%E6%8B%B7%E8%B4%9D-nio%E8%BF%87%E7%A8%8B.jpg" alt></p><p>如果底层NIC（网络接口卡）支持gather操作，可以进一步减少内核中的数据拷贝。在Linux 2.4以及更高版本的内核中，socket缓冲区描述符已被修改用来适应这个需求。这种方式不但减少上下文切换，同时消除了需要CPU参与的重复的数据拷贝。</p><p><img src="https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/java%E7%BC%96%E7%A8%8B/nio/%E8%AF%B4%E8%AF%B4%E9%9B%B6%E6%8B%B7%E8%B4%9D-nio%E8%BF%87%E7%A8%8B2.jpg" alt></p><p>用户这边的使用方式不变，依旧通过transferTo方法，但是方法的内部实现发生了变化：</p><ol><li><p>transferTo方法调用触发DMA引擎将文件上下文信息拷贝到内核缓冲区</p></li><li><p>数据不会被拷贝到套接字缓冲区，只有数据的描述符（包括数据位置和长度）被拷贝到套接字缓冲区。DMA 引擎直接将数据从内核缓冲区拷贝到协议引擎，这样减少了最后一次需要消耗CPU的拷贝操作。</p></li></ol><p>将一个文件拷贝到另一个目录，使用nio方式性能提升100%，<a href="https://github.com/zzkenyon/thinking/blob/master/nio/src/main/java/zerocopy/TransferToTest.java" target="_blank" rel="noopener">对比代码</a></p><h3 id="2-直接内存"><a href="#2-直接内存" class="headerlink" title="2. 直接内存"></a>2. 直接内存</h3><p>在不需要进行数据文件操作时，可以使用NIO的零拷贝。但如果既需要IO速度，又需要进行数据操作，则需要使用NIO的直接内存映射。</p><p>Linux提供的<strong>mmap</strong>系统调用, 它可以将一段用户空间内存映射到内核空间, 当映射成功后, 用户对这段内存区域的修改可以直接反映到内核空间；同样地， 内核空间对这段区域的修改也直接反映用户空间。正因为有这样的映射关系, 就不需要在用户态(User-space)与内核态(Kernel-space) 之间拷贝数据， 提高了数据传输的效率，这就是以内存直接映射为基础的零拷贝技术。</p><h4 id="2-1-直接内存的创建"><a href="#2-1-直接内存的创建" class="headerlink" title="2.1 直接内存的创建"></a>2.1 直接内存的创建</h4><p>在ByteBuffer有两个子类，HeapByteBuffer和DirectByteBuffer。前者是存在于JVM堆中的，后者是存在于Native堆中的。</p><p>申请堆内存</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ByteBuffer <span class="title">allocate</span><span class="params">(<span class="keyword">int</span> capacity)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (capacity &lt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException();</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> HeapByteBuffer(capacity, capacity);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>申请直接内存</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ByteBuffer <span class="title">allocateDirect</span><span class="params">(<span class="keyword">int</span> capacity)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> DirectByteBuffer(capacity);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="为什么使用直接内存"><a href="#为什么使用直接内存" class="headerlink" title="为什么使用直接内存"></a>为什么使用直接内存</h4><ul><li>对垃圾回收停顿的改善。因为full gc时，垃圾收集器会对所有分配的堆内内存进行扫描，垃圾收集对Java应用造成的影响，跟堆的大小是成正比的。过大的堆会影响Java应用的性能。如果使用堆外内存的话，堆外内存是直接受操作系统管理。这样做的结果就是能保持一个较小的JVM堆内存，以减少垃圾收集对应用的影响。full gc会回收空闲的直接内存。）</li><li>减少了数据从JVM拷贝到native内存的次数，在某些场景下可以提升程序I/O的性能。</li><li>可以突破JVM内存限制，操作更多的物理内存。</li></ul><h4 id="使用直接内存注意事项"><a href="#使用直接内存注意事项" class="headerlink" title="使用直接内存注意事项"></a>使用直接内存注意事项</h4><ul><li>与堆内存相比直接内存读数据快、申请慢，所以适合申请次数少，访问频繁的场合。</li><li>堆外内存只能通过序列化和反序列化来存储，保存对象速度比堆内存慢，不适合存储很复杂的对象。一般简单的对象或者扁平化的比较适合。</li><li>当直接内存不足时会触发full gc，排查full gc的时候，一定要考虑。</li><li>堆外内存难以控制，如果内存泄漏，那么很难排查</li></ul><h4 id="NIO的直接内存映射"><a href="#NIO的直接内存映射" class="headerlink" title="NIO的直接内存映射"></a>NIO的直接内存映射</h4><p>NIO中一个重要的类：MappedByteBuffer——java nio引入的文件内存映射方案，读写性能极高。MappedByteBuffer将文件直接映射到内存。可以映射整个文件，如果文件比较大的话可以考虑分段进行映射，只要指定文件的感兴趣部分就可以。</p><p>由于MappedByteBuffer申请的是直接内存，因此不受Minor GC控制，只能在发生Full GC时才能被回收，因此Java提供了DirectByteBuffer类来改善这一情况。它是MappedByteBuffer类的子类，同时它实现了DirectBuffer接口，维护一个Cleaner对象来完成内存回收。因此它既可以通过Full GC来回收内存，也可以调用clean()方法来进行回收</p><h4 id="NIO的直接内存映射的函数调用"><a href="#NIO的直接内存映射的函数调用" class="headerlink" title="NIO的直接内存映射的函数调用"></a>NIO的直接内存映射的函数调用</h4><p>FileChannel提供了map方法来把文件映射为内存对象：</p><p>MappedByteBuffer map(int mode,long position,long size);<br>可以把文件的从position开始的size大小的区域映射为内存对象，mode指出了 可访问该内存映像文件的方式</p><p>READ_ONLY,（只读）： 试图修改得到的缓冲区将导致抛出 ReadOnlyBufferException.(MapMode.READ_ONLY)</p><p>READ_WRITE（读/写）： 对得到的缓冲区的更改最终将传播到文件；该更改对映射到同一文件的其他程序不一定是可见的。 (MapMode.READ_WRITE)</p><p>PRIVATE（专用）： 对得到的缓冲区的更改不会传播到文件，并且该更改对映射到同一文件的其他程序也不是可见的；相反，会创建缓冲区已修改部分的专用副本。 (MapMode.PRIVATE)</p><blockquote><p>使用参数-XX:MaxDirectMemorySize=10M，可以指定DirectByteBuffer的大小最多是10M。</p></blockquote><p><a href="https://github.com/zzkenyon/thinking/blob/master/nio/src/main/java/zerocopy/MMPtest.java" target="_blank" rel="noopener">对比代码</a></p><p>将一个文件读入内存不做处理，与nio处理方式进行对比，直接内存处理性能提升500%</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;从一个业务场景开始：从本地磁盘读取一个文件通过socket发送出去。&lt;/p&gt;
&lt;p&gt;传统的I/O接口处理流程如下：读文件到应用-&amp;gt;应用打包文件到socket-&amp;gt;发送&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;应用发起系统调用sys_read()（或等价的方法）请求读磁盘文件&lt;/
      
    
    </summary>
    
    
      <category term="nio" scheme="http://yoursite.com/child/tags/nio/"/>
    
  </entry>
  
  <entry>
    <title>zookeeper-配置和基本操纵</title>
    <link href="http://yoursite.com/child/2019/11/30/zookeeper-%E9%85%8D%E7%BD%AE%E5%92%8C%E5%9F%BA%E6%9C%AC%E6%93%8D%E7%BA%B5/"/>
    <id>http://yoursite.com/child/2019/11/30/zookeeper-配置和基本操纵/</id>
    <published>2019-11-30T08:09:16.065Z</published>
    <updated>2019-11-30T08:09:16.065Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-配置开机自启"><a href="#1-配置开机自启" class="headerlink" title="1. 配置开机自启"></a>1. 配置开机自启</h4><p>把zookeeper做成服务</p><p>1、进入到/etc/rc.d/init.d目录下，新建一个zookeeper脚本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# cd /etc/rc.d/init.d/ </span><br><span class="line">[root@node1 init.d]# pwd </span><br><span class="line">/etc/rc.d/init.d </span><br><span class="line">[root@node1 init.d]# touch zookeeper</span><br></pre></td></tr></table></figure><p>2、给脚本添加执行权限</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 init.d]# chmod +x zookeeper</span><br></pre></td></tr></table></figure><p>3、使用命令vim zookeeper进行编辑，在脚本中输入如下内容，其中同上面注意事项一样要添加export JAVA_HOME=/usr/java/jdk1.8.0_112这一行，否则无法正常启动。</p><p>[root@zookeeper init.d]# vim zookeeper</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>!/bin/bash</span><br><span class="line"><span class="meta">#</span>chkconfig:2345 10 90</span><br><span class="line"><span class="meta">#</span>description:service zookeeper</span><br><span class="line">export     JAVA_HOME=/usr/lib/java/jdk-1.8.0_231</span><br><span class="line">ZOOKEEPER_HOME=/usr/local/apache/apache-zookeeper-3.5.6-bin</span><br><span class="line">case  "$1"   in</span><br><span class="line">     start)  su  root  $&#123;ZOOKEEPER_HOME&#125;/bin/zkServer.sh  start;;</span><br><span class="line">     stop)  su  root  $&#123;ZOOKEEPER_HOME&#125;/bin/zkServer.sh  stop;;</span><br><span class="line">     status)  su root  $&#123;ZOOKEEPER_HOME&#125;/bin/zkServer.sh    status;;</span><br><span class="line">     restart)  su root   $&#123;ZOOKEEPER_HOME&#125;/bin/zkServer.sh   restart;;</span><br><span class="line">     *)  echo "require start||stop|status|restart|";;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure><p>4、 使用service zookeeper start/stop/restart命令来尝试启动关闭重启zookeeper，使用service zookeeper status查看zookeeper状态。</p><p>5、添加到开机自启</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 init.d]# chkconfig --add zookeeper</span><br></pre></td></tr></table></figure><p>添加完之后，我们使用chkconfig –list来查看开机自启的服务中是否已经有我们的zookeeper了，如下所示，可以看到在最后一行便是我们的zookeeper服务了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 init.d]# chkconfig --list </span><br><span class="line">netconsole      0:off   1:off   2:off   3:off   4:off   5:off   6:off</span><br><span class="line">network         0:off   1:off   2:on    3:on    4:on    5:on    6:off</span><br><span class="line">zookeeper       0:off   1:off   2:on    3:on    4:on    5:on    6:off</span><br></pre></td></tr></table></figure><h4 id="2-zkCli客户端"><a href="#2-zkCli客户端" class="headerlink" title="2. zkCli客户端"></a>2. zkCli客户端</h4><p><a href="https://blog.csdn.net/dandandeshangni/article/details/80558383" target="_blank" rel="noopener">https://blog.csdn.net/dandandeshangni/article/details/80558383</a></p><h5 id="2-1-基本操作"><a href="#2-1-基本操作" class="headerlink" title="2.1 基本操作"></a>2.1 基本操作</h5><ul><li>列举子节点: ls path (ls /zookeeper)</li><li>查看节点更新信息：stat path (stat /zookeeper)</li><li>创建节点 ：create path val (creat /config “test string value”)</li><li>创建临时节点 ：create -e path val</li><li>创建顺序节点：create -s path val</li><li>修改节点：set path val (set /config “another config string”)</li><li>删除节点：delete path</li><li>监视节点：stat -w path、 get -w path</li></ul><h5 id="2-2-ACL权限控制"><a href="#2-2-ACL权限控制" class="headerlink" title="2.2 ACL权限控制"></a>2.2 ACL权限控制</h5><p>ZK的节点有5种操作权限：CREATE、READ、WRITE、DELETE、ADMIN 也就是 增、删、改、查、管理权限，这5种权限简写为crwda(即：每个单词的首字符缩写)。 注：这5种权限中，delete是指对子节点的删除权限，其它4种权限指对自身节点的操作权限</p><p>身份的认证有4种方式：</p><ul><li>world：默认方式，相当于全世界都能访问</li><li>auth：代表已经认证通过的用户(cli中可以通过addauth digest user:pwd 来添加当前上下文中的授权用户)</li><li>digest：即用户名:密码这种方式认证，这也是业务系统中最常用的</li><li>ip：使用Ip地址认证</li></ul><p>使用[scheme​ : id : permissions]来表示acl权限，比如-digest:username:password:cwrda</p><p>getAcl:获取某个节点的acl权限信息 getAcl path</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>World方案权限设置</span><br><span class="line">setAcl /config/global world:anyone:crwa</span><br><span class="line"><span class="meta">#</span>auth方案权限设置</span><br><span class="line">addauth digest test:123456 </span><br><span class="line">setAcl /config/global auth:test:123456:cdrwa</span><br><span class="line"><span class="meta">#</span>digest方案权限设置</span><br><span class="line">setAcl /config/global digest:test:V28q/NynI4JI3Rk54h0r8O5kMug=:cdra</span><br><span class="line"><span class="meta">#</span>ip权限设置</span><br><span class="line">setAcl /niocoder/ip ip:192.168.0.68:cdrwa</span><br></pre></td></tr></table></figure><h5 id="超级管理员"><a href="#超级管理员" class="headerlink" title="超级管理员"></a>超级管理员</h5><p>zk的权限管理表有一种ACL的模式叫做super，该模式的作用是方便管理节点。一旦我们为某一个节点设置了acl，那么其余的未授权的节点是无法访问或者操作该节点的，那么系统用久了以后，假如忘记了某一个节点的密码，那么就无法再操作这个节点了，所以需要这个super超级管理员用户权限，其作用还是很大的。</p><p>添加方式：只能在启动服务器的时候添加。</p><p>假设这个超管是：super:admin，通过代码得到其哈希值：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">String m = DigestAuthenticationProvider.generateDigest(<span class="string">"super:admin"</span>);</span><br></pre></td></tr></table></figure><p>m是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">super:xQJmxLMiHGwaqBvst5y6rkB6HQs=</span><br></pre></td></tr></table></figure><p>那么打开zk目录下的/bin/zkServer.sh服务器脚本文件，找到如下一行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup $JAVA "-Dzookeeper.log.dir=$&#123;ZOO_LOG_DIR&#125;" "-Dzookeeper.root.logger=$&#123;ZOO_LOG4J_PROP&#125;"</span><br></pre></td></tr></table></figure><p>这就是脚本中启动zk的命令，默认只有以上两个配置项，我们需要加一个超管的配置项：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">"-Dzookeeper.DigestAuthenticationProvider.superDigest=super:xQJmxLMiHGwaqBvst5y6rkB6HQs="</span><br></pre></td></tr></table></figure><p>第一个等号之后的就是刚才用户名密码的哈希值。 那么修改以后这条完整命令变成了：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nohup $JAVA "-Dzookeeper.log.dir=$&#123;ZOO_LOG_DIR&#125;" "-Dzookeeper.root.logger=$&#123;ZOO_LOG4J_PROP&#125;" "-Dzookeeper.DigestAuthenticationProvider.superDigest=super:xQJmxLMiHGwaqBvst5y6rkB6HQs="\</span><br><span class="line">    -cp "$CLASSPATH" $JVMFLAGS $ZOOMAIN "$ZOOCFG" &gt; "$_ZOO_DAEMON_OUT" 2&gt;&amp;1 &lt; /dev/null &amp;</span><br></pre></td></tr></table></figure><p>之后重新启动zk集群，进入zkCli输入如下命令添加权限：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">addauth digest super:admin</span><br></pre></td></tr></table></figure><p>假如zk有一个节点/test，acl为digest方案，但是忘记了用户名和密码，正常情况下，这次登陆如果不用那个digest授权是不能访问/test的数据的。但是由于我们配置了超管，所以这次还是可以访问到的。</p><p>需要说明的是，这个超管只是在这次服务器启动期间管用，如果关闭了服务器，并修改了服务器脚本，取消了超管配置，那么下一次启动就没有这个超管了。</p><h5 id="运维四字指令"><a href="#运维四字指令" class="headerlink" title="运维四字指令"></a>运维四字指令</h5><p>使用四字命令需要安装nc命令(yum install nc)</p><p>然后在启动脚本zkServer.sh里添加ＶＭ环境变量-Dzookeeper.4lw.commands.whitelist=*，便可以把所有四字指令添加到白名单（否则执行四字指令会报错is not executed because it is not in the whitelist），我是添加在脚本的这个位置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ZOOMAIN="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=$JMXPORT -Dcom.sun.management.jmxremote.authenticate=$JMXAUTH -Dcom.sun.management.jmxremote.ssl=$JMXSSL -Dzookeeper.jmx.log4j.disable=$JMXLOG4J org.apache.zookeeper.server.quorum.QuorumPeerMain"</span><br><span class="line">  fi</span><br><span class="line">else</span><br><span class="line">    echo "JMX disabled by user request" &gt;&amp;2</span><br><span class="line">    ZOOMAIN="org.apache.zookeeper.server.quorum.QuorumPeerMain"</span><br><span class="line">fi</span><br><span class="line"><span class="meta">#</span> 这里就是我添加的</span><br><span class="line"><span class="meta">#</span> 如果不想添加在这里，注意位置和赋值的顺序</span><br><span class="line">ZOOMAIN="-Dzookeeper.4lw.commands.whitelist=* $&#123;ZOOMAIN&#125;"</span><br></pre></td></tr></table></figure><p>重启zk即可。</p><p>四字指令调用方法：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]#echo xxxx | nc 192.168.0.68 2181</span><br></pre></td></tr></table></figure><p>其中xxxx为：</p><ul><li>stat 查看状态信息</li><li>ruok 查看zookeeper是否启动</li><li>dump 列出没有处理的节点，临时节点</li><li>conf 查看服务器配置</li><li>cons 显示连接到服务端的信息</li><li>envi 显示环境变量信息</li><li>mntr 查看zk的健康信息</li><li>wchs 展示watch的信息</li><li>wchc和wchp 显示session的watch信息 path的watch信息</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-配置开机自启&quot;&gt;&lt;a href=&quot;#1-配置开机自启&quot; class=&quot;headerlink&quot; title=&quot;1. 配置开机自启&quot;&gt;&lt;/a&gt;1. 配置开机自启&lt;/h4&gt;&lt;p&gt;把zookeeper做成服务&lt;/p&gt;
&lt;p&gt;1、进入到/etc/rc.d/init.d目
      
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/child/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>zookeeper-是什么以及能干什么</title>
    <link href="http://yoursite.com/child/2019/11/24/zookeeper-%E6%98%AF%E4%BB%80%E4%B9%88%E4%BB%A5%E5%8F%8A%E8%83%BD%E5%B9%B2%E4%BB%80%E4%B9%88/"/>
    <id>http://yoursite.com/child/2019/11/24/zookeeper-是什么以及能干什么/</id>
    <published>2019-11-23T16:00:00.000Z</published>
    <updated>2019-11-30T08:51:01.789Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-什么是-ZooKeeper"><a href="#1-什么是-ZooKeeper" class="headerlink" title="1. 什么是 ZooKeeper"></a>1. 什么是 ZooKeeper</h3><h4 id="1-1-ZooKeeper-的由来"><a href="#1-1-ZooKeeper-的由来" class="headerlink" title="1.1 ZooKeeper 的由来"></a>1.1 ZooKeeper 的由来</h4><p>下面这段内容摘自《从Paxos到Zookeeper 》第四章第一节的某段内容，推荐大家阅读：</p><blockquote><p>Zookeeper最早起源于雅虎研究院的一个研究小组。在当时，研究人员发现，在雅虎内部很多大型系统基本都需要依赖一个类似的系统来进行分布式协调，但是这些系统往往都存在分布式单点问题。所以，<strong>雅虎的开发人员就试图开发一个通用的无单点问题的分布式协调框架，以便让开发人员将精力集中在处理业务逻辑上。</strong></p><p>关于“ZooKeeper”这个项目的名字，其实也有一段趣闻。在立项初期，考虑到之前内部很多项目都是使用动物的名字来命名的（例如著名的Pig项目),雅虎的工程师希望给这个项目也取一个动物的名字。时任研究院的首席科学家RaghuRamakrishnan开玩笑地说：“在这样下去，我们这儿就变成动物园了！”此话一出，大家纷纷表示就叫动物园管理员吧一一一因为各个以动物命名的分布式组件放在一起，<strong>雅虎的整个分布式系统看上去就像一个大型的动物园了，而Zookeeper正好要用来进行分布式环境的协调一一于是，Zookeeper的名字也就由此诞生了。</strong></p></blockquote><h4 id="1-2-ZooKeeper-概览"><a href="#1-2-ZooKeeper-概览" class="headerlink" title="1.2 ZooKeeper 概览"></a>1.2 ZooKeeper 概览</h4><p>ZooKeeper 是一个开源的分布式协调服务，ZooKeeper框架最初是在“Yahoo!”上构建的，用于以简单而稳健的方式访问他们的应用程序。 后来，Apache ZooKeeper成为Hadoop，HBase和其他分布式框架使用的有组织服务的标准。 例如，Apache HBase使用ZooKeeper跟踪分布式数据的状态。</p><p><strong>ZooKeeper 的设计目标</strong>是将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一系列简单易用的接口提供给用户使用。</p><p><strong>ZooKeeper 是一个典型的分布式数据一致性解决方案</strong>，分布式应用程序可以基于 ZooKeeper 实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能。</p><p><strong>Zookeeper 一个最常用的使用场景</strong> 就是用于担任服务生产者和服务消费者的注册中心(提供发布订阅服务)。服务生产者将自己提供的服务注册到Zookeeper中心，服务的消费者在进行服务调用的时候先到Zookeeper中查找服务，获取到服务生产者的详细信息之后，再去调用服务生产者的内容与数据。如下图所示，在 Dubbo架构中 Zookeeper 就担任了注册中心这一角色。</p><p><img src="https://camo.githubusercontent.com/833bc92999192c594d7c49527b813fec7ab4453d/687474703a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f31382d392d31302f33353537313738322e6a7067" alt="Dubbo"></p><h4 id="1-2-结合使用情况的讲一下-ZooKeeper"><a href="#1-2-结合使用情况的讲一下-ZooKeeper" class="headerlink" title="1.2 结合使用情况的讲一下 ZooKeeper"></a>1.2 结合使用情况的讲一下 ZooKeeper</h4><p>在我自己做过的项目中，主要使用到了 ZooKeeper 作为 Dubbo 的注册中心(Dubbo 官方推荐使用 ZooKeeper注册中心)。另外在搭建 solr 集群的时候，我使用 ZooKeeper 作为 solr 集群的管理工具。这时，ZooKeeper 主要提供下面几个功能：1、集群管理：容错、负载均衡。2、配置文件的集中管理。3、集群的入口。</p><p>我个人觉得在使用 ZooKeeper 的时候，最好是使用 集群版的 ZooKeeper 而不是单机版的。官网给出的架构图就描述的是一个集群版的 ZooKeeper 。通常 3 台服务器就可以构成一个 ZooKeeper 集群了。</p><p><strong>为什么最好使用奇数台服务器构成 ZooKeeper 集群？</strong></p><p>所谓的zookeeper容错是指，当宕掉几个zookeeper服务器之后，剩下的个数必须大于宕掉的个数的话整个zookeeper才依然可用。假如我们的集群中有n台zookeeper服务器，那么也就是剩下的服务数必须大于n/2。先说一下结论，2n和2n-1的容忍度是一样的，都是n-1，大家可以先自己仔细想一想，这应该是一个很简单的数学问题了。 比如假如我们有3台，那么最大允许宕掉1台zookeeper服务器，如果我们有4台的的时候也同样只允许宕掉1台。 假如我们有5台，那么最大允许宕掉2台zookeeper服务器，如果我们有6台的的时候也同样只允许宕掉2台。</p><p>综上，何必增加那一个不必要的zookeeper呢？</p><h3 id="2-关于-ZooKeeper-的一些重要概念"><a href="#2-关于-ZooKeeper-的一些重要概念" class="headerlink" title="2. 关于 ZooKeeper 的一些重要概念"></a>2. 关于 ZooKeeper 的一些重要概念</h3><h4 id="2-1-重要概念总结"><a href="#2-1-重要概念总结" class="headerlink" title="2.1 重要概念总结"></a>2.1 重要概念总结</h4><ul><li>ZooKeeper 本身就是一个分布式程序，为了保证<strong>高可用</strong>，最好是以集群形态来部署 ZooKeeper。只要<strong>半数</strong>以上节点存活，ZooKeeper 就能正常服务。</li><li>ZooKeeper 将<strong>数据保存在内存中</strong>，这也就保证了 高吞吐量和低延迟，但是内存限制了能够存储的容量不太大，此限制也是保持znode中存储的数据量较小的进一步原因。</li><li>ZooKeeper 是<strong>在“读”多于“写”的应用程序中尤其地高性能</strong>，因为“写”会导致所有的服务器间同步状态。（“读”多于“写”是协调服务的典型场景。）</li><li>ZooKeeper有<strong>临时节点</strong>的概念。 当创建临时节点的客户端会话一直保持活动，瞬时节点就一直存在。而当会话终结时，瞬时节点被删除。持久节点是指一旦这个ZNode被创建了，除非主动进行ZNode的移除操作，否则这个ZNode将一直保存在Zookeeper上。</li><li>ZooKeeper <strong>底层</strong>其实只提供了<strong>两个功能</strong>：①管理（存储、读取）用户程序提交的数据；②为用户程序提供数据节点监听服务。</li></ul><h4 id="2-2-会话（Session）"><a href="#2-2-会话（Session）" class="headerlink" title="2.2 会话（Session）"></a>2.2 会话（Session）</h4><p>Session 指的<strong>是</strong> ZooKeeper 服务器与客户端会话。在 ZooKeeper 中，一个客户端连接是指客户端和服务器之间的<strong>一个 TCP 长连接</strong>。客户端启动的时候，首先会与服务器建立一个 TCP 连接，从第一次连接建立开始，客户端会话的生命周期也开始了。通过这个连接，客户端能够通过心跳检测与服务器保持有效的会话，也能够向Zookeeper服务器发送请求并接受响应，同时还能够通过该连接接收来自服务器的Watch事件通知。</p><p> Session的<code>sessionTimeout</code>值用来设置一个客户端会话的超时时间。当由于服务器压力太大、网络故障或是客户端主动断开连接等各种原因导致客户端连接断开时，只要<strong>在sessionTimeout规定的时间内能够重新连接上集群中任意一台</strong>服务器，那么之前创建的会话仍然有效。</p><p>在为客户端创建会话之前，服务端首先会为每个客户端都分配一个<strong>sessionID</strong>。由于 sessionID 是 Zookeeper 会话的一个重要标识，许多与会话相关的运行机制都是基于这个 sessionID 的，因此，无论是哪台服务器为客户端分配的 sessionID，都务必<strong>保证全局唯一</strong>。</p><h4 id="2-3-Znode"><a href="#2-3-Znode" class="headerlink" title="2.3 Znode"></a>2.3 Znode</h4><p>在谈到分布式的时候，我们通常说的“节点”是指组成集群的每一台机器。然而，在Zookeeper中，“节点”分为两类，第一类同样是指构成集群的机器，我们称之为机器节点；第二类则是指数据模型中的数据单元，我们称之为数据节点一一ZNode。</p><p>Zookeeper将所有数据存储在内存中，数据模型是一棵树（Znode Tree)，由斜杠（/）的进行分割的路径，就是一个Znode，例如/foo/path1。每个上都会保存自己的数据内容，同时还会保存一系列属性信息。</p><p>在Zookeeper中，node可以分为<strong>持久节点</strong>和<strong>临时节点</strong>两类。所谓持久节点是指一旦这个ZNode被创建了，除非主动进行ZNode的移除操作，否则这个ZNode将一直保存在Zookeeper上。而临时节点就不一样了，它的生命周期和客户端会话绑定，一旦客户端会话失效，那么这个客户端创建的所有临时节点都会被移除。 另外，ZooKeeper还允许用户为每个节点添加一个特殊的属性：<strong>SEQUENTIAL</strong>.一旦节点被标记上这个属性，那么在这个节点被创建的时候，Zookeeper会自动在其节点名后面追加上一个整型数字，这个整型数字是一个由父节点维护的自增数字。</p><h4 id="2-4-版本"><a href="#2-4-版本" class="headerlink" title="2.4 版本"></a>2.4 版本</h4><p>在前面我们已经提到，Zookeeper 的每个 ZNode 上都会存储数据，对应于每个ZNode，Zookeeper 都会为其维护一个叫作 <strong>Stat</strong> 的数据结构，Stat 中记录了这个 ZNode 的三个数据版本，分别是version（当前ZNode的版本）、cversion（当前ZNode子节点的版本）和 aversion（当前ZNode的ACL版本）。</p><h4 id="2-5-Watcher"><a href="#2-5-Watcher" class="headerlink" title="2.5 Watcher"></a>2.5 Watcher</h4><p>Watcher（事件监听器），是Zookeeper中的一个很重要的特性。Zookeeper允许用户在指定节点上注册一些Watcher，并且在一些特定事件触发的时候，ZooKeeper服务端会将事件通知到感兴趣的客户端上去，该机制是Zookeeper实现分布式协调服务的重要特性。</p><h3 id="2-6-ACL"><a href="#2-6-ACL" class="headerlink" title="2.6 ACL"></a>2.6 ACL</h3><p>Zookeeper采用ACL（AccessControlLists）策略来进行权限控制，类似于 UNIX 文件系统的权限控制。Zookeeper 定义了如下5种权限。</p><p><img src="https://camo.githubusercontent.com/b4f115ed9ee12cdd9442923100859bf1717f4e86/687474703a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f31382d392d31302f32373437333438302e6a7067" alt="img"></p><p>其中尤其需要注意的是，CREATE和DELETE这两种权限都是针对子节点的权限控制。</p><h3 id="3-ZooKeeper-特点"><a href="#3-ZooKeeper-特点" class="headerlink" title="3. ZooKeeper 特点"></a>3. ZooKeeper 特点</h3><ul><li><strong>顺序一致性：</strong> 从同一客户端发起的事务请求，最终将会严格地按照顺序被应用到 ZooKeeper 中去。</li><li><strong>原子性：</strong> 所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么整个集群中所有的机器都成功应用了某一个事务，要么都没有应用。</li><li><strong>单一系统映像 ：</strong> 无论客户端连到哪一个 ZooKeeper 服务器上，其看到的服务端数据模型都是一致的。</li><li><strong>可靠性：</strong> 一旦一次更改请求被应用，更改的结果就会被持久化，直到被下一次更改覆盖。</li></ul><h3 id="4-ZooKeeper-设计目标"><a href="#4-ZooKeeper-设计目标" class="headerlink" title="4. ZooKeeper 设计目标"></a>4. ZooKeeper 设计目标</h3><h4 id="4-1-简单的数据模型"><a href="#4-1-简单的数据模型" class="headerlink" title="4.1 简单的数据模型"></a>4.1 简单的数据模型</h4><p>ZooKeeper 允许分布式进程通过共享的层次结构命名空间进行相互协调，这与标准文件系统类似。 名称空间由 ZooKeeper 中的数据寄存器组成 - 称为znode，这些类似于文件和目录。 与为存储设计的典型文件系统不同，ZooKeeper数据保存在内存中，这意味着ZooKeeper可以实现高吞吐量和低延迟。</p><p><img src="https://camo.githubusercontent.com/305d94895208d5c5c7ead576b16895f36d995119/687474703a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f31382d392d31302f39343235313735372e6a7067" alt="img"></p><h4 id="4-2-可构建集群"><a href="#4-2-可构建集群" class="headerlink" title="4.2 可构建集群"></a>4.2 可构建集群</h4><p>为了保证高可用，最好是以集群形态来部署 ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么zookeeper本身仍然是可用的。 客户端在使用 ZooKeeper 时，需要知道集群机器列表，通过与集群中的某一台机器建立 TCP 连接来使用服务，客户端使用这个TCP链接来发送请求、获取结果、获取监听事件以及发送心跳包。如果这个连接异常断开了，客户端可以连接到另外的机器上。</p><p>ZooKeeper 官方提供的架构图：</p><p><img src="https://camo.githubusercontent.com/2195e2d261feb7dbb9922153d589dc87032570d1/687474703a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f31382d392d31302f36383930303638362e6a7067" alt="img"></p><p>上图中每一个Server代表一个安装Zookeeper服务的服务器。组成 ZooKeeper 服务的服务器都会在内存中维护当前的服务器状态，并且每台服务器之间都互相保持着通信。集群间通过 Zab 协议（Zookeeper Atomic Broadcast）来保持数据的一致性。</p><h4 id="4-3-顺序访问"><a href="#4-3-顺序访问" class="headerlink" title="4.3 顺序访问"></a>4.3 顺序访问</h4><p>对于来自客户端的每个更新请求，ZooKeeper 都会分配一个全局唯一的递增编号，这个编号反应了所有事务操作的先后顺序，应用程序可以使用 ZooKeeper 这个特性来实现更高层次的同步原语。 这个编号也叫做时间戳——zxid（Zookeeper Transaction Id）</p><h4 id="4-4-高性能"><a href="#4-4-高性能" class="headerlink" title="4.4 高性能"></a>4.4 高性能</h4><p>ZooKeeper 是高性能的。 在“读”多于“写”的应用程序中尤其地高性能，因为“写”会导致所有的服务器间同步状态。（“读”多于“写”是协调服务的典型场景。）</p><h3 id="5-ZooKeeper-集群角色介绍"><a href="#5-ZooKeeper-集群角色介绍" class="headerlink" title="5. ZooKeeper 集群角色介绍"></a>5. ZooKeeper 集群角色介绍</h3><p>最典型集群模式： <strong>Master/Slave 模式</strong>（主备模式）。在这种模式中，通常 Master服务器作为主服务器提供写服务，其他的 Slave 服务器从服务器通过异步复制的方式获取 Master 服务器最新的数据提供读服务。</p><p>但是，在 ZooKeeper 中没有选择传统的 Master/Slave 概念，而是引入了Leader、Follower 和 Observer 三种角色。如下图所示</p><p><img src="https://camo.githubusercontent.com/7e9c188ef73fdd1d10a3a5ea7dfa67d4c7cd859f/687474703a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f31382d392d31302f38393630323736322e6a7067" alt="img"></p><p>ZooKeeper 集群中的所有机器通过一个 Leader 选举过程来选定一台称为 “Leader” 的机器，Leader 既可以为客户端提供写服务又能提供读服务。除了 Leader 外，Follower 和 Observer 都只能提供读服务。<strong>Follower 和 Observer 唯一的区别在于 Observer 机器不参与 Leader 的选举过程，也不参与写操作的过半写成功策略</strong>，因此 Observer 机器可以在不影响写性能的情况下提升集群的读性能。</p><p><img src="https://camo.githubusercontent.com/f08946356f39f71ba0bdcf5ae10bc05a2e4d514b/687474703a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f31382d392d31332f39313632323339352e6a7067" alt="img"></p><p>当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB 协议就会进人恢复模式并选举产生新的Leader服务器。这个过程大致是这样的：</p><ol><li>Leader election（选举阶段）：节点在一开始都处于选举阶段，只要有一个节点得到超半数节点的票数，它就可以当选准 leader。</li><li>Discovery（发现阶段）：在这个阶段，followers 跟准 leader 进行通信，同步 followers 最近接收的事务提议。</li><li>Synchronization（同步阶段）:同步阶段主要是利用 leader 前一阶段获得的最新提议历史，同步集群中所有的副本。同步完成之后 准 leader 才会成为真正的 leader。</li><li>Broadcast（广播阶段） 到了这个阶段，Zookeeper 集群才能正式对外提供事务服务，并且 leader 可以进行消息广播。同时如果有新的节点加入，还需要对新节点进行同步。</li></ol><h3 id="6-ZooKeeper-amp-ZAB-协议-amp-Paxos算法"><a href="#6-ZooKeeper-amp-ZAB-协议-amp-Paxos算法" class="headerlink" title="6. ZooKeeper &amp;ZAB 协议&amp;Paxos算法"></a>6. ZooKeeper &amp;ZAB 协议&amp;Paxos算法</h3><h4 id="6-1-ZAB-协议-amp-Paxos算法"><a href="#6-1-ZAB-协议-amp-Paxos算法" class="headerlink" title="6.1 ZAB 协议&amp;Paxos算法"></a>6.1 ZAB 协议&amp;Paxos算法</h4><p>Paxos 算法应该可以说是 ZooKeeper 的灵魂了。但是，ZooKeeper 并没有完全采用 Paxos算法 ，而是使用 ZAB 协议作为其保证数据一致性的核心算法。另外，在ZooKeeper的官方文档中也指出，ZAB协议并不像 Paxos 算法那样，是一种通用的分布式一致性算法，它是一种特别为Zookeeper设计的崩溃可恢复的原子消息广播算法。</p><h4 id="6-2-ZAB-协议介绍"><a href="#6-2-ZAB-协议介绍" class="headerlink" title="6.2 ZAB 协议介绍"></a>6.2 ZAB 协议介绍</h4><p>ZAB（ZooKeeper Atomic Broadcast 原子广播） 协议是为分布式协调服务 ZooKeeper 专门设计的一种支持崩溃恢复的原子广播协议。 在 ZooKeeper 中，主要依赖 ZAB 协议来实现分布式数据一致性，基于该协议，ZooKeeper 实现了一种主备模式的系统架构来保持集群中各个副本之间的数据一致性。</p><h4 id="6-3-ZAB-协议的两种基本模式"><a href="#6-3-ZAB-协议的两种基本模式" class="headerlink" title="6.3 ZAB 协议的两种基本模式"></a>6.3 ZAB 协议的两种基本模式</h4><p>ZAB协议包括两种基本的模式，分别是 <strong>崩溃恢复</strong>和<strong>消息广播</strong>。当整个服务框架在启动过程中，或是当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB 协议就会进人恢复模式并选举产生新的Leader服务器。当选举产生了新的 Leader 服务器，同时集群中已经有过半的机器与该Leader服务器完成了状态同步之后，ZAB协议就会退出恢复模式。其中，<strong>所谓的状态同步是指数据同步，用来保证集群中存在过半的机器能够和Leader服务器的数据状态保持一致</strong>。</p><p><strong>当集群中已经有过半的Follower服务器完成了和Leader服务器的状态同步，那么整个服务框架就可以进人消息广播模式了。</strong> 当一台同样遵守ZAB协议的服务器启动后加人到集群中时，如果此时集群中已经存在一个Leader服务器在负责进行消息广播，那么新加人的服务器就会自觉地进人数据恢复模式：找到Leader所在的服务器，并与其进行数据同步，然后一起参与到消息广播流程中去。正如上文介绍中所说的，ZooKeeper设计成只允许唯一的一个Leader服务器来进行事务请求的处理。Leader服务器在接收到客户端的事务请求后，会生成对应的事务提案并发起一轮广播协议；而如果集群中的其他机器接收到客户端的事务请求，那么这些非Leader服务器会首先将这个事务请求转发给Leader服务器。</p><p>关于 ZAB 协议&amp;Paxos算法 需要讲和理解的东西太多了，推荐阅读下面两篇文章：</p><ul><li><a href="http://codemacro.com/2014/10/15/explain-poxos/" target="_blank" rel="noopener">图解 Paxos 一致性协议</a></li><li><a href="https://dbaplus.cn/news-141-1875-1.html" target="_blank" rel="noopener">Zookeeper ZAB 协议分析</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1-什么是-ZooKeeper&quot;&gt;&lt;a href=&quot;#1-什么是-ZooKeeper&quot; class=&quot;headerlink&quot; title=&quot;1. 什么是 ZooKeeper&quot;&gt;&lt;/a&gt;1. 什么是 ZooKeeper&lt;/h3&gt;&lt;h4 id=&quot;1-1-ZooKeep
      
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/child/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>web-（转）彻底理解cookie，session，token</title>
    <link href="http://yoursite.com/child/2019/11/23/web-%E5%BD%BB%E5%BA%95%E7%90%86%E8%A7%A3cookie%EF%BC%8Csession%EF%BC%8Ctoken/"/>
    <id>http://yoursite.com/child/2019/11/23/web-彻底理解cookie，session，token/</id>
    <published>2019-11-22T16:00:00.000Z</published>
    <updated>2020-03-20T07:30:55.422Z</updated>
    
    <content type="html"><![CDATA[<p>原文链接：<a href="https://www.cnblogs.com/moyand/p/9047978.html" target="_blank" rel="noopener">https://www.cnblogs.com/moyand/p/9047978.html</a></p><p>发展史</p><p>1、 很久很久以前，Web基本上就是文档的浏览而已，既然是浏览，作为服务器，不需要记录谁在某一段时间里都浏览了什么文 </p><p>档，每次请求都是一个新的HTTP协议，就是请求加响应，尤其是我不用记住是谁刚刚发了 HTTP请求，每个请求对我来说都是 </p><p>全新的。这段时间很嗨皮</p><p>2、 但是随着交互式Web应用的兴起，像在线购物网站，需要登录的网站等等，马上就面临一个问题，那就是要管理会话，必须记住 </p><p>哪些人登录系统，哪些人往自己的购物车中放商品，也就是说我必须把每个人区分开，这就是一个不小的挑战，因为HTTP请求是 </p><p>无状态的，所以想出的办法就是给大家发一个会话标识(session id),说白了就是一个随机的字串，每个人收到的都不一样，每次大 </p><p>家向我发起HTTP请求的时候，把这个字符串给一并捎过来，这样我就能区分开谁是谁了</p><p>3、 这样大家很嗨皮了，可是服务器就不嗨皮了，每个人只需要保存自己的session id，而服务器要保存所有人的session id !如果 </p><p>访问服务器多了，就得由成千上万，甚至几十万个。</p><p>这对服务器说是一个巨大的开销，严重的限制了服务器扩展能力，比如说我用两个机器组成了一个集群，小F通过机器A登录了系 </p><p>统，那session id会保存在机器A上，假设小F的下一次请求被转发到机器B怎么办？机器B可没有小F的session id啊。</p><p>有时候会采用_点小伎俩：session sticky,就是让小 F的请求一直粘连在机器A上，但是这也不管用，要是机器A挂掉了，还得转 </p><p>到机器B去。</p><p>那只好做session的复制了，把session id在两个机器之间搬来搬去，快累死了。</p><p><img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200311210943504.png" alt="image-20200311210943504"></p><p>后来有个叫Memcached的支了招：把session id 集中存储到衣蛾地方，所有的机器都来访问这个地方的数据，这样一来，就不用复制了。但是增加了单点失败的可能性，要是那个负责session的机器挂了，所有的人都得重新登录一遍，估计的被人骂死</p><p>后来也尝试把这个单点的机器搞成集群，增加可靠性，但是不管如何，这个小小的session对我来说是一个称重的负担。</p><p>4  于是就有人一直在思考，我为什么要保存这个可恶的session呢，让每个客户端去保存该多好</p><p>可是如果不保存这些session id 怎么验证客户端发给我的session id 的确是我生成的呢？如果不去验证，我们都不知道他们是不是合法的登录用户，那些不怀好意的家伙们就能伪造session id 为所欲为了</p><p>哦，对了 关键点就是验证</p><p>比如说，小F已经登陆了系统，我给他发一个令牌（Token），里面包含了小F的user id ，下一次小F再次通过Http请求访问我的时候，把这个token通过http header带过来不就可以了。</p><p>不过这和session id 没有本质区别啊 ，任何人都可以伪造，所以我的想点办法让别人伪造不聊</p><p>那就对数据做一个签名吧，比如说我用HMAC-SHA256算法，加上一个只我才知道的秘钥，对数据做一个签名，把这个签名和数据一起作为token，由于秘钥被人不知道，就无法伪造了。</p><p>这个token我们不保存，当小F把这个token发给我的时候，我在用同样的算法和密钥对数据在计算一次签名，和token中带的签名做个比较，如果相同，我就知道小F已经登陆过了，并且可以直接渠道小F的user id，若果不相同，数据部分肯定被人篡改过，我就发偶素发送者：对不起，没有验证。</p><p>Token中的数据是明文保存的（虽然我会用Base64坐下编码，但那不是加密），还是可以被别人看到的，所以我不能在其中保存像密码这样的敏感信息</p><p>当然，如果一根人的token被别人偷走了，那我也没办法，我也会任务小偷就是合法用户，这其实和一个人的session id 被别人偷走是一样的。</p><p>这样一来，我就不保存session id 了我只是生成token，然后验证token。用计算时间换区存储空间</p><p>解除了session id 这个负担，可以说是一身轻松，我的机器集群现在可以轻松的做水平扩展，用户访问量增大，直接加机器就行。这种无状态的感觉实在太好了！</p><h3 id="cookie"><a href="#cookie" class="headerlink" title="cookie"></a>cookie</h3><p>cookie是一个非常具体的东西，指的就是浏览器里能永久存储的一种数据，仅仅是浏览器实现的一种数据存储功能。</p><p>cookie有服务器生成，发送给浏览器，浏览器吧cookie一kv的形式保存到某个目录下的文本文件内，下一次请求同一网站时会把该cookie发送给服务器。由于cookie是存在客户端上的没所以浏览器加入了一些限制确保cookie不会给恶意使用，同事不会占据太多磁盘空间。所以每个域的cookie数量是有限的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;原文链接：&lt;a href=&quot;https://www.cnblogs.com/moyand/p/9047978.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.cnblogs.com/moyand/p/9047978.html
      
    
    </summary>
    
    
      <category term="web" scheme="http://yoursite.com/child/tags/web/"/>
    
  </entry>
  
  <entry>
    <title>mysql-innodb的事务管理与锁</title>
    <link href="http://yoursite.com/child/2019/11/23/mysql-innodb%E7%9A%84%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86%E4%B8%8E%E9%94%81/"/>
    <id>http://yoursite.com/child/2019/11/23/mysql-innodb的事务管理与锁/</id>
    <published>2019-11-22T16:00:00.000Z</published>
    <updated>2020-03-31T15:03:55.991Z</updated>
    
    <content type="html"><![CDATA[<p>典型的事务场景：下单、转账</p><p><strong>事物的定义：事务是DBMS执行过程中的一个逻辑单位，由一个有限的数据库操作序列构成</strong></p><p>MYSQL中支持事务的数据引擎：innodb  ndb</p><h5 id="1、数据库事务的四大特性是什么？"><a href="#1、数据库事务的四大特性是什么？" class="headerlink" title="1、数据库事务的四大特性是什么？"></a>1、数据库事务的四大特性是什么？</h5><p>原子性  Atomicity   由undo log保证</p><p>一致性  Consistent   数据完整性</p><p>隔离性   Isolation  不同事务之间处理同一段数据应当是隔离的互不干扰的</p><p>持久性   Durable  redo log</p><p><strong>原子性、隔离性和持久性最终都是为了实现一致性。</strong></p><h5 id="2、什么时候会出现事务、结束事务？"><a href="#2、什么时候会出现事务、结束事务？" class="headerlink" title="2、什么时候会出现事务、结束事务？"></a>2、什么时候会出现事务、结束事务？</h5><p>当我们执行单条语句的时候，会默认开启事务</p><p>mysql 参数 autocommit 默认为 on 开启状态，执行单条查询语句不需要显示的声明事务、提交事务</p><p>show global VARIABLE like ‘autocommit’  显示该参数的全局值</p><p>show session VARIABLE like ‘autocommit’ 显示当前会话该参数的值</p><p>set session autocommit=off; 关闭autocommit后，需要手动提交</p><p><strong>手动开启事务，两种方式</strong>  </p><p>start TRANSACATION;    </p><p> begin; </p><p>事务的结束：</p><p>提交结束 commit;</p><p>回滚结束 rollback；</p><p>连接断开 会话结束 -&gt; 事务结束</p><h5 id="3、事务并发带来的问题有哪些？"><a href="#3、事务并发带来的问题有哪些？" class="headerlink" title="3、事务并发带来的问题有哪些？"></a>3、事务并发带来的问题有哪些？</h5><p>脏读（读未提交）：事务A执行一条查询，事务B修改了这部分数据但没提交，导致A读取到事务B没有提交的数据，事务B可能回滚导致事务A读取到的数据是脏数据。</p><p>不可重复读：事务A执行一条查询后，事务B对这部分数据执行了update/delete并提交了，导致事务A再次查询时与上一次的查询结果不一致，称为不可重复度。</p><p>幻读：事务A执行一条范围查询后，事务B在此范围insert了若干条数据，导致事务A再次执行该查询是记录数增多，产生幻读。</p><p>以上三个问题称为数据库的读一致性问题，必须由数据库自己提供一定的事务隔离机制来解决</p><h5 id="4、SQL92-标准"><a href="#4、SQL92-标准" class="headerlink" title="4、SQL92 标准"></a>4、SQL92 标准</h5><p>许多数据库专家联合制定了一个标准，建议数据库厂商都按照这个标准提供一定的事务隔离级别，来解决事务并发问题。</p><p>看一下SQL92标准的官网：<a href="http://www.contrib.andrew.cmu.edu/~shadow/sql/sql1992.txt" target="_blank" rel="noopener">http://www.contrib.andrew.cmu.edu/~shadow/sql/sql1992.txt</a></p><p>在官网搜索_iso，会看到一张表格：</p><table><thead><tr><th style="text-align:left">Level</th><th>P1</th><th>P2</th><th>P3</th></tr></thead><tbody><tr><td style="text-align:left">READ UNCOMMITTED</td><td>Possible</td><td>Possible</td><td>Possible</td></tr><tr><td style="text-align:left">READ COMMITTED</td><td>Not Possible</td><td>Possible</td><td>Possible</td></tr><tr><td style="text-align:left">REPEATABLE READ</td><td>Not Possible</td><td>Not Possible</td><td>Possible</td></tr><tr><td style="text-align:left">SERIALIZABLE</td><td>Not Possible</td><td>Not Possible</td><td>Not Possible</td></tr></tbody></table><p>这里定义了四个隔离级别，右边的P1P2P3就是代表事务并发的三个问题，脏读，不可重复度，幻读。Possible表示在这个隔离级别下该问题有可能发生，Not Possible表示解决了该问题。</p><ul><li>Read Uncommited 未提交读</li></ul><p>顾名思义，事务可以读取到其他事物未提交的数据，使用这种隔离级别其实并未解决以上的任何问题</p><ul><li>Read Commited  已提交读</li></ul><p>只能读到其他事物已经提交了的数据，解决了脏读问题</p><ul><li>Repeatable Read  可重复读</li></ul><p>事务重复读取，保证重复读取数据一致，解决了不可重复度的问题</p><ul><li>Serializable 串行化</li></ul><p>事务串行化运行，没有并发自然没有不一性问题产生，但是严重影响效率，不推荐使用</p><p>不同的厂商或者数据库引擎在实现以上标准时会有一些差异。Oracle只实现了两种RC和Serializable，Innodb对以上的四种隔离级别都进行了实现，值得一提的是，innodb 对Repeatable Read 这一级别的实现同时也解决了幻读的问题，因此这一级别是innodb的默认事务隔离级别。</p><h5 id="5、innodb是如何实现的呢"><a href="#5、innodb是如何实现的呢" class="headerlink" title="5、innodb是如何实现的呢?"></a>5、innodb是如何实现的呢?</h5><p>如果要解决读一致性的问题 ，保证一个事务前后两次读取数据一致，实现事务隔离级别，应该怎么做 </p><p>方案一 ： LBCC 基于锁的并发控制</p><p>方案二： MVCC 基于多版本的并发控制  生成一个数据请求时间点的一致性数据，并用这个快照来提供一定级别的一致性读取。</p><p>首先介绍MVCC的实现原理</p><p>从三个隐藏字段开始</p><p>InnoDB为每行记录都实现了三个隐藏字段</p><p>DB_ROW_ID   6字节：行标识</p><p>DB_TRX_ID  6字节：插入或更新行的最后一个事务ID，自动递增（理解为创建版本号）</p><p>DB_ROLL_PTR：  7字节：回滚指针（理解为删除版本号）</p><p>mvcc核心思想，一个事务根据自己的事务id进行判断，</p><p>只能查询到创建版本号比我的事务ID小的  和  删除版本号比我事务ID大的记录  </p><p>innodb的锁：</p><p>锁的模式：</p><p>行锁—共享锁 和 排它锁</p><p>表所 — 意向排他锁 和 意向共享锁</p><p>为什么需要 表级别的意向锁</p><p>意向锁可以理解为表的锁标志</p><p>一个事务尝试给一张表加上表锁，前提是没有其他任何事务已经锁定了这张表的任意一行，那么需要检索所有的行确定没有锁。意向锁是又来避免这种检索的</p><p>锁的作用：</p><p>锁的算法：在什么时候锁定什么范围</p><p>记录锁</p><p>间隙锁</p><p>邻键锁</p><p>插入意向锁 </p><p>自增锁</p><p>解决资源竞争的问题</p><p>锁到底锁住了什么？</p><p>锁住的是索引</p><p>问题1 一张表没有索引或者没用到索引为什么会锁表？</p><p>一张表不可能没有索引，没有显示声明索引的表，隐藏的row_id字段会作为聚集索引。。。如果查询语句没有用到索引，那只能走全表扫描，就会锁住全表</p><p>问题2 为什么锁住辅助索引，会导致主键索引也被锁住？</p><p>回表</p><p>记录锁 —- 唯一索引 等值查询 精确匹配时</p><p>间隙锁—- 锁定记录不存在的范围区间，主要用来控制插入，不同间隙的锁互相不影响</p><p>邻键锁 —- 锁定查询的范围，包含记录和区间，执行了范围查询时会用到邻键锁，是行锁的默认锁定方式，以上两种是邻键锁的特殊情况</p><p>innodb在RR实现里就解决幻读问题 就是依靠邻 键锁</p><p>共享锁和排他锁   行所</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;典型的事务场景：下单、转账&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;事物的定义：事务是DBMS执行过程中的一个逻辑单位，由一个有限的数据库操作序列构成&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;MYSQL中支持事务的数据引擎：innodb  ndb&lt;/p&gt;
&lt;h5 id=&quot;1、数据库事务的四大
      
    
    </summary>
    
    
      <category term="数据库" scheme="http://yoursite.com/child/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>分布式-vagrant&amp;virtualBox使用说明</title>
    <link href="http://yoursite.com/child/2019/11/22/%E5%88%86%E5%B8%83%E5%BC%8F-vagrant&amp;virtualBox%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/"/>
    <id>http://yoursite.com/child/2019/11/22/分布式-vagrant&amp;virtualBox使用说明/</id>
    <published>2019-11-21T16:00:00.000Z</published>
    <updated>2019-12-10T13:21:59.433Z</updated>
    
    <content type="html"><![CDATA[<p>vagrant是一个工具，用于创建和部署虚拟化开发环境的，能与virtualVM、virtualBox等虚拟机软件搭配使用。</p><p>拿VirtualBox举例，VirtualBox会开放一个创建虚拟机的接口，Vagrant会利用这个接口创建虚拟机，并且通过Vagrant来管理，配置和自动安装虚拟机。</p><ul><li><p>安装最新版virtualBox</p></li><li><p>安装最新版vagrant</p></li></ul><h4 id="1、创建虚拟机"><a href="#1、创建虚拟机" class="headerlink" title="1、创建虚拟机"></a>1、创建虚拟机</h4><p>首先下载镜像，我们使用vagrant box add 命令进行下载</p><p>Vagrant 的 box，是一个打包好的单一文件，其中包含了一个完整系统的虚拟机相关数据。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 添加virtualBox，名字可自定义，使用官方的命名不需要url，下载速度慢，建议使用国内镜像源下载</span><br><span class="line">vagrant box add &#123;name&#125; &#123;url&#125;</span><br><span class="line"><span class="meta">#</span> 列出已下载所有的virtualBox</span><br><span class="line">vagrant box list</span><br><span class="line"><span class="meta">#</span> 移除指定的virtualBox</span><br><span class="line">vagrant box remove &#123;name&#125;</span><br></pre></td></tr></table></figure><p>本文使用中国科技大学的centos7镜像源，在cmd任意目录下执行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant box add centos7 http://mirrors.ustc.edu.cn/centos-cloud/centos/7/vagrant/x86_64/images/CentOS-7-x86_64-Vagrant-1708_01.VirtualBox.box</span><br></pre></td></tr></table></figure><p>在用户目录下新建文件夹 如：E:/vagrant/，在目录下执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vgrant init</span><br></pre></td></tr></table></figure><p>会生成一个vagrantfile文件，该文件是将要创建的虚拟机属性配置文件，如下修改文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">Vagrant.configure(&quot;2&quot;) do |config|</span><br><span class="line">   (1..3).each do |i|</span><br><span class="line">        config.vm.define &quot;node#&#123;i&#125;&quot; do |node|</span><br><span class="line">            # 设置虚拟机的Box</span><br><span class="line">            node.vm.box = &quot;centos7&quot;</span><br><span class="line"></span><br><span class="line">            # 设置虚拟机的主机名</span><br><span class="line">            node.vm.hostname=&quot;node#&#123;i&#125;&quot;</span><br><span class="line"></span><br><span class="line"># 设置虚拟机的IP</span><br><span class="line">            node.vm.network &quot;public_network&quot;, ip: &quot;192.168.2.#&#123;200+i&#125;&quot;</span><br><span class="line"></span><br><span class="line">            # VirtaulBox相关配置</span><br><span class="line">            node.vm.provider &quot;virtualbox&quot; do |v|</span><br><span class="line">                # 设置虚拟机的名称</span><br><span class="line">                v.name = &quot;node#&#123;i&#125;&quot;</span><br><span class="line">                # 设置虚拟机的内存大小</span><br><span class="line">                v.memory = 2048</span><br><span class="line">                # 设置虚拟机的CPU个数</span><br><span class="line">                v.cpus = 1</span><br><span class="line">            end</span><br><span class="line">        end</span><br><span class="line">   end</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>保存后，在当前目录执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant up</span><br></pre></td></tr></table></figure><p>vagrant会根据vagrantfile创建3台虚拟机并启动，本文将采用桥接网卡的网络模型，因此在virtualBox中将虚拟机关闭之后，对网络进行设置，取消默认勾选的NAT网络，只剩下桥接网卡。</p><h4 id="2、网络模型选择"><a href="#2、网络模型选择" class="headerlink" title="2、网络模型选择"></a>2、网络模型选择</h4><h5 id="2-1-网络选型原则"><a href="#2-1-网络选型原则" class="headerlink" title="2.1 网络选型原则"></a>2.1 网络选型原则</h5><p>​        第一：每个网络只负载一种业务类型的数据流量，功能单一化。例如连接外网用一个网络、虚拟机之间互通用一个网络、虚拟机与主机之间互通又是一个网络。这样的话可使每种网络上的数据流量比较纯净，同时也可以避免因为网络故障而影响到全部的业务。</p><p>​    第二：在保证网络功能的前提下，单一的网络要保证最小的连通性、最大的隔离性。比如用于连接外网的网络，最好禁止掉连通宿主机，其它虚拟机这种额外的功能，可最大程序的提高效率。</p><p>​    第三：网络的独立性。当有多种技术可以达成某种网络功能时，选型时应选择对外部环境依赖程度最小、独立性最高的实现方式，避免因外宿主机换了一个无线网络环境，而影响到在宿主机上虚拟出来的网络。</p><p>​    第四：最后一条就是效率。当有多种选择时，数据流动路径最短的那一种，往住是效率最高的一种。</p><h5 id="2-2-四种网络模式连通性汇总列表"><a href="#2-2-四种网络模式连通性汇总列表" class="headerlink" title="2.2 四种网络模式连通性汇总列表"></a>2.2 四种网络模式连通性汇总列表</h5><p>“o”表示连接，“x”表示不通。前提条件是用VirtualBox创建出网络后，没有进行额外的配置，NAT网络没有进行端口映射、仅主机网络没有进行连接共享等。理论上，通过一定的技术手段，所有的模式对所有的网络都是可以连通的。</p><p><img src="https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/%E7%BD%91%E7%BB%9C/virtualBox-net-1.png" alt></p><h5 id="2-3-VirtualBox四种网络模式独立性"><a href="#2-3-VirtualBox四种网络模式独立性" class="headerlink" title="2.3 VirtualBox四种网络模式独立性"></a>2.3 VirtualBox四种网络模式独立性</h5><p>独立性即对外部环境依赖性，分成高、中，低三档，越高说明越依赖于外部环境。</p><p><img src="https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/%E7%BD%91%E7%BB%9C/virtualBox-net-2.png" alt></p><h5 id="2-4-四种网络模式的典型应用"><a href="#2-4-四种网络模式的典型应用" class="headerlink" title="2.4 四种网络模式的典型应用"></a>2.4 四种网络模式的典型应用</h5><p>例如想用VirtualBox创建虚拟机，以安装部署OpenStack,那么应该用VirtualBox创建四个网络，每个网络都有单独的目的，每种网络各司其职，同时对外部的依赖性降到最低。</p><p><img src="https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/%E7%BD%91%E7%BB%9C/virtualBox-net-3.png" alt></p><h4 id="3、远程登录"><a href="#3、远程登录" class="headerlink" title="3、远程登录"></a>3、远程登录</h4><p>本文选用的桥接网卡，虚拟机将与宿主机共享网络，在一个网络之中的设备（宿主机以及同一路由器下的设备）都能使用桥接网卡的ip地址远程登录到虚拟机中，端口默认22，可以自行修改。</p><p>在登陆之前需要修改虚拟机sshd配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/ssh/sshd_config</span><br><span class="line"><span class="meta">#</span> 修改项如下</span><br><span class="line">PasswordAuthentication=yes</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>重启sshd服务</span><br><span class="line">service sshd restart</span><br></pre></td></tr></table></figure><p>笔者宿主机ip为192.168.2.110</p><p>查看node1虚拟机桥接网卡ip为 192.168.2.112，因此执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -p 22 root@192.168.2.112</span><br></pre></td></tr></table></figure><p>输入密码完成登录。</p><p>参考：</p><p><a href="https://blog.csdn.net/dkfajsldfsdfsd/article/details/79444582" target="_blank" rel="noopener">VirtualBox四种网络模式及典型配置</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;vagrant是一个工具，用于创建和部署虚拟化开发环境的，能与virtualVM、virtualBox等虚拟机软件搭配使用。&lt;/p&gt;
&lt;p&gt;拿VirtualBox举例，VirtualBox会开放一个创建虚拟机的接口，Vagrant会利用这个接口创建虚拟机，并且通过Vagra
      
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/child/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>分布式-vagrantfile简析</title>
    <link href="http://yoursite.com/child/2019/11/22/%E5%88%86%E5%B8%83%E5%BC%8F-vagrantfile%E7%AE%80%E6%9E%90/"/>
    <id>http://yoursite.com/child/2019/11/22/分布式-vagrantfile简析/</id>
    <published>2019-11-21T16:00:00.000Z</published>
    <updated>2019-12-10T13:21:30.803Z</updated>
    
    <content type="html"><![CDATA[<p>参考：</p><p><a href="https://blog.csdn.net/u011781521/article/details/80291765" target="_blank" rel="noopener">Vagrant的配置文件Vagrantfile详解</a></p><h5 id="1、box设置"><a href="#1、box设置" class="headerlink" title="1、box设置"></a>1、box设置</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config.vm.box = &quot;centos7&quot;</span><br></pre></td></tr></table></figure><p>该名称是再使用 vagrant init 中后面跟的名字。</p><h5 id="2、hostname设置"><a href="#2、hostname设置" class="headerlink" title="2、hostname设置"></a>2、hostname设置</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config.vm.hostname = &quot;node1&quot;</span><br></pre></td></tr></table></figure><p>设置hostname非常重要，因为当我们有很多台虚拟服务器的时候，都是依靠hostname來做识别的。比如，我安装了centos1,centos2 两台虚拟机，再启动时，我可以通过vagrant up centos1来指定只启动哪一台。</p><h5 id="3、虚拟机网络设置"><a href="#3、虚拟机网络设置" class="headerlink" title="3、虚拟机网络设置"></a>3、虚拟机网络设置</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">//Host-only模式</span><br><span class="line">config.vm.network &quot;private_network&quot;, ip: &quot;192.168.10.11&quot;</span><br><span class="line"></span><br><span class="line">//Bridge模式</span><br><span class="line">config.vm.network &quot;public_network&quot;, ip: &quot;10.1.2.61&quot;</span><br></pre></td></tr></table></figure><p>Vagrant的网络连接方式有三种：</p><ul><li><p>NAT : 缺省创建，用于让vm可以通过host转发访问局域网甚至互联网。</p></li><li><p>host-only : 只有主机可以访问vm，其他机器无法访问它。</p></li><li><p>bridge : 此模式下vm就像局域网中的一台独立的机器，可以被其他机器访问。</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">config.vm.network :private_network, ip: &quot;192.168.33.10&quot;</span><br><span class="line"></span><br><span class="line">配置当前vm的host-only网络的IP地址为192.168.33.10</span><br></pre></td></tr></table></figure><p>host-only 模式的IP可以不指定，而是采用dhcp自动生成的方式，如 :</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config.vm.network &quot;private_network&quot;, type: &quot;dhcp”</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#创建一个bridge桥接网络，指定IP</span><br><span class="line">config.vm.network &quot;public_network&quot;, ip: &quot;192.168.0.17&quot;</span><br><span class="line">#创建一个bridge桥接网络，指定桥接适配器</span><br><span class="line">config.vm.network &quot;public_network&quot;, bridge: &quot;en1: Wi-Fi (AirPort)&quot;</span><br><span class="line">#创建一个bridge桥接网络，不指定桥接适配器</span><br><span class="line">config.vm.network &quot;public_network&quot;</span><br></pre></td></tr></table></figure><h5 id="4、同步目录设置"><a href="#4、同步目录设置" class="headerlink" title="4、同步目录设置"></a>4、同步目录设置</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config.vm.synced_folder &quot;D:/xxx/code&quot;, &quot;/home/www/&quot;</span><br></pre></td></tr></table></figure><p>前面的路径(D:/xxx/code)是本机代码的地址，后面的地址就是虚拟机的目录。虚拟机的/vagrant目录默认挂载宿主机的开发目录(可以在进入虚拟机机后，使用df -h 查看)，这是在虚拟机启动时自动挂载的。我们还可以设置额外的共享目录，上面这个设定，第一个参数是宿主机的目录，第二个参数是虚拟机挂载的目录。</p><h5 id="5、端口转发设置"><a href="#5、端口转发设置" class="headerlink" title="5、端口转发设置"></a>5、端口转发设置</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config.vm.network :forwarded_port, guest: 80, host: 8080</span><br></pre></td></tr></table></figure><p>上面的配置把宿主机上的8080端口映射到客户虚拟机的80端口，例如你在虚拟机上使用nginx跑了一个Go应用，那么你在host上的浏览器中打开<a href="http://localhost:8080时，Vagrant就会把这个请求转发到虚拟机里跑在80端口的nginx服务上。不建议使用该方法，因为涉及端口占用问题，常常导致应用之间不能正常通信，建议使用Host-only和Bridge方式进行设置。" target="_blank" rel="noopener">http://localhost:8080时，Vagrant就会把这个请求转发到虚拟机里跑在80端口的nginx服务上。不建议使用该方法，因为涉及端口占用问题，常常导致应用之间不能正常通信，建议使用Host-only和Bridge方式进行设置。</a></p><p>guest和host是必须的，还有几个可选属性：</p><ul><li>guest_ip：字符串，vm指定绑定的Ip，缺省为0.0.0.0</li><li>host_ip：字符串，host指定绑定的Ip，缺省为0.0.0.0</li><li>protocol：字符串，可选TCP或UDP，缺省为TCP</li></ul><h5 id="6、定义vm的configure配置节点-一个节点就是一个虚拟机"><a href="#6、定义vm的configure配置节点-一个节点就是一个虚拟机" class="headerlink" title="6、定义vm的configure配置节点(一个节点就是一个虚拟机)"></a>6、定义vm的configure配置节点(一个节点就是一个虚拟机)</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">config.vm.define :mysql do |mysql_config|</span><br><span class="line">...</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>表示在config配置中，定义一个名为mysql的vm配置，该节点下的配置信息命名为mysql_config； 如果该Vagrantfile配置文件只定义了一个vm，这个配置节点层次可忽略。</p><p>还可以在一个Vagrantfile文件里建立多个虚拟机，一般情况下，你可以用多主机功能完成以下任务：</p><ul><li>分布式的服务，例如网站服务器和数据库服务器</li><li>分发系统</li><li>测试接口</li><li>灾难测试  </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Vagrant.configure(&quot;2&quot;) do |config|</span><br><span class="line">  config.vm.define &quot;web&quot; do |web|</span><br><span class="line">    web.vm.box = &quot;apache&quot;</span><br><span class="line">  end</span><br><span class="line">  config.vm.define &quot;db&quot; do |db|</span><br><span class="line">    db.vm.box = &quot;mysql&quot;</span><br><span class="line">  end</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>当定义了多主机之后，在使用vagrant命令的时候，就需要加上主机名，例如vagrant ssh web；也有一些命令，如果你不指定特定的主机，那么将会对所有的主机起作用，比如vagrant up；你也可以使用表达式指定特定的主机名，例如vagrant up /follower[0-9]/。</p><h5 id="7、通用数据-设置一些基础数据，供配置信息中调用。"><a href="#7、通用数据-设置一些基础数据，供配置信息中调用。" class="headerlink" title="7、通用数据 设置一些基础数据，供配置信息中调用。"></a>7、通用数据 设置一些基础数据，供配置信息中调用。</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">app_servers = &#123;</span><br><span class="line">    :service1 =&gt; &apos;192.168.33.20&apos;,</span><br><span class="line">    :service2 =&gt; &apos;192.168.33.21&apos;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里是定义一个hashmap，以key-value方式来存储vm主机名和ip地址。</p><h5 id="8、配置信息"><a href="#8、配置信息" class="headerlink" title="8、配置信息"></a>8、配置信息</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ENV[&quot;LC_ALL&quot;] = &quot;en_US.UTF-8&quot;</span><br><span class="line">指定vm的语言环境，缺省地，会继承host的locale配置</span><br><span class="line">Vagrant.configure(&quot;2&quot;) do |config|</span><br><span class="line">    # ...</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>参数2，表示的是当前配置文件使用的vagrant configure版本号为Vagrant 1.1+,如果取值为1，表示为Vagrant 1.0.x Vagrantfiles，旧版本暂不考虑，记住就写2即可。</p><p>do … end 为配置的开始结束符，所有配置信息都写在这两段代码之间。 config是为当前配置命名，你可以指定任意名称，如myvmconfig，在后面引用的时候，改为自己的名字即可。</p><h5 id="9、vm提供者配置"><a href="#9、vm提供者配置" class="headerlink" title="9、vm提供者配置"></a>9、vm提供者配置</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">config.vm.provider :virtualbox do |vb|</span><br><span class="line">     # ...</span><br><span class="line">end</span><br></pre></td></tr></table></figure><h5 id="10-vm-provider通用配置"><a href="#10-vm-provider通用配置" class="headerlink" title="10 vm provider通用配置"></a>10 vm provider通用配置</h5><p>虚机容器提供者配置，对于不同的provider，特有的一些配置，此处配置信息是针对virtualbox定义一个提供者，命名为vb，跟前面一样，这个名字随意取，只要节点内部调用一致即可。</p><p>配置信息又分为通用配置和个性化配置，通用配置对于不同provider是通用的，常用的通用配置如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">vb.name = &quot;centos7&quot;</span><br><span class="line"></span><br><span class="line">指定vm-name，也就是virtualbox管理控制台中的虚机名称。如果不指定该选项会生成一个随机的名字，不容易区分。</span><br><span class="line"></span><br><span class="line">vb.gui = true</span><br><span class="line"></span><br><span class="line">vagrant up启动时，是否自动打开virtual box的窗口，缺省为false</span><br><span class="line"></span><br><span class="line">vb.memory = &quot;1024&quot;</span><br><span class="line"></span><br><span class="line">指定vm内存，单位为MB</span><br><span class="line"></span><br><span class="line">vb.cpus = 2</span><br><span class="line"></span><br><span class="line">设置CPU个数</span><br></pre></td></tr></table></figure><h5 id="11-vm-provider个性化配置-virtualbox"><a href="#11-vm-provider个性化配置-virtualbox" class="headerlink" title="11 vm provider个性化配置(virtualbox)"></a>11 vm provider个性化配置(virtualbox)</h5><p>上面的provider配置是通用的配置，针对不同的虚拟机，还有一些的个性的配置，通过vb.customize配置来定制。</p><p>对virtual box的个性化配置，可以参考：VBoxManage modifyvm 命令的使用方法。详细的功能接口和使用说明，可以参考virtualbox官方文档。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">修改vb.name的值</span><br><span class="line">v.customize [&quot;modifyvm&quot;, :id, &quot;--name&quot;, &quot;mfsmaster2&quot;]</span><br><span class="line"></span><br><span class="line">如修改显存，缺省为8M，如果启动桌面，至少需要10M，如下修改为16M：</span><br><span class="line">vb.customize [&quot;modifyvm&quot;, :id, &quot;--vram&quot;, &quot;16&quot;]</span><br><span class="line"></span><br><span class="line">调整虚拟机的内存</span><br><span class="line">vb.customize [&quot;modifyvm&quot;, :id, &quot;--memory&quot;, &quot;1024&quot;]</span><br><span class="line"></span><br><span class="line">指定虚拟CPU个数</span><br><span class="line">vb.customize [&quot;modifyvm&quot;, :id, &quot;--cpus&quot;, &quot;2&quot;]</span><br><span class="line"></span><br><span class="line">增加光驱：</span><br><span class="line">vb.customize [&quot;storageattach&quot;,:id,&quot;--storagectl&quot;, &quot;IDE Controller&quot;,&quot;--port&quot;,&quot;0&quot;,&quot;--device&quot;,&quot;0&quot;,&quot;--type&quot;,&quot;dvddrive&quot;,&quot;--medium&quot;,&quot;/Applications/VirtualBox.app/Contents/MacOS/VBoxGuestAdditions.iso&quot;]</span><br><span class="line"></span><br><span class="line">注：meduim参数不可以为空，如果只挂载驱动器不挂在iso，指定为“emptydrive”。如果要卸载光驱，medium传入none即可。</span><br><span class="line">从这个指令可以看出，customize方法传入一个json数组，按照顺序传入参数即可。</span><br><span class="line"></span><br><span class="line">json数组传入多个参数</span><br><span class="line">v.customize [&quot;modifyvm&quot;, :id, &quot;--name&quot;, “mfsserver3&quot;, &quot;--memory&quot;, “2048&quot;]</span><br></pre></td></tr></table></figure><h5 id="12-一组相同配置的vm"><a href="#12-一组相同配置的vm" class="headerlink" title="12 一组相同配置的vm"></a>12 一组相同配置的vm</h5><p>前面配置了一组vm的hash map，定义一组vm时，使用如下节点遍历。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#遍历app_servers map，将key和value分别赋值给app_server_name和app_server_ip</span><br><span class="line">app_servers.each do |app_server_name, app_server_ip|</span><br><span class="line">#针对每一个app_server_name，来配置config.vm.define配置节点，命名为app_config</span><br><span class="line">    config.vm.define app_server_name do |app_config|</span><br><span class="line">#此处配置，参考config.vm.define</span><br><span class="line">    end</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>如果不想定义app_servers，下面也是一种方案:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">(1..3).each do |i|</span><br><span class="line">        config.vm.define &quot;app-#&#123;i&#125;&quot; do |node|</span><br><span class="line">        app_config.vm.hostname = &quot;app-#&#123;i&#125;.vagrant.internal&quot;</span><br><span class="line">        app_config.vm.provider &quot;virtualbox&quot; do |vb|</span><br><span class="line">            vb.name = app-#&#123;i&#125;</span><br><span class="line">        end</span><br><span class="line">  end</span><br><span class="line">end</span><br></pre></td></tr></table></figure><h5 id="13-provision任务"><a href="#13-provision任务" class="headerlink" title="13 provision任务"></a>13 provision任务</h5><p>你可以编写一些命令，让vagrant在启动虚拟机的时候自动执行，这样你就可以省去手动配置环境的时间了。</p><ul><li><p>脚本何时会被执行 </p><ul><li>第一次执行vagrant up命令</li><li>执行vagrant provision命令</li><li>执行vagrant reload –provision或者vagrant up –provision命令</li><li>你也可以在启动虚拟机的时候添加–no-provision参数以阻止脚本被执行</li></ul></li><li><p>provision任务是什么？</p></li></ul><p>provision任务是预先设置的一些操作指令，格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">config.vm.provision 命令字 json格式参数</span><br><span class="line">config.vm.provion 命令字 do |s|</span><br><span class="line">    s.参数名 = 参数值</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>每一个 config.vm.provision 命令字 代码段，我们称之为一个provisioner。<br>根据任务操作的对象，provisioner可以分为：</p><ul><li>Shell</li><li>File</li><li>Ansible</li><li>CFEngine</li><li>Chef</li><li>Docker</li><li>Puppet</li><li>Salt</li></ul><p>根据vagrantfile的层次，分为：</p><p>configure级：它定义在 Vagrant.configure(“2”) 的下一层次，形如： config.vm.provision …</p><p>vm级：它定义在 config.vm.define “web” do |web| 的下一层次，web.vm.provision …</p><p>执行的顺序是先执行configure级任务，再执行vm级任务，即便configure级任务在vm定义的下面才定义。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Vagrant.configure(&quot;2&quot;) do |config|</span><br><span class="line">  config.vm.provision &quot;shell&quot;, inline: &quot;echo 1&quot;</span><br><span class="line"></span><br><span class="line">  config.vm.define &quot;web&quot; do |web|</span><br><span class="line">    web.vm.provision &quot;shell&quot;, inline: &quot;echo 2&quot;</span><br><span class="line">  end</span><br><span class="line"></span><br><span class="line">  config.vm.provision &quot;shell&quot;, inline: &quot;echo 3&quot;</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">==&gt; default: &quot;1&quot;</span><br><span class="line">==&gt; default: &quot;2&quot;</span><br><span class="line">==&gt; default: &quot;3&quot;</span><br></pre></td></tr></table></figure><ul><li>如何使用</li></ul><p><strong>单行脚本</strong></p><p>helloword只是一个开始，对于inline模式，命令只能在写在一行中。</p><p>单行脚本使用的基本格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config.vm.provision &quot;shell&quot;, inline: &quot;echo fendo&quot;</span><br></pre></td></tr></table></figure><p>shell命令的参数还可以写入do … end代码块中，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">config.vm.provision &quot;shell&quot; do |s|</span><br><span class="line">  s.inline = &quot;echo hello provision.&quot;</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p><strong>内联脚本</strong></p><p>如果要执行脚本较多，可以在Vagrantfile中指定内联脚本，在Vagrant.configure节点外面，写入命名内联脚本：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$script = &lt;&lt;SCRIPT</span><br><span class="line">echo I am provisioning...</span><br><span class="line">echo hello provision.</span><br><span class="line">SCRIPT</span><br></pre></td></tr></table></figure><p>然后，inline调用如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config.vm.provision &quot;shell&quot;, inline: $script</span><br></pre></td></tr></table></figure><p><strong>外部脚本</strong></p><p>也可以把代码写入代码文件，并保存在一个shell里，进行调用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config.vm.provision &quot;shell&quot;, path: &quot;script.sh&quot;</span><br></pre></td></tr></table></figure><p>script.sh的内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo hello provision.</span><br></pre></td></tr></table></figure><p>#### </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;参考：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/u011781521/article/details/80291765&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Vagrant的配置文件Vagrantfile详解&lt;/
      
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/child/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>jvm-垃圾收集器</title>
    <link href="http://yoursite.com/child/2019/11/21/jvm-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"/>
    <id>http://yoursite.com/child/2019/11/21/jvm-垃圾回收/</id>
    <published>2019-11-20T16:00:00.000Z</published>
    <updated>2020-03-20T07:24:23.888Z</updated>
    
    <content type="html"><![CDATA[<p>垃圾对象检测：</p><ul><li>引用计数发</li><li>可达性分析</li></ul><p>GC root由哪些对象组成</p><ol><li>本地方法栈中引用的对象</li><li>虚拟机栈中引用的对象</li><li>方法区中类变量引用的对象</li><li>方法区中的常量引用的对象</li></ol><h3 id="1-垃圾收集算法和收集器"><a href="#1-垃圾收集算法和收集器" class="headerlink" title="1. 垃圾收集算法和收集器"></a>1. 垃圾收集算法和收集器</h3><p>垃圾收集算法有哪些：</p><ol><li>标记-清除   产生内存碎片、效率不高</li><li>标记-整理   效率低</li><li>复制   空间利用率低  </li></ol><p>新生代（Young区）对象朝生夕死，GC时存活概率小，所以适合复制算法</p><p>老年代（old区）对象，则适合使用标记清除或者标记整理</p><p>垃圾收集器有哪些</p><p>评价一个垃圾收集器优劣的指标是 吞吐量 和 停顿时间</p><p>一、新生代收集器</p><ol><li>Serial 收集器</li></ol><p>历史悠久的收集器，单线程运行，运行时会阻塞其他线程，使用复制算法，因此适用于新生代垃圾回收</p><ol start="2"><li>ParNew 收集器</li></ol><p>Serial收集器的并行版，同样采用复制算法，适用于新生代，单CPU性能比Serial差</p><p>运行在server模式下的虚拟中首选的新生代收集器</p><ol start="3"><li>Parallel Scavenge 收集器</li></ol><p>注重吞吐量，</p><p>吞吐量 = 程序运行时间/(程序运行时间+垃圾回收时间)‘</p><p>二、老年代收集器</p><ol><li>Serial old</li></ol><p>复制算法的实现，单线程运行</p><ol start="2"><li>Paraller Old</li></ol><p>最关注的点事吞吐量</p><ol start="3"><li>CMS 并发收集器</li></ol><p>Concurrent Mark Sweep—并发标记清理</p><p>并发：用户线程和垃圾回收线程一起执行</p><p>并行：多条垃圾回收线程同时执行</p><p>CMS 最关注的点是GC停顿时间，所以优点是低停顿时间（因为并发收集）</p><p>缺点就是会产生大量的内存碎片（因为采用标记-清理算法），且并发阶段会吞吐量降低</p><p>流程：初始标记-&gt;并发标记-&gt;重新标记-&gt; 并发清理</p><blockquote><p>初始标记，stw，标记的事GCroot</p><p>并发标记，与用户线程一起执行，执行可达性分析，标记不可达对象</p><p>重新标记，stw，标记并发标记阶段产生的新垃圾</p><p>并发清理，用户线程一起执行，回收标记的对象</p></blockquote><p>使用  -XX:+UseConcMarkSweepGC 开启CMS</p><p>三、G1  Garbage-First</p><p>整体上属于标记-整理算法的实现，不会产生内存碎片</p><p>比CMS先进的地方在于用户可以设置停顿时间的大小，G1会按照用户的设置的事件指定回收计划</p><p>G1可同时用于新生代和老年代的垃圾回收，核心在于对堆内存的重新划分，不同的内存区域对于G1来说只是逻辑上的区分，在物理层面，G1将内存划分成一个个的region统一进行管理。</p><p>G1收集器会先收集存活对象少的区域，也就是垃圾对象多的区域，这样可以有大量的空间可以释放出来，这就 </p><p>是Garbage First的由来 </p><p><img src="https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/jvm/gc/1584582498419.png" alt="1584582498419"></p><p>执行流程为：初始标记–&gt; 并发标记 –&gt; 最终标记 –&gt; 筛选回收 </p><blockquote><p>初始标记：stw，标记GC ROOT</p><p>并发标记：与用户线程并发执行，执行可达性分析</p><p>最终标记：stw，标记并发标记阶段用户线程产生的新垃圾</p><p>筛选回收：stw，对各个Region的回收价值和回收成本进行排序，根据用户设定的停顿时间指定回收计划</p></blockquote><p>总结：</p><p>Serial 和Serial Old 为串行收集器，适用于<strong><em>内存较小的嵌入式设备</em></strong></p><p>Parallel 和 Parallel Old 为并行收集器，吞吐量优先的收集器组合，适用于<strong><em>科学计算、后台处理</em></strong>等应用场景</p><p>CMS 和 G1 为并发收集器，停顿时间优先，CMS适用于老年代收集（标记-清除），G1适用于整个堆内存垃圾回收（标记-整理），适用与<strong><em>对响应时间要求较高的场景</em></strong>，比如Web</p><p>如何开启：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">（1）串行 </span><br><span class="line">-XX：+UseSerialGC </span><br><span class="line">-XX：+UseSerialOldGC </span><br><span class="line">（2）并行(吞吐量优先)： </span><br><span class="line">-XX：+UseParallelGC </span><br><span class="line">-XX：+UseParallelOldGC </span><br><span class="line">（3）并发收集器(响应时间优先) </span><br><span class="line">-XX：+UseConcMarkSweepGC </span><br><span class="line">-XX：+UseG1GC</span><br></pre></td></tr></table></figure><h3 id="2、GC分类"><a href="#2、GC分类" class="headerlink" title="2、GC分类"></a>2、GC分类</h3><p>Minor GC触发条件：当Eden区满时，触发Minor GC。</p><p>Full GC触发条件：<br>（1）调用System.gc时，系统建议执行Full GC，但是不必然执行<br>（2）老年代空间不足<br>（3）方法去空间不足<br>（4）通过Minor GC后进入老年代的平均大小大于老年代的可用内存<br>（5）由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;垃圾对象检测：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;引用计数发&lt;/li&gt;
&lt;li&gt;可达性分析&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GC root由哪些对象组成&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;本地方法栈中引用的对象&lt;/li&gt;
&lt;li&gt;虚拟机栈中引用的对象&lt;/li&gt;
&lt;li&gt;方法区中类变量引用的对象
      
    
    </summary>
    
    
      <category term="jvm" scheme="http://yoursite.com/child/tags/jvm/"/>
    
  </entry>
  
  <entry>
    <title>mysql-innodb的索引</title>
    <link href="http://yoursite.com/child/2019/11/20/mysql-innodb%E7%9A%84%E7%B4%A2%E5%BC%95/"/>
    <id>http://yoursite.com/child/2019/11/20/mysql-innodb的索引/</id>
    <published>2019-11-19T16:00:00.000Z</published>
    <updated>2020-03-31T15:04:26.257Z</updated>
    
    <content type="html"><![CDATA[<p>数据库索引是数据库管理系统中一个排序的<strong>数据结构</strong>，以协助快速查询更新数据库表中数据</p><p>索引类型：normal普通索引、unique唯一索引、全文索引</p><h4 id="索引用什么数据结构？"><a href="#索引用什么数据结构？" class="headerlink" title="索引用什么数据结构？"></a>索引用什么数据结构？</h4><p>有序列表？不行，插入有问题</p><p>单链表？不行，查找有问题</p><p>AVL树？平衡开销大，数据量大导致树太高，查询效率低下，单页存储数据量小</p><p>B树 不支持范围查询，查询效率不稳定</p><p>B+树  最牛逼</p><h4 id="何为B-树？"><a href="#何为B-树？" class="headerlink" title="何为B+树？"></a>何为B+树？</h4><p>度（分叉数）为m的B+树每个节点能存储的记录数为m-1</p><p>所有的行数据都存在叶子结点，中间节点都是索引值，用来排序。</p><p>innodb的页默认大小为16KB，B+树的索引节点即为一页</p><p>那么一棵高度为2的B+数至少能存多少数据？</p><p>假设主键为自增的bigint类型，占8字节，B+树指针为6字节，一页能存放的索引数量是16KB/14B=1170</p><p>即至少有1170页即18MB存放行数据。而实际上这个这个值应该比计算出来的要大，原因是理论上一个叶节点中可能存放的记录数应该是1-1170行，但是1170是按照<u>主键大小+指针大小</u>计算出来的值，真正的行数据肯定还会有其他的字段，因此叶节点不能存放1170行数据是肯定的，那么多出来的行数据就会使用新的页进行存储并通过指针进行连接，这部分页并没有直接与B+树的中间节点连接，所以也无法进行精确计算。</p><p><a href="https://www.cs.usfca.edu/~galles/visualization/Algorithms.html" target="_blank" rel="noopener">数据结构可视化网站</a></p><h4 id="主键索引有三种情形"><a href="#主键索引有三种情形" class="headerlink" title="主键索引有三种情形"></a>主键索引有三种情形</h4><p>有primaryKey –使用主键组织数据存储</p><p>没有主键，存在unique字段– 使用该unique字段组织数据存储</p><p>没有主键，没有unique字段–使用隐藏字段_rowid组织数据</p><h4 id="使用索引的注意点"><a href="#使用索引的注意点" class="headerlink" title="使用索引的注意点"></a>使用索引的注意点</h4><p>回表查询：命中辅助索引后，根据辅助索引查询到的主键，再去主键索引中查询数据，称为回表</p><p>覆盖索引：组成联合索引的字段包含了所需查询的字段，查询到辅助索引页即可得到结果，无需回表查询</p><ol><li><p>为什么不建议使用Select * ？</p><p>阻止了覆盖索引生效，导致回表查询，使用指定列的sql能节省数据库内存占用，提高数据传输效率</p></li><li><p>索引的最左匹配原则是什么意思？</p><p>有联合索引 index(A,B,C)</p><p>查询时，使用A、A&amp;B 、A&amp;B&amp;C 查询都能命中该索引，且与字段顺序无关，即B&amp;A也能命中</p><p>A&amp;C  B&amp;C  B&amp;C  B  C  都不符合最左匹配原则，不能命中</p></li><li><p>模糊匹配可以用到索引吗？</p><p>like %abc 不能命中索引，like abc%可以命中</p><p>因此我们得出结论：前导模糊匹配不能命中索引</p></li><li><p>负向查询 !=  not in &lt;&gt; 能不能用到索引？</p><p>能不能用到索引是优化器决定的，优化器基于开销判断，一般不推荐使用负向查询</p></li><li><p>为什么推荐递增字段做主键索引？</p><p>InnoDB的索引底层是B+树，且通过主键索引来组织数据存储。如果使用自增主键，那么每次插入新的记录，就会顺序添加到当前索引节点的后续位置（右边），当写满一页就会开辟新页，这样就会形成一个近似顺序填满的紧凑结构，插入过程无需移动已有数据。</p><p>而如果使用uuid或者身份证号这种不规则的数据作为主键索引，那么插入数据时，相当于随机插入，导致已有数据频繁移动，磁盘io开销变大，且可能产生大量的叶碎片</p></li></ol><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>使用索引应注意以下几点：</p><ul><li>负向查询不能命中索引</li><li>前导模糊查询不能命中索引</li><li>数据区分度不大不宜建立索引</li><li>在属性上进行计算不能命中索引</li></ul><p>并非周知的sql实践：</p><ul><li>业务存在大量单条查询，实用hash索引效率高</li><li>允许为null的字段有大坑，单列索引不存null值，复合索引不存全为null的值，设置为not null 或者设置默认值</li><li>固定范围取值的字段使用枚举类型而不是字符串</li></ul><p>小众实用的规则：</p><ul><li>明确返回结果数量，实用limit能提升查询效率</li><li>把计算放到业务层而不是数据库层</li><li>强制类型转换会扫描全表</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;数据库索引是数据库管理系统中一个排序的&lt;strong&gt;数据结构&lt;/strong&gt;，以协助快速查询更新数据库表中数据&lt;/p&gt;
&lt;p&gt;索引类型：normal普通索引、unique唯一索引、全文索引&lt;/p&gt;
&lt;h4 id=&quot;索引用什么数据结构？&quot;&gt;&lt;a href=&quot;#索引用什么数
      
    
    </summary>
    
    
      <category term="数据库" scheme="http://yoursite.com/child/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>JVM-元空间</title>
    <link href="http://yoursite.com/child/2019/11/06/jvm-%E5%85%83%E7%A9%BA%E9%97%B4/"/>
    <id>http://yoursite.com/child/2019/11/06/jvm-元空间/</id>
    <published>2019-11-05T16:00:00.000Z</published>
    <updated>2020-03-13T07:29:29.824Z</updated>
    
    <content type="html"><![CDATA[<p>基础概念：</p><ol><li><p><strong>方法区：</strong>jvm规范中的定义，指一片内存区域，用于存放加载到内存中的类信息、常量池等。</p></li><li><p><strong>永久代：</strong>JDK1.7（含）之前方法区的实现方式，使用永久代实现主要是为了把GC分代收集扩展至方法区，省去了专门为方法区编写内存管理代码的工作。</p></li><li><p><strong>元空间：</strong>JDK1.8（含）之后的方法区实现。</p></li><li><p><strong>instanceKlass ：</strong>java类的运行时结构数据，就是常说的类元数据，jvm底层C++实现，java应用程序不能直接访问该对象，而是通过java.lang.Class类的实例间接访问该部分信息。xx.class对象是java程序访问xx类instanceKlass 数据的接口，且xx.class对象其实是存在堆里的。</p></li><li><p><strong>指针压缩</strong></p><ul><li>64位平台上默认打开</li><li>设置-XX:+UseCompressedOops压缩对象指针， <strong>oops</strong>指的是普通对象指针(ordinary object pointers)， 会被压缩成32位。</li><li>设置-XX:+UseCompressedClassPointers压缩类指针，会被压缩成32位。</li></ul></li><li><p><strong>类指针压缩空间</strong>（Compressed Class Pointer Space）：对于64位平台，为了压缩JVM对象中的_klass指针的大小，引入了类指针压缩空间。</p><ul><li>只有是64位平台上启用了类指针压缩才会存在这个区域。</li><li>类指针压缩空间会有一个基地址</li></ul></li></ol><h3 id="1-永久代被取代"><a href="#1-永久代被取代" class="headerlink" title="1. 永久代被取代"></a>1. 永久代被取代</h3><p>Permanent Generation space是指内存的永久保存区域，用于存放Class和Meta的信息，类在被加载的时候被放入PermGen space区域，它和存放对象的堆区域不同，所以应用程序会加载很多类的话，就很可能出现永久代溢出错误，这种错误常见在web服务器对jsp进行预编译的时候。</p><h4 id="1-1-为什么移除持久代"><a href="#1-1-为什么移除持久代" class="headerlink" title="1.1 为什么移除持久代"></a>1.1 为什么移除持久代</h4><ul><li>永久代空间大小是在启动时固定好的——运行时很难进行调优。-XX:MaxPermSize，设置成多少好呢？</li><li>HotSpot的内部类型也是Java对象：它可能会在Full GC中被移动，同时它对应用不透明，且是非强类型的，难以跟踪调试，还需要存储元数据的元数据信息（meta-metadata）。</li><li>简化Full GC：每一个回收器有专门的元数据迭代器。</li><li>可以在GC不进行暂停的情况下并发地释放类数据。</li><li>使得原来受限于持久代的一些改进未来有可能实现</li></ul><p>根据上面的各种原因，永久代最终被移除，<strong>方法区移至Metaspace，字符串常量移至Java Heap</strong>。</p><h4 id="1-2-移除持久代后，PermGen空间的状况"><a href="#1-2-移除持久代后，PermGen空间的状况" class="headerlink" title="1.2 移除持久代后，PermGen空间的状况"></a>1.2 移除持久代后，PermGen空间的状况</h4><ul><li>这部分内存空间将全部移除。</li><li>JVM的参数：-XX:PermSize 和-XX:MaxPermSize 会被忽略并给出警告（如果在启用时设置了这两个参数）。</li></ul><h3 id="2-元空间"><a href="#2-元空间" class="headerlink" title="2. 元空间"></a>2. 元空间</h3><p>随着JDK1.8的到来，JVM不再有PermGen。但类的元数据信息还在，只不过不再是存储在连续的堆空间上，而是移动到叫做“Metaspace”的本地内存（Native memory）中。</p><h4 id="2-1-Metaspace的组成"><a href="#2-1-Metaspace的组成" class="headerlink" title="2.1 Metaspace的组成"></a>2.1 Metaspace的组成</h4><ul><li><p><strong>Klass Metaspace</strong> </p><ul><li><p>这块内存最多只会存在一块，用来存 instanceKlass</p></li><li><p>这部分默认放在<strong>类指针压缩空间</strong>中，是一块连续的内存区域，和之前的perm一样紧接着Heap。通过<strong>-XX:CompressedClassSpaceSize</strong>来控制这块内存的大小，默认是1 G。</p></li></ul></li></ul><ul><li>但是这块内存不是必须的，如果设置了<strong>-XX:-UseCompressedClassPointers</strong>，或者<strong>-Xmx设置大于32 G</strong>，就不会有这块内存，这种情况下instanceKlass都会存在NoKlass Metaspace里。</li></ul><ul><li><p><strong>NoKlass Metaspace</strong>:</p><ul><li><p>用来存instanceKlass相关的其他的内容，比如method，constantPool等，这块内存是由多块内存组合起来的，所以可以认为是不连续的内存块组成的。</p></li><li><p>这块内存是必须的，虽然叫做NoKlass Metaspace，但是也其实可以存instanceKlass的内容，上面已经提到了对应场景。</p></li><li>NoKlass Metaspace在本地内存中分配。</li></ul></li></ul><p>Klass Metaspace和NoKlass Metaspace 都是所有class-loader共享的，所以类加载器们要分配内存，但是每个类加载器都有一个SpaceManager，来管理属于这个类加载的内存小块。如果Klass Metaspace用完了，那就会报OOM异常，不过一般情况下不会，NoKlass Metaspace是由一块块内存慢慢组合起来的，在没有达到限制条件的情况下，会不断加长这条链，让它可以持续工作。</p><h4 id="2-2-Metaspace的几个参数"><a href="#2-2-Metaspace的几个参数" class="headerlink" title="2.2 Metaspace的几个参数"></a>2.2 Metaspace的几个参数</h4><p>如果我们要改变Metaspace的一些行为，我们一般会对其相关的一些参数做调整，因为Metaspace的参数本身不是很多，所以我这里将涉及到的所有参数都做一个介绍。</p><ul><li><p>MetaspaceSize ：初始空间大小，达到该值就会触发垃圾收集进行类型卸载，同时GC会对该值进行调整：如果释放了大量的空间，就适当降低该值；如果释放了很少的空间，那么在不超过MaxMetaspaceSize时，适当提高该值。 </p></li><li><p>MaxMetaspaceSize ：最大空间，默认是没有限制的。 </p></li><li><p>MinMetaspaceFreeRatio ：在GC之后，最小的Metaspace剩余空间容量的百分比，减少为分配空间所导致的垃圾收集 </p></li><li><p>MaxMetaspaceFreeRatio ：在GC之后，最大的Metaspace剩余空间容量的百分比，减少为释放空间所导致的垃圾收集</p></li><li><p>CompressedClassSpaceSize ：默认1 G，这个参数主要是设置Klass Metaspace的大小，不过这个参数设置了也不一定起作用，前提是能开启压缩指针，假如-Xmx超过了32 G，压缩指针是开启不来的。如果有Klass Metaspace，那这块内存是和Heap连着的。</p></li><li><p>MinMetaspaceExpansion ：MinMetaspaceExpansion和MaxMetaspaceExpansion这两个参数或许和大家认识的并不一样，也许很多人会认为这两个参数不就是内存不够的时候，然后扩容的最小大小吗？其实不然</p><p>这两个参数和扩容其实并没有直接的关系，也就是并不是为了增大committed的内存，而是为了增大触发metaspace GC的阈值</p><p>这两个参数主要是在比较特殊的场景下救急使用，比如gcLocker或者<code>should_concurrent_collect</code>的一些场景，因为这些场景下接下来会做一次GC，相信在接下来的GC中可能会释放一些metaspace的内存，于是先临时扩大下metaspace触发GC的阈值，而有些内存分配失败其实正好是因为这个阈值触顶导致的，于是可以通过增大阈值暂时绕过去</p><p>默认332.8K，增大触发metaspace GC阈值的最小要求。假如我们要救急分配的内存很小，没有达到MinMetaspaceExpansion，但是我们会将这次触发metaspace GC的阈值提升MinMetaspaceExpansion，之所以要大于这次要分配的内存大小主要是为了防止别的线程也有类似的请求而频繁触发相关的操作，不过如果要分配的内存超过了MaxMetaspaceExpansion，那MinMetaspaceExpansion将会是要分配的内存大小基础上的一个增量</p></li><li><p>MaxMetaspaceExpansion ：默认5.2M，增大触发metaspace GC阈值的最大要求。假如说我们要分配的内存超过了MinMetaspaceExpansion但是低于MaxMetaspaceExpansion，那增量是MaxMetaspaceExpansion，如果超过了MaxMetaspaceExpansion，那增量是MinMetaspaceExpansion加上要分配的内存大小</p><p>注：每次分配只会给对应的线程一次扩展触发metaspace GC阈值的机会，如果扩展了，但是还不能分配，那就只能等着做GC了</p></li><li><p>UseLargePagesInMetaspace ：默认false，这个参数是说是否在metaspace里使用LargePage，一般情况下我们使用4 KB的page size，这个参数依赖于UseLargePages这个参数开启，不过这个参数我们一般不开。</p></li><li><p>InitialBootClassLoaderMetaspaceSize ：64位下默认4M，32位下默认2200K，metasapce前面已经提到主要分了两大块，Klass Metaspace以及NoKlass Metaspace，而NoKlass Metaspace是由一块块内存组合起来的，这个参数决定了NoKlass Metaspace的第一个内存Block的大小，即2*InitialBootClassLoaderMetaspaceSize，同时为bootstrapClassLoader的第一块内存chunk分配了InitialBootClassLoaderMetaspaceSize的大小</p></li></ul><h4 id="2-3-Metaspace内存管理"><a href="#2-3-Metaspace内存管理" class="headerlink" title="2.3  Metaspace内存管理"></a>2.3  Metaspace内存管理</h4><ol><li>在metaspace中，类和其元数据的生命周期与其对应的类加载器相同，只要类的类加载器是存活的，在Metaspace中的类元数据也是存活的，不能被回收。</li><li>每个加载器有单独的存储空间。</li><li>省掉了GC扫描及压缩的时间。</li><li>当GC发现某个类加载器不再存活了，会把对应的空间整个回收。</li></ol><p>参考文档：</p><p><a href="https://www.cnblogs.com/duanxz/p/3520829.html" target="_blank" rel="noopener">Metaspace 之一：Metaspace整体介绍（永久代被替换原因、元空间特点、元空间内存查看分析方法</a></p><p><a href="https://www.jianshu.com/p/92a5fbb33764" target="_blank" rel="noopener">JVM源码分析之Metaspace解密</a></p><p><a href="https://www.jianshu.com/p/1a0b4bf8d498" target="_blank" rel="noopener">JDK8 的FullGC 之 metaspace</a></p><p><a href="https://www.jianshu.com/p/a6f19189ec62" target="_blank" rel="noopener">JVM学习——元空间（Metaspace）</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;基础概念：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;方法区：&lt;/strong&gt;jvm规范中的定义，指一片内存区域，用于存放加载到内存中的类信息、常量池等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;永久代：&lt;/strong&gt;JDK1.7（含）之前方法区的实现
      
    
    </summary>
    
    
      <category term="JVM" scheme="http://yoursite.com/child/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>git-规范的commit message（转）</title>
    <link href="http://yoursite.com/child/2019/10/23/git-%E8%A7%84%E8%8C%83%E7%9A%84Commit%20Message/"/>
    <id>http://yoursite.com/child/2019/10/23/git-规范的Commit Message/</id>
    <published>2019-10-22T16:00:00.000Z</published>
    <updated>2019-11-08T12:55:43.084Z</updated>
    
    <content type="html"><![CDATA[<p>git上每次提交，Commit message 都包括三个部分：Header，Body 和 Footer。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">type</span>&gt;</span>(<span class="tag">&lt;<span class="name">scope</span>&gt;</span>): <span class="tag">&lt;<span class="name">subject</span>&gt;</span></span><br><span class="line">// 空一行</span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">// 空一行</span><br><span class="line"><span class="tag">&lt;<span class="name">footer</span>&gt;</span></span><br></pre></td></tr></table></figure><p>其中，Header 是必需的，Body 和 Footer 可以省略。</p><p>不管是哪一个部分，任何一行都不得超过72个字符（或100个字符）。这是为了避免自动换行影响美观。</p><h3 id="Header-必需"><a href="#Header-必需" class="headerlink" title="Header(必需)"></a>Header(必需)</h3><ul><li><p><strong>type(必需)</strong> 用于说明 commit 的类别</p><blockquote><ul><li>feat：新功能（feature）</li><li>fix：修补bug</li><li>docs：文档（documentation）</li><li>style： 格式（不影响代码运行的变动）</li><li>refactor：重构（即不是新增功能，也不是修改bug的代码变动）</li><li>test：增加测试</li><li>chore：构建过程或辅助工具的变动</li><li>revert：用于以前的 commit，则必须以<code>revert:</code>开头，后面跟着被撤销 Commit 的 Header。</li></ul></blockquote></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">revert: feat(pencil): add &apos;graphiteWidth&apos; option</span><br><span class="line"></span><br><span class="line">This reverts commit 667ecc1654a317a13331b17617d973392f415f02.</span><br></pre></td></tr></table></figure><p>Body部分的格式是固定的，必须写成<code>This reverts commit &amp;lt;hash&gt;.</code>，其中的<code>hash</code>是被撤销 commit 的 SHA 标识符。</p><p>如果当前 commit 与被撤销的 commit，在同一个发布（release）里面，那么它们都不会出现在 Change log 里面。如果两者在不同的发布，那么当前 commit，会出现在 Change log 的<code>Reverts</code>小标题下面。</p><p>如果<strong>type</strong>为<code>feat</code>和<code>fix</code>，则该 commit 将肯定出现在 Change log 之中。其他情况（<code>docs</code>、<code>chore</code>、<code>style</code>、<code>refactor</code>、<code>test</code>）由你决定，要不要放入 Change log，建议是不要。</p><p><strong>scope</strong> 用于说明 commit 影响的范围，比如数据层、控制层、视图层等等，视项目不同而不同。</p><p><strong>subject(必需)</strong> 是 commit 目的的简短描述，不超过50个字符。</p><blockquote><ul><li>以动词开头，使用第一人称现在时，比如<code>change</code>，而不是<code>changed</code>或<code>changes</code></li><li>第一个字母小写</li><li>结尾不加句号（<code>.</code>）</li></ul></blockquote><h3 id="Body"><a href="#Body" class="headerlink" title="Body"></a>Body</h3><p>Body 部分是对本次 commit 的详细描述，可以分成多行。</p><p>有两个注意点:</p><ul><li>使用第一人称现在时，比如使用<code>change</code>而不是<code>changed</code>或<code>changes</code>。</li><li>应该说明代码变动的动机，以及与以前行为的对比。</li></ul><h3 id="Footer"><a href="#Footer" class="headerlink" title="Footer"></a>Footer</h3><p>Footer 部分只用于两种情况。</p><ul><li><p><strong>不兼容变动</strong></p><p>如果当前代码与上一个版本不兼容，则 Footer 部分以<code>BREAKING CHANGE</code>开头，后面是对变动的描述、以及变动理由和迁移方法。</p></li><li><p><strong>关闭 Issue</strong></p><p>如果当前 commit 针对某个issue，那么可以在 Footer 部分关闭这个 issue 。</p><blockquote><p>Closes #234</p></blockquote><p>也可以一次关闭多个 issue 。</p><blockquote><p>Closes #123, #245, #992</p></blockquote></li></ul><p><a href="https://links.jianshu.com/go?to=http%3A%2F%2Fwww.ruanyifeng.com%2Fblog%2F2016%2F01%2Fcommit_message_change_log.html" target="_blank" rel="noopener">原文链接</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;git上每次提交，Commit message 都包括三个部分：Header，Body 和 Footer。&lt;/p&gt;
&lt;figure class=&quot;highlight xml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;l
      
    
    </summary>
    
    
      <category term="其他" scheme="http://yoursite.com/child/tags/%E5%85%B6%E4%BB%96/"/>
    
  </entry>
  
  <entry>
    <title>redis-缓存数据库双写一致性方案解析</title>
    <link href="http://yoursite.com/child/2019/09/02/redis-%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7/"/>
    <id>http://yoursite.com/child/2019/09/02/redis-缓存数据库双写一致性/</id>
    <published>2019-09-01T16:00:00.000Z</published>
    <updated>2019-09-04T07:03:07.000Z</updated>
    
    <content type="html"><![CDATA[<p>从理论上来说，设置过期时间是保证缓存数据库最终一致性的解决方案。在这种方案下，我们可以对存入缓存的数据设置过期时间，所有写操作以数据库为准，对缓存操作知识尽最大努力即可。也就是说如果数据库写成功，缓存更新失败，那么只要到达过期时间，后面的请求自然会从数据库中读取新值然后填回缓存。因此，接下来讨论的思路不依赖于给缓存设置过期时间这个方案。</p><p>本文讨论三种更新策略：</p><ul><li>先更新数据库，再更新缓存</li><li>先删除缓存，再更新数据库</li><li>先更新数据库，再删除缓存</li></ul><p>没有先更新缓存再更新数据库的方案，因为所有的写操作要以数据库为准，这种情况下若更新数据库失败，缓存失效后再次读数据库将取得旧值。</p><h3 id="1、先更新数据库，再更新缓存"><a href="#1、先更新数据库，再更新缓存" class="headerlink" title="1、先更新数据库，再更新缓存"></a>1、先更新数据库，再更新缓存</h3><p>该方案从<strong>线程安全角度</strong>看</p><p>假设同时有请求A和请求B进行更新操作，如下图所示的情况下最终数据库中的数据是B请求的数据，缓存中的数据数A请求的数据，最终出现了不一致的情况。这种情况因为网络情况等原因是可能出现的</p><p><img src="https://wx2.sinaimg.cn/large/87c9e458ly1g6nhtih33dj20fj05aq2v.jpg" alt="更更"></p><p>该方案从<strong>业务场景角度</strong>看</p><ol><li>如果是一个写多读少的场景，使用这种方案会导致数据压根没读到，缓存就被频繁的更新，浪费性能</li><li>如果写入db的值需要经过一系列复杂的计算再写入缓存，那么每次写入缓存前都需要计算缓存值，无疑是在浪费性能</li></ol><p>所以，更新缓存不可取，删除缓存更合适。</p><h3 id="2、先删除缓存，再更新数据库"><a href="#2、先删除缓存，再更新数据库" class="headerlink" title="2、先删除缓存，再更新数据库"></a>2、先删除缓存，再更新数据库</h3><p>首先看该方案会导致不一致的情况：</p><p><img src="https://ws1.sinaimg.cn/large/87c9e458ly1g6nhu1u8qjj20fs0663yi.jpg" alt="删更"></p><p>这种情况就会导致不一致的情形出现，而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。</p><p>那么，<strong>如何解决呢？</strong></p><p><strong>延时双删策略</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(String key,Object data)</span></span>&#123;</span><br><span class="line">        redis.delKey(key);</span><br><span class="line">        db.updateData(data);</span><br><span class="line">        Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">        redis.delKey(key);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>说明：<br>（1）先淘汰缓存<br>（2）再写数据库<br>（3）休眠1秒，再次淘汰缓存<br>这么做，可以将1秒内所造成的缓存脏数据，再次删除。<br><strong>那么，这个1秒怎么确定的，具体该休眠多久呢？</strong><br>针对上面的情形，读者应该自行评估自己的项目的读数据业务逻辑的耗时。然后写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百ms即可。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。</p><h3 id="3、先更新数据库，再删除缓存"><a href="#3、先更新数据库，再删除缓存" class="headerlink" title="3、先更新数据库，再删除缓存"></a>3、先更新数据库，再删除缓存</h3><p>首先，先说一下。老外提出了一个缓存更新套路，名为<a href="https://docs.microsoft.com/en-us/azure/architecture/patterns/cache-aside" target="_blank" rel="noopener">《Cache-Aside pattern》</a>。其中就指出</p><ul><li><strong>失效</strong>：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。</li><li><strong>命中</strong>：应用程序从cache中取数据，取到后返回。</li><li><strong>更新</strong>：先把数据存到数据库中，成功后，再让缓存失效。</li></ul><p>另外，知名社交网站facebook也在论文<a href="https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf" target="_blank" rel="noopener">《Scaling Memcache at Facebook》</a>中提出，他们用的也是先更新数据库，再删缓存的策略。</p><p><strong>这种情况不存在并发问题么？</strong><br>不是的。假设这会有两个请求，一个请求A做更新操作，一个请求B做查询操作，那么会有如下情形产生<br><img src="https://wx1.sinaimg.cn/large/87c9e458ly1g6nhuewolbj20fs066dfv.jpg" alt="更删"><br>如果发生上述情况，确实是会发生脏数据。</p><p><strong>然而，发生这种情况的必要条件是</strong><br>1、B读db时A还没有完成写db，这样B才能读到旧数据</p><p>2、A写db比B读db先完成，这样A才会在B更新缓存之前删缓存</p><p>因此只有在B请求读db成功但还没有更新缓存之前，A请求更新db结束并执行了删缓存操作，才有可能发生以上的情况，这个方案较第二种方案产生不一致的概率低很多。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;从理论上来说，设置过期时间是保证缓存数据库最终一致性的解决方案。在这种方案下，我们可以对存入缓存的数据设置过期时间，所有写操作以数据库为准，对缓存操作知识尽最大努力即可。也就是说如果数据库写成功，缓存更新失败，那么只要到达过期时间，后面的请求自然会从数据库中读取新值然后填回
      
    
    </summary>
    
    
      <category term="redis" scheme="http://yoursite.com/child/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis-总结精讲</title>
    <link href="http://yoursite.com/child/2019/09/02/reids-%E6%80%BB%E7%BB%93%E7%B2%BE%E8%AE%B2/"/>
    <id>http://yoursite.com/child/2019/09/02/reids-总结精讲/</id>
    <published>2019-09-01T16:00:00.000Z</published>
    <updated>2019-09-02T09:49:42.854Z</updated>
    
    <content type="html"><![CDATA[<p>本文围绕以下几个主题：</p><p>1、为什么使用redis<br>2、使用redis有什么缺点<br>3、单线程的redis为什么这么快<br>4、redis的数据类型，以及每种数据类型的使用场景<br>5、redis的过期策略以及内存淘汰机制<br>6、redis和数据库双写一致性问题<br>7、如何应对缓存穿透和缓存雪崩问题<br>8、如何解决redis的并发竞争问题</p><h3 id="1、为什么使用redis"><a href="#1、为什么使用redis" class="headerlink" title="1、为什么使用redis"></a>1、为什么使用redis</h3><p>在项目中使用redis，主要是从两个角度去考虑:<strong>性能</strong>和<strong>并发</strong>。当然redis还具备可以做分布式锁等其他功能，但是如果只是为了分布式锁这些其他功能，完全还有其他中间件(如zookpeer等)代替，并不是非要使用redis。因此，这个问题主要从性能和并发两个角度去答。</p><h4 id="1-1-性能"><a href="#1-1-性能" class="headerlink" title="1.1 性能"></a>1.1 性能</h4><p>如下图所示，我们在碰到需要执行耗时特别久，且结果不频繁变动的SQL，就特别适合将运行结果放入缓存。这样，后面的请求就去缓存中读取，使得请求能够<strong>迅速响应</strong>。</p><p><strong>题外话：</strong>忽然想聊一下这个<strong>迅速响应</strong>的标准。其实根据交互效果的不同，这个响应时间没有固定标准。不过曾经有人这么告诉我:”在理想状态下，我们的页面跳转需要在<strong>瞬间</strong>解决，对于页内操作则需要在<strong>刹那</strong>间解决。另外，超过<strong>一弹指</strong>的耗时操作要有进度提示，并且可以随时中止或取消，这样才能给用户最好的体验。”<br>那么<strong>瞬间、刹那、一弹指</strong>具体是多少时间呢？<br>根据《摩诃僧祗律》记载</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">一刹那者为一念，二十念为一瞬，二十瞬为一弹指，二十弹指为一罗预，二十罗预为一须臾，一日一夜有三十须臾。</span><br></pre></td></tr></table></figure><p>那么，经过周密的计算，一<strong>瞬间</strong>为0.36 秒,一<strong>刹那</strong>有 0.018 秒.一<strong>弹指</strong>长达 7.2 秒。</p><h4 id="1-2-并发"><a href="#1-2-并发" class="headerlink" title="1.2 并发"></a>1.2 并发</h4><p>在大并发的情况下，所有的请求直接访问数据库，数据库会出现连接异常。这个时候，就需要使用redis做一个缓冲操作，让请求先访问到redis，而不是直接访问数据库。</p><h3 id="2、使用redis有什么缺点"><a href="#2、使用redis有什么缺点" class="headerlink" title="2、使用redis有什么缺点"></a>2、使用redis有什么缺点</h3><p>基本上使用redis都会碰到一些问题，常见的也就几个。</p><ul><li>缓存和数据库双写一致性问题</li><li>缓存雪崩问题</li><li>缓存击穿问题</li><li>缓存的并发竞争问题</li></ul><p>这四个问题项目中比较常遇见，具体解决方案，后文给出。</p><h3 id="3、单线程的redis为什么这么快"><a href="#3、单线程的redis为什么这么快" class="headerlink" title="3、单线程的redis为什么这么快"></a>3、单线程的redis为什么这么快</h3><p>这个问题其实是对redis内部机制的一个考察，主要是以下三点</p><ul><li>纯内存操作</li><li>单线程操作，避免了频繁的上下文切换</li><li>采用了非阻塞<strong>I/O多路复用</strong></li></ul><h3 id="4、redis的数据类型，以及每种数据类型的使用场景"><a href="#4、redis的数据类型，以及每种数据类型的使用场景" class="headerlink" title="4、redis的数据类型，以及每种数据类型的使用场景"></a>4、redis的数据类型，以及每种数据类型的使用场景</h3><ol><li>String<br>这个其实没啥好说的，最常规的set/get操作，value可以是String也可以是数字。一般做<strong>一些复杂的计数功能的缓存。</strong></li><li>hash<br>这里value存放的是结构化的对象，比较方便的就是操作其中的某个字段。在做<strong>单点登录</strong>的时候，就是用这种数据结构存储用户信息，以cookieId作为key，设置30分钟为缓存过期时间，能很好的模拟出类似session的效果。</li><li>list<br>使用List的数据结构，可以<strong>做简单的消息队列的功能</strong>。另外还有一个就是，可以利用lrange命令，<strong>做基于redis的分页功能</strong>，性能极佳，用户体验好。</li><li>set<br>因为set堆放的是一堆不重复值的集合。所以可以做<strong>全局去重的功能</strong>。为什么不用JVM自带的Set进行去重？因为我们的系统一般都是集群部署，使用JVM自带的Set，比较麻烦，难道为了一个做一个全局去重，再起一个公共服务，太麻烦了。<br>另外，就是利用交集、并集、差集等操作，可以<strong>计算共同喜好，全部的喜好，自己独有的喜好等功能</strong>。</li><li>sorted set多了一个权重参数score,集合中的元素能够按score进行排列。可以做<strong>排行榜应用，取TOP N操作</strong>、<strong>延时任务</strong>、<strong>范围查找</strong>等。</li></ol><h3 id="5、redis的过期策略以及内存淘汰机制"><a href="#5、redis的过期策略以及内存淘汰机制" class="headerlink" title="5、redis的过期策略以及内存淘汰机制"></a>5、redis的过期策略以及内存淘汰机制</h3><p>redis采用的是<u><strong>定期删除+惰性删除</strong></u>策略。</p><h4 id="5-1-为什么不用定时删除策略"><a href="#5-1-为什么不用定时删除策略" class="headerlink" title="5.1 为什么不用定时删除策略"></a>5.1 为什么不用定时删除策略</h4><p>定时删除,用一个定时器来负责监视key,过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key,因此没有采用这一策略.</p><h4 id="5-2-定期删除-惰性删除是如何工作的"><a href="#5-2-定期删除-惰性删除是如何工作的" class="headerlink" title="5.2 定期删除+惰性删除是如何工作的"></a>5.2 定期删除+惰性删除是如何工作的</h4><p>定期删除，redis默认每个100ms检查，是否有过期的key,有过期key则删除。需要说明的是，redis不是每个100ms将所有的key检查一次，而是随机抽取进行检查(如果每隔100ms,全部key进行检查，redis岂不是卡死)。因此，如果只采用定期删除策略，会导致很多key到时间没有删除。<br>于是，惰性删除派上用场。也就是说在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除。</p><h4 id="5-2-定期删除-惰性删除的问题"><a href="#5-2-定期删除-惰性删除的问题" class="headerlink" title="5.2 定期删除+惰性删除的问题"></a>5.2 定期删除+惰性删除的问题</h4><p>如果定期删除没删除key。然后你也没即时去请求key，也就是说惰性删除也没生效。这样，redis的内存会越来越高。</p><p>解决方法：采用<strong>内存淘汰机制</strong>。<br>在redis.conf中有一行配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">maxmemory-policy volatile-lru</span><br></pre></td></tr></table></figure><p>该配置就是配内存淘汰策略的(什么，你没配过？好好反省一下自己)</p><ul><li>noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。<strong>不推荐</strong></li><li>allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。<strong>推荐使用</strong></li><li>allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。<strong>不推荐</strong></li><li>volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。<strong>这种情况一般是把redis既当缓存，又做持久化存储的时候才用。</strong></li><li>volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。<strong>不推荐</strong></li><li>volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。<strong>不推荐</strong></li></ul><h3 id="6、redis和数据库双写一致性问题"><a href="#6、redis和数据库双写一致性问题" class="headerlink" title="6、redis和数据库双写一致性问题"></a>6、redis和数据库双写一致性问题</h3><p> 一致性问题是分布式常见问题，还可以再分为最终一致性和强一致性。数据库和缓存双写，就必然会存在不一致的问题。答这个问题，先明白一个前提。就是<strong>如果对数据有强一致性要求，不能放缓存。</strong>我们所做的一切，只能保证最终一致性。另外，我们所做的方案其实从根本上来说，只能说<strong>降低不一致发生的概率</strong>，无法完全避免。因此，有强一致性要求的数据，不能放缓存。</p><p>首先，采取正确更新策略，<strong>先更新数据库，再删缓存</strong>。其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用消息队列。</p><h3 id="7、如何应对缓存穿透、缓存击穿和缓存雪崩问题"><a href="#7、如何应对缓存穿透、缓存击穿和缓存雪崩问题" class="headerlink" title="7、如何应对缓存穿透、缓存击穿和缓存雪崩问题"></a>7、如何应对缓存穿透、缓存击穿和缓存雪崩问题</h3><h4 id="7-1-缓存穿透"><a href="#7-1-缓存穿透" class="headerlink" title="7.1 缓存穿透"></a>7.1 缓存穿透</h4><p>缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求，如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大</p><p>解决方案：</p><ol><li>接口层增加校验，如用户鉴权校验，id做基础校验，id&lt;=0的直接拦截；</li><li>从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击</li></ol><h4 id="7-2-缓存击穿"><a href="#7-2-缓存击穿" class="headerlink" title="7.2 缓存击穿"></a>7.2 缓存击穿</h4><p>缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力</p><p>解决方案：</p><ol><li>设置热点数据永远不过期。</li><li>加互斥锁</li></ol><h4 id="7-3-缓存雪崩"><a href="#7-3-缓存雪崩" class="headerlink" title="7.3 缓存雪崩"></a>7.3 缓存雪崩</h4><p>缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是，        缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。</p><p>解决方案：</p><ol><li>缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。</li><li>如果缓存数据库是分布式部署，将热点数据均匀分布在不同的缓存数据库中。</li><li>设置热点数据永远不过期。</li></ol><h3 id="8、如何解决redis的并发竞争问题"><a href="#8、如何解决redis的并发竞争问题" class="headerlink" title="8、如何解决redis的并发竞争问题"></a>8、如何解决redis的并发竞争问题</h3><p>这个问题大致就是，同时有多个子系统去set一个key。这个时候要注意什么呢？大家思考过么。需要说明一下，博主提前百度了一下，发现答案基本都是推荐用redis事务机制。博主<strong>不推荐使用redis的事务机制。</strong>因为我们的生产环境，基本都是redis集群环境，做了数据分片操作。你一个事务中有涉及到多个key操作的时候，这多个key不一定都存储在同一个redis-server上。因此，<strong>redis的事务机制，十分鸡肋。</strong></p><ol><li>如果对这个key操作，<strong>不要求顺序</strong><br>这种情况下，准备一个分布式锁，大家去抢锁，抢到锁就做set操作即可，比较简单。</li><li>如果对这个key操作，<strong>要求顺序</strong><br>假设有一个key1,系统A需要将key1设置为valueA,系统B需要将key1设置为valueB,系统C需要将key1设置为valueC.<br>期望按照key1的value值按照 valueA–&gt;valueB–&gt;valueC的顺序变化。这种时候我们在数据写入数据库的时候，需要保存一个时间戳。假设时间戳如下</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">系统A key 1 &#123;valueA  3:00&#125;</span><br><span class="line">系统B key 1 &#123;valueB  3:05&#125;</span><br><span class="line">系统C key 1 &#123;valueC  3:10&#125;</span><br></pre></td></tr></table></figure><p>那么，假设系统B先抢到锁，将key1设置为{valueB 3:05}。接下来系统A抢到锁，发现自己的valueA的时间戳早于缓存中的时间戳，那就不做set操作了。以此类推。</p><p>其他方法，比如利用队列，将set方法变成串行访问也可以。总之，灵活变通。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文围绕以下几个主题：&lt;/p&gt;
&lt;p&gt;1、为什么使用redis&lt;br&gt;2、使用redis有什么缺点&lt;br&gt;3、单线程的redis为什么这么快&lt;br&gt;4、redis的数据类型，以及每种数据类型的使用场景&lt;br&gt;5、redis的过期策略以及内存淘汰机制&lt;br&gt;6、redis和数
      
    
    </summary>
    
    
      <category term="redis" scheme="http://yoursite.com/child/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis-键空间通知</title>
    <link href="http://yoursite.com/child/2019/08/02/redis-%E9%94%AE%E7%A9%BA%E9%97%B4%E9%80%9A%E7%9F%A5/"/>
    <id>http://yoursite.com/child/2019/08/02/redis-键空间通知/</id>
    <published>2019-08-01T16:00:00.000Z</published>
    <updated>2019-11-30T09:11:30.998Z</updated>
    
    <content type="html"><![CDATA[<p>需求：redis中缓存了一些状态量，业务需要时刻关注状态量变化</p><p>方案一：轮询检查（各方面性能太差）</p><p>方案二：redis提供的键空间通知机制（redis主动推送，优选）</p><h3 id="1、发布与订阅"><a href="#1、发布与订阅" class="headerlink" title="1、发布与订阅"></a>1、发布与订阅</h3><p><a href="http://doc.redisfans.com/pub_sub/subscribe.html#subscribe" target="_blank" rel="noopener"><em>SUBSCRIBE</em></a> /<a href="http://doc.redisfans.com/pub_sub/unsubscribe.html#unsubscribe" target="_blank" rel="noopener"><em>UNSUBSCRIBE</em></a>/<a href="http://doc.redisfans.com/pub_sub/publish.html#publish" target="_blank" rel="noopener"><em>PUBLISH</em></a> 三个命令实现了发布与订阅信息泛型（Publish/Subscribe messaging paradigm)，在这个实现中，发送者（发送信息的客户端）不是将信息直接发送给特定的接收者（接收信息的客户端），而是将信息发送给频道（channel），然后由频道将信息转发给所有对这个频道感兴趣的订阅者。</p><p>发送者无须知道任何关于订阅者的信息，而订阅者也无须知道是那个客户端给它发送信息，它只要关注自己感兴趣的频道即可。</p><p>对发布者和订阅者进行解构，可以极大地提高系统的扩展性，并得到一个更动态的网络拓扑。</p><p>比如说，要订阅频道<code>foo</code>和<code>bar</code>，客户端可以使用频道名字作为参数来调用 <em>SUBSCRIBE</em> 命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SUBSCRIBE foo bar</span><br></pre></td></tr></table></figure><p>当有客户端发送信息到这些频道时，Redis 会将传入的信息推送到所有订阅这些频道的客户端里面。</p><p>正在订阅频道的客户端不应该发送除 <em>SUBSCRIBE</em> 和 <em>UNSUBSCRIBE</em> 之外的其他命令。 其中，<em>SUBSCRIBE</em> 可以用于订阅更多频道，而 <em>UNSUBSCRIBE</em> 则可以用于退订已订阅的一个或多个频道。</p><p><em>SUBSCRIBE</em> 和 <em>UNSUBSCRIBE</em>的执行结果会以信息的形式返回，客户端可以通过分析所接收信息的第一个元素，从而判断所收到的内容是一条真正的信息，还是 <em>SUBSCRIBE</em> 或 <em>UNSUBSCRIBE</em> 命令的操作结果。</p><h4 id="1-1-信息格式"><a href="#1-1-信息格式" class="headerlink" title="1.1 信息格式"></a>1.1 信息格式</h4><p>频道转发的每条信息都是一条带有三个元素的多条批量回复。</p><ul><li><p>第一个元素标识了信息的类型，有以下三种类型：</p><ul><li>subscribe： 表示当前客户端成功地订阅了信息第二个元素所指示的频道，而此时信息的第三个元素则记录了目前客户端已订阅频道的总数。</li><li>unsubscribe： 表示当前客户端成功地退订了信息第二个元素所指示的频道，而此时信息的第三个元素记录了客户端目前仍在订阅的频道数量。 当客户端订阅的频道数量降为<code>0</code>时，客户端不再订阅任何频道，它可以像往常一样，执行任何 Redis 命令。</li><li>message： 表示这条信息是由某个客户端执行 <em>PUBLISH</em> 命令所发送的，真正的信息。 </li></ul></li><li><p>第二个元素是信息来源的频道。</p></li><li><p>第三个元素则是信息的内容。</p></li></ul><h4 id="1-2-订阅模式"><a href="#1-2-订阅模式" class="headerlink" title="1.2 订阅模式"></a>1.2 订阅模式</h4><p>Redis 的发布与订阅实现支持模式匹配： 客户端可以订阅一个带<code>*</code>号的模式，如果某些频道的名字和这个模式匹配，那么当有信息发送给这个/这些频道的时候，客户端也会收到这个/这些频道的信息。</p><p>比如说，执行命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PSUBSCRIBE news.*</span><br></pre></td></tr></table></figure><p>的客户端将收到来自<code>news.art.figurative</code>、<code>news.music.jazz</code>等频道的信息。</p><p>客户端订阅的模式里面可以包含多个 glob 风格的通配符，比如<code>*</code>、<code>?</code>和<code>[...]</code>，等等。</p><p>执行命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PUNSUBSCRIBE news.*</span><br></pre></td></tr></table></figure><p>将退订<code>news.*</code>模式，其他已订阅的模式不会被影响。</p><p>通过订阅模式接收到的信息，和通过订阅频道接收到的信息，两者的格式不太一样：</p><p>通过订阅模式而接收到的信息的类型为<code>pmessage</code>： 这代表有某个客户端通过 <em>PUBLISH</em> 向某个频道发送了信息，而这个频道刚好匹配了当前客户端所订阅的某个模式。 信息的第二个元素记录了被匹配的模式，第三个元素记录了被匹配的频道的名字，最后一个元素则记录了信息的实际内容。</p><p>客户端处理 <em>PSUBSCRIBE</em> 和 <em>PUNSUBSCRIBE</em> 返回值的方式，和客户端处理 <em>SUBSCRIBE</em> 和 <em>UNSUBSCRIBE</em> 的方式类似： 通过对信息的第一个元素进行分析，客户端可以判断接收到的信息是一个真正的信息，还是 <em>PSUBSCRIBE</em> 或 <em>PUNSUBSCRIBE</em> 命令的返回值。</p><h3 id="2、发布什么"><a href="#2、发布什么" class="headerlink" title="2、发布什么"></a>2、发布什么</h3><p>键空间通知使得客户端可以通过订阅频道或模式，来接收那些以某种方式改动了 Redis 数据集的事件。</p><p>以下是一些键空间通知发送的事件的例子：</p><ul><li>所有修改键的命令。</li><li>所有接收到 <em>LPUSH</em> 命令的键。</li><li><code>0</code>号数据库中所有已过期的键。</li></ul><p>事件通过 Redis 的订阅与发布功能（pub/sub）来进行分发，因此所有支持订阅与发布功能的客户端都可以在无须做任何修改的情况下，直接使用键空间通知功能。</p><p>因为 Redis 目前的订阅与发布功能采取的是发送即忘策略，所以如果你的程序需要可靠事件通知，那么目前的键空间通知可能并不适合你： 当订阅事件的客户端断线时，它会丢失所有在断线期间分发给它的事件。</p><p>未来将会支持更可靠的事件分发，这种支持可能会通过让订阅与发布功能本身变得更可靠来实现，也可能会在 Lua 脚本中对消息的订阅与发布进行监听，从而实现类似将事件推入到列表这样的操作。</p><h4 id="2-1-通知类型"><a href="#2-1-通知类型" class="headerlink" title="2.1 通知类型"></a>2.1 通知类型</h4><p>对于每个修改数据库的操作，键空间通知都会发送两种不同类型的事件。</p><p>比如说，对<code>0</code>号数据库的键<code>mykey</code>执行 <em>DEL</em> 命令时，系统将分发两条消息，相当于执行以下两个 <em>PUBLISH</em> 命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PUBLISH __keyspace@0__:mykey del</span><br><span class="line">PUBLISH __keyevent@0__:del mykey</span><br></pre></td></tr></table></figure><p>订阅第一个频道<code>__keyspace@0__:mykey</code>可以接收<code>0</code>号数据库中所有修改键<code>mykey</code>的事件，而订阅第二个频道<code>__keyevent@0__:del</code>则可以接收<code>0</code>号数据库中所有执行<code>del</code>命令的键。</p><p>以<code>keyspace</code>为前缀的频道被称为<strong>键空间通知</strong>，而以<code>keyevent</code>为前缀的频道则被称为<strong>键事件通知</strong>。</p><p>当<code>del mykey</code>命令执行时：</p><ul><li>键空间频道的订阅者将接收到被执行的事件的名字，在这个例子中，就是<code>del</code>。</li><li>键事件频道的订阅者将接收到被执行事件的键的名字，在这个例子中，就是<code>mykey</code>。</li></ul><h4 id="2-2-配置"><a href="#2-2-配置" class="headerlink" title="2.2 配置"></a>2.2 配置</h4><p>因为开启键空间通知功能需要消耗一些 CPU ，所以在默认配置下，该功能处于关闭状态。</p><p>可以通过修改<code>redis.conf</code>文件（<strong>重启生效且一直有效</strong>），或者直接使用<code>CONFIG SET</code>命令（<strong>立即生效且重启失效</strong>）来开启或关闭键空间通知功能：</p><ul><li>当<code>notify-keyspace-events</code>选项的参数为空字符串时，功能关闭。</li><li>另一方面，当参数不是空字符串时，功能开启。</li></ul><p><code>notify-keyspace-events</code>的参数可以是以下字符的任意组合，它指定了服务器该发送哪些类型的通知：</p><table><thead><tr><th style="text-align:left">字符</th><th style="text-align:left">发送的通知</th></tr></thead><tbody><tr><td style="text-align:left"><code>K</code></td><td style="text-align:left">键空间通知，所有通知以<code>__keyspace@&lt;db&gt;__</code>为前缀</td></tr><tr><td style="text-align:left"><code>E</code></td><td style="text-align:left">键事件通知，所有通知以<code>__keyevent@&lt;db&gt;__</code>为前缀</td></tr><tr><td style="text-align:left"><code>g</code></td><td style="text-align:left"><code>DEL</code>、<code>EXPIRE</code>、<code>RENAME</code>等类型无关的通用命令的通知</td></tr><tr><td style="text-align:left"><code>$</code></td><td style="text-align:left">字符串命令的通知</td></tr><tr><td style="text-align:left"><code>l</code></td><td style="text-align:left">列表命令的通知</td></tr><tr><td style="text-align:left"><code>s</code></td><td style="text-align:left">集合命令的通知</td></tr><tr><td style="text-align:left"><code>h</code></td><td style="text-align:left">哈希命令的通知</td></tr><tr><td style="text-align:left"><code>z</code></td><td style="text-align:left">有序集合命令的通知</td></tr><tr><td style="text-align:left"><code>x</code></td><td style="text-align:left">过期事件：每当有过期键被删除时发送</td></tr><tr><td style="text-align:left"><code>e</code></td><td style="text-align:left">驱逐(evict)事件：每当有键因为<code>maxmemory</code>政策而被删除时发送</td></tr><tr><td style="text-align:left"><code>A</code></td><td style="text-align:left">参数<code>g$lshzxe</code>的别名</td></tr></tbody></table><p>输入的参数中至少要有一个<code>K</code>或者<code>E</code>，否则的话，不管其余的参数是什么，都不会有任何通知被分发。</p><p>举个例子，如果只想订阅键空间中和列表相关的通知，那么参数就应该设为<code>Kl</code>，诸如此类。</p><p>将参数设为字符串<code>&quot;AKE&quot;</code>表示发送所有类型的通知。</p><h4 id="2-3-过期通知的发送时间"><a href="#2-3-过期通知的发送时间" class="headerlink" title="2.3 过期通知的发送时间"></a>2.3 过期通知的发送时间</h4><p>我们已经了解了redis的键过期机制为 定期删除 + 惰性删除：</p><ul><li>当一个键被访问时，程序会对这个键进行检查，如果键已经过期，那么该键将被删除。</li><li>底层系统会在后台渐进地查找并删除那些过期的键，从而处理那些已经过期、但是不会被访问到的键。</li></ul><p>当过期键被以上两个程序的任意一个发现、 并且将键从数据库中删除时，Redis 会产生一个<code>expired</code>通知。</p><p>Redis 并不保证生存时间（TTL）变为<code>0</code>的键会立即被删除： 如果程序没有访问这个过期键，或者带有生存时间的键非常多的话，那么在键的生存时间变为<code>0</code>，直到键真正被删除这中间，可能会有一段比较显著的时间间隔。</p><p>因此，Redis 产生<code>expired</code>通知的时间为过期键被删除的时候，而不是键的生存时间变为<code>0</code>的时候。命令产生的通知</p><h4 id="附录："><a href="#附录：" class="headerlink" title="附录："></a>附录：</h4><p>以下列表记录了不同命令所产生的不同通知：</p><ul><li><a href="http://doc.redisfans.com/key/del.html#del" target="_blank" rel="noopener"><em>DEL</em></a> 命令为每个被删除的键产生一个<code>del</code>通知。</li><li><a href="http://doc.redisfans.com/key/rename.html#rename" target="_blank" rel="noopener"><em>RENAME</em></a> 产生两个通知：为来源键（source key）产生一个<code>rename_from</code>通知，并为目标键（destination key）产生一个<code>rename_to</code>通知。</li><li><a href="http://doc.redisfans.com/key/expire.html#expire" target="_blank" rel="noopener"><em>EXPIRE</em></a> 和 <a href="http://doc.redisfans.com/key/expireat.html#expireat" target="_blank" rel="noopener"><em>EXPIREAT</em></a> 在键被正确设置过期时间时产生一个<code>expire</code>通知。当 <a href="http://doc.redisfans.com/key/expireat.html#expireat" target="_blank" rel="noopener"><em>EXPIREAT</em></a> 设置的时间已经过期，或者 <a href="http://doc.redisfans.com/key/expire.html#expire" target="_blank" rel="noopener"><em>EXPIRE</em></a> 传入的时间为负数值时，键被删除，并产生一个<code>del</code>通知。</li><li>每当一个键因为过期而被删除时，产生一个<code>expired</code>通知。</li><li><a href="http://doc.redisfans.com/key/sort.html#sort" target="_blank" rel="noopener"><em>SORT</em></a> 在命令带有<code>STORE</code>参数时产生一个<code>sortstore</code>事件。如果<code>STORE</code>指示的用于保存排序结果的键已经存在，那么程序还会发送一个<code>del</code>事件。</li><li><a href="http://doc.redisfans.com/string/set.html#set" target="_blank" rel="noopener"><em>SET</em></a> 以及它的所有变种（<a href="http://doc.redisfans.com/string/setex.html#setex" target="_blank" rel="noopener"><em>SETEX</em></a> 、 <a href="http://doc.redisfans.com/string/setnx.html#setnx" target="_blank" rel="noopener"><em>SETNX</em></a> 和 <a href="http://doc.redisfans.com/string/getset.html#getset" target="_blank" rel="noopener"><em>GETSET</em></a>）都产生<code>set</code>通知。其中 <a href="http://doc.redisfans.com/string/setex.html#setex" target="_blank" rel="noopener"><em>SETEX</em></a> 还会产生<code>expire</code>通知。</li><li><a href="http://doc.redisfans.com/string/mset.html#mset" target="_blank" rel="noopener"><em>MSET</em></a> 为每个键产生一个<code>set</code>通知。</li><li><a href="http://doc.redisfans.com/string/setrange.html#setrange" target="_blank" rel="noopener"><em>SETRANGE</em></a> 产生一个<code>setrange</code>通知。</li><li><a href="http://doc.redisfans.com/string/incr.html#incr" target="_blank" rel="noopener"><em>INCR</em></a> 、 <a href="http://doc.redisfans.com/string/decr.html#decr" target="_blank" rel="noopener"><em>DECR</em></a> 、 <a href="http://doc.redisfans.com/string/incrby.html#incrby" target="_blank" rel="noopener"><em>INCRBY</em></a> 和 <a href="http://doc.redisfans.com/string/decrby.html#decrby" target="_blank" rel="noopener"><em>DECRBY</em></a> 都产生<code>incrby</code>通知。</li><li><a href="http://doc.redisfans.com/string/incrbyfloat.html#incrbyfloat" target="_blank" rel="noopener"><em>INCRBYFLOAT</em></a> 产生<code>incrbyfloat</code>通知。</li><li><a href="http://doc.redisfans.com/string/append.html#append" target="_blank" rel="noopener"><em>APPEND</em></a> 产生<code>append</code>通知。</li><li><a href="http://doc.redisfans.com/list/lpush.html#lpush" target="_blank" rel="noopener"><em>LPUSH</em></a> 和 <a href="http://doc.redisfans.com/list/lpushx.html#lpushx" target="_blank" rel="noopener"><em>LPUSHX</em></a> 都产生单个<code>lpush</code>通知，即使有多个输入元素时，也是如此。</li><li><a href="http://doc.redisfans.com/list/rpush.html#rpush" target="_blank" rel="noopener"><em>RPUSH</em></a> 和 <a href="http://doc.redisfans.com/list/rpushx.html#rpushx" target="_blank" rel="noopener"><em>RPUSHX</em></a> 都产生单个<code>rpush</code>通知，即使有多个输入元素时，也是如此。</li><li><a href="http://doc.redisfans.com/list/rpop.html#rpop" target="_blank" rel="noopener"><em>RPOP</em></a> 产生<code>rpop</code>通知。如果被弹出的元素是列表的最后一个元素，那么还会产生一个<code>del</code>通知。</li><li><a href="http://doc.redisfans.com/list/lpop.html#lpop" target="_blank" rel="noopener"><em>LPOP</em></a> 产生<code>lpop</code>通知。如果被弹出的元素是列表的最后一个元素，那么还会产生一个<code>del</code>通知。</li><li><a href="http://doc.redisfans.com/list/linsert.html#linsert" target="_blank" rel="noopener"><em>LINSERT</em></a> 产生一个<code>linsert</code>通知。</li><li><a href="http://doc.redisfans.com/list/lset.html#lset" target="_blank" rel="noopener"><em>LSET</em></a> 产生一个<code>lset</code>通知。</li><li><a href="http://doc.redisfans.com/list/ltrim.html#ltrim" target="_blank" rel="noopener"><em>LTRIM</em></a> 产生一个<code>ltrim</code>通知。如果 <a href="http://doc.redisfans.com/list/ltrim.html#ltrim" target="_blank" rel="noopener"><em>LTRIM</em></a> 执行之后，列表键被清空，那么还会产生一个<code>del</code>通知。</li><li><a href="http://doc.redisfans.com/list/rpoplpush.html#rpoplpush" target="_blank" rel="noopener"><em>RPOPLPUSH</em></a> 和 <a href="http://doc.redisfans.com/list/brpoplpush.html#brpoplpush" target="_blank" rel="noopener"><em>BRPOPLPUSH</em></a> 产生一个<code>rpop</code>通知，以及一个<code>lpush</code>通知。两个命令都会保证<code>rpop</code>的通知在<code>lpush</code>的通知之前分发。如果从键弹出元素之后，被弹出的列表键被清空，那么还会产生一个<code>del</code>通知。</li><li><a href="http://doc.redisfans.com/hash/hset.html#hset" target="_blank" rel="noopener"><em>HSET</em></a> 、 <a href="http://doc.redisfans.com/hash/hsetnx.html#hsetnx" target="_blank" rel="noopener"><em>HSETNX</em></a> 和 <a href="http://doc.redisfans.com/hash/hmset.html#hmset" target="_blank" rel="noopener"><em>HMSET</em></a> 都只产生一个<code>hset</code>通知。</li><li><a href="http://doc.redisfans.com/hash/hincrby.html#hincrby" target="_blank" rel="noopener"><em>HINCRBY</em></a> 产生一个<code>hincrby</code>通知。</li><li><a href="http://doc.redisfans.com/hash/hincrbyfloat.html#hincrbyfloat" target="_blank" rel="noopener"><em>HINCRBYFLOAT</em></a> 产生一个<code>hincrbyfloat</code>通知。</li><li><a href="http://doc.redisfans.com/hash/hdel.html#hdel" target="_blank" rel="noopener"><em>HDEL</em></a> 产生一个<code>hdel</code>通知。如果执行 <a href="http://doc.redisfans.com/hash/hdel.html#hdel" target="_blank" rel="noopener"><em>HDEL</em></a> 之后，哈希键被清空，那么还会产生一个<code>del</code>通知。</li><li><a href="http://doc.redisfans.com/set/sadd.html#sadd" target="_blank" rel="noopener"><em>SADD</em></a> 产生一个<code>sadd</code>通知，即使有多个输入元素时，也是如此。</li><li><a href="http://doc.redisfans.com/set/srem.html#srem" target="_blank" rel="noopener"><em>SREM</em></a> 产生一个<code>srem</code>通知，如果执行 <a href="http://doc.redisfans.com/set/srem.html#srem" target="_blank" rel="noopener"><em>SREM</em></a> 之后，集合键被清空，那么还会产生一个<code>del</code>通知。</li><li><a href="http://doc.redisfans.com/set/smove.html#smove" target="_blank" rel="noopener"><em>SMOVE</em></a> 为来源键（source key）产生一个<code>srem</code>通知，并为目标键（destination key）产生一个<code>sadd</code>事件。</li><li><a href="http://doc.redisfans.com/set/spop.html#spop" target="_blank" rel="noopener"><em>SPOP</em></a> 产生一个<code>spop</code>事件。如果执行 <a href="http://doc.redisfans.com/set/spop.html#spop" target="_blank" rel="noopener"><em>SPOP</em></a> 之后，集合键被清空，那么还会产生一个<code>del</code>通知。</li><li><a href="http://doc.redisfans.com/set/sinterstore.html#sinterstore" target="_blank" rel="noopener"><em>SINTERSTORE</em></a> 、 <a href="http://doc.redisfans.com/set/sunionstore.html#sunionstore" target="_blank" rel="noopener"><em>SUNIONSTORE</em></a> 和 <a href="http://doc.redisfans.com/set/sdiffstore.html#sdiffstore" target="_blank" rel="noopener"><em>SDIFFSTORE</em></a> 分别产生<code>sinterstore</code>、<code>sunionostore</code>和<code>sdiffstore</code>三种通知。如果用于保存结果的键已经存在，那么还会产生一个<code>del</code>通知。</li><li><a href="http://doc.redisfans.com/sorted_set/zincrby.html#zincrby" target="_blank" rel="noopener"><em>ZINCRBY</em></a> 产生一个<code>zincr</code>通知。（译注：非对称，请注意。）</li><li><a href="http://doc.redisfans.com/sorted_set/zadd.html#zadd" target="_blank" rel="noopener"><em>ZADD</em></a> 产生一个<code>zadd</code>通知，即使有多个输入元素时，也是如此。</li><li><a href="http://doc.redisfans.com/sorted_set/zrem.html#zrem" target="_blank" rel="noopener"><em>ZREM</em></a> 产生一个<code>zrem</code>通知，即使有多个输入元素时，也是如此。如果执行 <a href="http://doc.redisfans.com/sorted_set/zrem.html#zrem" target="_blank" rel="noopener"><em>ZREM</em></a> 之后，有序集合键被清空，那么还会产生一个<code>del</code>通知。</li><li><a href="http://doc.redisfans.com/sorted_set/zremrangebyscore.html#zremrangebyscore" target="_blank" rel="noopener"><em>ZREMRANGEBYSCORE</em></a> 产生一个<code>zrembyscore</code>通知。（译注：非对称，请注意。）如果用于保存结果的键已经存在，那么还会产生一个<code>del</code>通知。</li><li><a href="http://doc.redisfans.com/sorted_set/zremrangebyrank.html#zremrangebyrank" target="_blank" rel="noopener"><em>ZREMRANGEBYRANK</em></a> 产生一个<code>zrembyrank</code>通知。（译注：非对称，请注意。）如果用于保存结果的键已经存在，那么还会产生一个<code>del</code>通知。</li><li><a href="http://doc.redisfans.com/sorted_set/zinterstore.html#zinterstore" target="_blank" rel="noopener"><em>ZINTERSTORE</em></a> 和 <a href="http://doc.redisfans.com/sorted_set/zunionstore.html#zunionstore" target="_blank" rel="noopener"><em>ZUNIONSTORE</em></a> 分别产生<code>zinterstore</code>和<code>zunionstore</code>两种通知。如果用于保存结果的键已经存在，那么还会产生一个<code>del</code>通知。</li><li>每当一个键因为<code>maxmemory</code>政策而被删除以回收内存时，产生一个<code>evicted</code>通知。</li></ul><p>所有命令都只在键<strong>真的</strong>被改动了之后，才会产生通知。</p><p>比如说，当 <a href="http://doc.redisfans.com/set/srem.html#srem" target="_blank" rel="noopener"><em>SREM</em></a> 试图删除不存在于集合的元素时，删除操作会执行失败，因为没有真正的改动键，所以这一操作不会发送通知。</p><p>如果对命令所产生的通知有疑问，最好还是使用以下命令，自己来验证一下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ redis-cli config set notify-keyspace-events KEA</span><br><span class="line">$ redis-cli --csv psubscribe &apos;__key*__:*&apos;</span><br><span class="line">Reading messages... (press Ctrl-C to quit)</span><br><span class="line">&quot;psubscribe&quot;,&quot;__key*__:*&quot;,1</span><br></pre></td></tr></table></figure><p>然后，只要在其他终端里用 Redis 客户端发送命令，就可以看到产生的通知了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&quot;pmessage&quot;,&quot;__key*__:*&quot;,&quot;__keyspace@0__:foo&quot;,&quot;set&quot;</span><br><span class="line">&quot;pmessage&quot;,&quot;__key*__:*&quot;,&quot;__keyevent@0__:set&quot;,&quot;foo&quot;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;需求：redis中缓存了一些状态量，业务需要时刻关注状态量变化&lt;/p&gt;
&lt;p&gt;方案一：轮询检查（各方面性能太差）&lt;/p&gt;
&lt;p&gt;方案二：redis提供的键空间通知机制（redis主动推送，优选）&lt;/p&gt;
&lt;h3 id=&quot;1、发布与订阅&quot;&gt;&lt;a href=&quot;#1、发布与订阅&quot;
      
    
    </summary>
    
    
      <category term="redis" scheme="http://yoursite.com/child/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis-数据持久化配置</title>
    <link href="http://yoursite.com/child/2019/08/01/redis-%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96%E9%85%8D%E7%BD%AE/"/>
    <id>http://yoursite.com/child/2019/08/01/redis-数据持久化配置/</id>
    <published>2019-07-31T16:00:00.000Z</published>
    <updated>2019-08-19T13:41:41.779Z</updated>
    
    <content type="html"><![CDATA[<p>redis的数据持久化功能默认是没有开启的，当我们kill掉redis-server进程并重启后，此前所有的缓存数据都会丢失，所以为了防止redis服务器宕机而造成数据丢失，我们应该打开redis的数据持久化功能。</p><p>redis持久化方式有两种：RDB 和 AOF，本文将围绕这两种持久化方式展开。</p><h3 id="1、持久化原理"><a href="#1、持久化原理" class="headerlink" title="1、持久化原理"></a>1、持久化原理</h3><ul><li>RDB的原理是生成当前数据集的快照文件dump.rdb，当服务器宕机重启后，服务器会根据该备份文件恢复数据，备份的是数据。</li><li>AOF的原理是维护一个数据写入日志（aof文件），在服务器执行写入命令的时候，在aof文件尾部添加命令。服务器宕机重启后，自动执行aof文件中的数据写入命令恢复数据。</li></ul><h3 id="2、运行过程"><a href="#2、运行过程" class="headerlink" title="2、运行过程"></a>2、运行过程</h3><h4 id="2-1-RDB方式"><a href="#2-1-RDB方式" class="headerlink" title="2.1 RDB方式"></a>2.1 RDB方式</h4><p>当 Redis 需要保存 <code>dump.rdb</code> 文件时， 服务器执行以下操作：</p><ol><li>Redis 调用 <code>fork()</code> ，同时拥有父进程和子进程。</li><li>子进程将数据集写入到一个临时 RDB 文件中。</li><li>当子进程完成对新 RDB 文件的写入时，Redis 用新 RDB 文件替换原来的 RDB 文件，并删除旧的 RDB 文件。</li></ol><h4 id="2-2-AOF方式"><a href="#2-2-AOF方式" class="headerlink" title="2.2 AOF方式"></a>2.2 AOF方式</h4><p>每当 Redis 执行一个改变数据集的命令时（比如 <strong>SET</strong>、<strong>INCR</strong>）， 这个命令就会被追加到 AOF 文件的末尾， 当 Redis 重新启时， 程序就可以通过重新执行 AOF 文件中的命令来达到重建数据集的目的。</p><h5 id="AOF重写"><a href="#AOF重写" class="headerlink" title="AOF重写"></a>AOF重写</h5><p>举个例子， 如果你对一个计数器调用了 100 次<strong>INCR</strong> ， 那么仅仅是为了保存这个计数器的当前值， AOF 文件就需要使用 100 条记录。</p><p>然而在实际上， 只使用一条 <strong>SET</strong> 命令已经足以保存计数器的当前值了， 其余 99 条记录实际上都是多余的。</p><p>为了处理这种情况， Redis 支持一种有趣的特性： 可以在不打断服务客户端的情况下， 对 AOF 文件进行重建（rebuild）。</p><p>执行 <a href="http://doc.redisfans.com/server/bgrewriteaof.html#bgrewriteaof" target="_blank" rel="noopener"><em>BGREWRITEAOF</em></a> 命令， Redis 将生成一个新的 AOF 文件， 这个文件包含重建当前数据集所需的最少命令。</p><p>Redis 2.2 需要自己手动执行 <a href="http://doc.redisfans.com/server/bgrewriteaof.html#bgrewriteaof" target="_blank" rel="noopener"><em>BGREWRITEAOF</em></a> 命令； Redis 2.4 则可以自动触发 AOF 重写， 具体信息请查看 2.4 的示例配置文件。</p><h5 id="重写过程"><a href="#重写过程" class="headerlink" title="重写过程"></a>重写过程</h5><p>AOF 重写和 RDB 创建快照一样，都巧妙地利用了copy-on-write机制。</p><ol><li>Redis 执行 <code>fork()</code> ，现在同时拥有父进程和子进程。</li><li>子进程开始将新 AOF 文件的内容写入到临时文件。</li><li>对于所有新执行的写入命令，父进程一边将它们累积到一个内存缓存中，一边将这些改动追加到现有 AOF 文件的末尾： 这样即使在重写的中途发生停机，现有的 AOF 文件也还是安全的。</li><li>当子进程完成重写工作时，它给父进程发送一个信号，父进程在接收到信号之后，将内存缓存中的所有数据追加到新 AOF 文件的末尾。</li><li>现在 Redis 原子地用新文件替换旧文件，之后所有命令都会直接追加到新 AOF 文件的末尾。</li></ol><h3 id="3、优劣势对比"><a href="#3、优劣势对比" class="headerlink" title="3、优劣势对比"></a>3、优劣势对比</h3><table><thead><tr><th style="text-align:center">RDB</th><th style="text-align:center">AOF</th></tr></thead><tbody><tr><td style="text-align:center"><strong>备份策略灵活多样可配置</strong></td><td style="text-align:center"><em>只有三种持久化策略</em></td></tr><tr><td style="text-align:center"><strong>rdb文件内容紧凑，适合灾难恢复</strong></td><td style="text-align:center">-</td></tr><tr><td style="text-align:center"><strong>备份过程不影响redis性能</strong></td><td style="text-align:center"><em>持久化策略决定是否影响redis性能</em></td></tr><tr><td style="text-align:center"><strong>大数据集恢复速度快</strong></td><td style="text-align:center"><em>大数据量恢复速度较慢</em></td></tr><tr><td style="text-align:center"><em>可靠性地，丢失数据概率高</em></td><td style="text-align:center"><strong>持久化可靠性高，丢失数据概率低</strong></td></tr><tr><td style="text-align:center"><em>rdb文件不可读</em></td><td style="text-align:center"><strong>aof文件可读性高，易于分析</strong></td></tr><tr><td style="text-align:center"><em>每次生成快照都需要操作整个数据集</em></td><td style="text-align:center"><strong>aof文件只需要进行追加操作</strong></td></tr></tbody></table><p>总结来说：</p><p>RDB方式备份时费劲，恢复时很给力，持久化可靠性低；AOF方式备份简单，恢复时稍费力，持久化可靠性高。具体使用哪种方式，需要根据具体业务场景进行选择。</p><h3 id="4、配置方式"><a href="#4、配置方式" class="headerlink" title="4、配置方式"></a>4、配置方式</h3><h4 id="4-1-RDB配置"><a href="#4-1-RDB配置" class="headerlink" title="4.1 RDB配置"></a>4.1 RDB配置</h4><h5 id="手动触发"><a href="#手动触发" class="headerlink" title="手动触发"></a>手动触发</h5><p>RDB通过手动执行命令<strong>SAVE</strong>或者<strong>BGSAVE</strong>生成快照文件，SAVE会阻塞服务器进程直到成功生成备份，不推荐使用；使用BGSAVE，服务器进程会fork一个子进程，异步执行备份，此过程服务器只有在fork()的时候阻塞。</p><h5 id="自动触发-配置文件"><a href="#自动触发-配置文件" class="headerlink" title="自动触发(配置文件)"></a>自动触发(配置文件)</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 停用rdb</span><br><span class="line"><span class="meta">#</span>save ""</span><br><span class="line">save 900 1 #表示900 秒内如果至少有 1 个 key 的值变化，则保存</span><br><span class="line">save 300 10 #表示300 秒内如果至少有 10 个 key 的值变化，则保存</span><br><span class="line">save 60 10000 #表示60 秒内如果至少有 10000 个 key 的值变化，则保存</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>当启用了RDB且最后一次后台保存数据失败，Redis是否停止接收数据，默认yes</span><br><span class="line">stop-writes-on-bgsave-error yes</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>对于存储到磁盘中的快照，可以设置是否采用LZF进行压缩存储，默认yes</span><br><span class="line">rdbcompression yes</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>在存储快照后，我们还可以让redis使用CRC64算法来进行数据校验</span><br><span class="line"><span class="meta">#</span>但是这样做会增加大约10%的性能消耗，默认yes</span><br><span class="line">rdbchecksum yes</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>设置快照的文件名，默认是 dump.rdb</span><br><span class="line">dbfilename dump.rdb</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>设置快照文件的存放路径，这个配置项一定是个目录，而不能是文件名</span><br><span class="line">dir /var/redis/6379</span><br></pre></td></tr></table></figure><h4 id="4-2-AOF配置"><a href="#4-2-AOF配置" class="headerlink" title="4.2 AOF配置"></a>4.2 AOF配置</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 开启aof</span><br><span class="line">appendonly yes</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> aof文件名称</span><br><span class="line">appendfilename "appendonly.aof"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 三种持久化策略</span><br><span class="line"><span class="meta">#</span> appendfsync always  # 每次修改数据集都会追加一次</span><br><span class="line">appendfsync everysec  # 每1秒追加一次 </span><br><span class="line"><span class="meta">#</span> appendfsync no  # 交给系统控制，linux 系统是30秒</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> If you have latency problems turn this to "yes". Otherwise leave it as</span><br><span class="line"><span class="meta">#</span> "no" that is the safest pick from the point of view of durability.</span><br><span class="line">no-appendfsync-on-rewrite no</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 当aof文件增长量达到100%，自动重写（设为0则永不重写）</span><br><span class="line">auto-aof-rewrite-percentage 100</span><br><span class="line"><span class="meta">#</span> 当aof文件小于这个值，不会自动重写</span><br><span class="line">auto-aof-rewrite-min-size 64mb</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> </span><br><span class="line">aof-load-truncated yes</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> </span><br><span class="line">aof-use-rdb-preamble no</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;redis的数据持久化功能默认是没有开启的，当我们kill掉redis-server进程并重启后，此前所有的缓存数据都会丢失，所以为了防止redis服务器宕机而造成数据丢失，我们应该打开redis的数据持久化功能。&lt;/p&gt;
&lt;p&gt;redis持久化方式有两种：RDB 和 AO
      
    
    </summary>
    
    
      <category term="redis" scheme="http://yoursite.com/child/tags/redis/"/>
    
  </entry>
  
</feed>
