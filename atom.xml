<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>黑风雅过吟</title>
  
  <subtitle>不积跬步无以至千里</subtitle>
  <link href="/zzkenyon.github.io/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/child/"/>
  <updated>2020-04-26T07:38:52.295Z</updated>
  <id>http://yoursite.com/child/</id>
  
  <author>
    <name>Zhao Zhengkang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>nio-epoll高效运行原理</title>
    <link href="http://yoursite.com/child/2020/04/26/nio-epoll%E9%AB%98%E6%95%88%E8%BF%90%E8%A1%8C%E5%8E%9F%E7%90%86/"/>
    <id>http://yoursite.com/child/2020/04/26/nio-epoll高效运行原理/</id>
    <published>2020-04-25T16:00:00.000Z</published>
    <updated>2020-04-26T07:38:52.295Z</updated>
    
    <content type="html"><![CDATA[<p>开始的疑问</p><p>1、epoll是基于事件的，那么有哪些事件，事件由谁来触发？</p><p>2、jdk nio是怎么和epoll实现对接的？</p><p>带着这两个疑问，查阅了网上一些文章，大概能解答以上两点疑惑</p><p>链接：<a href="https://baijiahao.baidu.com/s?id=1641172494287388070&amp;wfr=spider&amp;for=pc" target="_blank" rel="noopener">彻底搞懂epoll高效运行的原理</a></p><p>epoll是一种I/O事件通知机制，是linux 内核实现IO多路复用的一个实现。</p><p>IO多路复用是指，在一个操作里同时监听多个输入输出源，在其中一个或多个输入输出源可用的时候返回，然后对其的进行读写操作。</p><p><strong>事件</strong></p><p>可读事件，当文件描述符关联的内核读缓冲区可读，则触发可读事件。(可读：内核缓冲区非空，有数据可以读取)可写事件，当文件描述符关联的内核写缓冲区可写，则触发可写事件。(可写：内核缓冲区不满，有空闲空间可以写入）</p><p>epoll的通俗解释是一种当文件描述符的内核缓冲区非空的时候，发出可读信号通知，当写缓冲区不满的时候，发出可写信号通知的机制</p><h4 id="epoll的API"><a href="#epoll的API" class="headerlink" title="epoll的API"></a>epoll的API</h4><p>epoll的核心是3个API，核心数据结构是：1个红黑树和1个链表</p><p><img src="https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/rpc/epoll%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86.png" alt="epoll"></p><p><strong>1. int epoll_create(int size);</strong><br>创建一个epoll对象，返回对象的句柄，后面两个操作都已该句柄为核心。</p><p>参数size用来表示要监听的fd数量的最大值，之后版本的Linux已弃用该参数。</p><p><strong>2.int epoll_ctl(int epfd, int op, int fd, struct epoll_event* event);</strong><br>epoll的事件注册接口，负责将被监听的描述符添加到红黑树或从红黑树中删除或者对监听事件进行修改。<br>参数 epfd 表示epoll对象句柄；<br>参数 op 表示动作，用三个宏来表示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">EPOLL_CTL_ADD <span class="comment">//注册新的fd到epfd中；</span></span><br><span class="line">EPOLL_CTL_MOD <span class="comment">//修改已经注册的fd的监听事件；</span></span><br><span class="line">EPOLL_CTL_DEL <span class="comment">//从epfd中删除一个fd；</span></span><br></pre></td></tr></table></figure><p>参数 fd 是需要监听的fd</p><p>参数 event 表示此次注册的事件，struct epoll_event结构如下：</p><p>data域是唯一能给出描述符信息的字段，所以在调用epoll_ctl加入一个需要监测的描述符时，一定要在此域写入描述符相关信息；events域是bit mask，描述一组epoll事件，在epoll_ctl调用中解释为：描述符所期望的epoll事件，可多选。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">表示某个fd上某事件被触发了</span></span><br><span class="line"><span class="comment">**/</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">epoll_event</span> &#123;</span></span><br><span class="line">    <span class="keyword">__uint32_t</span> events; <span class="comment">// 在被监测的文件描述符上实际发生的事件。</span></span><br><span class="line">    <span class="keyword">epoll_data_t</span> data; </span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">union</span> epoll_data &#123;</span><br><span class="line">    <span class="keyword">void</span> *ptr; <span class="comment">// 指向用户自定义数据 </span></span><br><span class="line">    <span class="keyword">int</span> fd; <span class="comment">//注册的文件描述符</span></span><br><span class="line">    <span class="keyword">__uint32_t</span> u32; <span class="comment">//32-bit integer</span></span><br><span class="line">    <span class="keyword">__uint64_t</span> u64; <span class="comment">//64-bit integer</span></span><br><span class="line">&#125; <span class="keyword">epoll_data_t</span>;</span><br></pre></td></tr></table></figure><p>常用的epoll事件</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">EPOLLIN <span class="comment">//表示对应的文件描述符可以读（包括对端SOCKET正常关闭）</span></span><br><span class="line">EPOLLOUT <span class="comment">//表示对应的文件描述符可以写</span></span><br><span class="line">EPOLLET <span class="comment">//将 EPOLL设为边缘触发</span></span><br><span class="line">EPOLLONESHOT <span class="comment">//第一次进行通知，之后不再监测</span></span><br><span class="line">EPOLLPRI <span class="comment">//由带外数据触发</span></span><br><span class="line">EPOLLERR <span class="comment">//描述符产生错误时触发，默认检测事件</span></span><br><span class="line">EPOLLHUP <span class="comment">//本端描述符产生一个挂断事件，默认监测事件</span></span><br><span class="line">EPOLLRDHUP <span class="comment">//对端描述符产生一个挂断事件</span></span><br></pre></td></tr></table></figure><h4 id="epoll的两种触发方式"><a href="#epoll的两种触发方式" class="headerlink" title="epoll的两种触发方式"></a>epoll的两种触发方式</h4><p>epoll监控多个文件描述符的I/O事件。epoll支持边缘触发(edge trigger，ET)或水平触发（level trigger，LT)，通过epoll_wait等待I/O事件，如果当前没有可用的事件则阻塞调用线程。</p><p>select和poll只支持LT工作模式，epoll的默认的工作模式是LT模式。</p><p><strong>1.水平触发的时机</strong></p><p>对于读操作，只要缓冲内容不为空，LT模式返回读就绪。对于写操作，只要缓冲区还不满，LT模式会返回写就绪。当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。如果这次没有把数据一次性全部读写完(如读写缓冲区太小)，那么下次调用 epoll_wait()时，它还会通知你在上没读写完的文件描述符上继续读写，当然如果你一直不去读写，它会一直通知你。如果系统中有大量你不需要读写的就绪文件描述符，而它们每次都会返回，这样会大大降低处理程序检索自己关心的就绪文件描述符的效率。</p><p><strong>2.边缘触发的时机</strong></p><p>对于读操作当缓冲区由不可读变为可读的时候，即缓冲区由空变为不空的时候。当有新数据到达时，即缓冲区中的待读数据变多的时候。当缓冲区有数据可读，且应用进程对相应的描述符进行EPOLL_CTL_MOD 修改EPOLLIN事件时。对于写操作当缓冲区由不可写变为可写时。当有旧数据被发送走，即缓冲区中的内容变少的时候。当缓冲区有空间可写，且应用进程对相应的描述符进行EPOLL_CTL_MOD 修改EPOLLOUT事件时。当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。如果这次没有把数据全部读写完(如读写缓冲区太小)，那么下次调用epoll_wait()时，它不会通知你，也就是它只会通知你一次，直到该文件描述符上出现第二次可读写事件才会通知你。这种模式比水平触发效率高，系统不会充斥大量你不关心的就绪文件描述符。</p><p>在ET模式下， 缓冲区从不可读变成可读，会唤醒应用进程，缓冲区数据变少的情况，则不会再唤醒应用进程。</p><p>举例1：</p><p>读缓冲区刚开始是空的读缓冲区写入2KB数据水平触发和边缘触发模式此时都会发出可读信号收到信号通知后，读取了1KB的数据，读缓冲区还剩余1KB数据水平触发会再次进行通知，而边缘触发不会再进行通知</p><p>举例2：（以脉冲的高低电平为例）</p><p>水平触发：0为无数据，1为有数据。缓冲区有数据则一直为1，则一直触发。边缘触发发：0为无数据，1为有数据，只要在0变到1的上升沿才触发。JDK并没有实现边缘触发，Netty重新实现了epoll机制，采用边缘触发方式；另外像Nginx也采用边缘触发。</p><p>JDK在Linux已经默认使用epoll方式，但是JDK的epoll采用的是水平触发，而Netty重新实现了epoll机制，采用边缘触发方式，netty epoll transport 暴露了更多的nio没有的配置参数，如 TCP_CORK, SO_REUSEADDR等等；另外像Nginx也采用边缘触发。</p><h4 id="epoll与select、poll的对比"><a href="#epoll与select、poll的对比" class="headerlink" title="epoll与select、poll的对比"></a>epoll与select、poll的对比</h4><p><strong>1. 用户态将文件描述符传入内核的方式</strong></p><p>select：创建3个文件描述符集并拷贝到内核中，分别监听读、写、异常动作。这里受到单个进程可以打开的fd数量限制，默认是1024。poll：将传入的struct pollfd结构体数组拷贝到内核中进行监听。epoll：执行epoll_create会在内核的高速cache区中建立一颗红黑树以及就绪链表(该链表存储已经就绪的文件描述符)。接着用户执行的epoll_ctl函数添加文件描述符会在红黑树上增加相应的结点。</p><p><strong>2. 内核态检测文件描述符读写状态的方式</strong></p><p>select：采用轮询方式，遍历所有fd，最后返回一个描述符读写操作是否就绪的mask掩码，根据这个掩码给fd_set赋值。poll：同样采用轮询方式，查询每个fd的状态，如果就绪则在等待队列中加入一项并继续遍历。epoll：采用回调机制。在执行epoll_ctl的add操作时，不仅将文件描述符放到红黑树上，而且也注册了回调函数，内核在检测到某文件描述符可读/可写时会调用回调函数，该回调函数将文件描述符放在就绪链表中。</p><p><strong>3. 找到就绪的文件描述符并传递给用户态的方式</strong></p><p>select：将之前传入的fd_set拷贝传出到用户态并返回就绪的文件描述符总数。用户态并不知道是哪些文件描述符处于就绪态，需要遍历来判断。poll：将之前传入的fd数组拷贝传出用户态并返回就绪的文件描述符总数。用户态并不知道是哪些文件描述符处于就绪态，需要遍历来判断。epoll：epoll_wait只用观察就绪链表中有无数据即可，最后将链表的数据返回给数组并返回就绪的数量。内核将就绪的文件描述符放在传入的数组中，所以只用遍历依次处理即可。这里返回的文件描述符是通过mmap让内核和用户空间共享同一块内存实现传递的，减少了不必要的拷贝。</p><p><strong>4. 重复监听的处理方式</strong></p><p>select：将新的监听文件描述符集合拷贝传入内核中，继续以上步骤。poll：将新的struct pollfd结构体数组拷贝传入内核中，继续以上步骤。epoll：无需重新构建红黑树，直接沿用已存在的即可。</p><p><strong>epoll更高效的原因</strong></p><p>select和poll的动作基本一致，只是poll采用链表来进行文件描述符的存储，而select采用fd标注位来存放，所以select会受到最大连接数的限制，而poll不会。select、poll、epoll虽然都会返回就绪的文件描述符数量。但是select和poll并不会明确指出是哪些文件描述符就绪，而epoll会。造成的区别就是，系统调用返回后，调用select和poll的程序需要遍历监听的整个文件描述符找到是谁处于就绪，而epoll则直接处理即可。select、poll都需要将有关文件描述符的数据结构拷贝进内核，最后再拷贝出来。而epoll创建的有关文件描述符的数据结构本身就存于内核态中，系统调用返回时利用mmap()文件映射内存加速与内核空间的消息传递：即epoll使用mmap减少复制开销。select、poll采用轮询的方式来检查文件描述符是否处于就绪态，而epoll采用回调机制。造成的结果就是，随着fd的增加，select和poll的效率会线性降低，而epoll不会受到太大影响，除非活跃的socket很多。epoll的边缘触发模式效率高，系统不会充斥大量不关心的就绪文件描述符虽然epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;开始的疑问&lt;/p&gt;
&lt;p&gt;1、epoll是基于事件的，那么有哪些事件，事件由谁来触发？&lt;/p&gt;
&lt;p&gt;2、jdk nio是怎么和epoll实现对接的？&lt;/p&gt;
&lt;p&gt;带着这两个疑问，查阅了网上一些文章，大概能解答以上两点疑惑&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https
      
    
    </summary>
    
    
      <category term="nio" scheme="http://yoursite.com/child/tags/nio/"/>
    
  </entry>
  
  <entry>
    <title>CSRF攻击与防御（转）</title>
    <link href="http://yoursite.com/child/2020/04/14/%E5%85%B6%E4%BB%96-CSRF%E6%94%BB%E5%87%BB%E4%B8%8E%E9%98%B2%E5%BE%A1/"/>
    <id>http://yoursite.com/child/2020/04/14/其他-CSRF攻击与防御/</id>
    <published>2020-04-13T16:00:00.000Z</published>
    <updated>2020-05-07T08:56:48.207Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://www.phpddt.com/reprint/csrf.html" target="_blank" rel="noopener">转载地址</a></p><p><strong>CSRF概念：</strong>CSRF跨站点请求伪造(Cross—Site Request Forgery)，跟XSS攻击一样，存在巨大的危害性，你可以这样来理解：攻击者盗用了你的身份，以你的名义发送恶意请求，对服务器来说这个请求是完全合法的，但是却完成了攻击者所期望的一个操作，比如以你的名义发送邮件、发消息，盗取你的账号，添加系统管理员，甚至于购买商品、虚拟货币转账等。 如下：其中Web A为存在CSRF漏洞的网站，Web B为攻击者构建的恶意网站，User C为Web A网站的合法用户。</p><h4 id="CSRF攻击攻击原理及过程如下："><a href="#CSRF攻击攻击原理及过程如下：" class="headerlink" title="CSRF攻击攻击原理及过程如下："></a>CSRF攻击攻击原理及过程如下：</h4><ol><li><p>用户C打开浏览器，访问受信任网站A，输入用户名和密码请求登录网站A；</p></li><li><p>在用户信息通过验证后，网站A产生Cookie信息并返回给浏览器，此时用户登录网站A成功，可以正常发送请求到网站A；</p></li><li><p>用户未退出网站A之前，在同一浏览器中，打开一个TAB页访问网站B；</p></li><li><p>网站B接收到用户请求后，返回一些攻击性代码，并发出一个请求要求访问第三方站点A；</p></li><li><p>浏览器在接收到这些攻击性代码后，根据网站B的请求，在用户不知情的情况下携带Cookie信息，向网站A发出请求。网站A并不知道该请求其实是由B发起的，所以会根据用户C的Cookie信息以C的权限处理该请求，导致来自网站B的恶意代码被执行。 </p></li></ol><h4 id="CSRF攻击实例"><a href="#CSRF攻击实例" class="headerlink" title="CSRF攻击实例"></a>CSRF攻击实例</h4><p>受害者 Bob 在银行有一笔存款，通过对银行的网站发送请求 <a href="http://bank.example/withdraw?account=bob&amp;amount=1000000&amp;for=bob2" target="_blank" rel="noopener">http://bank.example/withdraw?account=bob&amp;amount=1000000&amp;for=bob2</a> 可以使 Bob 把 1000000 的存款转到 bob2 的账号下。通常情况下，该请求发送到网站后，服务器会先验证该请求是否来自一个合法的 session，并且该 session 的用户 Bob 已经成功登陆。</p><p>黑客 Mallory 自己在该银行也有账户，他知道上文中的 URL 可以把钱进行转帐操作。Mallory 可以自己发送一个请求给银行：<a href="http://bank.example/withdraw?account=bob&amp;amount=1000000&amp;for=Mallory。但是这个请求来自" target="_blank" rel="noopener">http://bank.example/withdraw?account=bob&amp;amount=1000000&amp;for=Mallory。但是这个请求来自</a> Mallory 而非 Bob，他不能通过安全认证，因此该请求不会起作用。</p><p>这时，Mallory 想到使用 CSRF 的攻击方式，他先自己做一个网站，在网站中放入如下代码： src=”<a href="http://bank.example/withdraw?account=bob&amp;amount=1000000&amp;for=Mallory" target="_blank" rel="noopener">http://bank.example/withdraw?account=bob&amp;amount=1000000&amp;for=Mallory</a> ”，并且通过广告等诱使 Bob 来访问他的网站。当 Bob 访问该网站时，上述 url 就会从 Bob 的浏览器发向银行，而这个请求会附带 Bob 浏览器中的 cookie 一起发向银行服务器。大多数情况下，该请求会失败，因为他要求 Bob 的认证信息。但是，如果 Bob 当时恰巧刚访问他的银行后不久，他的浏览器与银行网站之间的 session 尚未过期，浏览器的 cookie 之中含有 Bob 的认证信息。这时，悲剧发生了，这个 url 请求就会得到响应，钱将从 Bob 的账号转移到 Mallory 的账号，而 Bob 当时毫不知情。等以后 Bob 发现账户钱少了，即使他去银行查询日志，他也只能发现确实有一个来自于他本人的合法请求转移了资金，没有任何被攻击的痕迹。而 Mallory 则可以拿到钱后逍遥法外。 </p><h4 id="CSRF漏洞检测："><a href="#CSRF漏洞检测：" class="headerlink" title="CSRF漏洞检测："></a>CSRF漏洞检测：</h4><p>检测CSRF漏洞是一项比较繁琐的工作，最简单的方法就是抓取一个正常请求的数据包，去掉Referer字段后再重新提交，如果该提交还有效，那么基本上可以确定存在CSRF漏洞。</p><p>随着对CSRF漏洞研究的不断深入，不断涌现出一些专门针对CSRF漏洞进行检测的工具，如CSRFTester，CSRF Request Builder等。</p><p>以CSRFTester工具为例，CSRF漏洞检测工具的测试原理如下：使用CSRFTester进行测试时，首先需要抓取我们在浏览器中访问过的所有链接以及所有的表单等信息，然后通过在CSRFTester中修改相应的表单等信息，重新提交，这相当于一次伪造客户端请求。如果修改后的测试请求成功被网站服务器接受，则说明存在CSRF漏洞，当然此款工具也可以被用来进行CSRF攻击。</p><h4 id="防御CSRF攻击："><a href="#防御CSRF攻击：" class="headerlink" title="防御CSRF攻击："></a>防御CSRF攻击：</h4><h4 id="（1）验证-HTTP-Referer-字段"><a href="#（1）验证-HTTP-Referer-字段" class="headerlink" title="（1）验证 HTTP Referer 字段"></a>（1）验证 HTTP Referer 字段</h4><p>根据 HTTP 协议，在 HTTP 头中有一个字段叫 Referer，它记录了该 HTTP 请求的来源地址。在通常情况下，访问一个安全受限页面的请求来自于同一个网站，比如需要访问 <a href="http://bank.example/withdraw?account=bob&amp;amount=1000000&amp;for=Mallory，用户必须先登陆" target="_blank" rel="noopener">http://bank.example/withdraw?account=bob&amp;amount=1000000&amp;for=Mallory，用户必须先登陆</a> bank.example，然后通过点击页面上的按钮来触发转账事件。这时，该转帐请求的 Referer 值就会是转账按钮所在的页面的 URL，通常是以 bank.example 域名开头的地址。而如果黑客要对银行网站实施 CSRF 攻击，他只能在他自己的网站构造请求，当用户通过黑客的网站发送请求到银行时，该请求的 Referer 是指向黑客自己的网站。因此，要防御 CSRF 攻击，银行网站只需要对于每一个转账请求验证其 Referer 值，如果是以 bank.example 开头的域名，则说明该请求是来自银行网站自己的请求，是合法的。如果 Referer 是其他网站的话，则有可能是黑客的 CSRF 攻击，拒绝该请求。</p><p>这种方法的显而易见的好处就是简单易行，网站的普通开发人员不需要操心 CSRF 的漏洞，只需要在最后给所有安全敏感的请求统一增加一个拦截器来检查 Referer 的值就可以。特别是对于当前现有的系统，不需要改变当前系统的任何已有代码和逻辑，没有风险，非常便捷。</p><p>然而，这种方法并非万无一失。Referer 的值是由浏览器提供的，虽然 HTTP 协议上有明确的要求，但是每个浏览器对于 Referer 的具体实现可能有差别，并不能保证浏览器自身没有安全漏洞。使用验证 Referer 值的方法，就是把安全性都依赖于第三方（即浏览器）来保障，从理论上来讲，这样并不安全。事实上，对于某些浏览器，比如 IE6 或 FF2，目前已经有一些方法可以篡改 Referer 值。如果 bank.example 网站支持 IE6 浏览器，黑客完全可以把用户浏览器的 Referer 值设为以 bank.example 域名开头的地址，这样就可以通过验证，从而进行 CSRF 攻击。</p><p>即便是使用最新的浏览器，黑客无法篡改 Referer 值，这种方法仍然有问题。因为 Referer 值会记录下用户的访问来源，有些用户认为这样会侵犯到他们自己的隐私权，特别是有些组织担心 Referer 值会把组织内网中的某些信息泄露到外网中。因此，用户自己可以设置浏览器使其在发送请求时不再提供 Referer。当他们正常访问银行网站时，网站会因为请求没有 Referer 值而认为是 CSRF 攻击，拒绝合法用户的访问。</p><h4 id="（2）在请求地址中添加-token-并验证"><a href="#（2）在请求地址中添加-token-并验证" class="headerlink" title="（2）在请求地址中添加 token 并验证"></a>（2）在请求地址中添加 token 并验证</h4><p>CSRF 攻击之所以能够成功，是因为黑客可以完全伪造用户的请求，该请求中所有的用户验证信息都是存在于 cookie 中，因此黑客可以在不知道这些验证信息的情况下直接利用用户自己的 cookie 来通过安全验证。要抵御 CSRF，关键在于在请求中放入黑客所不能伪造的信息，并且该信息不存在于 cookie 之中。可以在 HTTP 请求中以参数的形式加入一个随机产生的 token，并在服务器端建立一个拦截器来验证这个 token，如果请求中没有 token 或者 token 内容不正确，则认为可能是 CSRF 攻击而拒绝该请求。</p><p>这种方法要比检查 Referer 要安全一些，token 可以在用户登陆后产生并放于 session 之中，然后在每次请求时把 token 从 session 中拿出，与请求中的 token 进行比对，但这种方法的难点在于如何把 token 以参数的形式加入请求。对于 GET 请求，token 将附在请求地址之后，这样 URL 就变成 <a href="http://url?csrftoken=tokenvalue。" target="_blank" rel="noopener">http://url?csrftoken=tokenvalue。</a> 而对于 POST 请求来说，要在 form 的最后加上 <input type="hidden" name="csrftoken" value="tokenvalue">，这样就把 token 以参数的形式加入请求了。但是，在一个网站中，可以接受请求的地方非常多，要对于每一个请求都加上 token 是很麻烦的，并且很容易漏掉，通常使用的方法就是在每次页面加载时，使用 javascript 遍历整个 dom 树，对于 dom 中所有的 a 和 form 标签后加入 token。这样可以解决大部分的请求，但是对于在页面加载之后动态生成的 html 代码，这种方法就没有作用，还需要程序员在编码时手动添加 token。</p><p>该方法还有一个缺点是难以保证 token 本身的安全。特别是在一些论坛之类支持用户自己发表内容的网站，黑客可以在上面发布自己个人网站的地址。由于系统也会在这个地址后面加上 token，黑客可以在自己的网站上得到这个 token，并马上就可以发动 CSRF 攻击。为了避免这一点，系统可以在添加 token 的时候增加一个判断，如果这个链接是链到自己本站的，就在后面添加 token，如果是通向外网则不加。不过，即使这个 csrftoken 不以参数的形式附加在请求之中，黑客的网站也同样可以通过 Referer 来得到这个 token 值以发动 CSRF 攻击。这也是一些用户喜欢手动关闭浏览器 Referer 功能的原因。</p><h4 id="（3）在-HTTP-头中自定义属性并验证"><a href="#（3）在-HTTP-头中自定义属性并验证" class="headerlink" title="（3）在 HTTP 头中自定义属性并验证"></a>（3）在 HTTP 头中自定义属性并验证</h4><p>这种方法也是使用 token 并进行验证，和上一种方法不同的是，这里并不是把 token 以参数的形式置于 HTTP 请求之中，而是把它放到 HTTP 头中自定义的属性里。通过 XMLHttpRequest 这个类，可以一次性给所有该类请求加上 csrftoken 这个 HTTP 头属性，并把 token 值放入其中。这样解决了上种方法在请求中加入 token 的不便，同时，通过 XMLHttpRequest 请求的地址不会被记录到浏览器的地址栏，也不用担心 token 会透过 Referer 泄露到其他网站中去。</p><p>然而这种方法的局限性非常大。XMLHttpRequest 请求通常用于 Ajax 方法中对于页面局部的异步刷新，并非所有的请求都适合用这个类来发起，而且通过该类请求得到的页面不能被浏览器所记录下，从而进行前进，后退，刷新，收藏等操作，给用户带来不便。另外，对于没有进行 CSRF 防护的遗留系统来说，要采用这种方法来进行防护，要把所有请求都改为 XMLHttpRequest 请求，这样几乎是要重写整个网站，这代价无疑是不能接受的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;http://www.phpddt.com/reprint/csrf.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;转载地址&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CSRF概念：&lt;/strong&gt;CSRF跨站点请求伪造(Cros
      
    
    </summary>
    
    
      <category term="其他" scheme="http://yoursite.com/child/tags/%E5%85%B6%E4%BB%96/"/>
    
  </entry>
  
  <entry>
    <title>ELK日志系统</title>
    <link href="http://yoursite.com/child/2020/04/07/%E5%88%86%E5%B8%83%E5%BC%8F-%E6%97%A5%E5%BF%97%E4%B8%8A%E4%BC%A0es/"/>
    <id>http://yoursite.com/child/2020/04/07/分布式-日志上传es/</id>
    <published>2020-04-06T16:00:00.000Z</published>
    <updated>2020-05-07T08:45:23.060Z</updated>
    
    <content type="html"><![CDATA[<h4 id="ElasticSearch部署"><a href="#ElasticSearch部署" class="headerlink" title="ElasticSearch部署"></a>ElasticSearch部署</h4><p>下载解压改配置文件/config/elasticsearch.yml</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">cluster.name:</span> <span class="string">my-application</span></span><br><span class="line"><span class="string">node.name:</span> <span class="string">node-1</span></span><br><span class="line"><span class="string">network.host:</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line"><span class="string">http.port:</span> <span class="number">9200</span></span><br><span class="line"><span class="string">cluster.initial_master_nodes:</span> <span class="string">["node-1"]</span></span><br></pre></td></tr></table></figure><p>启动es命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/app/elasticSearch</span><br><span class="line"><span class="comment">#后台启动</span></span><br><span class="line">./bin/elasticksearch -d</span><br></pre></td></tr></table></figure><h4 id="Kibana部署"><a href="#Kibana部署" class="headerlink" title="Kibana部署"></a>Kibana部署</h4><p>下载解压改配置文件/config/kibana.yml：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">port:</span> <span class="number">5601</span></span><br><span class="line"><span class="string">server.host:</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line"><span class="string">elasticsearch.hosts:</span> <span class="string">["ip:port","ip:port"]</span></span><br></pre></td></tr></table></figure><p>启动kibana命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/app/kibana</span><br><span class="line"><span class="comment">#后台启动</span></span><br><span class="line">nohup ./bin/kibana &amp;</span><br></pre></td></tr></table></figure><h4 id="logstash部署"><a href="#logstash部署" class="headerlink" title="logstash部署"></a>logstash部署</h4><p>启动logstash</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/app/logstash/bin</span><br><span class="line"><span class="comment">#测试</span></span><br><span class="line">logstash --path.settings ../config/ -f ../config/logstash.conf --config.test_and_exit</span><br><span class="line"><span class="comment">#启动</span></span><br><span class="line">logstash -f ../config/logstash-es.conf</span><br><span class="line"><span class="comment">#查看端口监听状态以及pid</span></span><br><span class="line">netstat -lntp |grep 10514</span><br></pre></td></tr></table></figure><p>logstash-es.conf 文件</p><p><a href="https://blog.51cto.com/kinglab/2450986" target="_blank" rel="noopener">参考链接</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">    tcp &#123;</span><br><span class="line">        port =&gt; 4569</span><br><span class="line">        codec =&gt; <span class="string">"json"</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">filter &#123;</span><br><span class="line">  grok &#123;</span><br><span class="line">    match=&gt;&#123;<span class="string">"message"</span>=&gt; <span class="string">"%&#123;IP:client&#125; %&#123;WORD:method&#125; %&#123;URIPATHPARAM:request&#125; %&#123;NUMBER:bytes&#125; %&#123;NUMBER:duration&#125;"</span> &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">stdout&#123;</span><br><span class="line">codec=&gt;rubydebug</span><br><span class="line">&#125;</span><br><span class="line">    elasticsearch &#123;</span><br><span class="line">        action =&gt; <span class="string">"index"</span></span><br><span class="line">        hosts =&gt; [<span class="string">"10.0.12.72:9200"</span>]</span><br><span class="line">        index =&gt; <span class="string">"%&#123;[appname]&#125;"</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>logback.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span> <span class="attr">debug</span>=<span class="string">"false"</span> <span class="attr">scan</span>=<span class="string">"false"</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"log.path"</span> <span class="attr">value</span>=<span class="string">"D:\\logs"</span> /&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"console"</span></span></span><br><span class="line"><span class="tag">              <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.ConsoleAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>%d&#123;MM-dd HH:mm:ss.SSS&#125; %-5level [%logger&#123;50&#125;] - %msg%n</span><br><span class="line">            <span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"log"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.RollingFileAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">file</span>&gt;</span>$&#123;log.path&#125;/log.log<span class="tag">&lt;/<span class="name">file</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rollingPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">fileNamePattern</span>&gt;</span>$&#123;log.path&#125;\log.%i.log.%d&#123;yyyy-MM-dd-HH&#125;<span class="tag">&lt;/<span class="name">fileNamePattern</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">maxFileSize</span>&gt;</span>50MB<span class="tag">&lt;/<span class="name">maxFileSize</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">maxHistory</span>&gt;</span>30<span class="tag">&lt;/<span class="name">maxHistory</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">rollingPolicy</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.encoder.PatternLayoutEncoder"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; - %X&#123;traceId&#125; - %m%n<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"logstash"</span> <span class="attr">class</span>=<span class="string">"net.logstash.logback.appender.LogstashTcpSocketAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">param</span> <span class="attr">name</span>=<span class="string">"Encoding"</span> <span class="attr">value</span>=<span class="string">"UTF-8"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">destination</span>&gt;</span>10.0.12.72:10514<span class="tag">&lt;/<span class="name">destination</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span> <span class="attr">class</span>=<span class="string">"net.logstash.logback.encoder.LogstashEncoder"</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!--%&#123;appName&#125;中的appName需要在属性中配置，作为字段写入到doc中--&gt;</span></span><br><span class="line">            <span class="comment">&lt;!--&lt;customFields&gt;&#123;"appname":"%&#123;appName&#125;"&#125;&lt;/customFields&gt;--&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">customFields</span>&gt;</span>&#123;"appname":"myapp"&#125;<span class="tag">&lt;/<span class="name">customFields</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">connectionStrategy</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">roundRobin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">connectionTTL</span>&gt;</span>5 minutes<span class="tag">&lt;/<span class="name">connectionTTL</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">roundRobin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">connectionStrategy</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">root</span> <span class="attr">level</span>=<span class="string">"info"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"log"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">root</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"com.cetiti.es.controller"</span> <span class="attr">level</span>=<span class="string">"INFO"</span> <span class="attr">addtivity</span>=<span class="string">"false"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"console"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"logstash"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p>参考文档：</p><p><a href="https://www.jianshu.com/p/d66bfe7e9127" target="_blank" rel="noopener">ELK-概念</a></p><p><a href="https://www.cnblogs.com/wangzhuxing/p/9665905.html" target="_blank" rel="noopener">logback+ELK日志搭建</a></p><p><a href="https://cloud.tencent.com/developer/article/1353068" target="_blank" rel="noopener">一文快速上手Logstash</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;ElasticSearch部署&quot;&gt;&lt;a href=&quot;#ElasticSearch部署&quot; class=&quot;headerlink&quot; title=&quot;ElasticSearch部署&quot;&gt;&lt;/a&gt;ElasticSearch部署&lt;/h4&gt;&lt;p&gt;下载解压改配置文件/config/e
      
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/child/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>SpringCloud-服务注册、调用以及负载均衡</title>
    <link href="http://yoursite.com/child/2020/01/02/SpringCloud-%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E3%80%81%E8%B0%83%E7%94%A8%E4%BB%A5%E5%8F%8A%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    <id>http://yoursite.com/child/2020/01/02/SpringCloud-服务注册、调用以及负载均衡/</id>
    <published>2020-01-01T16:00:00.000Z</published>
    <updated>2020-01-02T06:34:36.000Z</updated>
    
    <content type="html"><![CDATA[<h4 id="父项目依赖配置："><a href="#父项目依赖配置：" class="headerlink" title="父项目依赖配置："></a>父项目依赖配置：</h4><p>父项目pom配置：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">spring.boot.version</span>&gt;</span>2.2.0.RELEASE<span class="tag">&lt;/<span class="name">spring.boot.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">spring.cloud.version</span>&gt;</span>Hoxton.RELEASE<span class="tag">&lt;/<span class="name">spring.cloud.version</span>&gt;</span></span><br><span class="line">    ...</span><br><span class="line"><span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependencyManagement</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-dependencies<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;spring.boot.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">type</span>&gt;</span>pom<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>import<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-dependencies<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;spring.cloud.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>import<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">type</span>&gt;</span>pom<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencyManagement</span>&gt;</span></span><br></pre></td></tr></table></figure><p>boot版本号 2.2.x.RELEASE 应当使用的cloud版本序列为Hoxton.RELEASE</p><p>父pom中这样配置，子模块中引入boot和cloud的依赖不再需要填写版本号信息，统一了系统的依赖版本</p><h4 id="服务器配置："><a href="#服务器配置：" class="headerlink" title="服务器配置："></a>服务器配置：</h4><p>主类上注解@EnableEurekaServer，表示是服务器</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr"> application:</span></span><br><span class="line"><span class="attr">   name:</span> <span class="string">eureka-server</span></span><br><span class="line"><span class="attr">eureka:</span></span><br><span class="line"><span class="attr">  instance:</span></span><br><span class="line"><span class="attr">    hostname:</span> <span class="string">localhost</span></span><br><span class="line"><span class="attr">  client:</span></span><br><span class="line"><span class="attr">    registerWithEureka:</span> <span class="literal">false</span> <span class="comment">#是否要注册到eureka</span></span><br><span class="line"><span class="attr">    fetchRegistry:</span> <span class="literal">false</span> <span class="comment">#表示是否从Eureka Server获取注册信息</span></span><br><span class="line"><span class="attr">    serviceUrl:</span></span><br><span class="line"><span class="attr">      defaultZone:</span> <span class="attr">http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/</span> <span class="comment">#单机配置</span></span><br></pre></td></tr></table></figure><p>eureka服务器不需要注册注册中心让别人发线，所以配置registerWithEureka为false </p><p>也不需要获取其他服务的注册信息所以registerWithEureka 也为false</p><p><strong>安全访问</strong></p><p>eureka服务器可以配置安全访问，需要引入依赖spring-boot-stater-security，并配置user和password</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr"> security:</span></span><br><span class="line"><span class="attr">   user:</span></span><br><span class="line"><span class="attr">     name:</span> <span class="string">admin</span></span><br><span class="line"><span class="attr">     password:</span> <span class="number">123456</span></span><br></pre></td></tr></table></figure><p>所有的客户端对的client.serviceUrl.defaultZone 都需要使用user:passwod@host 的形式进行配置</p><p>eg:  <a href="http://admin:123456@localhost:8761/erueka/" target="_blank" rel="noopener">http://admin:123456@localhost:8761/erueka/</a></p><h4 id="注册服务"><a href="#注册服务" class="headerlink" title="注册服务"></a>注册服务</h4><p>主类注解@EnableEurekaClient，表示是客户端</p><p>基本配置：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  application:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">user-provider</span></span><br><span class="line"><span class="attr">eureka:</span></span><br><span class="line"><span class="attr">  client:</span></span><br><span class="line"><span class="attr">    healthcheck:</span></span><br><span class="line"><span class="attr">      enabled:</span> <span class="literal">true</span> <span class="comment">#开启健康检查，需要引入actuator依赖</span></span><br><span class="line"><span class="attr">    service-url:</span></span><br><span class="line"><span class="attr">      defaultZone:</span> <span class="attr">http://localhost:8761/eureka/</span> <span class="comment">#告诉服务提供者要把服务注册到哪儿</span></span><br><span class="line"><span class="attr">  instance:</span></span><br><span class="line"><span class="attr">      prefer-ip-address:</span> <span class="literal">true</span> <span class="comment">#显示客户端真实ip</span></span><br></pre></td></tr></table></figure><p>如果是eureka服务器集群，defaultZone可以写个url，用“,”隔开</p><p>若同一个服务需要部署多个实例，配置文件中服务名称srping.application.name需要一致</p><h4 id="调用服务"><a href="#调用服务" class="headerlink" title="调用服务"></a>调用服务</h4><p>服务调用方也需要引入eureka-client依赖，但需设置不注册到服务中心</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">eureka:</span></span><br><span class="line"><span class="attr">  client:</span></span><br><span class="line"><span class="attr">    register-with-eureka:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure><p>服务调用可以使用ribbon或者feign进行负载均衡</p><p><strong>使用ribbon：</strong></p><p>eureka-client包中已经引入了netflix-ribbon，所以不用单独添加依赖。</p><p>注册一个RestTemplate Bean</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="meta">@EnableEurekaClient</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConsumerApp</span></span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">SpringApplication.run(ConsumerApp.class);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="meta">@LoadBalanced</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> RestTemplater <span class="title">restTemplate</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> RestTemplate();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>根据服务名称调用服务：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span>  <span class="title">UserController</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span>  <span class="keyword">final</span> String URL_PREFIX = <span class="string">"http://USER-PROVIDER"</span>;</span><br><span class="line">    <span class="keyword">private</span> RestTemplate restTemplate;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setRestTemplate</span><span class="params">(RestTemplate template)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.restTemplate = template;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping</span>(<span class="string">"/user/&#123;id&#125;"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> User <span class="title">getUser</span><span class="params">(@PathVariable(<span class="string">"id"</span>)</span>Long id)</span>&#123;</span><br><span class="line">        <span class="comment">//调用远程服务 http请求</span></span><br><span class="line">        String url = URL_PREFIX+<span class="string">"/provider/user/"</span>+id;</span><br><span class="line">        <span class="keyword">return</span> restTemplate.getForObject(url,User.class);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>缺点是需要拼接字符串。</p><p><strong>使用feign</strong></p><p>feign底层也是使用的ribbon</p><p>主类添加注解@EnableEurekaClient表示服务消费者是Eurrka客户端</p><p>主类添加注解@EnableFeignClients表示使用Fegin进行负载</p><p>首先定义fegint访问接口：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@FeignClient</span>(value=<span class="string">"user-provider"</span>)<span class="comment">//需要调用的服务名称</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">UserServiceFeignClient</span></span>&#123;</span><br><span class="line">    <span class="comment">//此处为服务提供者提供的url</span></span><br><span class="line">    <span class="meta">@GetMapping</span>(<span class="string">"provider/user/&#123;id&#125;"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> User <span class="title">getUser</span><span class="params">(@PathVariable(<span class="string">"id"</span>)</span>Long id)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在Controller中访问</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserController</span></span>&#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> UserServiceFeignClient client;</span><br><span class="line">    <span class="comment">//此处为服务消费者提供的url</span></span><br><span class="line">    <span class="meta">@GetMapping</span>(<span class="string">"/user/&#123;id&#125;"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> User <span class="title">getUser</span><span class="params">(@PathVariable(<span class="string">"id"</span>)</span> Long id)</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> client.getUser(id);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>比直接使用ribbon优雅多了</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;父项目依赖配置：&quot;&gt;&lt;a href=&quot;#父项目依赖配置：&quot; class=&quot;headerlink&quot; title=&quot;父项目依赖配置：&quot;&gt;&lt;/a&gt;父项目依赖配置：&lt;/h4&gt;&lt;p&gt;父项目pom配置：&lt;/p&gt;
&lt;figure class=&quot;highlight xml&quot;&gt;&lt;t
      
    
    </summary>
    
    
      <category term="SpringCloud" scheme="http://yoursite.com/child/tags/SpringCloud/"/>
    
  </entry>
  
  <entry>
    <title>redis-热key问题</title>
    <link href="http://yoursite.com/child/2020/01/02/redis-%E7%83%AD%E7%82%B9key%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/child/2020/01/02/redis-热点key问题/</id>
    <published>2020-01-01T16:00:00.000Z</published>
    <updated>2020-01-02T09:24:23.593Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.cnblogs.com/rjzheng/p/10874537.html" target="_blank" rel="noopener">原文链接</a></p><p>所谓热key问题就是，突然有几十万的请求去访问redis上的某个特定key。那么，这样会造成流量过于集中，达到物理网卡上限，从而导致这台redis的服务器宕机。<br>那接下来这个key的请求，就会直接怼到你的数据库上，导致你的服务不可用。</p><h3 id="1-怎么发现热key"><a href="#1-怎么发现热key" class="headerlink" title="1. 怎么发现热key"></a>1. 怎么发现热key</h3><p><strong><em>方法一:凭借业务经验，进行预估哪些是热key</em></strong><br>其实这个方法还是挺有可行性的。比如某商品在做秒杀，那这个商品的key就可以判断出是热key。</p><p>缺点很明显，并非所有业务都能预估出哪些key是热key。</p><p><strong><em>方法二:在客户端进行收集</em></strong><br>这个方式就是在操作redis之前，加入一行代码进行数据统计。那么这个数据统计的方式有很多种，也可以是给外部的通讯系统发送一个通知信息。缺点就是对客户端代码造成入侵。</p><p><strong><em>方法三:在Proxy层做收集</em></strong><br>有些集群架构是下面这样的，Proxy可以是Twemproxy，是统一的入口。可以在Proxy层做收集上报，但是缺点很明显，并非所有的redis集群架构都有proxy。</p><p><img src="https://img2018.cnblogs.com/blog/725429/201905/725429-20190516112209464-1290077151.png" alt="img"></p><p><strong><em>方法四:用redis自带命令</em></strong></p><ol><li>monitor命令，该命令可以实时抓取出redis服务器接收到的命令，然后写代码统计出热key是啥。当然，也有现成的分析工具可以给你使用，比如<code>redis-faina</code>。但是该命令在高并发的条件下，有内存增暴增的隐患，还会降低redis的性能。</li><li>hotkeys参数，redis 4.0.3提供了redis-cli的热点key发现功能，执行redis-cli时加上–hotkeys选项即可。但是该参数在执行的时候，如果key比较多，执行起来比较慢。</li></ol><p>缺点是对redis性能影响较大</p><p><strong><em>方法五:自己抓包评估</em></strong><br>Redis客户端使用TCP协议与服务端进行交互，通信协议采用的是RESP。自己写程序监听端口，按照RESP协议规则解析数据，进行分析。缺点就是开发成本高，维护困难，有丢包可能性。</p><p>以上五种方案，各有优缺点。根据自己业务场景进行抉择即可。那么发现热key后，如何解决呢？</p><h3 id="2-如何解决"><a href="#2-如何解决" class="headerlink" title="2. 如何解决"></a>2. 如何解决</h3><p>目前业内的方案有两种</p><p><strong><em>方案一：利用二级缓存</em></strong><br>比如利用<code>ehcache</code>，或者一个<code>HashMap</code>都可以。在你发现热key以后，把热key加载到系统的JVM中。<br>针对这种热key请求，会直接从jvm中取，而不会走到redis层。<br>假设此时有十万个针对同一个key的请求过来,如果没有本地缓存，这十万个请求就直接怼到同一台redis上了。<br>现在假设，你的应用层有50台机器，OK，你也有jvm缓存了。这十万个请求平均分散开来，每个机器有2000个请求，会从JVM中取到value值，然后返回数据。避免了十万个请求怼到同一台redis上的情形。</p><p><strong><em>方案二：备份热key</em></strong><br>这个方案也很简单。不要让key走到同一台redis上不就行了。我们把这个key，在多个redis上都存一份不就好了。接下来，有热key请求进来的时候，我们就在有备份的redis上随机选取一台，进行访问取值，返回数据。<br>假设redis的集群数量为N，步骤如下图所示</p><p><img src="https://img2018.cnblogs.com/blog/725429/201905/725429-20190516112222759-656135438.png" alt="img"></p><p>注:不一定是2N，你想取3N，4N都可以，看要求。<br>伪代码如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> M = N * <span class="number">2</span></span><br><span class="line"><span class="comment">//生成随机数</span></span><br><span class="line">random = GenRandom(<span class="number">0</span>, M)</span><br><span class="line"><span class="comment">//构造备份新key</span></span><br><span class="line">bakHotKey = hotKey + “_” + random</span><br><span class="line">data = redis.GET(bakHotKey)</span><br><span class="line"><span class="keyword">if</span> data == NULL &#123;</span><br><span class="line">    data = GetFromDB()</span><br><span class="line">    redis.SET(bakHotKey, expireTime + GenRandom(<span class="number">0</span>,<span class="number">5</span>))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-业内方案"><a href="#3-业内方案" class="headerlink" title="3. 业内方案"></a>3. 业内方案</h3><p>OK，其实看完上面的内容，大家可能会有一个疑问。</p><blockquote><p><strong>有办法在项目运行过程中，自动发现热key，然后程序自动处理么？</strong></p></blockquote><p>嗯，好问题，那我们来讲讲业内怎么做的。其实只有两步</p><ol><li>监控热key</li><li>通知系统做处理</li></ol><p>正巧，前几天有赞出了一篇《有赞透明多级缓存解决方案（TMC）》，里头也有提到热点key问题，我们刚好借此说明</p><ul><li>监控热key</li></ul><p>在监控热key方面，有赞用的是<strong><em>方式二：在客户端进行收集</em></strong>。<br>在《有赞透明多级缓存解决方案（TMC）》中有一句话提到</p><blockquote><p><strong>TMC 对原生jedis包的JedisPool和Jedis类做了改造，在JedisPool初始化过程中集成TMC“热点发现”+“本地缓存”功能Hermes-SDK包的初始化逻辑。</strong></p></blockquote><p>也就说人家改写了jedis原生的jar包，加入了Hermes-SDK包。<br>那Hermes-SDK包用来干嘛？<br>OK，就是做<strong>热点发现</strong>和<strong>本地缓存</strong>。</p><p>从监控的角度看，该包对于Jedis-Client的每次key值访问请求，Hermes-SDK 都会通过其通信模块将key访问事件异步上报给Hermes服务端集群，以便其根据上报数据进行“热点探测”。</p><p>当然，这只是其中一种方式，有的公司在监控方面用的是方式五:<strong>自己抓包评估</strong>。</p><p>具体是这么做的，先利用flink搭建一套流式计算系统。然后自己写一个抓包程序抓redis监听端口的数据，抓到数据后往kafka里丢。接下来，流式计算系统消费kafka里的数据，进行数据统计即可，也能达到监控热key的目的。</p><ul><li>通知系统做处理</li></ul><p>在这个角度，有赞用的是上面的<strong><em>解决方案一:利用二级缓存进行处理</em></strong>。</p><p>有赞在监控到热key后，Hermes服务端集群会通过各种手段通知各业务系统里的Hermes-SDK，告诉他们:”老弟，这个key是热key，记得做本地缓存。”</p><p>于是Hermes-SDK就会将该key缓存在本地，对于后面的请求。Hermes-SDK发现这个是一个热key，直接从本地中拿，而不会去访问集群。</p><p>除了这种通知方式以外。我们也可以这么做，比如你的流式计算系统监控到热key了，往zookeeper里头的某个节点里写。然后你的业务系统监听该节点，发现节点数据变化了，就代表发现热key。最后往本地缓存里写，也是可以的。</p><p>通知方式各种各样，大家可以自由发挥。本文只是提供一个思路。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/rjzheng/p/10874537.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原文链接&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;所谓热key问题就是，突然有几十万的请求去访问redis上的某个
      
    
    </summary>
    
    
      <category term="redis" scheme="http://yoursite.com/child/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>mysql-innoDB架构分析</title>
    <link href="http://yoursite.com/child/2020/01/02/mysql-innoDB%E6%9E%B6%E6%9E%84%E5%88%86%E6%9E%90/"/>
    <id>http://yoursite.com/child/2020/01/02/mysql-innoDB架构分析/</id>
    <published>2020-01-01T16:00:00.000Z</published>
    <updated>2020-03-31T15:05:22.133Z</updated>
    
    <content type="html"><![CDATA[<p>先上一张官网的架构图，本文将按照架构图中的组件逐一分析。</p><p><img src="https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/mysql/innodb-architecture.png" alt="https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/mysql/innodb-architecture.png"></p><h4 id="1-buffer-pool"><a href="#1-buffer-pool" class="headerlink" title="1. buffer pool"></a>1. buffer pool</h4><p>按照局部性原理，将预期会使用到的数据缓存到内存中，避免每次读取数据都需要进行磁盘i/o，提升i/o性能，这块存放缓存的内存区域就是buffer pool。</p><p>buffer pool 是一种降低磁盘访问的机制。</p><p>磁盘访问通常以页为单位。</p><p>缓存池常见的实现方式是LRU（链表实现，为了减少数据移动），管理磁盘页。</p><p>缓存池管理方式–LRU（链表实现，为了减少数据移动）</p><p>普通LRU会有以下问题：</p><ul><li>预读取失效，预读取的页不会真正被读取<ul><li>优化思路：让预读失效页尽快出内存，真正读取页才挪到LRU头部</li><li>方案：分代管理，预读取进入老生代，真正读取再进入新生代</li></ul></li><li>缓冲池污染，要批量扫描大量数据，导致缓冲池中的热点页被大量替换出去<ul><li>方案：在老生代设置停留时间，只有被真正读取并且停留时间达到阈值，才会移步新生代</li></ul></li></ul><p><strong>innoDB 的buffer pool 对应参数</strong></p><p>参数：innodb_buffer_pool_size</p><p>介绍：配置缓冲池的大小，在内存允许的情况下，DBA往往会建议调大这个参数，越多数据和索引放到内存里，数据库的性能会越好。 </p><p>参数：innodb_old_blocks_pct</p><p>介绍：老生代占整个LRU链长度的比例，默认是37，即整个LRU中新生代与老生代长度比例是63:37。</p><p><em>画外音：如果把这个参数设为100，就退化为普通LRU了。</em></p><p>参数：innodb_old_blocks_time</p><p>介绍：老生代停留时间窗口，单位是毫秒，默认是1000，即同时满足“被访问”与“在老生代停留时间超过1秒”两个条件，才会被插入到新生代头部。</p><p><a href="https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&amp;mid=2651962450&amp;idx=1&amp;sn=ce17c4da8d20ce275f75d0f2ef5e40c9&amp;chksm=bd2d098e8a5a809834aaa07da0d7546555385543fb6d687a7cf94d183ab061cd301a76547411&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Buffer pool 参考链接</a></p><p>对于读请求，buffer pool 能够减少磁盘的io，提高性能，那么对于写请求呢？change buffer此时登场。</p><h4 id="2-Change-Buffer"><a href="#2-Change-Buffer" class="headerlink" title="2. Change Buffer"></a>2. Change Buffer</h4><p>而对于写请求的优化，就是使用change buffer 来降低磁盘io的</p><p>主要应用于<strong>不在缓冲池中的非唯一普通索引页的写操作</strong></p><p>如果要写的页写已经在缓冲池中了是怎样一个写流程？</p><p>为什么唯一索引不适用呢？</p><p>唯一索引的话每次插入操作都需要检查索引的唯一性</p><p><a href="https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&amp;mid=2651962467&amp;idx=1&amp;sn=899ea157b0fc6f849ec80a4d055a309b&amp;chksm=bd2d09bf8a5a80a972a2e16a190ed7dffe03f89015ead707bdfcc5aeb8388fb278f397c125f1&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">change buffer 参考</a></p><p>相关参数：</p><p><strong>参数</strong>：innodb_change_buffer_max_size</p><p><strong>介绍</strong>：配置写缓冲的大小，占整个缓冲池的比例，默认值是25%，最大值是50%。</p><p><em>画外音：写多读少的业务，才需要调大这个值，读多写少的业务，25%其实也多了。</em></p><p><strong>参数</strong>：innodb_change_buffering</p><p><strong>介绍</strong>：配置哪些写操作启用写缓冲，可以设置成all/none/inserts/deletes等。</p><h4 id="3-Log-buffer"><a href="#3-Log-buffer" class="headerlink" title="3. Log buffer"></a>3. Log buffer</h4><p>知其然，知其所以然。思路比结论重要</p><p>事务提交时，事务日志为什么要先写到log buffer 在写到os cache中呢？</p><p>虽然是内存操作，但是日志写到os cache中需要进行上下文切换切换到内核态，每次事务提交都直接写则每次都要切换到内核态。先写到log buffer中，将每次写优化为批量写，减少上下文切换次数。</p><p><em>这个优化思路很常见，高并发的MQ落盘，高并发的业务数据落盘，都可以使用。</em></p><h4 id="4-AHI–Adaptive-Hash-Index"><a href="#4-AHI–Adaptive-Hash-Index" class="headerlink" title="4. AHI–Adaptive Hash Index"></a>4. AHI–Adaptive Hash Index</h4><p>自适应哈希索引</p><p><strong>为什么叫自适应？</strong></p><p>用户不能创建，是mysql优化器自行判断，需要时创建</p><p><strong>既然是hash，key是什么，value是什么？</strong></p><p>key是索引键值</p><p>value是索引记录的页面位置</p><p>所以hash索引是索引的索引</p><p><strong>为什么要用哈希索引进行优化？</strong></p><p>通过附加索引查询数据时，有时候会进行回表查询，这样会导致查询连路很长降低查询效率</p><p><strong>哪些业务适用，哪些业务不适用？</strong></p><p>单行记录查询、索引范围查询、记录数不多能全部放到内存中—-适用</p><p>业务中有大量join、like时，AHI的维护会成为负担，建议手动关闭。</p><h4 id="5-redo-log"><a href="#5-redo-log" class="headerlink" title="5. redo log"></a>5. redo log</h4><p>有单独文章讲解</p><h4 id="6-double-write-buffer"><a href="#6-double-write-buffer" class="headerlink" title="6. double write buffer"></a>6. double write buffer</h4><p>知其然，知其所以然。思路比结论重要</p><p><strong>解决什么问题？</strong></p><p>innoDB数据页大小是16k，文件系统中的数据页（后称系统页）大小是4K，那么写数据库时我们将一页数据页落盘，需要刷写4页系统页，如果在此过程中系统掉电，将造成磁盘数据页损坏（例如，前两页系统页已被刷写，后两页未刷写）。</p><p><strong>如何解决？</strong></p><p>DWB缓存即将刷写的数据页。。</p><p>DWB具有两层架构，分为内存和磁盘</p><p>当有数据要落盘时：</p><p>第一步：将内存中修改后的数据页memcopy到dwb内存中</p><p>第二步：将dwb内存中的数据页写入dwb磁盘</p><p>第三步：将dwb中的数据页落盘到磁盘数据页</p><p>假使第二步掉电，磁盘数据页也还是完整的，可以通过redo log进行恢复</p><p>假如第三笔掉电，dwb中的数据页也是完整的，可以直接落盘</p><p><strong>性能影响大吗？</strong></p><p>第一步属于内存操作，速度很快</p><p>第二步属于磁盘顺序追加写，1秒几万次没问题</p><p>第三步不属于额外操作</p><p>另外，dwb 由128页组成，容量2MB，会分两次刷入dwb磁盘，每次1M，速度也很快</p><p><em>有第三方评测，性能损失约为10%</em></p><p>可以通过：</p><p>show global status like “%dblwr%” 查看dwb使用情况</p><p>Innodb_dblwr_pages_written 记录dwb中的写入页数</p><p>Innodb_dblwr_writes 记录dwb的写入次数</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;先上一张官网的架构图，本文将按照架构图中的组件逐一分析。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/mysql/innodb-architecture.png&quot; alt=&quot;https
      
    
    </summary>
    
    
      <category term="数据库" scheme="http://yoursite.com/child/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>mysql-redo log写流程分析(转)</title>
    <link href="http://yoursite.com/child/2020/01/02/mysql-redo%20log%E5%86%99%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90/"/>
    <id>http://yoursite.com/child/2020/01/02/mysql-redo log写流程分析/</id>
    <published>2020-01-01T16:00:00.000Z</published>
    <updated>2020-03-31T15:12:07.506Z</updated>
    
    <content type="html"><![CDATA[<p>原文链接：<a href="https://mp.weixin.qq.com/s/-Hx2KKYMEQCcTC-ADEuwVA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/-Hx2KKYMEQCcTC-ADEuwVA</a></p><p>为什么我的事务提交了，还会丢失数据呢？</p><p>这要从innoDB的一个参数说起</p><p><em>innodb_flush_log_at_trx_commit</em></p><p>参数的字面意思是innodb在事务提交时更新日志的方式，这个参数有 0，1，2 三种取值，表示有三种方式更新日志</p><p>首先我们要弄清楚事务提交时会更新那些日志呢？</p><p>前滚日志redo log 和 回滚日志undo log ，这两者称为innodb的事务日志。</p><p>事务提交后，存储引擎要将事务对数据的修改刷写到磁盘上以保证事务的ACID特性</p><blockquote><p><strong>A</strong>: atomicity-原子性</p><p><strong>C</strong>: consistency-一致性</p><p><strong>I</strong>: isolation-隔离性</p><p><strong>D</strong>: durability-持久性</p></blockquote><p>这个刷盘，是一个随机写，随机写性能较低，如果每次事务提交都刷盘，会极大影响数据库的性能。</p><p>知其然，知其所以然。思路比结论重要</p><p>所以为了优化随机写带来的低性能，架构设计中有两个常见的优化方法：</p><p>（1）先写日志(write log first)，将随机写优化为<strong>顺序写</strong>；</p><p>（2）将每次写优化为<strong>批量写</strong>；</p><p>这两个优化，InnoDB都用上了。</p><p>先说第一个优化，将对数据的修改先顺序写到日志里，这个日志就是redo log。</p><p>假如某一时刻，数据库崩溃，还没来得及将数据页刷盘，数据库重启时，会重做redo log里的内容，以保证已提交事务对数据的影响被刷到磁盘上。因此，redo log 又称为重做日志。</p><p>一句话，redo log是为了保证已提交事务的ACID特性，同时能够提高数据库性能的技术。</p><p>既然redo log能保证事务的ACID特性，那为什么还会出现，水友提问中出现的“数据库奔溃，丢数据”的问题呢？一起看下redo log的实现细节。</p><p><strong>redo log的三层架构</strong></p><p>画了一个丑图，简单说明下redo log的三层架构：</p><ul><li><strong>粉色</strong>，是InnoDB的一项很重要的内存结构(In-Memory Structure)，日志缓冲区(Log Buffer)，这一层，是MySQL应用程序用户态</li><li><strong>屎黄色</strong>，是操作系统的缓冲区(OS cache)，这一层，是OS内核态</li><li><strong>蓝色</strong>，是落盘的日志文件</li></ul><p><img src="https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/mysql/redolog-1.PNG" alt="redolog-1"></p><p><strong>redo log最终落盘的步骤如何？</strong></p><p><strong>首先</strong>，事务提交的时候，会写入Log Buffer，这里调用的是MySQL自己的函数WriteRedoLog；</p><p><strong>接着</strong>，只有当MySQL发起系统调用写文件write时，Log Buffer里的数据，才会写到OS cache。注意，MySQL系统调用完write之后，就认为文件已经写完，如果不flush，什么时候落盘，是操作系统决定的；</p><blockquote><p>画外音：<strong>有时候打日志，明明</strong>printf<strong>了，</strong>tail -f**却看不到，就是这个原因，这个细节在《明明打印到文件了，为啥tail -f看不到》一文里说过，此处不再展开。</p></blockquote><p><strong>最后</strong>，由操作系统（当然，MySQL也可以主动flush）将OS cache里的数据，最终fsync到磁盘上；</p><p><strong>操作系统为什么要缓冲数据到</strong>OS cache里，而不直接刷盘呢？</p><p>这里就是将“每次写”优化为“批量写”，以提高操作系统性能。</p><p><strong>数据库为什么要缓冲数据到Log Buffer</strong>里，而不是直接write呢？</p><p>这也是“每次写”优化为“批量写”思路的体现，以提高数据库性能。</p><blockquote><p>画外音：这个优化思路，非常常见，高并发的MQ落盘，高并发的业务数据落盘，都可以使用。</p></blockquote><p>redo log的三层架构，MySQL做了一次批量写优化，OS做了一次批量写优化，确实能极大提升性能，但有什么副作用吗？</p><blockquote><p>画外音：有优点，必有缺点。</p></blockquote><p>这个<strong>副作用</strong>，就是可能丢失数据：</p><p>（1）事务提交时，将redo log写入Log Buffer，就会认为事务提交成功；</p><p>（2）如果写入Log Buffer的数据，write入OS cache之前，数据库崩溃，就会出现数据丢失；</p><p>（3）如果写入OS cache的数据，fsync入磁盘之前，操作系统奔溃，也可能出现数据丢失；</p><blockquote><p>画外音：如上文所说，应用程序系统调用完write之后（不可能每次write后都立刻flush，这样写日志很蠢），就认为写成功了，操作系统何时fsync，应用程序并不知道，如果操作系统崩溃，数据可能丢失。</p></blockquote><p>任何脱离业务的技术方案都是耍流氓：</p><p>（1）有些业务允许低效，但不允许一丁点数据丢失；</p><p>（2）有些业务必须高性能高吞吐，能够容忍少量数据丢失；</p><p><strong>MySQL是如何折衷的呢？</strong></p><p>MySQL有一个参数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">innodb_flush_log_at_trx_commit</span><br></pre></td></tr></table></figure><p>能够控制事务提交时，刷redo log的策略。</p><p>目前有<strong>三种策略</strong>：</p><p><img src="https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/mysql/redolog-2.PNG" alt="redolog-2"></p><p><strong>策略一：最佳性能</strong>(innodb_flush_log_at_trx_commit=0)</p><p>每隔一秒，才将Log Buffer中的数据批量write入OS cache，同时MySQL主动fsync。</p><p>这种策略，如果数据库奔溃，有一秒的数据丢失。</p><p><strong>策略二：强一致</strong>(innodb_flush_log_at_trx_commit=1)</p><p>每次事务提交，都将Log Buffer中的数据write入OS cache，同时MySQL主动fsync。</p><p>这种策略，是InnoDB的默认配置，为的是保证事务ACID特性。</p><p><strong>策略三：折衷</strong>(innodb_flush_log_at_trx_commit=2)</p><p>每次事务提交，都将Log Buffer中的数据write入OS cache；</p><p>每隔一秒，MySQL主动将OS cache中的数据批量fsync。</p><p><em>画外音：**磁盘IO次数不确定，因为操作系统的fsync频率并不是MySQL能控制的。</em></p><p>这种策略，如果操作系统奔溃，最多有一秒的数据丢失。</p><blockquote><p>画外音：因为OS也会fsync，MySQL主动fsync的周期是一秒，所以最多丢一秒数据。</p></blockquote><p><img src="https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/mysql/redolog-3.PNG" alt="redolog-3"></p><p>讲了这么多，回到水友的提问上来，数据库崩溃，重启后丢失了数据，有很大的可能，是将innodb_flush_log_at_trx_commit参数设置为0了，这位水友最好和DBA一起检查一下InnoDB的配置。</p><p>可能有水友要问，<strong>高并发的业务，InnoDB运用哪种刷盘策略最合适？</strong></p><p>高并发业务，行业最佳实践，是使用<strong>第三种折衷配置</strong>（=2），这是因为：</p><ol><li>配置为2和配置为0，性能差异并不大，因为将数据从Log Buffer拷贝到OS cache，虽然跨越用户态与内核态，但毕竟只是内存的数据拷贝，速度很快；</li><li>配置为2和配置为0，安全性差异巨大，操作系统崩溃的概率相比MySQL应用程序崩溃的概率，小很多，设置为2，只要操作系统不奔溃，也绝对不会丢数据。</li></ol><p><strong>总结</strong></p><p>一、为了保证事务的ACID特性，理论上每次事务提交都应该刷盘，但此时效率很低，有两种优化方向：</p><ol><li>随机写优化为顺序写；</li><li>每次写优化为批量写；</li></ol><p>二、redo log是一种顺序写，它有三层架构：</p><ol><li>MySQL应用层：Log Buffer</li><li>OS内核层：OS cache</li><li>OS文件：log file</li></ol><p>三、为了满足不用业务对于吞吐量与一致性的需求，MySQL事务提交时刷redo log有三种策略：</p><ul><li>0：每秒write一次OS cache，同时fsync刷磁盘，性能好；</li><li>1：每次都write入OS cache，同时fsync刷磁盘，一致性好；</li><li>2：每次都write入OS cache，每秒fsync刷磁盘，折衷；</li></ul><p>四、高并发业务，行业内的最佳实践，是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">innodb_flush_log_at_trx_commit=2</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;原文链接：&lt;a href=&quot;https://mp.weixin.qq.com/s/-Hx2KKYMEQCcTC-ADEuwVA&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s/-Hx2KKYMEQCcTC
      
    
    </summary>
    
    
      <category term="数据库" scheme="http://yoursite.com/child/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>jvm-对象的内存布局</title>
    <link href="http://yoursite.com/child/2019/12/31/jvm-%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80/"/>
    <id>http://yoursite.com/child/2019/12/31/jvm-对象的内存布局/</id>
    <published>2019-12-30T16:00:00.000Z</published>
    <updated>2019-12-31T02:29:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>对象内的布局是：最前面是对象头，有两个VM内部字段：_mark 和 _klass。</p><p>后面紧跟着就是对象的所有实例字段，紧凑排布，规则如下：</p><ul><li>继承深度越浅的类所声明的字段越靠前，继承深度越深的类所声明的字段越靠后。</li><li>在同一个类中声明的字段按字段的类型宽度来重排序，对普通Java类默认的排序是：long/double - 8字节、int/float - 4字节、short/char - 2字节、byte/boolean - 1字节，最后是引用类型字段（4或8字节）。</li><li>每个字段按照其宽度来对齐；最终对象默认再做一次8字节对齐。在类继承的边界上如果有因对齐而带来的空隙的话，可以把子类的字段拉到空隙里。</li></ul><p>这种排布方式可以让原始类型字段最大限度地紧凑排布在一起，减少字段间因为对齐而带来的空隙；同时又让引用类型字段尽可能排布在一起，减少OopMap的开销。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span> </span>&#123;</span><br><span class="line">  <span class="keyword">boolean</span> b;</span><br><span class="line">  Object o1;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">B</span> <span class="keyword">extends</span> <span class="title">A</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> i;</span><br><span class="line">  <span class="keyword">long</span> l;</span><br><span class="line">  Object o2;</span><br><span class="line">  <span class="keyword">float</span> f;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">C</span> <span class="keyword">extends</span> <span class="title">B</span> </span>&#123;</span><br><span class="line">  <span class="keyword">boolean</span> b;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>它的实例对象布局就是：（假定是64位HotSpot VM，默认开启压缩指针的话）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">--&gt;  +0 [ _mark     ] (64-bit header word)</span><br><span class="line">     +8 [ _klass    ] (32-bit header word, compressed klass pointer)</span><br><span class="line">    +12 [ A.b       ] (boolean, 1 byte)</span><br><span class="line">    +13 [ (padding) ] (padding for alignment, 3 bytes)</span><br><span class="line">    +16 [ A.o1      ] (reference, compressed pointer, 4 bytes)</span><br><span class="line">    +20 [ B.i       ] (int, 4 bytes)</span><br><span class="line">    +24 [ B.l       ] (long, 8 bytes)</span><br><span class="line">    +32 [ B.f       ] (float, 4 bytes)</span><br><span class="line">    +36 [ B.o2      ] (reference, compressed pointer, 4 bytes)</span><br><span class="line">    +40 [ C.b       ] (boolean, 1 byte)</span><br><span class="line">    +41 [ (padding) ] (padding for object alignment, 7 bytes)</span><br></pre></td></tr></table></figure><p>所以C类的对象实例大小，在这个设定下是48字节，其中有10字节是为对齐而浪费掉的padding，12字节是对象头，剩下的26字节是用户自己代码声明的实例字段。</p><p>留意到C类里字段的排布是按照这个顺序的：对象头 - Object声明的字段（无） - A声明的字段 - B声明的字段 - C声明的字段——按继承深度从浅到深排布。而每个类里面的字段排布顺序则按前面说的规则，按宽度来重排序。同时，如果类继承边界上有空隙（例如这里A和B之间其实本来会有一个4字节的空隙，但B里正好声明了一些不宽于4字节的字段，就可以把第一个不宽于4字节的字段拉到该空隙里，也就是 B.i 的位置）。</p><p>同时也请留意到A类和C类都声明了名字为b的字段。它们之间有什么关系？——没关系。<br>Java里，<strong>字段是不参与多态</strong>的。</p><p>派生类如果声明了跟基类同名的字段，则两个字段在最终的实例中都会存在；派生类的版本只会在名字上遮盖（shadow / hide）掉基类字段的名字，而不会与基类字段合并或令其消失。上面例子特意演示了一下A.b 与 C.b 同时存在的这个情况。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;对象内的布局是：最前面是对象头，有两个VM内部字段：_mark 和 _klass。&lt;/p&gt;
&lt;p&gt;后面紧跟着就是对象的所有实例字段，紧凑排布，规则如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;继承深度越浅的类所声明的字段越靠前，继承深度越深的类所声明的字段越靠后。&lt;/li&gt;
&lt;li&gt;在
      
    
    </summary>
    
    
      <category term="jvm" scheme="http://yoursite.com/child/tags/jvm/"/>
    
  </entry>
  
  <entry>
    <title>reids-5.0版本的高可用集群搭建</title>
    <link href="http://yoursite.com/child/2019/12/31/redis-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    <id>http://yoursite.com/child/2019/12/31/redis-集群搭建/</id>
    <published>2019-12-30T16:00:00.000Z</published>
    <updated>2020-01-02T08:05:49.915Z</updated>
    
    <content type="html"><![CDATA[<p>Redis系统介绍：</p><p><a href="https://www.jianshu.com/p/2a23257af57b" target="_blank" rel="noopener">Redis的基础介绍与安装使用步骤</a><br><a href="https://www.jianshu.com/p/c95c8450c5b6" target="_blank" rel="noopener">Redis的基础数据结构与使用</a><br><a href="https://www.jianshu.com/p/4e6b7809e10a" target="_blank" rel="noopener">Redis核心原理</a><br><a href="https://www.jianshu.com/p/8045b92fafb2" target="_blank" rel="noopener">Redis 5 之后版本的高可用集群搭建</a><br><a href="https://www.jianshu.com/p/6355d0827aea" target="_blank" rel="noopener">Redis 5 版本的高可用集群的水平扩展</a><br><a href="https://www.jianshu.com/p/e6894713a6d5" target="_blank" rel="noopener">Redis 5 集群选举原理分析</a><br><a href="https://www.jianshu.com/p/575544f68615" target="_blank" rel="noopener">Redis 5 通信协议解析以及手写一个Jedis客户端</a></p><hr><h4 id="1-集群方案比较："><a href="#1-集群方案比较：" class="headerlink" title="1. 集群方案比较："></a>1. 集群方案比较：</h4><h5 id="1-1-哨兵模式："><a href="#1-1-哨兵模式：" class="headerlink" title="1.1 哨兵模式："></a>1.1 哨兵模式：</h5><p>在redis3.0以前的版本要实现集群一般是借助哨兵sentinel工具来监控master节点的状态，如果master节点异常，则会做主从切换，将某一台slave作为master，哨兵的配置略微复杂，并且性能和高可用性等各方面表现一般，特别是在主从切换的瞬间存在访问瞬断的情况，而且哨兵模式只有一个主节点对外提供服务，没法支持很高的并发，且单个主节点内存也不宜设置得过大，否则会导致持久化文件过大，影响数据恢复或主从同步的效率。</p><p><img src="https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/redis/redis-cluster%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F.png" alt="哨兵模式"></p><h5 id="1-2-高可用集群模式："><a href="#1-2-高可用集群模式：" class="headerlink" title="1.2 高可用集群模式："></a>1.2 高可用集群模式：</h5><p>redis集群是一个由多个主从节点群组成的分布式服务器群，它具有复制、高可用和分片特性。Redis集群不需要sentinel哨兵也能完成节点移除和故障转移的功能。需要将每个节点设置成集群模式，这种集群模式没有中心节点，可水平扩展，据官方文档称可以线性扩展到上万个节点(官方推荐不超过1000个节点)。redis集群的性能和高可用性均优于之前版本的哨兵模式，且集群配置非常简单。</p><p><img src="https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/redis/redis-cluster%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84.png" alt="高可用架构"></p><h4 id="2-开始搭建"><a href="#2-开始搭建" class="headerlink" title="2. 开始搭建"></a>2. 开始搭建</h4><h5 id="2-1-安装redis"><a href="#2-1-安装redis" class="headerlink" title="2.1 安装redis"></a>2.1 安装redis</h5><p>参考之前博客：Redis的基础介绍与安装使用步骤：<a href="https://www.jianshu.com/p/2a23257af57b" target="_blank" rel="noopener">https://www.jianshu.com/p/2a23257af57b</a></p><p>下载地址：<a href="http://redis.io/download" target="_blank" rel="noopener">http://redis.io/download</a></p><p>1、安装gcc</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install gcc</span><br></pre></td></tr></table></figure><p>2、把下载好的redis-5.0.2.tar.gz放在/usr/local文件夹下，并解压</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget http://download.redis.io/releases/redis-5.0.2.tar.gz</span><br><span class="line">tar xzf redis-5.0.2.tar.gz</span><br><span class="line"><span class="built_in">cd</span> redis-5.0.2</span><br></pre></td></tr></table></figure><p>3、进入到解压好的redis-5.0.2目录下，进行编译与安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make &amp; make install</span><br></pre></td></tr></table></figure><p>4、启动并指定配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">src/redis-server redis.conf</span><br></pre></td></tr></table></figure><p>（注意要使用后台启动，所以修改redis.conf里的daemonize改为yes)</p><p>5、验证启动是否成功</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -ef | grep redis</span><br></pre></td></tr></table></figure><p>6、进入redis客户端</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/redis/redis-5.0.2/src</span><br><span class="line">./redis-cli</span><br></pre></td></tr></table></figure><p>7、退出客户端</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">exit</span></span><br></pre></td></tr></table></figure><p>8、退出redis服务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pkill redis-server</span><br><span class="line"><span class="built_in">kill</span> 进程号</span><br><span class="line">src/redis-cli shutdown</span><br></pre></td></tr></table></figure><h5 id="2-2-集群搭建"><a href="#2-2-集群搭建" class="headerlink" title="2.2 集群搭建"></a>2.2 集群搭建</h5><p>redis集群需要至少要三个master节点，我们这里搭建三个master节点，并且给每个master再搭建一个slave节点，总共6个redis节点，这里用一台机器（可以多台机器部署，修改一下ip地址就可以了）部署6个redis实例，三主三从，搭建集群的步骤如下：</p><p><strong>第一步：</strong>在机器的/usr/local下创建文件夹redis-cluster，然后在其下面创建6个文件夾如下:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /usr/<span class="built_in">local</span>/redis-cluster</span><br><span class="line"></span><br><span class="line">mkdir 8001 8002 8003 8004 8005 8006</span><br></pre></td></tr></table></figure><p><strong>第二步：</strong>把之前的redis.conf配置文件copy到8001下，修改如下内容：</p><blockquote><p>1）daemonize yes</p><p>2）port 8001（分别对每个机器的端口号进行设置）</p><p>3）dir /usr/local/redis-cluster/8001/（指定数据文件存放位置，必须要指定不同的目录位置，不然会丢失数据）</p><p>4）cluster-enabled yes（启动集群模式）</p><p>5）cluster-config-file nodes-8001.conf（集群节点信息文件，这里800x最好和port对应上）</p><p>6）cluster-node-timeout 5000</p><p>7)  bind 127.0.0.1（去掉bind绑定访问ip信息）</p><p>8)  protected-mode  no   （关闭保护模式）</p><p>9）appendonly yes</p><p>如果要设置密码需要增加如下配置：</p><p>10）requirepass xxx     (设置redis访问密码)</p><p>11）masterauth  xxx     (设置集群节点间访问密码，跟上面一致)</p></blockquote><p><strong>第三步：</strong>把修改后的配置文件，copy到8002-8006，修改第2、3、5项里的端口号，可以用批量替换：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%s/源字符串/目的字符串/g</span><br></pre></td></tr></table></figure><p><strong>第四步：</strong>分别启动6个redis实例，然后检查是否启动成功</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/redis-5.0.7/src/redis-server /usr/<span class="built_in">local</span>/redis-cluster/800*/redis.conf</span><br></pre></td></tr></table></figure><p><strong>第五步：</strong>用redis-cli创建整个redis集群(redis5以前的版本集群是依靠ruby脚本redis-trib.rb实现)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/redis-5.0.7/src/redis-cli -a xxx --cluster create --cluster-replicas 1 192.168.2.116:8001 192.168.2.116:8002 192.168.2.116:8003 192.168.2.116:8004 192.168.2.116:8005 192.168.2.116:8006</span><br></pre></td></tr></table></figure><p>代表为每个创建的主服务器节点创建一个从服务器节点</p><p><strong>第六步：</strong>验证集群：</p><p>1）连接任意一个客户端即可：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./redis-cli -c -a xxx -h 192.168.2.116 -p 8001</span><br></pre></td></tr></table></figure><p>提示：-a访问服务端密码，-c表示集群模式，指定ip地址和端口号</p><p>例如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/redis-5.0.2/src/redis-cli -a xxx -c -h 192.168.2.116 -p 8001</span><br></pre></td></tr></table></figure><p>注意这里进入到8002了，redirected。</p><p>2）进行验证： cluster info（查看集群信息）、cluster nodes（查看节点列表）</p><p>3）进行数据操作验证</p><p>4）关闭集群则需要逐个进行关闭，使用命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/redis/src/redis-cli -a xxx -c -h 192.168.2.116 -p 8001 shutdown</span><br></pre></td></tr></table></figure><h4 id="3-设置开机自启"><a href="#3-设置开机自启" class="headerlink" title="3. 设置开机自启"></a>3. 设置开机自启</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/init.d/redis</span><br></pre></td></tr></table></figure><p>将如下代码粘贴进去：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/src/sh</span></span><br><span class="line"><span class="comment"># chkconfig: 2345 80 90</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Simple Redis init.d script conceived to work on Linux systems</span></span><br><span class="line"><span class="comment"># as it does use of the /proc filesystem.</span></span><br><span class="line">​</span><br><span class="line">REDISPORT1=8001</span><br><span class="line">REDISPORT2=8002</span><br><span class="line">REDISPORT3=8003</span><br><span class="line">REDISPORT4=8004</span><br><span class="line">REDISPORT5=8005</span><br><span class="line">REDISPORT6=8006</span><br><span class="line">EXEC=/usr/<span class="built_in">local</span>/redis-5.0.7/src/redis-server</span><br><span class="line">CLIEXEC=/usr/<span class="built_in">local</span>/redis-5.0.7/src/redis-cli</span><br><span class="line">​</span><br><span class="line">PIDFILE=/var/run/redis_<span class="variable">$&#123;REDISPORT1&#125;</span>.pid</span><br><span class="line">​</span><br><span class="line">CONF1=<span class="string">"/usr/local/redis-cluster/<span class="variable">$&#123;REDISPORT1&#125;</span>/redis.conf"</span></span><br><span class="line">CONF2=<span class="string">"/usr/local/redis-cluster/<span class="variable">$&#123;REDISPORT2&#125;</span>/redis.conf"</span></span><br><span class="line">CONF3=<span class="string">"/usr/local/redis-cluster/<span class="variable">$&#123;REDISPORT3&#125;</span>/redis.conf"</span></span><br><span class="line">CONF4=<span class="string">"/usr/local/redis-cluster/<span class="variable">$&#123;REDISPORT4&#125;</span>/redis.conf"</span></span><br><span class="line">CONF5=<span class="string">"/usr/local/redis-cluster/<span class="variable">$&#123;REDISPORT5&#125;</span>/redis.conf"</span></span><br><span class="line">CONF6=<span class="string">"/usr/local/redis-cluster/<span class="variable">$&#123;REDISPORT6&#125;</span>/redis.conf"</span></span><br><span class="line">​</span><br><span class="line"><span class="keyword">case</span> <span class="string">"<span class="variable">$1</span>"</span> <span class="keyword">in</span></span><br><span class="line">    start)</span><br><span class="line">        <span class="keyword">if</span> [ -f <span class="variable">$PIDFILE</span> ]</span><br><span class="line">        <span class="keyword">then</span></span><br><span class="line">                <span class="built_in">echo</span> <span class="string">"<span class="variable">$PIDFILE</span> exists, process is already running or crashed"</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">                <span class="built_in">echo</span> <span class="string">"Starting Redis cluster server..."</span></span><br><span class="line">                <span class="variable">$EXEC</span> <span class="variable">$CONF1</span> &amp;</span><br><span class="line">                <span class="variable">$EXEC</span> <span class="variable">$CONF2</span> &amp;</span><br><span class="line">                <span class="variable">$EXEC</span> <span class="variable">$CONF3</span> &amp;</span><br><span class="line">                <span class="variable">$EXEC</span> <span class="variable">$CONF4</span> &amp;</span><br><span class="line">                <span class="variable">$EXEC</span> <span class="variable">$CONF5</span> &amp;</span><br><span class="line">                <span class="variable">$EXEC</span> <span class="variable">$CONF6</span> &amp;</span><br><span class="line">                <span class="built_in">echo</span> <span class="string">"启动成功..."</span></span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">        ;;</span><br><span class="line">    stop)</span><br><span class="line">        <span class="keyword">if</span> [ ! -f <span class="variable">$PIDFILE</span> ]</span><br><span class="line">        <span class="keyword">then</span></span><br><span class="line">                <span class="built_in">echo</span> <span class="string">"<span class="variable">$PIDFILE</span> does not exist, process is not running"</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">                PID=$(cat <span class="variable">$PIDFILE</span>)</span><br><span class="line">                <span class="built_in">echo</span> <span class="string">"Stopping ..."</span></span><br><span class="line">                <span class="variable">$CLIEXEC</span> -p <span class="variable">$REDISPORT1</span> shutdown</span><br><span class="line">                <span class="variable">$CLIEXEC</span> -p <span class="variable">$REDISPORT2</span> shutdown</span><br><span class="line">                <span class="variable">$CLIEXEC</span> -p <span class="variable">$REDISPORT3</span> shutdown</span><br><span class="line">                <span class="variable">$CLIEXEC</span> -p <span class="variable">$REDISPORT4</span> shutdown</span><br><span class="line">                <span class="variable">$CLIEXEC</span> -p <span class="variable">$REDISPORT5</span> shutdown</span><br><span class="line">                <span class="variable">$CLIEXEC</span> -p <span class="variable">$REDISPORT6</span> shutdown</span><br><span class="line">                <span class="keyword">while</span> [ -x /proc/<span class="variable">$&#123;PID&#125;</span> ]</span><br><span class="line">                <span class="keyword">do</span></span><br><span class="line">                    <span class="built_in">echo</span> <span class="string">"Waiting for Redis cluster to shutdown ..."</span></span><br><span class="line">                    sleep 1</span><br><span class="line">                <span class="keyword">done</span></span><br><span class="line">                <span class="built_in">echo</span> <span class="string">"Redis cluster stopped"</span></span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">        ;;</span><br><span class="line">    *)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"Please use start or stop as first argument"</span></span><br><span class="line">        ;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure><p>添加权限</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod +x /etc/init.d/redis</span><br></pre></td></tr></table></figure><p>加入开机启动服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chkconfig --add redis</span><br></pre></td></tr></table></figure><p>使用命令进行开启或关闭redis集群</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">service redis start </span><br><span class="line">service redis stop</span><br></pre></td></tr></table></figure><p><a href="https://www.jianshu.com/p/8045b92fafb2" target="_blank" rel="noopener">原文连接</a></p><p><a href="https://blog.csdn.net/qq_37859539/article/details/83715803" target="_blank" rel="noopener">https://blog.csdn.net/qq_37859539/article/details/83715803</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Redis系统介绍：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/2a23257af57b&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Redis的基础介绍与安装使用步骤&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https
      
    
    </summary>
    
    
      <category term="redis" scheme="http://yoursite.com/child/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>nio-说说零拷贝</title>
    <link href="http://yoursite.com/child/2019/12/19/nio-%E8%AF%B4%E8%AF%B4%E9%9B%B6%E6%8B%B7%E8%B4%9D/"/>
    <id>http://yoursite.com/child/2019/12/19/nio-说说零拷贝/</id>
    <published>2019-12-18T16:00:00.000Z</published>
    <updated>2020-04-21T08:07:49.905Z</updated>
    
    <content type="html"><![CDATA[<p>从一个业务场景开始：从本地磁盘读取一个文件通过socket发送出去。</p><p>传统的I/O接口处理流程如下：读文件到应用-&gt;应用打包文件到socket-&gt;发送</p><ol><li>应用发起系统调用sys_read()（或等价的方法）请求读磁盘文件</li><li>系统切换到内核态，读磁盘数据到内核读缓冲区（DMA方式）</li><li>系统将内核读缓冲区数据拷贝到应用缓冲区（CPU拷贝），read方法返回，系统切换到用户态。</li><li>应用包装好数据后发起send() 系统调用</li><li>系统切换到内核态，将数据写入到socket缓冲区（CPU拷贝）</li><li>将socket缓冲区的数据发送给网络接口卡（DMA方式），网卡发出</li><li>send() 返回，系统切换到用户态回到应用。</li></ol><p>整个过程将经历4次上下文切换，2次CPU拷贝。</p><p><img src="https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/java%E7%BC%96%E7%A8%8B/nio/%E8%AF%B4%E8%AF%B4%E9%9B%B6%E6%8B%B7%E8%B4%9D-%E4%BC%A0%E7%BB%9FIO%E8%BF%87%E7%A8%8B.jpg" alt="I/O过程"></p><h3 id="1-NIO的零拷贝"><a href="#1-NIO的零拷贝" class="headerlink" title="1. NIO的零拷贝"></a>1. NIO的零拷贝</h3><p>java.nio包中有一个TransferTo接口，专门用来发送数据，我们来看看它是怎么做的。</p><p>TransferTo接口调用了本地TransferTo方法，在Linux平台上将发起<strong>sendfile</strong>系统调用，执行过程如下：</p><ol><li>应用发起sendfile系统调用请求发送文件</li><li>系统切换到内核态，读磁盘数据到内核读缓冲区（DMA方式）</li><li>将内核读缓冲区的数据直接拷贝到socket缓冲区（CPU拷贝）</li><li>将socket缓冲区的数据发送给网络接口卡（DMA方式），网卡发出</li><li>系统切换到用户态回到应用</li></ol><p>整个过程经历2次上下文切换和1次CPU拷贝。</p><p><img src="https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/java%E7%BC%96%E7%A8%8B/nio/%E8%AF%B4%E8%AF%B4%E9%9B%B6%E6%8B%B7%E8%B4%9D-nio%E8%BF%87%E7%A8%8B.jpg" alt></p><p>如果底层NIC（网络接口卡）支持gather操作，可以进一步减少内核中的数据拷贝。在Linux 2.4以及更高版本的内核中，socket缓冲区描述符已被修改用来适应这个需求。这种方式不但减少上下文切换，同时消除了需要CPU参与的重复的数据拷贝。</p><p><img src="https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/java%E7%BC%96%E7%A8%8B/nio/%E8%AF%B4%E8%AF%B4%E9%9B%B6%E6%8B%B7%E8%B4%9D-nio%E8%BF%87%E7%A8%8B2.jpg" alt></p><p>用户这边的使用方式不变，依旧通过transferTo方法，但是方法的内部实现发生了变化：</p><ol><li><p>transferTo方法调用触发DMA引擎将文件上下文信息拷贝到内核缓冲区</p></li><li><p>数据不会被拷贝到套接字缓冲区，只有数据的描述符（包括数据位置和长度）被拷贝到套接字缓冲区。DMA 引擎直接将数据从内核缓冲区拷贝到协议引擎，这样减少了最后一次需要消耗CPU的拷贝操作。</p></li></ol><p>将一个文件拷贝到另一个目录，使用nio方式性能提升100%，<a href="https://github.com/zzkenyon/thinking/blob/master/nio/src/main/java/zerocopy/TransferToTest.java" target="_blank" rel="noopener">对比代码</a></p><h3 id="2-直接内存"><a href="#2-直接内存" class="headerlink" title="2. 直接内存"></a>2. 直接内存</h3><p>在不需要进行数据文件操作时，可以使用NIO的零拷贝。但如果既需要IO速度，又需要进行数据操作，则需要使用NIO的直接内存映射。</p><p>Linux提供的<strong>mmap</strong>系统调用, 它可以将一段用户空间内存映射到内核空间, 当映射成功后, 用户对这段内存区域的修改可以直接反映到内核空间；同样地， 内核空间对这段区域的修改也直接反映用户空间。正因为有这样的映射关系, 就不需要在用户态(User-space)与内核态(Kernel-space) 之间拷贝数据， 提高了数据传输的效率，这就是以内存直接映射为基础的零拷贝技术。</p><h4 id="2-1-直接内存的创建"><a href="#2-1-直接内存的创建" class="headerlink" title="2.1 直接内存的创建"></a>2.1 直接内存的创建</h4><p>在ByteBuffer有两个子类，HeapByteBuffer和DirectByteBuffer。前者是存在于JVM堆中的，后者是存在于Native堆中的。</p><p>申请堆内存</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ByteBuffer <span class="title">allocate</span><span class="params">(<span class="keyword">int</span> capacity)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (capacity &lt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException();</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> HeapByteBuffer(capacity, capacity);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>申请直接内存</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ByteBuffer <span class="title">allocateDirect</span><span class="params">(<span class="keyword">int</span> capacity)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> DirectByteBuffer(capacity);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="为什么使用直接内存"><a href="#为什么使用直接内存" class="headerlink" title="为什么使用直接内存"></a>为什么使用直接内存</h4><ul><li>对垃圾回收停顿的改善。因为full gc时，垃圾收集器会对所有分配的堆内内存进行扫描，垃圾收集对Java应用造成的影响，跟堆的大小是成正比的。过大的堆会影响Java应用的性能。如果使用堆外内存的话，堆外内存是直接受操作系统管理。这样做的结果就是能保持一个较小的JVM堆内存，以减少垃圾收集对应用的影响。full gc会回收空闲的直接内存。）</li><li>减少了数据从JVM拷贝到native内存的次数，在某些场景下可以提升程序I/O的性能。</li><li>可以突破JVM内存限制，操作更多的物理内存。</li></ul><h4 id="使用直接内存注意事项"><a href="#使用直接内存注意事项" class="headerlink" title="使用直接内存注意事项"></a>使用直接内存注意事项</h4><ul><li>与堆内存相比直接内存读数据快、申请慢，所以适合申请次数少，访问频繁的场合。</li><li>堆外内存只能通过序列化和反序列化来存储，保存对象速度比堆内存慢，不适合存储很复杂的对象。一般简单的对象或者扁平化的比较适合。</li><li>当直接内存不足时会触发full gc，排查full gc的时候，一定要考虑。</li><li>堆外内存难以控制，如果内存泄漏，那么很难排查</li></ul><h4 id="NIO的直接内存映射"><a href="#NIO的直接内存映射" class="headerlink" title="NIO的直接内存映射"></a>NIO的直接内存映射</h4><p>NIO中一个重要的类：MappedByteBuffer——java nio引入的文件内存映射方案，读写性能极高。MappedByteBuffer将文件直接映射到内存。可以映射整个文件，如果文件比较大的话可以考虑分段进行映射，只要指定文件的感兴趣部分就可以。</p><p>由于MappedByteBuffer申请的是直接内存，因此不受Minor GC控制，只能在发生Full GC时才能被回收，因此Java提供了DirectByteBuffer类来改善这一情况。它是MappedByteBuffer类的子类，同时它实现了DirectBuffer接口，维护一个Cleaner对象来完成内存回收。因此它既可以通过Full GC来回收内存，也可以调用clean()方法来进行回收</p><h4 id="NIO的直接内存映射的函数调用"><a href="#NIO的直接内存映射的函数调用" class="headerlink" title="NIO的直接内存映射的函数调用"></a>NIO的直接内存映射的函数调用</h4><p>FileChannel提供了map方法来把文件映射为内存对象：</p><p>MappedByteBuffer map(int mode,long position,long size);<br>可以把文件的从position开始的size大小的区域映射为内存对象，mode指出了 可访问该内存映像文件的方式</p><p>READ_ONLY,（只读）： 试图修改得到的缓冲区将导致抛出 ReadOnlyBufferException.(MapMode.READ_ONLY)</p><p>READ_WRITE（读/写）： 对得到的缓冲区的更改最终将传播到文件；该更改对映射到同一文件的其他程序不一定是可见的。 (MapMode.READ_WRITE)</p><p>PRIVATE（专用）： 对得到的缓冲区的更改不会传播到文件，并且该更改对映射到同一文件的其他程序也不是可见的；相反，会创建缓冲区已修改部分的专用副本。 (MapMode.PRIVATE)</p><blockquote><p>使用参数-XX:MaxDirectMemorySize=10M，可以指定DirectByteBuffer的大小最多是10M。</p></blockquote><p><a href="https://github.com/zzkenyon/thinking/blob/master/nio/src/main/java/zerocopy/MMPtest.java" target="_blank" rel="noopener">对比代码</a></p><p>将一个文件读入内存不做处理，与nio处理方式进行对比，直接内存处理性能提升500%</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;从一个业务场景开始：从本地磁盘读取一个文件通过socket发送出去。&lt;/p&gt;
&lt;p&gt;传统的I/O接口处理流程如下：读文件到应用-&amp;gt;应用打包文件到socket-&amp;gt;发送&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;应用发起系统调用sys_read()（或等价的方法）请求读磁盘文件&lt;/
      
    
    </summary>
    
    
      <category term="nio" scheme="http://yoursite.com/child/tags/nio/"/>
    
  </entry>
  
  <entry>
    <title>zookeeper配置和基本操纵</title>
    <link href="http://yoursite.com/child/2019/11/30/%E5%88%86%E5%B8%83%E5%BC%8F-zookeeper-%E9%85%8D%E7%BD%AE%E5%92%8C%E5%9F%BA%E6%9C%AC%E6%93%8D%E7%BA%B5/"/>
    <id>http://yoursite.com/child/2019/11/30/分布式-zookeeper-配置和基本操纵/</id>
    <published>2019-11-30T08:09:16.065Z</published>
    <updated>2020-05-07T08:59:02.906Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-配置开机自启"><a href="#1-配置开机自启" class="headerlink" title="1. 配置开机自启"></a>1. 配置开机自启</h4><p>把zookeeper做成服务</p><p>1、进入到/etc/rc.d/init.d目录下，新建一个zookeeper脚本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# cd /etc/rc.d/init.d/ </span><br><span class="line">[root@node1 init.d]# pwd </span><br><span class="line">/etc/rc.d/init.d </span><br><span class="line">[root@node1 init.d]# touch zookeeper</span><br></pre></td></tr></table></figure><p>2、给脚本添加执行权限</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 init.d]# chmod +x zookeeper</span><br></pre></td></tr></table></figure><p>3、使用命令vim zookeeper进行编辑，在脚本中输入如下内容，其中同上面注意事项一样要添加export JAVA_HOME=/usr/java/jdk1.8.0_112这一行，否则无法正常启动。</p><p>[root@zookeeper init.d]# vim zookeeper</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>!/bin/bash</span><br><span class="line"><span class="meta">#</span>chkconfig:2345 10 90</span><br><span class="line"><span class="meta">#</span>description:service zookeeper</span><br><span class="line">export     JAVA_HOME=/usr/lib/java/jdk-1.8.0_231</span><br><span class="line">ZOOKEEPER_HOME=/usr/local/apache/apache-zookeeper-3.5.6-bin</span><br><span class="line">case  "$1"   in</span><br><span class="line">     start)  su  root  $&#123;ZOOKEEPER_HOME&#125;/bin/zkServer.sh  start;;</span><br><span class="line">     stop)  su  root  $&#123;ZOOKEEPER_HOME&#125;/bin/zkServer.sh  stop;;</span><br><span class="line">     status)  su root  $&#123;ZOOKEEPER_HOME&#125;/bin/zkServer.sh    status;;</span><br><span class="line">     restart)  su root   $&#123;ZOOKEEPER_HOME&#125;/bin/zkServer.sh   restart;;</span><br><span class="line">     *)  echo "require start||stop|status|restart|";;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure><p>4、 使用service zookeeper start/stop/restart命令来尝试启动关闭重启zookeeper，使用service zookeeper status查看zookeeper状态。</p><p>5、添加到开机自启</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 init.d]# chkconfig --add zookeeper</span><br></pre></td></tr></table></figure><p>添加完之后，我们使用chkconfig –list来查看开机自启的服务中是否已经有我们的zookeeper了，如下所示，可以看到在最后一行便是我们的zookeeper服务了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 init.d]# chkconfig --list </span><br><span class="line">netconsole      0:off   1:off   2:off   3:off   4:off   5:off   6:off</span><br><span class="line">network         0:off   1:off   2:on    3:on    4:on    5:on    6:off</span><br><span class="line">zookeeper       0:off   1:off   2:on    3:on    4:on    5:on    6:off</span><br></pre></td></tr></table></figure><h4 id="2-zkCli客户端"><a href="#2-zkCli客户端" class="headerlink" title="2. zkCli客户端"></a>2. zkCli客户端</h4><p><a href="https://blog.csdn.net/dandandeshangni/article/details/80558383" target="_blank" rel="noopener">https://blog.csdn.net/dandandeshangni/article/details/80558383</a></p><h5 id="2-1-基本操作"><a href="#2-1-基本操作" class="headerlink" title="2.1 基本操作"></a>2.1 基本操作</h5><ul><li>列举子节点: ls path (ls /zookeeper)</li><li>查看节点更新信息：stat path (stat /zookeeper)</li><li>创建节点 ：create path val (creat /config “test string value”)</li><li>创建临时节点 ：create -e path val</li><li>创建顺序节点：create -s path val</li><li>修改节点：set path val (set /config “another config string”)</li><li>删除节点：delete path</li><li>监视节点：stat -w path、 get -w path</li></ul><h5 id="2-2-ACL权限控制"><a href="#2-2-ACL权限控制" class="headerlink" title="2.2 ACL权限控制"></a>2.2 ACL权限控制</h5><p>ZK的节点有5种操作权限：CREATE、READ、WRITE、DELETE、ADMIN 也就是 增、删、改、查、管理权限，这5种权限简写为crwda(即：每个单词的首字符缩写)。 注：这5种权限中，delete是指对子节点的删除权限，其它4种权限指对自身节点的操作权限</p><p>身份的认证有4种方式：</p><ul><li>world：默认方式，相当于全世界都能访问</li><li>auth：代表已经认证通过的用户(cli中可以通过addauth digest user:pwd 来添加当前上下文中的授权用户)</li><li>digest：即用户名:密码这种方式认证，这也是业务系统中最常用的</li><li>ip：使用Ip地址认证</li></ul><p>使用[scheme​ : id : permissions]来表示acl权限，比如-digest:username:password:cwrda</p><p>getAcl:获取某个节点的acl权限信息 getAcl path</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>World方案权限设置</span><br><span class="line">setAcl /config/global world:anyone:crwa</span><br><span class="line"><span class="meta">#</span>auth方案权限设置</span><br><span class="line">addauth digest test:123456 </span><br><span class="line">setAcl /config/global auth:test:123456:cdrwa</span><br><span class="line"><span class="meta">#</span>digest方案权限设置</span><br><span class="line">setAcl /config/global digest:test:V28q/NynI4JI3Rk54h0r8O5kMug=:cdra</span><br><span class="line"><span class="meta">#</span>ip权限设置</span><br><span class="line">setAcl /niocoder/ip ip:192.168.0.68:cdrwa</span><br></pre></td></tr></table></figure><h5 id="超级管理员"><a href="#超级管理员" class="headerlink" title="超级管理员"></a>超级管理员</h5><p>zk的权限管理表有一种ACL的模式叫做super，该模式的作用是方便管理节点。一旦我们为某一个节点设置了acl，那么其余的未授权的节点是无法访问或者操作该节点的，那么系统用久了以后，假如忘记了某一个节点的密码，那么就无法再操作这个节点了，所以需要这个super超级管理员用户权限，其作用还是很大的。</p><p>添加方式：只能在启动服务器的时候添加。</p><p>假设这个超管是：super:admin，通过代码得到其哈希值：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">String m = DigestAuthenticationProvider.generateDigest(<span class="string">"super:admin"</span>);</span><br></pre></td></tr></table></figure><p>m是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">super:xQJmxLMiHGwaqBvst5y6rkB6HQs=</span><br></pre></td></tr></table></figure><p>那么打开zk目录下的/bin/zkServer.sh服务器脚本文件，找到如下一行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup $JAVA "-Dzookeeper.log.dir=$&#123;ZOO_LOG_DIR&#125;" "-Dzookeeper.root.logger=$&#123;ZOO_LOG4J_PROP&#125;"</span><br></pre></td></tr></table></figure><p>这就是脚本中启动zk的命令，默认只有以上两个配置项，我们需要加一个超管的配置项：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">"-Dzookeeper.DigestAuthenticationProvider.superDigest=super:xQJmxLMiHGwaqBvst5y6rkB6HQs="</span><br></pre></td></tr></table></figure><p>第一个等号之后的就是刚才用户名密码的哈希值。 那么修改以后这条完整命令变成了：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nohup $JAVA "-Dzookeeper.log.dir=$&#123;ZOO_LOG_DIR&#125;" "-Dzookeeper.root.logger=$&#123;ZOO_LOG4J_PROP&#125;" "-Dzookeeper.DigestAuthenticationProvider.superDigest=super:xQJmxLMiHGwaqBvst5y6rkB6HQs="\</span><br><span class="line">    -cp "$CLASSPATH" $JVMFLAGS $ZOOMAIN "$ZOOCFG" &gt; "$_ZOO_DAEMON_OUT" 2&gt;&amp;1 &lt; /dev/null &amp;</span><br></pre></td></tr></table></figure><p>之后重新启动zk集群，进入zkCli输入如下命令添加权限：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">addauth digest super:admin</span><br></pre></td></tr></table></figure><p>假如zk有一个节点/test，acl为digest方案，但是忘记了用户名和密码，正常情况下，这次登陆如果不用那个digest授权是不能访问/test的数据的。但是由于我们配置了超管，所以这次还是可以访问到的。</p><p>需要说明的是，这个超管只是在这次服务器启动期间管用，如果关闭了服务器，并修改了服务器脚本，取消了超管配置，那么下一次启动就没有这个超管了。</p><h5 id="运维四字指令"><a href="#运维四字指令" class="headerlink" title="运维四字指令"></a>运维四字指令</h5><p>使用四字命令需要安装nc命令(yum install nc)</p><p>然后在启动脚本zkServer.sh里添加ＶＭ环境变量-Dzookeeper.4lw.commands.whitelist=*，便可以把所有四字指令添加到白名单（否则执行四字指令会报错is not executed because it is not in the whitelist），我是添加在脚本的这个位置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ZOOMAIN="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=$JMXPORT -Dcom.sun.management.jmxremote.authenticate=$JMXAUTH -Dcom.sun.management.jmxremote.ssl=$JMXSSL -Dzookeeper.jmx.log4j.disable=$JMXLOG4J org.apache.zookeeper.server.quorum.QuorumPeerMain"</span><br><span class="line">  fi</span><br><span class="line">else</span><br><span class="line">    echo "JMX disabled by user request" &gt;&amp;2</span><br><span class="line">    ZOOMAIN="org.apache.zookeeper.server.quorum.QuorumPeerMain"</span><br><span class="line">fi</span><br><span class="line"><span class="meta">#</span> 这里就是我添加的</span><br><span class="line"><span class="meta">#</span> 如果不想添加在这里，注意位置和赋值的顺序</span><br><span class="line">ZOOMAIN="-Dzookeeper.4lw.commands.whitelist=* $&#123;ZOOMAIN&#125;"</span><br></pre></td></tr></table></figure><p>重启zk即可。</p><p>四字指令调用方法：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]#echo xxxx | nc 192.168.0.68 2181</span><br></pre></td></tr></table></figure><p>其中xxxx为：</p><ul><li>stat 查看状态信息</li><li>ruok 查看zookeeper是否启动</li><li>dump 列出没有处理的节点，临时节点</li><li>conf 查看服务器配置</li><li>cons 显示连接到服务端的信息</li><li>envi 显示环境变量信息</li><li>mntr 查看zk的健康信息</li><li>wchs 展示watch的信息</li><li>wchc和wchp 显示session的watch信息 path的watch信息</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-配置开机自启&quot;&gt;&lt;a href=&quot;#1-配置开机自启&quot; class=&quot;headerlink&quot; title=&quot;1. 配置开机自启&quot;&gt;&lt;/a&gt;1. 配置开机自启&lt;/h4&gt;&lt;p&gt;把zookeeper做成服务&lt;/p&gt;
&lt;p&gt;1、进入到/etc/rc.d/init.d目
      
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/child/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>（转）彻底理解cookie，session，token</title>
    <link href="http://yoursite.com/child/2019/11/23/web-%E5%BD%BB%E5%BA%95%E7%90%86%E8%A7%A3cookie%EF%BC%8Csession%EF%BC%8Ctoken/"/>
    <id>http://yoursite.com/child/2019/11/23/web-彻底理解cookie，session，token/</id>
    <published>2019-11-22T16:00:00.000Z</published>
    <updated>2020-05-07T08:57:33.499Z</updated>
    
    <content type="html"><![CDATA[<p>原文链接：<a href="https://www.cnblogs.com/moyand/p/9047978.html" target="_blank" rel="noopener">https://www.cnblogs.com/moyand/p/9047978.html</a></p><p>发展史</p><p>1、 很久很久以前，Web基本上就是文档的浏览而已，既然是浏览，作为服务器，不需要记录谁在某一段时间里都浏览了什么文 </p><p>档，每次请求都是一个新的HTTP协议，就是请求加响应，尤其是我不用记住是谁刚刚发了 HTTP请求，每个请求对我来说都是 </p><p>全新的。这段时间很嗨皮</p><p>2、 但是随着交互式Web应用的兴起，像在线购物网站，需要登录的网站等等，马上就面临一个问题，那就是要管理会话，必须记住 </p><p>哪些人登录系统，哪些人往自己的购物车中放商品，也就是说我必须把每个人区分开，这就是一个不小的挑战，因为HTTP请求是 </p><p>无状态的，所以想出的办法就是给大家发一个会话标识(session id),说白了就是一个随机的字串，每个人收到的都不一样，每次大 </p><p>家向我发起HTTP请求的时候，把这个字符串给一并捎过来，这样我就能区分开谁是谁了</p><p>3、 这样大家很嗨皮了，可是服务器就不嗨皮了，每个人只需要保存自己的session id，而服务器要保存所有人的session id !如果 </p><p>访问服务器多了，就得由成千上万，甚至几十万个。</p><p>这对服务器说是一个巨大的开销，严重的限制了服务器扩展能力，比如说我用两个机器组成了一个集群，小F通过机器A登录了系 </p><p>统，那session id会保存在机器A上，假设小F的下一次请求被转发到机器B怎么办？机器B可没有小F的session id啊。</p><p>有时候会采用_点小伎俩：session sticky,就是让小 F的请求一直粘连在机器A上，但是这也不管用，要是机器A挂掉了，还得转 </p><p>到机器B去。</p><p>那只好做session的复制了，把session id在两个机器之间搬来搬去，快累死了。</p><p><img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200311210943504.png" alt="image-20200311210943504"></p><p>后来有个叫Memcached的支了招：把session id 集中存储到衣蛾地方，所有的机器都来访问这个地方的数据，这样一来，就不用复制了。但是增加了单点失败的可能性，要是那个负责session的机器挂了，所有的人都得重新登录一遍，估计的被人骂死</p><p>后来也尝试把这个单点的机器搞成集群，增加可靠性，但是不管如何，这个小小的session对我来说是一个称重的负担。</p><p>4  于是就有人一直在思考，我为什么要保存这个可恶的session呢，让每个客户端去保存该多好</p><p>可是如果不保存这些session id 怎么验证客户端发给我的session id 的确是我生成的呢？如果不去验证，我们都不知道他们是不是合法的登录用户，那些不怀好意的家伙们就能伪造session id 为所欲为了</p><p>哦，对了 关键点就是验证</p><p>比如说，小F已经登陆了系统，我给他发一个令牌（Token），里面包含了小F的user id ，下一次小F再次通过Http请求访问我的时候，把这个token通过http header带过来不就可以了。</p><p>不过这和session id 没有本质区别啊 ，任何人都可以伪造，所以我的想点办法让别人伪造不聊</p><p>那就对数据做一个签名吧，比如说我用HMAC-SHA256算法，加上一个只我才知道的秘钥，对数据做一个签名，把这个签名和数据一起作为token，由于秘钥被人不知道，就无法伪造了。</p><p>这个token我们不保存，当小F把这个token发给我的时候，我在用同样的算法和密钥对数据在计算一次签名，和token中带的签名做个比较，如果相同，我就知道小F已经登陆过了，并且可以直接渠道小F的user id，若果不相同，数据部分肯定被人篡改过，我就发偶素发送者：对不起，没有验证。</p><p>Token中的数据是明文保存的（虽然我会用Base64坐下编码，但那不是加密），还是可以被别人看到的，所以我不能在其中保存像密码这样的敏感信息</p><p>当然，如果一根人的token被别人偷走了，那我也没办法，我也会任务小偷就是合法用户，这其实和一个人的session id 被别人偷走是一样的。</p><p>这样一来，我就不保存session id 了我只是生成token，然后验证token。用计算时间换区存储空间</p><p>解除了session id 这个负担，可以说是一身轻松，我的机器集群现在可以轻松的做水平扩展，用户访问量增大，直接加机器就行。这种无状态的感觉实在太好了！</p><h3 id="cookie"><a href="#cookie" class="headerlink" title="cookie"></a>cookie</h3><p>cookie是一个非常具体的东西，指的就是浏览器里能永久存储的一种数据，仅仅是浏览器实现的一种数据存储功能。</p><p>cookie有服务器生成，发送给浏览器，浏览器吧cookie一kv的形式保存到某个目录下的文本文件内，下一次请求同一网站时会把该cookie发送给服务器。由于cookie是存在客户端上的没所以浏览器加入了一些限制确保cookie不会给恶意使用，同事不会占据太多磁盘空间。所以每个域的cookie数量是有限的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;原文链接：&lt;a href=&quot;https://www.cnblogs.com/moyand/p/9047978.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.cnblogs.com/moyand/p/9047978.html
      
    
    </summary>
    
    
      <category term="web" scheme="http://yoursite.com/child/tags/web/"/>
    
  </entry>
  
  <entry>
    <title>mysql-innodb的事务管理与锁</title>
    <link href="http://yoursite.com/child/2019/11/23/mysql-innodb%E7%9A%84%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86%E4%B8%8E%E9%94%81/"/>
    <id>http://yoursite.com/child/2019/11/23/mysql-innodb的事务管理与锁/</id>
    <published>2019-11-22T16:00:00.000Z</published>
    <updated>2020-03-31T15:03:55.991Z</updated>
    
    <content type="html"><![CDATA[<p>典型的事务场景：下单、转账</p><p><strong>事物的定义：事务是DBMS执行过程中的一个逻辑单位，由一个有限的数据库操作序列构成</strong></p><p>MYSQL中支持事务的数据引擎：innodb  ndb</p><h5 id="1、数据库事务的四大特性是什么？"><a href="#1、数据库事务的四大特性是什么？" class="headerlink" title="1、数据库事务的四大特性是什么？"></a>1、数据库事务的四大特性是什么？</h5><p>原子性  Atomicity   由undo log保证</p><p>一致性  Consistent   数据完整性</p><p>隔离性   Isolation  不同事务之间处理同一段数据应当是隔离的互不干扰的</p><p>持久性   Durable  redo log</p><p><strong>原子性、隔离性和持久性最终都是为了实现一致性。</strong></p><h5 id="2、什么时候会出现事务、结束事务？"><a href="#2、什么时候会出现事务、结束事务？" class="headerlink" title="2、什么时候会出现事务、结束事务？"></a>2、什么时候会出现事务、结束事务？</h5><p>当我们执行单条语句的时候，会默认开启事务</p><p>mysql 参数 autocommit 默认为 on 开启状态，执行单条查询语句不需要显示的声明事务、提交事务</p><p>show global VARIABLE like ‘autocommit’  显示该参数的全局值</p><p>show session VARIABLE like ‘autocommit’ 显示当前会话该参数的值</p><p>set session autocommit=off; 关闭autocommit后，需要手动提交</p><p><strong>手动开启事务，两种方式</strong>  </p><p>start TRANSACATION;    </p><p> begin; </p><p>事务的结束：</p><p>提交结束 commit;</p><p>回滚结束 rollback；</p><p>连接断开 会话结束 -&gt; 事务结束</p><h5 id="3、事务并发带来的问题有哪些？"><a href="#3、事务并发带来的问题有哪些？" class="headerlink" title="3、事务并发带来的问题有哪些？"></a>3、事务并发带来的问题有哪些？</h5><p>脏读（读未提交）：事务A执行一条查询，事务B修改了这部分数据但没提交，导致A读取到事务B没有提交的数据，事务B可能回滚导致事务A读取到的数据是脏数据。</p><p>不可重复读：事务A执行一条查询后，事务B对这部分数据执行了update/delete并提交了，导致事务A再次查询时与上一次的查询结果不一致，称为不可重复度。</p><p>幻读：事务A执行一条范围查询后，事务B在此范围insert了若干条数据，导致事务A再次执行该查询是记录数增多，产生幻读。</p><p>以上三个问题称为数据库的读一致性问题，必须由数据库自己提供一定的事务隔离机制来解决</p><h5 id="4、SQL92-标准"><a href="#4、SQL92-标准" class="headerlink" title="4、SQL92 标准"></a>4、SQL92 标准</h5><p>许多数据库专家联合制定了一个标准，建议数据库厂商都按照这个标准提供一定的事务隔离级别，来解决事务并发问题。</p><p>看一下SQL92标准的官网：<a href="http://www.contrib.andrew.cmu.edu/~shadow/sql/sql1992.txt" target="_blank" rel="noopener">http://www.contrib.andrew.cmu.edu/~shadow/sql/sql1992.txt</a></p><p>在官网搜索_iso，会看到一张表格：</p><table><thead><tr><th style="text-align:left">Level</th><th>P1</th><th>P2</th><th>P3</th></tr></thead><tbody><tr><td style="text-align:left">READ UNCOMMITTED</td><td>Possible</td><td>Possible</td><td>Possible</td></tr><tr><td style="text-align:left">READ COMMITTED</td><td>Not Possible</td><td>Possible</td><td>Possible</td></tr><tr><td style="text-align:left">REPEATABLE READ</td><td>Not Possible</td><td>Not Possible</td><td>Possible</td></tr><tr><td style="text-align:left">SERIALIZABLE</td><td>Not Possible</td><td>Not Possible</td><td>Not Possible</td></tr></tbody></table><p>这里定义了四个隔离级别，右边的P1P2P3就是代表事务并发的三个问题，脏读，不可重复度，幻读。Possible表示在这个隔离级别下该问题有可能发生，Not Possible表示解决了该问题。</p><ul><li>Read Uncommited 未提交读</li></ul><p>顾名思义，事务可以读取到其他事物未提交的数据，使用这种隔离级别其实并未解决以上的任何问题</p><ul><li>Read Commited  已提交读</li></ul><p>只能读到其他事物已经提交了的数据，解决了脏读问题</p><ul><li>Repeatable Read  可重复读</li></ul><p>事务重复读取，保证重复读取数据一致，解决了不可重复度的问题</p><ul><li>Serializable 串行化</li></ul><p>事务串行化运行，没有并发自然没有不一性问题产生，但是严重影响效率，不推荐使用</p><p>不同的厂商或者数据库引擎在实现以上标准时会有一些差异。Oracle只实现了两种RC和Serializable，Innodb对以上的四种隔离级别都进行了实现，值得一提的是，innodb 对Repeatable Read 这一级别的实现同时也解决了幻读的问题，因此这一级别是innodb的默认事务隔离级别。</p><h5 id="5、innodb是如何实现的呢"><a href="#5、innodb是如何实现的呢" class="headerlink" title="5、innodb是如何实现的呢?"></a>5、innodb是如何实现的呢?</h5><p>如果要解决读一致性的问题 ，保证一个事务前后两次读取数据一致，实现事务隔离级别，应该怎么做 </p><p>方案一 ： LBCC 基于锁的并发控制</p><p>方案二： MVCC 基于多版本的并发控制  生成一个数据请求时间点的一致性数据，并用这个快照来提供一定级别的一致性读取。</p><p>首先介绍MVCC的实现原理</p><p>从三个隐藏字段开始</p><p>InnoDB为每行记录都实现了三个隐藏字段</p><p>DB_ROW_ID   6字节：行标识</p><p>DB_TRX_ID  6字节：插入或更新行的最后一个事务ID，自动递增（理解为创建版本号）</p><p>DB_ROLL_PTR：  7字节：回滚指针（理解为删除版本号）</p><p>mvcc核心思想，一个事务根据自己的事务id进行判断，</p><p>只能查询到创建版本号比我的事务ID小的  和  删除版本号比我事务ID大的记录  </p><p>innodb的锁：</p><p>锁的模式：</p><p>行锁—共享锁 和 排它锁</p><p>表所 — 意向排他锁 和 意向共享锁</p><p>为什么需要 表级别的意向锁</p><p>意向锁可以理解为表的锁标志</p><p>一个事务尝试给一张表加上表锁，前提是没有其他任何事务已经锁定了这张表的任意一行，那么需要检索所有的行确定没有锁。意向锁是又来避免这种检索的</p><p>锁的作用：</p><p>锁的算法：在什么时候锁定什么范围</p><p>记录锁</p><p>间隙锁</p><p>邻键锁</p><p>插入意向锁 </p><p>自增锁</p><p>解决资源竞争的问题</p><p>锁到底锁住了什么？</p><p>锁住的是索引</p><p>问题1 一张表没有索引或者没用到索引为什么会锁表？</p><p>一张表不可能没有索引，没有显示声明索引的表，隐藏的row_id字段会作为聚集索引。。。如果查询语句没有用到索引，那只能走全表扫描，就会锁住全表</p><p>问题2 为什么锁住辅助索引，会导致主键索引也被锁住？</p><p>回表</p><p>记录锁 —- 唯一索引 等值查询 精确匹配时</p><p>间隙锁—- 锁定记录不存在的范围区间，主要用来控制插入，不同间隙的锁互相不影响</p><p>邻键锁 —- 锁定查询的范围，包含记录和区间，执行了范围查询时会用到邻键锁，是行锁的默认锁定方式，以上两种是邻键锁的特殊情况</p><p>innodb在RR实现里就解决幻读问题 就是依靠邻 键锁</p><p>共享锁和排他锁   行所</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;典型的事务场景：下单、转账&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;事物的定义：事务是DBMS执行过程中的一个逻辑单位，由一个有限的数据库操作序列构成&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;MYSQL中支持事务的数据引擎：innodb  ndb&lt;/p&gt;
&lt;h5 id=&quot;1、数据库事务的四大
      
    
    </summary>
    
    
      <category term="数据库" scheme="http://yoursite.com/child/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>分布式-vagrant&amp;virtualBox使用说明</title>
    <link href="http://yoursite.com/child/2019/11/22/%E5%88%86%E5%B8%83%E5%BC%8F-vagrant&amp;virtualBox%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/"/>
    <id>http://yoursite.com/child/2019/11/22/分布式-vagrant&amp;virtualBox使用说明/</id>
    <published>2019-11-21T16:00:00.000Z</published>
    <updated>2019-12-10T13:21:59.433Z</updated>
    
    <content type="html"><![CDATA[<p>vagrant是一个工具，用于创建和部署虚拟化开发环境的，能与virtualVM、virtualBox等虚拟机软件搭配使用。</p><p>拿VirtualBox举例，VirtualBox会开放一个创建虚拟机的接口，Vagrant会利用这个接口创建虚拟机，并且通过Vagrant来管理，配置和自动安装虚拟机。</p><ul><li><p>安装最新版virtualBox</p></li><li><p>安装最新版vagrant</p></li></ul><h4 id="1、创建虚拟机"><a href="#1、创建虚拟机" class="headerlink" title="1、创建虚拟机"></a>1、创建虚拟机</h4><p>首先下载镜像，我们使用vagrant box add 命令进行下载</p><p>Vagrant 的 box，是一个打包好的单一文件，其中包含了一个完整系统的虚拟机相关数据。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 添加virtualBox，名字可自定义，使用官方的命名不需要url，下载速度慢，建议使用国内镜像源下载</span><br><span class="line">vagrant box add &#123;name&#125; &#123;url&#125;</span><br><span class="line"><span class="meta">#</span> 列出已下载所有的virtualBox</span><br><span class="line">vagrant box list</span><br><span class="line"><span class="meta">#</span> 移除指定的virtualBox</span><br><span class="line">vagrant box remove &#123;name&#125;</span><br></pre></td></tr></table></figure><p>本文使用中国科技大学的centos7镜像源，在cmd任意目录下执行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant box add centos7 http://mirrors.ustc.edu.cn/centos-cloud/centos/7/vagrant/x86_64/images/CentOS-7-x86_64-Vagrant-1708_01.VirtualBox.box</span><br></pre></td></tr></table></figure><p>在用户目录下新建文件夹 如：E:/vagrant/，在目录下执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vgrant init</span><br></pre></td></tr></table></figure><p>会生成一个vagrantfile文件，该文件是将要创建的虚拟机属性配置文件，如下修改文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">Vagrant.configure(&quot;2&quot;) do |config|</span><br><span class="line">   (1..3).each do |i|</span><br><span class="line">        config.vm.define &quot;node#&#123;i&#125;&quot; do |node|</span><br><span class="line">            # 设置虚拟机的Box</span><br><span class="line">            node.vm.box = &quot;centos7&quot;</span><br><span class="line"></span><br><span class="line">            # 设置虚拟机的主机名</span><br><span class="line">            node.vm.hostname=&quot;node#&#123;i&#125;&quot;</span><br><span class="line"></span><br><span class="line"># 设置虚拟机的IP</span><br><span class="line">            node.vm.network &quot;public_network&quot;, ip: &quot;192.168.2.#&#123;200+i&#125;&quot;</span><br><span class="line"></span><br><span class="line">            # VirtaulBox相关配置</span><br><span class="line">            node.vm.provider &quot;virtualbox&quot; do |v|</span><br><span class="line">                # 设置虚拟机的名称</span><br><span class="line">                v.name = &quot;node#&#123;i&#125;&quot;</span><br><span class="line">                # 设置虚拟机的内存大小</span><br><span class="line">                v.memory = 2048</span><br><span class="line">                # 设置虚拟机的CPU个数</span><br><span class="line">                v.cpus = 1</span><br><span class="line">            end</span><br><span class="line">        end</span><br><span class="line">   end</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>保存后，在当前目录执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant up</span><br></pre></td></tr></table></figure><p>vagrant会根据vagrantfile创建3台虚拟机并启动，本文将采用桥接网卡的网络模型，因此在virtualBox中将虚拟机关闭之后，对网络进行设置，取消默认勾选的NAT网络，只剩下桥接网卡。</p><h4 id="2、网络模型选择"><a href="#2、网络模型选择" class="headerlink" title="2、网络模型选择"></a>2、网络模型选择</h4><h5 id="2-1-网络选型原则"><a href="#2-1-网络选型原则" class="headerlink" title="2.1 网络选型原则"></a>2.1 网络选型原则</h5><p>​        第一：每个网络只负载一种业务类型的数据流量，功能单一化。例如连接外网用一个网络、虚拟机之间互通用一个网络、虚拟机与主机之间互通又是一个网络。这样的话可使每种网络上的数据流量比较纯净，同时也可以避免因为网络故障而影响到全部的业务。</p><p>​    第二：在保证网络功能的前提下，单一的网络要保证最小的连通性、最大的隔离性。比如用于连接外网的网络，最好禁止掉连通宿主机，其它虚拟机这种额外的功能，可最大程序的提高效率。</p><p>​    第三：网络的独立性。当有多种技术可以达成某种网络功能时，选型时应选择对外部环境依赖程度最小、独立性最高的实现方式，避免因外宿主机换了一个无线网络环境，而影响到在宿主机上虚拟出来的网络。</p><p>​    第四：最后一条就是效率。当有多种选择时，数据流动路径最短的那一种，往住是效率最高的一种。</p><h5 id="2-2-四种网络模式连通性汇总列表"><a href="#2-2-四种网络模式连通性汇总列表" class="headerlink" title="2.2 四种网络模式连通性汇总列表"></a>2.2 四种网络模式连通性汇总列表</h5><p>“o”表示连接，“x”表示不通。前提条件是用VirtualBox创建出网络后，没有进行额外的配置，NAT网络没有进行端口映射、仅主机网络没有进行连接共享等。理论上，通过一定的技术手段，所有的模式对所有的网络都是可以连通的。</p><p><img src="https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/%E7%BD%91%E7%BB%9C/virtualBox-net-1.png" alt></p><h5 id="2-3-VirtualBox四种网络模式独立性"><a href="#2-3-VirtualBox四种网络模式独立性" class="headerlink" title="2.3 VirtualBox四种网络模式独立性"></a>2.3 VirtualBox四种网络模式独立性</h5><p>独立性即对外部环境依赖性，分成高、中，低三档，越高说明越依赖于外部环境。</p><p><img src="https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/%E7%BD%91%E7%BB%9C/virtualBox-net-2.png" alt></p><h5 id="2-4-四种网络模式的典型应用"><a href="#2-4-四种网络模式的典型应用" class="headerlink" title="2.4 四种网络模式的典型应用"></a>2.4 四种网络模式的典型应用</h5><p>例如想用VirtualBox创建虚拟机，以安装部署OpenStack,那么应该用VirtualBox创建四个网络，每个网络都有单独的目的，每种网络各司其职，同时对外部的依赖性降到最低。</p><p><img src="https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/%E7%BD%91%E7%BB%9C/virtualBox-net-3.png" alt></p><h4 id="3、远程登录"><a href="#3、远程登录" class="headerlink" title="3、远程登录"></a>3、远程登录</h4><p>本文选用的桥接网卡，虚拟机将与宿主机共享网络，在一个网络之中的设备（宿主机以及同一路由器下的设备）都能使用桥接网卡的ip地址远程登录到虚拟机中，端口默认22，可以自行修改。</p><p>在登陆之前需要修改虚拟机sshd配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/ssh/sshd_config</span><br><span class="line"><span class="meta">#</span> 修改项如下</span><br><span class="line">PasswordAuthentication=yes</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>重启sshd服务</span><br><span class="line">service sshd restart</span><br></pre></td></tr></table></figure><p>笔者宿主机ip为192.168.2.110</p><p>查看node1虚拟机桥接网卡ip为 192.168.2.112，因此执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -p 22 root@192.168.2.112</span><br></pre></td></tr></table></figure><p>输入密码完成登录。</p><p>参考：</p><p><a href="https://blog.csdn.net/dkfajsldfsdfsd/article/details/79444582" target="_blank" rel="noopener">VirtualBox四种网络模式及典型配置</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;vagrant是一个工具，用于创建和部署虚拟化开发环境的，能与virtualVM、virtualBox等虚拟机软件搭配使用。&lt;/p&gt;
&lt;p&gt;拿VirtualBox举例，VirtualBox会开放一个创建虚拟机的接口，Vagrant会利用这个接口创建虚拟机，并且通过Vagra
      
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/child/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>分布式-vagrantfile简析</title>
    <link href="http://yoursite.com/child/2019/11/22/%E5%88%86%E5%B8%83%E5%BC%8F-vagrantfile%E7%AE%80%E6%9E%90/"/>
    <id>http://yoursite.com/child/2019/11/22/分布式-vagrantfile简析/</id>
    <published>2019-11-21T16:00:00.000Z</published>
    <updated>2019-12-10T13:21:30.803Z</updated>
    
    <content type="html"><![CDATA[<p>参考：</p><p><a href="https://blog.csdn.net/u011781521/article/details/80291765" target="_blank" rel="noopener">Vagrant的配置文件Vagrantfile详解</a></p><h5 id="1、box设置"><a href="#1、box设置" class="headerlink" title="1、box设置"></a>1、box设置</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config.vm.box = &quot;centos7&quot;</span><br></pre></td></tr></table></figure><p>该名称是再使用 vagrant init 中后面跟的名字。</p><h5 id="2、hostname设置"><a href="#2、hostname设置" class="headerlink" title="2、hostname设置"></a>2、hostname设置</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config.vm.hostname = &quot;node1&quot;</span><br></pre></td></tr></table></figure><p>设置hostname非常重要，因为当我们有很多台虚拟服务器的时候，都是依靠hostname來做识别的。比如，我安装了centos1,centos2 两台虚拟机，再启动时，我可以通过vagrant up centos1来指定只启动哪一台。</p><h5 id="3、虚拟机网络设置"><a href="#3、虚拟机网络设置" class="headerlink" title="3、虚拟机网络设置"></a>3、虚拟机网络设置</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">//Host-only模式</span><br><span class="line">config.vm.network &quot;private_network&quot;, ip: &quot;192.168.10.11&quot;</span><br><span class="line"></span><br><span class="line">//Bridge模式</span><br><span class="line">config.vm.network &quot;public_network&quot;, ip: &quot;10.1.2.61&quot;</span><br></pre></td></tr></table></figure><p>Vagrant的网络连接方式有三种：</p><ul><li><p>NAT : 缺省创建，用于让vm可以通过host转发访问局域网甚至互联网。</p></li><li><p>host-only : 只有主机可以访问vm，其他机器无法访问它。</p></li><li><p>bridge : 此模式下vm就像局域网中的一台独立的机器，可以被其他机器访问。</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">config.vm.network :private_network, ip: &quot;192.168.33.10&quot;</span><br><span class="line"></span><br><span class="line">配置当前vm的host-only网络的IP地址为192.168.33.10</span><br></pre></td></tr></table></figure><p>host-only 模式的IP可以不指定，而是采用dhcp自动生成的方式，如 :</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config.vm.network &quot;private_network&quot;, type: &quot;dhcp”</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#创建一个bridge桥接网络，指定IP</span><br><span class="line">config.vm.network &quot;public_network&quot;, ip: &quot;192.168.0.17&quot;</span><br><span class="line">#创建一个bridge桥接网络，指定桥接适配器</span><br><span class="line">config.vm.network &quot;public_network&quot;, bridge: &quot;en1: Wi-Fi (AirPort)&quot;</span><br><span class="line">#创建一个bridge桥接网络，不指定桥接适配器</span><br><span class="line">config.vm.network &quot;public_network&quot;</span><br></pre></td></tr></table></figure><h5 id="4、同步目录设置"><a href="#4、同步目录设置" class="headerlink" title="4、同步目录设置"></a>4、同步目录设置</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config.vm.synced_folder &quot;D:/xxx/code&quot;, &quot;/home/www/&quot;</span><br></pre></td></tr></table></figure><p>前面的路径(D:/xxx/code)是本机代码的地址，后面的地址就是虚拟机的目录。虚拟机的/vagrant目录默认挂载宿主机的开发目录(可以在进入虚拟机机后，使用df -h 查看)，这是在虚拟机启动时自动挂载的。我们还可以设置额外的共享目录，上面这个设定，第一个参数是宿主机的目录，第二个参数是虚拟机挂载的目录。</p><h5 id="5、端口转发设置"><a href="#5、端口转发设置" class="headerlink" title="5、端口转发设置"></a>5、端口转发设置</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config.vm.network :forwarded_port, guest: 80, host: 8080</span><br></pre></td></tr></table></figure><p>上面的配置把宿主机上的8080端口映射到客户虚拟机的80端口，例如你在虚拟机上使用nginx跑了一个Go应用，那么你在host上的浏览器中打开<a href="http://localhost:8080时，Vagrant就会把这个请求转发到虚拟机里跑在80端口的nginx服务上。不建议使用该方法，因为涉及端口占用问题，常常导致应用之间不能正常通信，建议使用Host-only和Bridge方式进行设置。" target="_blank" rel="noopener">http://localhost:8080时，Vagrant就会把这个请求转发到虚拟机里跑在80端口的nginx服务上。不建议使用该方法，因为涉及端口占用问题，常常导致应用之间不能正常通信，建议使用Host-only和Bridge方式进行设置。</a></p><p>guest和host是必须的，还有几个可选属性：</p><ul><li>guest_ip：字符串，vm指定绑定的Ip，缺省为0.0.0.0</li><li>host_ip：字符串，host指定绑定的Ip，缺省为0.0.0.0</li><li>protocol：字符串，可选TCP或UDP，缺省为TCP</li></ul><h5 id="6、定义vm的configure配置节点-一个节点就是一个虚拟机"><a href="#6、定义vm的configure配置节点-一个节点就是一个虚拟机" class="headerlink" title="6、定义vm的configure配置节点(一个节点就是一个虚拟机)"></a>6、定义vm的configure配置节点(一个节点就是一个虚拟机)</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">config.vm.define :mysql do |mysql_config|</span><br><span class="line">...</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>表示在config配置中，定义一个名为mysql的vm配置，该节点下的配置信息命名为mysql_config； 如果该Vagrantfile配置文件只定义了一个vm，这个配置节点层次可忽略。</p><p>还可以在一个Vagrantfile文件里建立多个虚拟机，一般情况下，你可以用多主机功能完成以下任务：</p><ul><li>分布式的服务，例如网站服务器和数据库服务器</li><li>分发系统</li><li>测试接口</li><li>灾难测试  </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Vagrant.configure(&quot;2&quot;) do |config|</span><br><span class="line">  config.vm.define &quot;web&quot; do |web|</span><br><span class="line">    web.vm.box = &quot;apache&quot;</span><br><span class="line">  end</span><br><span class="line">  config.vm.define &quot;db&quot; do |db|</span><br><span class="line">    db.vm.box = &quot;mysql&quot;</span><br><span class="line">  end</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>当定义了多主机之后，在使用vagrant命令的时候，就需要加上主机名，例如vagrant ssh web；也有一些命令，如果你不指定特定的主机，那么将会对所有的主机起作用，比如vagrant up；你也可以使用表达式指定特定的主机名，例如vagrant up /follower[0-9]/。</p><h5 id="7、通用数据-设置一些基础数据，供配置信息中调用。"><a href="#7、通用数据-设置一些基础数据，供配置信息中调用。" class="headerlink" title="7、通用数据 设置一些基础数据，供配置信息中调用。"></a>7、通用数据 设置一些基础数据，供配置信息中调用。</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">app_servers = &#123;</span><br><span class="line">    :service1 =&gt; &apos;192.168.33.20&apos;,</span><br><span class="line">    :service2 =&gt; &apos;192.168.33.21&apos;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里是定义一个hashmap，以key-value方式来存储vm主机名和ip地址。</p><h5 id="8、配置信息"><a href="#8、配置信息" class="headerlink" title="8、配置信息"></a>8、配置信息</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ENV[&quot;LC_ALL&quot;] = &quot;en_US.UTF-8&quot;</span><br><span class="line">指定vm的语言环境，缺省地，会继承host的locale配置</span><br><span class="line">Vagrant.configure(&quot;2&quot;) do |config|</span><br><span class="line">    # ...</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>参数2，表示的是当前配置文件使用的vagrant configure版本号为Vagrant 1.1+,如果取值为1，表示为Vagrant 1.0.x Vagrantfiles，旧版本暂不考虑，记住就写2即可。</p><p>do … end 为配置的开始结束符，所有配置信息都写在这两段代码之间。 config是为当前配置命名，你可以指定任意名称，如myvmconfig，在后面引用的时候，改为自己的名字即可。</p><h5 id="9、vm提供者配置"><a href="#9、vm提供者配置" class="headerlink" title="9、vm提供者配置"></a>9、vm提供者配置</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">config.vm.provider :virtualbox do |vb|</span><br><span class="line">     # ...</span><br><span class="line">end</span><br></pre></td></tr></table></figure><h5 id="10-vm-provider通用配置"><a href="#10-vm-provider通用配置" class="headerlink" title="10 vm provider通用配置"></a>10 vm provider通用配置</h5><p>虚机容器提供者配置，对于不同的provider，特有的一些配置，此处配置信息是针对virtualbox定义一个提供者，命名为vb，跟前面一样，这个名字随意取，只要节点内部调用一致即可。</p><p>配置信息又分为通用配置和个性化配置，通用配置对于不同provider是通用的，常用的通用配置如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">vb.name = &quot;centos7&quot;</span><br><span class="line"></span><br><span class="line">指定vm-name，也就是virtualbox管理控制台中的虚机名称。如果不指定该选项会生成一个随机的名字，不容易区分。</span><br><span class="line"></span><br><span class="line">vb.gui = true</span><br><span class="line"></span><br><span class="line">vagrant up启动时，是否自动打开virtual box的窗口，缺省为false</span><br><span class="line"></span><br><span class="line">vb.memory = &quot;1024&quot;</span><br><span class="line"></span><br><span class="line">指定vm内存，单位为MB</span><br><span class="line"></span><br><span class="line">vb.cpus = 2</span><br><span class="line"></span><br><span class="line">设置CPU个数</span><br></pre></td></tr></table></figure><h5 id="11-vm-provider个性化配置-virtualbox"><a href="#11-vm-provider个性化配置-virtualbox" class="headerlink" title="11 vm provider个性化配置(virtualbox)"></a>11 vm provider个性化配置(virtualbox)</h5><p>上面的provider配置是通用的配置，针对不同的虚拟机，还有一些的个性的配置，通过vb.customize配置来定制。</p><p>对virtual box的个性化配置，可以参考：VBoxManage modifyvm 命令的使用方法。详细的功能接口和使用说明，可以参考virtualbox官方文档。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">修改vb.name的值</span><br><span class="line">v.customize [&quot;modifyvm&quot;, :id, &quot;--name&quot;, &quot;mfsmaster2&quot;]</span><br><span class="line"></span><br><span class="line">如修改显存，缺省为8M，如果启动桌面，至少需要10M，如下修改为16M：</span><br><span class="line">vb.customize [&quot;modifyvm&quot;, :id, &quot;--vram&quot;, &quot;16&quot;]</span><br><span class="line"></span><br><span class="line">调整虚拟机的内存</span><br><span class="line">vb.customize [&quot;modifyvm&quot;, :id, &quot;--memory&quot;, &quot;1024&quot;]</span><br><span class="line"></span><br><span class="line">指定虚拟CPU个数</span><br><span class="line">vb.customize [&quot;modifyvm&quot;, :id, &quot;--cpus&quot;, &quot;2&quot;]</span><br><span class="line"></span><br><span class="line">增加光驱：</span><br><span class="line">vb.customize [&quot;storageattach&quot;,:id,&quot;--storagectl&quot;, &quot;IDE Controller&quot;,&quot;--port&quot;,&quot;0&quot;,&quot;--device&quot;,&quot;0&quot;,&quot;--type&quot;,&quot;dvddrive&quot;,&quot;--medium&quot;,&quot;/Applications/VirtualBox.app/Contents/MacOS/VBoxGuestAdditions.iso&quot;]</span><br><span class="line"></span><br><span class="line">注：meduim参数不可以为空，如果只挂载驱动器不挂在iso，指定为“emptydrive”。如果要卸载光驱，medium传入none即可。</span><br><span class="line">从这个指令可以看出，customize方法传入一个json数组，按照顺序传入参数即可。</span><br><span class="line"></span><br><span class="line">json数组传入多个参数</span><br><span class="line">v.customize [&quot;modifyvm&quot;, :id, &quot;--name&quot;, “mfsserver3&quot;, &quot;--memory&quot;, “2048&quot;]</span><br></pre></td></tr></table></figure><h5 id="12-一组相同配置的vm"><a href="#12-一组相同配置的vm" class="headerlink" title="12 一组相同配置的vm"></a>12 一组相同配置的vm</h5><p>前面配置了一组vm的hash map，定义一组vm时，使用如下节点遍历。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#遍历app_servers map，将key和value分别赋值给app_server_name和app_server_ip</span><br><span class="line">app_servers.each do |app_server_name, app_server_ip|</span><br><span class="line">#针对每一个app_server_name，来配置config.vm.define配置节点，命名为app_config</span><br><span class="line">    config.vm.define app_server_name do |app_config|</span><br><span class="line">#此处配置，参考config.vm.define</span><br><span class="line">    end</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>如果不想定义app_servers，下面也是一种方案:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">(1..3).each do |i|</span><br><span class="line">        config.vm.define &quot;app-#&#123;i&#125;&quot; do |node|</span><br><span class="line">        app_config.vm.hostname = &quot;app-#&#123;i&#125;.vagrant.internal&quot;</span><br><span class="line">        app_config.vm.provider &quot;virtualbox&quot; do |vb|</span><br><span class="line">            vb.name = app-#&#123;i&#125;</span><br><span class="line">        end</span><br><span class="line">  end</span><br><span class="line">end</span><br></pre></td></tr></table></figure><h5 id="13-provision任务"><a href="#13-provision任务" class="headerlink" title="13 provision任务"></a>13 provision任务</h5><p>你可以编写一些命令，让vagrant在启动虚拟机的时候自动执行，这样你就可以省去手动配置环境的时间了。</p><ul><li><p>脚本何时会被执行 </p><ul><li>第一次执行vagrant up命令</li><li>执行vagrant provision命令</li><li>执行vagrant reload –provision或者vagrant up –provision命令</li><li>你也可以在启动虚拟机的时候添加–no-provision参数以阻止脚本被执行</li></ul></li><li><p>provision任务是什么？</p></li></ul><p>provision任务是预先设置的一些操作指令，格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">config.vm.provision 命令字 json格式参数</span><br><span class="line">config.vm.provion 命令字 do |s|</span><br><span class="line">    s.参数名 = 参数值</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>每一个 config.vm.provision 命令字 代码段，我们称之为一个provisioner。<br>根据任务操作的对象，provisioner可以分为：</p><ul><li>Shell</li><li>File</li><li>Ansible</li><li>CFEngine</li><li>Chef</li><li>Docker</li><li>Puppet</li><li>Salt</li></ul><p>根据vagrantfile的层次，分为：</p><p>configure级：它定义在 Vagrant.configure(“2”) 的下一层次，形如： config.vm.provision …</p><p>vm级：它定义在 config.vm.define “web” do |web| 的下一层次，web.vm.provision …</p><p>执行的顺序是先执行configure级任务，再执行vm级任务，即便configure级任务在vm定义的下面才定义。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Vagrant.configure(&quot;2&quot;) do |config|</span><br><span class="line">  config.vm.provision &quot;shell&quot;, inline: &quot;echo 1&quot;</span><br><span class="line"></span><br><span class="line">  config.vm.define &quot;web&quot; do |web|</span><br><span class="line">    web.vm.provision &quot;shell&quot;, inline: &quot;echo 2&quot;</span><br><span class="line">  end</span><br><span class="line"></span><br><span class="line">  config.vm.provision &quot;shell&quot;, inline: &quot;echo 3&quot;</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">==&gt; default: &quot;1&quot;</span><br><span class="line">==&gt; default: &quot;2&quot;</span><br><span class="line">==&gt; default: &quot;3&quot;</span><br></pre></td></tr></table></figure><ul><li>如何使用</li></ul><p><strong>单行脚本</strong></p><p>helloword只是一个开始，对于inline模式，命令只能在写在一行中。</p><p>单行脚本使用的基本格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config.vm.provision &quot;shell&quot;, inline: &quot;echo fendo&quot;</span><br></pre></td></tr></table></figure><p>shell命令的参数还可以写入do … end代码块中，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">config.vm.provision &quot;shell&quot; do |s|</span><br><span class="line">  s.inline = &quot;echo hello provision.&quot;</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p><strong>内联脚本</strong></p><p>如果要执行脚本较多，可以在Vagrantfile中指定内联脚本，在Vagrant.configure节点外面，写入命名内联脚本：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$script = &lt;&lt;SCRIPT</span><br><span class="line">echo I am provisioning...</span><br><span class="line">echo hello provision.</span><br><span class="line">SCRIPT</span><br></pre></td></tr></table></figure><p>然后，inline调用如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config.vm.provision &quot;shell&quot;, inline: $script</span><br></pre></td></tr></table></figure><p><strong>外部脚本</strong></p><p>也可以把代码写入代码文件，并保存在一个shell里，进行调用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config.vm.provision &quot;shell&quot;, path: &quot;script.sh&quot;</span><br></pre></td></tr></table></figure><p>script.sh的内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo hello provision.</span><br></pre></td></tr></table></figure><p>#### </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;参考：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/u011781521/article/details/80291765&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Vagrant的配置文件Vagrantfile详解&lt;/
      
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/child/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>jvm-垃圾收集器</title>
    <link href="http://yoursite.com/child/2019/11/21/jvm-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"/>
    <id>http://yoursite.com/child/2019/11/21/jvm-垃圾回收/</id>
    <published>2019-11-20T16:00:00.000Z</published>
    <updated>2020-03-20T07:24:23.888Z</updated>
    
    <content type="html"><![CDATA[<p>垃圾对象检测：</p><ul><li>引用计数发</li><li>可达性分析</li></ul><p>GC root由哪些对象组成</p><ol><li>本地方法栈中引用的对象</li><li>虚拟机栈中引用的对象</li><li>方法区中类变量引用的对象</li><li>方法区中的常量引用的对象</li></ol><h3 id="1-垃圾收集算法和收集器"><a href="#1-垃圾收集算法和收集器" class="headerlink" title="1. 垃圾收集算法和收集器"></a>1. 垃圾收集算法和收集器</h3><p>垃圾收集算法有哪些：</p><ol><li>标记-清除   产生内存碎片、效率不高</li><li>标记-整理   效率低</li><li>复制   空间利用率低  </li></ol><p>新生代（Young区）对象朝生夕死，GC时存活概率小，所以适合复制算法</p><p>老年代（old区）对象，则适合使用标记清除或者标记整理</p><p>垃圾收集器有哪些</p><p>评价一个垃圾收集器优劣的指标是 吞吐量 和 停顿时间</p><p>一、新生代收集器</p><ol><li>Serial 收集器</li></ol><p>历史悠久的收集器，单线程运行，运行时会阻塞其他线程，使用复制算法，因此适用于新生代垃圾回收</p><ol start="2"><li>ParNew 收集器</li></ol><p>Serial收集器的并行版，同样采用复制算法，适用于新生代，单CPU性能比Serial差</p><p>运行在server模式下的虚拟中首选的新生代收集器</p><ol start="3"><li>Parallel Scavenge 收集器</li></ol><p>注重吞吐量，</p><p>吞吐量 = 程序运行时间/(程序运行时间+垃圾回收时间)‘</p><p>二、老年代收集器</p><ol><li>Serial old</li></ol><p>复制算法的实现，单线程运行</p><ol start="2"><li>Paraller Old</li></ol><p>最关注的点事吞吐量</p><ol start="3"><li>CMS 并发收集器</li></ol><p>Concurrent Mark Sweep—并发标记清理</p><p>并发：用户线程和垃圾回收线程一起执行</p><p>并行：多条垃圾回收线程同时执行</p><p>CMS 最关注的点是GC停顿时间，所以优点是低停顿时间（因为并发收集）</p><p>缺点就是会产生大量的内存碎片（因为采用标记-清理算法），且并发阶段会吞吐量降低</p><p>流程：初始标记-&gt;并发标记-&gt;重新标记-&gt; 并发清理</p><blockquote><p>初始标记，stw，标记的事GCroot</p><p>并发标记，与用户线程一起执行，执行可达性分析，标记不可达对象</p><p>重新标记，stw，标记并发标记阶段产生的新垃圾</p><p>并发清理，用户线程一起执行，回收标记的对象</p></blockquote><p>使用  -XX:+UseConcMarkSweepGC 开启CMS</p><p>三、G1  Garbage-First</p><p>整体上属于标记-整理算法的实现，不会产生内存碎片</p><p>比CMS先进的地方在于用户可以设置停顿时间的大小，G1会按照用户的设置的事件指定回收计划</p><p>G1可同时用于新生代和老年代的垃圾回收，核心在于对堆内存的重新划分，不同的内存区域对于G1来说只是逻辑上的区分，在物理层面，G1将内存划分成一个个的region统一进行管理。</p><p>G1收集器会先收集存活对象少的区域，也就是垃圾对象多的区域，这样可以有大量的空间可以释放出来，这就 </p><p>是Garbage First的由来 </p><p><img src="https://zzk-markdown.oss-cn-hangzhou.aliyuncs.com/jvm/gc/1584582498419.png" alt="1584582498419"></p><p>执行流程为：初始标记–&gt; 并发标记 –&gt; 最终标记 –&gt; 筛选回收 </p><blockquote><p>初始标记：stw，标记GC ROOT</p><p>并发标记：与用户线程并发执行，执行可达性分析</p><p>最终标记：stw，标记并发标记阶段用户线程产生的新垃圾</p><p>筛选回收：stw，对各个Region的回收价值和回收成本进行排序，根据用户设定的停顿时间指定回收计划</p></blockquote><p>总结：</p><p>Serial 和Serial Old 为串行收集器，适用于<strong><em>内存较小的嵌入式设备</em></strong></p><p>Parallel 和 Parallel Old 为并行收集器，吞吐量优先的收集器组合，适用于<strong><em>科学计算、后台处理</em></strong>等应用场景</p><p>CMS 和 G1 为并发收集器，停顿时间优先，CMS适用于老年代收集（标记-清除），G1适用于整个堆内存垃圾回收（标记-整理），适用与<strong><em>对响应时间要求较高的场景</em></strong>，比如Web</p><p>如何开启：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">（1）串行 </span><br><span class="line">-XX：+UseSerialGC </span><br><span class="line">-XX：+UseSerialOldGC </span><br><span class="line">（2）并行(吞吐量优先)： </span><br><span class="line">-XX：+UseParallelGC </span><br><span class="line">-XX：+UseParallelOldGC </span><br><span class="line">（3）并发收集器(响应时间优先) </span><br><span class="line">-XX：+UseConcMarkSweepGC </span><br><span class="line">-XX：+UseG1GC</span><br></pre></td></tr></table></figure><h3 id="2、GC分类"><a href="#2、GC分类" class="headerlink" title="2、GC分类"></a>2、GC分类</h3><p>Minor GC触发条件：当Eden区满时，触发Minor GC。</p><p>Full GC触发条件：<br>（1）调用System.gc时，系统建议执行Full GC，但是不必然执行<br>（2）老年代空间不足<br>（3）方法去空间不足<br>（4）通过Minor GC后进入老年代的平均大小大于老年代的可用内存<br>（5）由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;垃圾对象检测：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;引用计数发&lt;/li&gt;
&lt;li&gt;可达性分析&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GC root由哪些对象组成&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;本地方法栈中引用的对象&lt;/li&gt;
&lt;li&gt;虚拟机栈中引用的对象&lt;/li&gt;
&lt;li&gt;方法区中类变量引用的对象
      
    
    </summary>
    
    
      <category term="jvm" scheme="http://yoursite.com/child/tags/jvm/"/>
    
  </entry>
  
  <entry>
    <title>mysql-innodb的索引</title>
    <link href="http://yoursite.com/child/2019/11/20/mysql-innodb%E7%9A%84%E7%B4%A2%E5%BC%95/"/>
    <id>http://yoursite.com/child/2019/11/20/mysql-innodb的索引/</id>
    <published>2019-11-19T16:00:00.000Z</published>
    <updated>2020-03-31T15:04:26.257Z</updated>
    
    <content type="html"><![CDATA[<p>数据库索引是数据库管理系统中一个排序的<strong>数据结构</strong>，以协助快速查询更新数据库表中数据</p><p>索引类型：normal普通索引、unique唯一索引、全文索引</p><h4 id="索引用什么数据结构？"><a href="#索引用什么数据结构？" class="headerlink" title="索引用什么数据结构？"></a>索引用什么数据结构？</h4><p>有序列表？不行，插入有问题</p><p>单链表？不行，查找有问题</p><p>AVL树？平衡开销大，数据量大导致树太高，查询效率低下，单页存储数据量小</p><p>B树 不支持范围查询，查询效率不稳定</p><p>B+树  最牛逼</p><h4 id="何为B-树？"><a href="#何为B-树？" class="headerlink" title="何为B+树？"></a>何为B+树？</h4><p>度（分叉数）为m的B+树每个节点能存储的记录数为m-1</p><p>所有的行数据都存在叶子结点，中间节点都是索引值，用来排序。</p><p>innodb的页默认大小为16KB，B+树的索引节点即为一页</p><p>那么一棵高度为2的B+数至少能存多少数据？</p><p>假设主键为自增的bigint类型，占8字节，B+树指针为6字节，一页能存放的索引数量是16KB/14B=1170</p><p>即至少有1170页即18MB存放行数据。而实际上这个这个值应该比计算出来的要大，原因是理论上一个叶节点中可能存放的记录数应该是1-1170行，但是1170是按照<u>主键大小+指针大小</u>计算出来的值，真正的行数据肯定还会有其他的字段，因此叶节点不能存放1170行数据是肯定的，那么多出来的行数据就会使用新的页进行存储并通过指针进行连接，这部分页并没有直接与B+树的中间节点连接，所以也无法进行精确计算。</p><p><a href="https://www.cs.usfca.edu/~galles/visualization/Algorithms.html" target="_blank" rel="noopener">数据结构可视化网站</a></p><h4 id="主键索引有三种情形"><a href="#主键索引有三种情形" class="headerlink" title="主键索引有三种情形"></a>主键索引有三种情形</h4><p>有primaryKey –使用主键组织数据存储</p><p>没有主键，存在unique字段– 使用该unique字段组织数据存储</p><p>没有主键，没有unique字段–使用隐藏字段_rowid组织数据</p><h4 id="使用索引的注意点"><a href="#使用索引的注意点" class="headerlink" title="使用索引的注意点"></a>使用索引的注意点</h4><p>回表查询：命中辅助索引后，根据辅助索引查询到的主键，再去主键索引中查询数据，称为回表</p><p>覆盖索引：组成联合索引的字段包含了所需查询的字段，查询到辅助索引页即可得到结果，无需回表查询</p><ol><li><p>为什么不建议使用Select * ？</p><p>阻止了覆盖索引生效，导致回表查询，使用指定列的sql能节省数据库内存占用，提高数据传输效率</p></li><li><p>索引的最左匹配原则是什么意思？</p><p>有联合索引 index(A,B,C)</p><p>查询时，使用A、A&amp;B 、A&amp;B&amp;C 查询都能命中该索引，且与字段顺序无关，即B&amp;A也能命中</p><p>A&amp;C  B&amp;C  B&amp;C  B  C  都不符合最左匹配原则，不能命中</p></li><li><p>模糊匹配可以用到索引吗？</p><p>like %abc 不能命中索引，like abc%可以命中</p><p>因此我们得出结论：前导模糊匹配不能命中索引</p></li><li><p>负向查询 !=  not in &lt;&gt; 能不能用到索引？</p><p>能不能用到索引是优化器决定的，优化器基于开销判断，一般不推荐使用负向查询</p></li><li><p>为什么推荐递增字段做主键索引？</p><p>InnoDB的索引底层是B+树，且通过主键索引来组织数据存储。如果使用自增主键，那么每次插入新的记录，就会顺序添加到当前索引节点的后续位置（右边），当写满一页就会开辟新页，这样就会形成一个近似顺序填满的紧凑结构，插入过程无需移动已有数据。</p><p>而如果使用uuid或者身份证号这种不规则的数据作为主键索引，那么插入数据时，相当于随机插入，导致已有数据频繁移动，磁盘io开销变大，且可能产生大量的叶碎片</p></li></ol><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>使用索引应注意以下几点：</p><ul><li>负向查询不能命中索引</li><li>前导模糊查询不能命中索引</li><li>数据区分度不大不宜建立索引</li><li>在属性上进行计算不能命中索引</li></ul><p>并非周知的sql实践：</p><ul><li>业务存在大量单条查询，实用hash索引效率高</li><li>允许为null的字段有大坑，单列索引不存null值，复合索引不存全为null的值，设置为not null 或者设置默认值</li><li>固定范围取值的字段使用枚举类型而不是字符串</li></ul><p>小众实用的规则：</p><ul><li>明确返回结果数量，实用limit能提升查询效率</li><li>把计算放到业务层而不是数据库层</li><li>强制类型转换会扫描全表</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;数据库索引是数据库管理系统中一个排序的&lt;strong&gt;数据结构&lt;/strong&gt;，以协助快速查询更新数据库表中数据&lt;/p&gt;
&lt;p&gt;索引类型：normal普通索引、unique唯一索引、全文索引&lt;/p&gt;
&lt;h4 id=&quot;索引用什么数据结构？&quot;&gt;&lt;a href=&quot;#索引用什么数
      
    
    </summary>
    
    
      <category term="数据库" scheme="http://yoursite.com/child/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>JVM-元空间</title>
    <link href="http://yoursite.com/child/2019/11/06/jvm-%E5%85%83%E7%A9%BA%E9%97%B4/"/>
    <id>http://yoursite.com/child/2019/11/06/jvm-元空间/</id>
    <published>2019-11-05T16:00:00.000Z</published>
    <updated>2020-03-13T07:29:29.824Z</updated>
    
    <content type="html"><![CDATA[<p>基础概念：</p><ol><li><p><strong>方法区：</strong>jvm规范中的定义，指一片内存区域，用于存放加载到内存中的类信息、常量池等。</p></li><li><p><strong>永久代：</strong>JDK1.7（含）之前方法区的实现方式，使用永久代实现主要是为了把GC分代收集扩展至方法区，省去了专门为方法区编写内存管理代码的工作。</p></li><li><p><strong>元空间：</strong>JDK1.8（含）之后的方法区实现。</p></li><li><p><strong>instanceKlass ：</strong>java类的运行时结构数据，就是常说的类元数据，jvm底层C++实现，java应用程序不能直接访问该对象，而是通过java.lang.Class类的实例间接访问该部分信息。xx.class对象是java程序访问xx类instanceKlass 数据的接口，且xx.class对象其实是存在堆里的。</p></li><li><p><strong>指针压缩</strong></p><ul><li>64位平台上默认打开</li><li>设置-XX:+UseCompressedOops压缩对象指针， <strong>oops</strong>指的是普通对象指针(ordinary object pointers)， 会被压缩成32位。</li><li>设置-XX:+UseCompressedClassPointers压缩类指针，会被压缩成32位。</li></ul></li><li><p><strong>类指针压缩空间</strong>（Compressed Class Pointer Space）：对于64位平台，为了压缩JVM对象中的_klass指针的大小，引入了类指针压缩空间。</p><ul><li>只有是64位平台上启用了类指针压缩才会存在这个区域。</li><li>类指针压缩空间会有一个基地址</li></ul></li></ol><h3 id="1-永久代被取代"><a href="#1-永久代被取代" class="headerlink" title="1. 永久代被取代"></a>1. 永久代被取代</h3><p>Permanent Generation space是指内存的永久保存区域，用于存放Class和Meta的信息，类在被加载的时候被放入PermGen space区域，它和存放对象的堆区域不同，所以应用程序会加载很多类的话，就很可能出现永久代溢出错误，这种错误常见在web服务器对jsp进行预编译的时候。</p><h4 id="1-1-为什么移除持久代"><a href="#1-1-为什么移除持久代" class="headerlink" title="1.1 为什么移除持久代"></a>1.1 为什么移除持久代</h4><ul><li>永久代空间大小是在启动时固定好的——运行时很难进行调优。-XX:MaxPermSize，设置成多少好呢？</li><li>HotSpot的内部类型也是Java对象：它可能会在Full GC中被移动，同时它对应用不透明，且是非强类型的，难以跟踪调试，还需要存储元数据的元数据信息（meta-metadata）。</li><li>简化Full GC：每一个回收器有专门的元数据迭代器。</li><li>可以在GC不进行暂停的情况下并发地释放类数据。</li><li>使得原来受限于持久代的一些改进未来有可能实现</li></ul><p>根据上面的各种原因，永久代最终被移除，<strong>方法区移至Metaspace，字符串常量移至Java Heap</strong>。</p><h4 id="1-2-移除持久代后，PermGen空间的状况"><a href="#1-2-移除持久代后，PermGen空间的状况" class="headerlink" title="1.2 移除持久代后，PermGen空间的状况"></a>1.2 移除持久代后，PermGen空间的状况</h4><ul><li>这部分内存空间将全部移除。</li><li>JVM的参数：-XX:PermSize 和-XX:MaxPermSize 会被忽略并给出警告（如果在启用时设置了这两个参数）。</li></ul><h3 id="2-元空间"><a href="#2-元空间" class="headerlink" title="2. 元空间"></a>2. 元空间</h3><p>随着JDK1.8的到来，JVM不再有PermGen。但类的元数据信息还在，只不过不再是存储在连续的堆空间上，而是移动到叫做“Metaspace”的本地内存（Native memory）中。</p><h4 id="2-1-Metaspace的组成"><a href="#2-1-Metaspace的组成" class="headerlink" title="2.1 Metaspace的组成"></a>2.1 Metaspace的组成</h4><ul><li><p><strong>Klass Metaspace</strong> </p><ul><li><p>这块内存最多只会存在一块，用来存 instanceKlass</p></li><li><p>这部分默认放在<strong>类指针压缩空间</strong>中，是一块连续的内存区域，和之前的perm一样紧接着Heap。通过<strong>-XX:CompressedClassSpaceSize</strong>来控制这块内存的大小，默认是1 G。</p></li></ul></li></ul><ul><li>但是这块内存不是必须的，如果设置了<strong>-XX:-UseCompressedClassPointers</strong>，或者<strong>-Xmx设置大于32 G</strong>，就不会有这块内存，这种情况下instanceKlass都会存在NoKlass Metaspace里。</li></ul><ul><li><p><strong>NoKlass Metaspace</strong>:</p><ul><li><p>用来存instanceKlass相关的其他的内容，比如method，constantPool等，这块内存是由多块内存组合起来的，所以可以认为是不连续的内存块组成的。</p></li><li><p>这块内存是必须的，虽然叫做NoKlass Metaspace，但是也其实可以存instanceKlass的内容，上面已经提到了对应场景。</p></li><li>NoKlass Metaspace在本地内存中分配。</li></ul></li></ul><p>Klass Metaspace和NoKlass Metaspace 都是所有class-loader共享的，所以类加载器们要分配内存，但是每个类加载器都有一个SpaceManager，来管理属于这个类加载的内存小块。如果Klass Metaspace用完了，那就会报OOM异常，不过一般情况下不会，NoKlass Metaspace是由一块块内存慢慢组合起来的，在没有达到限制条件的情况下，会不断加长这条链，让它可以持续工作。</p><h4 id="2-2-Metaspace的几个参数"><a href="#2-2-Metaspace的几个参数" class="headerlink" title="2.2 Metaspace的几个参数"></a>2.2 Metaspace的几个参数</h4><p>如果我们要改变Metaspace的一些行为，我们一般会对其相关的一些参数做调整，因为Metaspace的参数本身不是很多，所以我这里将涉及到的所有参数都做一个介绍。</p><ul><li><p>MetaspaceSize ：初始空间大小，达到该值就会触发垃圾收集进行类型卸载，同时GC会对该值进行调整：如果释放了大量的空间，就适当降低该值；如果释放了很少的空间，那么在不超过MaxMetaspaceSize时，适当提高该值。 </p></li><li><p>MaxMetaspaceSize ：最大空间，默认是没有限制的。 </p></li><li><p>MinMetaspaceFreeRatio ：在GC之后，最小的Metaspace剩余空间容量的百分比，减少为分配空间所导致的垃圾收集 </p></li><li><p>MaxMetaspaceFreeRatio ：在GC之后，最大的Metaspace剩余空间容量的百分比，减少为释放空间所导致的垃圾收集</p></li><li><p>CompressedClassSpaceSize ：默认1 G，这个参数主要是设置Klass Metaspace的大小，不过这个参数设置了也不一定起作用，前提是能开启压缩指针，假如-Xmx超过了32 G，压缩指针是开启不来的。如果有Klass Metaspace，那这块内存是和Heap连着的。</p></li><li><p>MinMetaspaceExpansion ：MinMetaspaceExpansion和MaxMetaspaceExpansion这两个参数或许和大家认识的并不一样，也许很多人会认为这两个参数不就是内存不够的时候，然后扩容的最小大小吗？其实不然</p><p>这两个参数和扩容其实并没有直接的关系，也就是并不是为了增大committed的内存，而是为了增大触发metaspace GC的阈值</p><p>这两个参数主要是在比较特殊的场景下救急使用，比如gcLocker或者<code>should_concurrent_collect</code>的一些场景，因为这些场景下接下来会做一次GC，相信在接下来的GC中可能会释放一些metaspace的内存，于是先临时扩大下metaspace触发GC的阈值，而有些内存分配失败其实正好是因为这个阈值触顶导致的，于是可以通过增大阈值暂时绕过去</p><p>默认332.8K，增大触发metaspace GC阈值的最小要求。假如我们要救急分配的内存很小，没有达到MinMetaspaceExpansion，但是我们会将这次触发metaspace GC的阈值提升MinMetaspaceExpansion，之所以要大于这次要分配的内存大小主要是为了防止别的线程也有类似的请求而频繁触发相关的操作，不过如果要分配的内存超过了MaxMetaspaceExpansion，那MinMetaspaceExpansion将会是要分配的内存大小基础上的一个增量</p></li><li><p>MaxMetaspaceExpansion ：默认5.2M，增大触发metaspace GC阈值的最大要求。假如说我们要分配的内存超过了MinMetaspaceExpansion但是低于MaxMetaspaceExpansion，那增量是MaxMetaspaceExpansion，如果超过了MaxMetaspaceExpansion，那增量是MinMetaspaceExpansion加上要分配的内存大小</p><p>注：每次分配只会给对应的线程一次扩展触发metaspace GC阈值的机会，如果扩展了，但是还不能分配，那就只能等着做GC了</p></li><li><p>UseLargePagesInMetaspace ：默认false，这个参数是说是否在metaspace里使用LargePage，一般情况下我们使用4 KB的page size，这个参数依赖于UseLargePages这个参数开启，不过这个参数我们一般不开。</p></li><li><p>InitialBootClassLoaderMetaspaceSize ：64位下默认4M，32位下默认2200K，metasapce前面已经提到主要分了两大块，Klass Metaspace以及NoKlass Metaspace，而NoKlass Metaspace是由一块块内存组合起来的，这个参数决定了NoKlass Metaspace的第一个内存Block的大小，即2*InitialBootClassLoaderMetaspaceSize，同时为bootstrapClassLoader的第一块内存chunk分配了InitialBootClassLoaderMetaspaceSize的大小</p></li></ul><h4 id="2-3-Metaspace内存管理"><a href="#2-3-Metaspace内存管理" class="headerlink" title="2.3  Metaspace内存管理"></a>2.3  Metaspace内存管理</h4><ol><li>在metaspace中，类和其元数据的生命周期与其对应的类加载器相同，只要类的类加载器是存活的，在Metaspace中的类元数据也是存活的，不能被回收。</li><li>每个加载器有单独的存储空间。</li><li>省掉了GC扫描及压缩的时间。</li><li>当GC发现某个类加载器不再存活了，会把对应的空间整个回收。</li></ol><p>参考文档：</p><p><a href="https://www.cnblogs.com/duanxz/p/3520829.html" target="_blank" rel="noopener">Metaspace 之一：Metaspace整体介绍（永久代被替换原因、元空间特点、元空间内存查看分析方法</a></p><p><a href="https://www.jianshu.com/p/92a5fbb33764" target="_blank" rel="noopener">JVM源码分析之Metaspace解密</a></p><p><a href="https://www.jianshu.com/p/1a0b4bf8d498" target="_blank" rel="noopener">JDK8 的FullGC 之 metaspace</a></p><p><a href="https://www.jianshu.com/p/a6f19189ec62" target="_blank" rel="noopener">JVM学习——元空间（Metaspace）</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;基础概念：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;方法区：&lt;/strong&gt;jvm规范中的定义，指一片内存区域，用于存放加载到内存中的类信息、常量池等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;永久代：&lt;/strong&gt;JDK1.7（含）之前方法区的实现
      
    
    </summary>
    
    
      <category term="JVM" scheme="http://yoursite.com/child/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>git规范的commit message（转）</title>
    <link href="http://yoursite.com/child/2019/10/23/%E5%85%B6%E4%BB%96-git%E8%A7%84%E8%8C%83%E7%9A%84Commit%20Message/"/>
    <id>http://yoursite.com/child/2019/10/23/其他-git规范的Commit Message/</id>
    <published>2019-10-22T16:00:00.000Z</published>
    <updated>2020-05-07T08:52:39.249Z</updated>
    
    <content type="html"><![CDATA[<p>git上每次提交，Commit message 都包括三个部分：Header，Body 和 Footer。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">type</span>&gt;</span>(<span class="tag">&lt;<span class="name">scope</span>&gt;</span>): <span class="tag">&lt;<span class="name">subject</span>&gt;</span></span><br><span class="line">// 空一行</span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">// 空一行</span><br><span class="line"><span class="tag">&lt;<span class="name">footer</span>&gt;</span></span><br></pre></td></tr></table></figure><p>其中，Header 是必需的，Body 和 Footer 可以省略。</p><p>不管是哪一个部分，任何一行都不得超过72个字符（或100个字符）。这是为了避免自动换行影响美观。</p><h3 id="Header-必需"><a href="#Header-必需" class="headerlink" title="Header(必需)"></a>Header(必需)</h3><ul><li><p><strong>type(必需)</strong> 用于说明 commit 的类别</p><blockquote><ul><li>feat：新功能（feature）</li><li>fix：修补bug</li><li>docs：文档（documentation）</li><li>style： 格式（不影响代码运行的变动）</li><li>refactor：重构（即不是新增功能，也不是修改bug的代码变动）</li><li>test：增加测试</li><li>chore：构建过程或辅助工具的变动</li><li>revert：用于以前的 commit，则必须以<code>revert:</code>开头，后面跟着被撤销 Commit 的 Header。</li></ul></blockquote></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">revert: feat(pencil): add &apos;graphiteWidth&apos; option</span><br><span class="line"></span><br><span class="line">This reverts commit 667ecc1654a317a13331b17617d973392f415f02.</span><br></pre></td></tr></table></figure><p>Body部分的格式是固定的，必须写成<code>This reverts commit &amp;lt;hash&gt;.</code>，其中的<code>hash</code>是被撤销 commit 的 SHA 标识符。</p><p>如果当前 commit 与被撤销的 commit，在同一个发布（release）里面，那么它们都不会出现在 Change log 里面。如果两者在不同的发布，那么当前 commit，会出现在 Change log 的<code>Reverts</code>小标题下面。</p><p>如果<strong>type</strong>为<code>feat</code>和<code>fix</code>，则该 commit 将肯定出现在 Change log 之中。其他情况（<code>docs</code>、<code>chore</code>、<code>style</code>、<code>refactor</code>、<code>test</code>）由你决定，要不要放入 Change log，建议是不要。</p><p><strong>scope</strong> 用于说明 commit 影响的范围，比如数据层、控制层、视图层等等，视项目不同而不同。</p><p><strong>subject(必需)</strong> 是 commit 目的的简短描述，不超过50个字符。</p><blockquote><ul><li>以动词开头，使用第一人称现在时，比如<code>change</code>，而不是<code>changed</code>或<code>changes</code></li><li>第一个字母小写</li><li>结尾不加句号（<code>.</code>）</li></ul></blockquote><h3 id="Body"><a href="#Body" class="headerlink" title="Body"></a>Body</h3><p>Body 部分是对本次 commit 的详细描述，可以分成多行。</p><p>有两个注意点:</p><ul><li>使用第一人称现在时，比如使用<code>change</code>而不是<code>changed</code>或<code>changes</code>。</li><li>应该说明代码变动的动机，以及与以前行为的对比。</li></ul><h3 id="Footer"><a href="#Footer" class="headerlink" title="Footer"></a>Footer</h3><p>Footer 部分只用于两种情况。</p><ul><li><p><strong>不兼容变动</strong></p><p>如果当前代码与上一个版本不兼容，则 Footer 部分以<code>BREAKING CHANGE</code>开头，后面是对变动的描述、以及变动理由和迁移方法。</p></li><li><p><strong>关闭 Issue</strong></p><p>如果当前 commit 针对某个issue，那么可以在 Footer 部分关闭这个 issue 。</p><blockquote><p>Closes #234</p></blockquote><p>也可以一次关闭多个 issue 。</p><blockquote><p>Closes #123, #245, #992</p></blockquote></li></ul><p><a href="https://links.jianshu.com/go?to=http%3A%2F%2Fwww.ruanyifeng.com%2Fblog%2F2016%2F01%2Fcommit_message_change_log.html" target="_blank" rel="noopener">原文链接</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;git上每次提交，Commit message 都包括三个部分：Header，Body 和 Footer。&lt;/p&gt;
&lt;figure class=&quot;highlight xml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;l
      
    
    </summary>
    
    
      <category term="其他" scheme="http://yoursite.com/child/tags/%E5%85%B6%E4%BB%96/"/>
    
  </entry>
  
  <entry>
    <title>redis-缓存数据库双写一致性方案解析</title>
    <link href="http://yoursite.com/child/2019/09/02/redis-%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7/"/>
    <id>http://yoursite.com/child/2019/09/02/redis-缓存数据库双写一致性/</id>
    <published>2019-09-01T16:00:00.000Z</published>
    <updated>2019-09-04T07:03:07.000Z</updated>
    
    <content type="html"><![CDATA[<p>从理论上来说，设置过期时间是保证缓存数据库最终一致性的解决方案。在这种方案下，我们可以对存入缓存的数据设置过期时间，所有写操作以数据库为准，对缓存操作知识尽最大努力即可。也就是说如果数据库写成功，缓存更新失败，那么只要到达过期时间，后面的请求自然会从数据库中读取新值然后填回缓存。因此，接下来讨论的思路不依赖于给缓存设置过期时间这个方案。</p><p>本文讨论三种更新策略：</p><ul><li>先更新数据库，再更新缓存</li><li>先删除缓存，再更新数据库</li><li>先更新数据库，再删除缓存</li></ul><p>没有先更新缓存再更新数据库的方案，因为所有的写操作要以数据库为准，这种情况下若更新数据库失败，缓存失效后再次读数据库将取得旧值。</p><h3 id="1、先更新数据库，再更新缓存"><a href="#1、先更新数据库，再更新缓存" class="headerlink" title="1、先更新数据库，再更新缓存"></a>1、先更新数据库，再更新缓存</h3><p>该方案从<strong>线程安全角度</strong>看</p><p>假设同时有请求A和请求B进行更新操作，如下图所示的情况下最终数据库中的数据是B请求的数据，缓存中的数据数A请求的数据，最终出现了不一致的情况。这种情况因为网络情况等原因是可能出现的</p><p><img src="https://wx2.sinaimg.cn/large/87c9e458ly1g6nhtih33dj20fj05aq2v.jpg" alt="更更"></p><p>该方案从<strong>业务场景角度</strong>看</p><ol><li>如果是一个写多读少的场景，使用这种方案会导致数据压根没读到，缓存就被频繁的更新，浪费性能</li><li>如果写入db的值需要经过一系列复杂的计算再写入缓存，那么每次写入缓存前都需要计算缓存值，无疑是在浪费性能</li></ol><p>所以，更新缓存不可取，删除缓存更合适。</p><h3 id="2、先删除缓存，再更新数据库"><a href="#2、先删除缓存，再更新数据库" class="headerlink" title="2、先删除缓存，再更新数据库"></a>2、先删除缓存，再更新数据库</h3><p>首先看该方案会导致不一致的情况：</p><p><img src="https://ws1.sinaimg.cn/large/87c9e458ly1g6nhu1u8qjj20fs0663yi.jpg" alt="删更"></p><p>这种情况就会导致不一致的情形出现，而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。</p><p>那么，<strong>如何解决呢？</strong></p><p><strong>延时双删策略</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(String key,Object data)</span></span>&#123;</span><br><span class="line">        redis.delKey(key);</span><br><span class="line">        db.updateData(data);</span><br><span class="line">        Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">        redis.delKey(key);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>说明：<br>（1）先淘汰缓存<br>（2）再写数据库<br>（3）休眠1秒，再次淘汰缓存<br>这么做，可以将1秒内所造成的缓存脏数据，再次删除。<br><strong>那么，这个1秒怎么确定的，具体该休眠多久呢？</strong><br>针对上面的情形，读者应该自行评估自己的项目的读数据业务逻辑的耗时。然后写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百ms即可。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。</p><h3 id="3、先更新数据库，再删除缓存"><a href="#3、先更新数据库，再删除缓存" class="headerlink" title="3、先更新数据库，再删除缓存"></a>3、先更新数据库，再删除缓存</h3><p>首先，先说一下。老外提出了一个缓存更新套路，名为<a href="https://docs.microsoft.com/en-us/azure/architecture/patterns/cache-aside" target="_blank" rel="noopener">《Cache-Aside pattern》</a>。其中就指出</p><ul><li><strong>失效</strong>：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。</li><li><strong>命中</strong>：应用程序从cache中取数据，取到后返回。</li><li><strong>更新</strong>：先把数据存到数据库中，成功后，再让缓存失效。</li></ul><p>另外，知名社交网站facebook也在论文<a href="https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf" target="_blank" rel="noopener">《Scaling Memcache at Facebook》</a>中提出，他们用的也是先更新数据库，再删缓存的策略。</p><p><strong>这种情况不存在并发问题么？</strong><br>不是的。假设这会有两个请求，一个请求A做更新操作，一个请求B做查询操作，那么会有如下情形产生<br><img src="https://wx1.sinaimg.cn/large/87c9e458ly1g6nhuewolbj20fs066dfv.jpg" alt="更删"><br>如果发生上述情况，确实是会发生脏数据。</p><p><strong>然而，发生这种情况的必要条件是</strong><br>1、B读db时A还没有完成写db，这样B才能读到旧数据</p><p>2、A写db比B读db先完成，这样A才会在B更新缓存之前删缓存</p><p>因此只有在B请求读db成功但还没有更新缓存之前，A请求更新db结束并执行了删缓存操作，才有可能发生以上的情况，这个方案较第二种方案产生不一致的概率低很多。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;从理论上来说，设置过期时间是保证缓存数据库最终一致性的解决方案。在这种方案下，我们可以对存入缓存的数据设置过期时间，所有写操作以数据库为准，对缓存操作知识尽最大努力即可。也就是说如果数据库写成功，缓存更新失败，那么只要到达过期时间，后面的请求自然会从数据库中读取新值然后填回
      
    
    </summary>
    
    
      <category term="redis" scheme="http://yoursite.com/child/tags/redis/"/>
    
  </entry>
  
</feed>
